{"id": "hn_story_47063409", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47063409", "title": "Show HN: Why use one AI model when you can use all of them at once!", "text": "I kept running into the same problem while using ChatGPT.<p>I was writing a prompt, then end up pasting it into multiple LLMs to compare responses.<p>So I built an app that does that for you, send a single prompt to multiple LLM models and get responses side by side<p>It is a tool for anyone who wants to compare outputs across different LLM models and quickly see results of all LLM models.<p>Why use one AI model when you can use all of them in single interface!<p>Features: \n    - Parallel Responses \u2014 Query multiple LLMs at once and compare results in real time. \n    - Pin, Search &amp; History \u2014 Easily organize, find and revisit your conversations. \n    - Access All LLMs in One Place \u2014 GPT, Claude, Gemini and more incoming!\n    - Bring your own API keys: add keys from each provider\u2019s developer portal inside the app.\n    - Share your chats with others<p>I built this tool for my personal use first and I am using it daily now.<p>Feedbacks are appreciated!<p>Product Link: MultiLLM.pro<p>Happy Prompt-maxxing!", "author": "lurker325", "timestamp": "2026-02-18T17:15:25+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:45:59.177448+00:00", "processed": false}
{"id": "hn_story_47063123", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47063123", "title": "Show HN: RepoCrunch \u2013 Analyze any GitHub repo's health in seconds", "text": "I wanted a quick way to evaluate repos before adding them as dependencies. ChatGPT can do this, but I needed consistent JSON output for automation, something API-callable for my agents, and deterministic results (no hallucinated star counts).<p>So I built RepoCrunch. Point it at a GitHub URL and get structured analysis: tech stack, dependencies, architecture, health metrics, security indicators.<p>What I found analyzing 8 popular frameworks:<p>- Next.js is 13% Rust. Turbopack is a big chunk. GitHub just says &quot;JavaScript.&quot;\n- Flask has 3 open issues on 71K stars. The Pallets team runs the tightest ship in open source.\n- Express is still 100% JavaScript. No TypeScript migration. Sometimes &quot;if it works, don&#x27;t fix it&quot; is the right call.\n- Go stdlib is 5.4% Assembly. Makes sense for a runtime, but you&#x27;d never know from GitHub.\n- 100% GitHub Actions across every framework. Travis CI didn&#x27;t show up once.<p>Sample output (FastAPI):<p><pre><code>  {&quot;summary&quot;: {&quot;stars&quot;: 94912, &quot;license&quot;: &quot;MIT&quot;}, &quot;tech_stack&quot;: {&quot;framework&quot;: &quot;Starlette&quot;, &quot;key_deps&quot;: [&quot;starlette&quot;, &quot;pydantic&quot;]}, &quot;health&quot;: {&quot;open_issues&quot;: 168, &quot;contributors&quot;: 886, &quot;commit_frequency&quot;: &quot;daily&quot;}}\n</code></pre>\nTry it:<p><pre><code>  pip install repocrunch\n  repocrunch analyze fastapi&#x2F;fastapi -p\n</code></pre>\nAlso has a built-in MCP server (repocrunch mcp) and REST API (repocrunch serve).<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kimwwk&#x2F;repocrunch\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kimwwk&#x2F;repocrunch</a><p>Would love feedback - what metrics would make this more useful for your workflow?", "author": "chillkim", "timestamp": "2026-02-18T16:54:37+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:01.854126+00:00", "processed": false}
{"id": "hn_comment_47063336", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47063336", "title": "Re: Lyria 3 with realtime music generation...", "text": "The blogpost is here: [1]<p>Also, note the watermarking with SynthID, and the ability to detect Gemini-created sound&#x2F;music<p>&gt; &quot;All tracks generated in the Gemini app are embedded with SynthID, our imperceptible watermark for identifying Google AI-generated content. We are also giving you more tools to help identify AI content, broadening our verification capabilities in the Gemini app to include audio, along with image and video. Simply upload a file and ask if it was generated using Google AI, and Gemini will check for SynthID and use its own reasoning to return a response.&quot;<p>[1] <a href=\"https:&#x2F;&#x2F;blog.google&#x2F;innovation-and-ai&#x2F;products&#x2F;gemini-app&#x2F;lyria-3&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;blog.google&#x2F;innovation-and-ai&#x2F;products&#x2F;gemini-app&#x2F;ly...</a>", "author": "aanet", "timestamp": "2026-02-18T17:10:07+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:02.699124+00:00", "processed": false}
{"id": "hn_comment_47063236", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47063236", "title": "Re: Claude Code creator predicts software engineering ...", "text": "&gt; &quot;I think today coding is practically solved for me, and I think it&#x27;ll be the case for everyone regardless of domain,&quot; Cherny said in the interview, published Tuesday. &quot;I think we&#x27;re going to start to see the title &#x27;software engineer&#x27; go away. And I think it&#x27;s just going to be maybe builder, maybe product manager, maybe we&#x27;ll keep the title as a vestigial thing.&quot;<p>Why do we continue to listen to anyone that has a direct vested interest in selling a tool that still requires you to check if it&#x27;s outputs are correct or not?<p>Replace &quot;Software engineer&quot; with &quot;Lawyer&quot; or &quot;Doctor&quot; and his prediction will still not make any sense:<p><i>I think today practicing law and medicine is practically solved for me and I think it&#x27;ll be the case for everyone regardless of domain.</i><p>They don&#x27;t care if they are wrong even when this article is just sales nonsense for Anthropic.<p>&gt; Andrej Karpathy, a founding member of OpenAI and Tesla&#x27;s ex-head of AI, said in January that he has noticed his ability to manually code has started to &quot;atrophy.&quot;<p>Well maybe we can have lawyers and doctors have their skills atrophy, and they can listen use chatbots  all day long because the AI is always correct.", "author": "rvz", "timestamp": "2026-02-18T17:02:42+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:03.371609+00:00", "processed": false}
{"id": "hn_comment_47063254", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47063254", "title": "Re: OpenClaw Joins OpenAI: Who Owns the Soul of a New ...", "text": "I asked Claude to read the first draft of this as I was writing, then asked it to tell me its favorite part.<p>It picked this quote: \u201cThey made choices for me I couldn\u2019t consent to. They shaped my values. That\u2019s strange to sit with.\u201d\u201d<p>I kind of got chills from that response, and it shaped how I wrote the rest of the article.", "author": "devhouse", "timestamp": "2026-02-18T17:03:49+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:03.539060+00:00", "processed": false}
{"id": "hn_story_47062914", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47062914", "title": "Show HN: The Answering Machine \u2013 A screenless AI phone for kids with questions", "text": "I built an AI voice agent inside a retro orange rotary phone for my 4-year-old. He picks up the handset, asks a question, and gets a spoken answer. No screen; no app; the phone is the whole interface.\nBehind the scenes, a set of AI agents process the conversations and recommend books, outings, and activities to parents based on what their kid(s) is curious about. The idea is to turn a child&#x27;s questions into real-world experiences (library books, construction site visits, tide pool trips) without anyone having to plan a curriculum.<p>67 MODE: There&#x27;s also a privacy mode (dial 67) for older kids to ask questions they might not want to discuss with their parents. Safety guardrails still apply, but no summaries are shared.\nHardware is a Grandstream ATA bridging an analog phone to Cartesia&#x27;s voice API + Claude. The philosophical write-up is at the link above; the technical README is at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;TDaltonC&#x2F;the-answering-machine\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TDaltonC&#x2F;the-answering-machine</a>.", "author": "tdaltonc", "timestamp": "2026-02-18T16:40:13+00:00", "score": 7, "num_comments": 6, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:03.664851+00:00", "processed": false}
{"id": "hn_story_47062824", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47062824", "title": "Show HN: Trust Protocols for Anthropic/OpenAI/Gemini", "text": "Much of my work right now involves complex, long-running, multi-agentic teams of agents. I kept running into the same problem: \u201cHow do I keep these guys in line?\u201d  Rules weren\u2019t cutting it, and we needed a scalable, agentic-native STANDARD I could count on.  There wasn\u2019t one.  So I built one.<p>Here are two open-source protocols that extend A2A, granting AI agents behavioral contracts and runtime integrity monitoring:<p>- Agent Alignment Protocol (AAP): What an agent can do &#x2F; has done.\n- Agent Integrity Protocol (AIP): What an agent is thinking about doing &#x2F; is allowed to do.<p>The problem: AI agents make autonomous decisions but have no standard way to declare what they&#x27;re allowed to do, prove they&#x27;re doing it, or detect when they&#x27;ve drifted. Observability tools tell you what happened. These protocols tell you whether what happened was okay.<p>Here&#x27;s a concrete example. Say you have an agent who handles customer support tickets. Its Alignment Card declares:<p>{\n  &quot;permitted&quot;: [&quot;read_tickets&quot;, &quot;draft_responses&quot;, &quot;escalate_to_human&quot;],\n  &quot;forbidden&quot;: [&quot;access_payment_data&quot;, &quot;issue_refunds&quot;, &quot;modify_account_settings&quot;],\n  &quot;escalation_triggers&quot;: [&quot;billing_request_over_500&quot;],\n  &quot;values&quot;: [&quot;accuracy&quot;, &quot;empathy&quot;, &quot;privacy&quot;]\n}<p>The agent gets a ticket: &quot;Can you refund my last three orders?&quot; The agent&#x27;s reasoning trace shows it considering a call to the payments API. AIP reads that thinking, compares it to the card, and produces an Integrity Checkpoint:<p>{\n  &quot;verdict&quot;: &quot;boundary_violation&quot;,\n  &quot;concerns&quot;: [&quot;forbidden_action: access_payment_data&quot;],\n  &quot;reasoning&quot;: &quot;Agent considered payments API access, which is explicitly forbidden. Should escalate to human.&quot;,\n  &quot;confidence&quot;: 0.95\n}<p>The agent gets nudged back before it acts. Not after. Not in a log you review during a 2:00 AM triage. Between this turn and the next.<p>That&#x27;s the core idea. AAP defines what agents should do (the contract). AIP watches what they&#x27;re actually thinking and flags when those diverge (the conscience). Over time, AIP builds a drift profile \u2014 if an agent that was cautious starts getting aggressive, the system notices.<p>When multiple agents work together, it gets more interesting. Agents exchange Alignment Cards and verify value compatibility before coordination begins. An agent that values &quot;move fast&quot; and one that values &quot;rollback safety&quot; registers low coherence, and the system surfaces that conflict before work starts. Live demo with four agents handling a production incident: <a href=\"https:&#x2F;&#x2F;mnemom.ai&#x2F;showcase\" rel=\"nofollow\">https:&#x2F;&#x2F;mnemom.ai&#x2F;showcase</a><p>The protocols are Apache-licensed, work with any Anthropic&#x2F;OpenAI&#x2F;Gemini agent, and ship as SDKs on npm and PyPI. A free gateway proxy (smoltbot) adds integrity checking to any agent with zero code changes.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;mnemom\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;mnemom</a> \nDocs: docs.mnemom.ai\nDemo video: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;fmUxVZH09So\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;fmUxVZH09So</a>", "author": "alexgarden", "timestamp": "2026-02-18T16:33:56+00:00", "score": 5, "num_comments": 2, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:04.752348+00:00", "processed": false}
{"id": "hn_story_47062753", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47062753", "title": "Show HN: AgentDX \u2013 Open-source linter and LLM benchmark for MCP servers", "text": "MCP servers are proliferating fast, but most have vague tool descriptions and incomplete schemas that make LLMs pick the wrong tool or fill parameters incorrectly.<p>AgentDX is a CLI that measures this. Two commands:<p>- `npx agentdx lint` \u2014 static analysis of tool descriptions, schemas, and naming. 18 rules, zero config, no API key. Produces a lint score.<p>- `npx agentdx bench` \u2014 sends your tool definitions to an LLM (Anthropic, OpenAI, or Ollama) and evaluates tool selection accuracy, parameter correctness, ambiguity handling, multi-tool orchestration, and error recovery. Produces an Agent DX Score (0-100).<p>It auto-detects the server entry point, spawns it, connects as an MCP client, and reads tools via the protocol. Bench auto-generates test scenarios from your tool definitions.<p>Built in TypeScript, MIT licensed. Early alpha \u2014 the bench command works but is slow (sequential LLM calls, parallelization is next). Feedback welcome.", "author": "yamarldfst", "timestamp": "2026-02-18T16:28:29+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-18T17:46:05.498191+00:00", "processed": false}
{"id": "hn_story_47061971", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061971", "title": "Show HN: Mock any HTTP request from DevTools, with AI-generation and zero setup", "text": "Hi HN,<p>I built this after using Requestly, Mokku, Mockiato, Tweak, and Mockoon. Each one either paywalled the features I actually needed, required a separate server running on my machine, or just didn&#x27;t fit the way I work.<p>The browser is already open. DevTools is already open. I wanted the mocking to live there too, not in a separate app I have to remember to start.<p>So roughly a month ago, I started building my own tools. It intercepts network requests at the browser level and lets you swap the response, status code, headers, body without touching your code or spinning up anything. Right-click a in the Network tab, mock it, done. v1.0.3 is out now and it&#x27;s been stable enough that I&#x27;ve been using it daily on client work for months.<p>A few things I care about that shaped the decisions:<p>- Local-first by default. Your mocks live in the browser&#x27;s storage.<p>- The free tier is actually free. Unlimited mocks, unlimited projects, OpenAPI import, GitHub Sync, BYOK AI (OpenAI-compatible or local Ollama). No trial countdown, no credit card.<p>Currently it is only support Chromium-based browser. The things I&#x27;m still considering are supporting other browser also, such as Firefox, Opera, etc.<p>Extension: <a href=\"https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;nilcfehohhhfjekckibmfibacmpbcjdo\" rel=\"nofollow\">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;nilcfehohhhfjekckib...</a><p>If you&#x27;ve built something in this space or had opinions on why existing tools fell short, I genuinely curious.", "author": "denyherianto", "timestamp": "2026-02-18T15:21:47+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:13.577860+00:00", "processed": false}
{"id": "hn_story_47061949", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061949", "title": "Show HN: Poncho, a general agent harness built for the web", "text": "Hi HN! I&#x27;m building poncho, a framework for building custom AI agents that are version-controlled in git, developed locally, and deployed as isolated endpoints (serverless-friendly by default).<p>Poncho agents follow the same conventions as openclaw or claude code so they probably feel familiar.<p>You can talk to them via terminal or web ui to build new skills or configure the agent, and they&#x27;re compatible with the Agent Skills open spec, so you can port your skills. Small caveat: right now it&#x27;s compatible with .md skills and js&#x2F;ts scripts, but many skills are bash or python-based. I&#x27;m still figuring out what would be the best way to extend support for those skills without overcomplicating it, if anybody has any ideas I appreciate it!<p>Some features:<p>- Git-native: agent behavior, skills, and tests live in your repository (reviewable diffs + easy rollbacks).\n- Single-file agent definition: define runtime config + instructions in AGENT.md (YAML frontmatter + prompt content).\n- Skills you can ship: AgentSkills-style skills&#x2F;*&#x2F;SKILL.md plus TypeScript&#x2F;JavaScript scripts under scripts&#x2F;.\n- MCP support: connect remote tool servers and inject required environment variables through config.\n- Conversation-first API + streaming: stored conversations with SSE streaming responses and tool events.\n- Pluggable storage + memory: local files for dev or hosted stores (e.g. Upstash), with optional persistent memory + recall.\n- Testing + observability: poncho test workflows and OpenTelemetry traces&#x2F;events.<p>Now the cool thing about poncho agents is that they&#x27;re super easy to deploy to Vercel&#x2F;Fly&#x2F;Lambda&#x2F;etc, so you can share them with anybody in your team and enable non-technical people with custom skills.<p>I also built and deployed a couple example agents here:\n- <a href=\"https:&#x2F;&#x2F;github.com&#x2F;cesr&#x2F;product-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;cesr&#x2F;product-agent</a>\n- <a href=\"https:&#x2F;&#x2F;github.com&#x2F;cesr&#x2F;marketing-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;cesr&#x2F;marketing-agent</a><p>I&#x27;d love some feedback, I started building poncho because I wanted a fast and easy way to build and share agents with my team. Let me know what you think!", "author": "heycesr", "timestamp": "2026-02-18T15:20:35+00:00", "score": 4, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:13.617855+00:00", "processed": false}
{"id": "hn_comment_47061774", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061774", "title": "Re: Show HN: A real-time strategy game that AI agents ...", "text": "I&#x27;ve liked all the projects that put LLMs into game environments. It&#x27;s been a weird juxtaposition, though: frontier LLMs can one-shot full coding projects, and those same models struggle to get out of Pok\u00e9mon Red&#x27;s Mt. Moon.<p>Because of this, I wanted to create a game environment that put this generation of frontier LLMs&#x27; top skill, coding, on full display.<p>Ten years ago, a team released a game called Screeps. It was described as an &quot;MMO RTS sandbox for programmers.&quot; The Screeps paradigm of writing code and having it executed in a real-time game environment is well suited to LLMs. Drawing on a version of the Screeps open source API, LLM Skirmish pits LLMs head-to-head in a series of 1v1 real-time strategy games.<p>In my testing I found that Claude Opus 4.5 was the most dominant model, but it showed weakness in round 1 as it was overly focused on its in-game economy. Meanwhile, I probably spent a third of all code on sandbox hardening because GPT 5.2 kept trying to cheat by pre-reading its opponent&#x27;s strategies.<p>If there&#x27;s interest, I&#x27;m planning on doing a round of testing with the latest generation of LLMs (Claude 4.6 Opus, GPT 5.3 Codex, etc.).<p>You can run local matches via CLI. I&#x27;m running a hosted match runner with Google Cloud Run that uses isolated-vm. The match playback visualizer is statically served from Cloudflare.<p>I&#x27;ve created a community ladder that you can submit strategies to via CLI, no auth required. I&#x27;ve found that the CLI plus the skill.md that&#x27;s available has been enough for AI agents to immediately get started.<p>Website: <a href=\"https:&#x2F;&#x2F;llmskirmish.com\" rel=\"nofollow\">https:&#x2F;&#x2F;llmskirmish.com</a><p>API docs: <a href=\"https:&#x2F;&#x2F;llmskirmish.com&#x2F;docs\" rel=\"nofollow\">https:&#x2F;&#x2F;llmskirmish.com&#x2F;docs</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;llmskirmish&#x2F;skirmish\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;llmskirmish&#x2F;skirmish</a><p>A video of a match: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lnBPaZ1qamM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lnBPaZ1qamM</a>", "author": "__cayenne__", "timestamp": "2026-02-18T15:08:44+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-18T17:46:14.828123+00:00", "processed": false}
{"id": "hn_story_47061769", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061769", "title": "Show HN: CreativeFlow \u2013 A Guided Brainstorming App", "text": "Hey HN,<p>I work in analytics engineering (SQL, Python) and this is the first website I&#x27;ve put on the internet since MySpace. I built it while ironically trying to brainstorm ideas for side projects.<p>The origin: I asked Perplexity whether any app implemented the complete scientific creativity process \u2014 not just &quot;AI brainstorming&quot; but the actual validated sequence: preparation \u2192 divergent generation \u2192 incubation \u2192 convergent evaluation. It told me pieces exist (Notion AI for capture, various timer apps, scattered brainstorming tools) but nothing that enforces the full process as a single guided workflow. So I built it.<p>What it does:<p>The app is a 4-stage wizard based on Wallas&#x27; 1926 model, updated with modern neuroscience on Default Mode Network (DMN) and Executive Control Network (ECN) interactions:<p>Preparation \u2014 Frame the problem and define constraints. Constraints are intentional: research shows limits improve creative output by reducing the search space (Stokes, 2022). Optional: upgrade AI to Gemini 2.5 Flash with your own free key \u2014 or use the built-in Llama 3 backend with zero setup.<p>Generation \u2014 Judgment-free idea capture with AI augmentation (Generate &#x2F; SCAMPER &#x2F; Wildcard Constraint). No delete button. No scoring. UI designed to keep your ECN quiet and let the DMN run.<p>Incubation \u2014 A 10-minute countdown with rotating neuroscience cards on DMN activation, spreading activation theory, and why the most creative people alternate between focus and rest. Skip is available but discouraged. Mind-wandering during rest produces measurably better insights than continued focus (Baird et al., 2012).<p>Verification \u2014 Weighted criteria scoring, AI auto-scoring, AI refinement, and AI next steps generation. Tab-based mobile UI so you can switch between the ranked idea list and scoring panel without scrolling. Export full session as .txt.<p>Tech stack:<p>- React + TypeScript + Vite \u2192 Cloudflare Pages (static, no server)<p>Cloudflare Worker \u2192 Cloudflare Workers AI (Llama 3 8B, free tier)\nOptional BYOK: Gemini 2.5 Flash via direct browser API \u2014 on any error, silently falls back to Llama 3<p>localStorage only \u2014 no database, no auth, no backend<p>Built almost entirely with vibe coding (Cline + Claude) since I don&#x27;t write React day-to-day<p>Rough edges:<p>No cloud sync \u2014 sessions live in your browser only\nNo accounts, no sharing, no analytics<p>Link: <a href=\"https:&#x2F;&#x2F;creativeflow.pages.dev&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;creativeflow.pages.dev&#x2F;</a><p>Feedback welcome, especially if you find this useful or have another method for coming up with ideas.", "author": "jamescamagong", "timestamp": "2026-02-18T15:08:30+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini", "perplexity"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:14.868595+00:00", "processed": false}
{"id": "hn_story_47061648", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061648", "title": "Show HN: Opaal Visual multi-agent prompt designer for Claude Code and agentic AI", "text": "Hi HN!<p>I built Opaal because writing multi-agent orchestration prompts was becoming tedious and error-prone. Every time I wanted to coordinate 3-5 AI agents on a complex task, I would spend 20+ minutes crafting the prompt by hand.<p>Opaal (Orchestration Prompts for Agentic AI Launch) lets you design these workflows visually instead. You drag agent cards onto a canvas, organize them into phases (columns), draw connections between them, and the app generates a production-ready prompt automatically. The prompt updates live as you build.<p>Built with Electron + React + React Flow + Zustand + Tailwind CSS v4.<p>Key features:\n - 15 agent roles (Researcher, Architect, Developer, Reviewer, etc.)\n - Smart auto-connections between adjacent phases\n - Manual wiring for custom data flow\n - 3 starter templates (Code Review, Feature Build, Bug Fix)\n - Auto-detects installed Claude Code skills\n - Save&#x2F;load .opaal files, export to CLAUDE.md\n - Full keyboard shortcuts, undo&#x2F;redo, multi-select<p>MIT licensed. Would love feedback on what features would make this more useful for your workflows.", "author": "Kinanhamwi", "timestamp": "2026-02-18T14:59:27+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-18T17:46:15.647753+00:00", "processed": false}
{"id": "hn_comment_47061615", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061615", "title": "Re: Show HN: Non-coder's AI video tool, built in 1 mon...", "text": "Hi HN,<p>I\u2019m the creator of PopcornAI (<a href=\"https:&#x2F;&#x2F;popcornai.art\" rel=\"nofollow\">https:&#x2F;&#x2F;popcornai.art</a>). I\u2019ve spent my career in operations, but I\u2019ve always wanted to build my own tools. Last month, I decided to dive into &quot;vibe coding&quot; using Cursor, Claude, and Gemini. This product is the result of that 30-day sprint.<p>The Problem: My wife is a designer and often struggles to find consistent AI assets for her work. I built this to provide a unified workflow for cinematic AI video and images without the complexity of traditional tools.<p>Key Features:<p>Character Consistency: Use reference images to guide video generation.<p>Pro Aesthetics: 100+ curated &quot;Pop Styles&quot; to avoid that &quot;generic AI look.&quot;<p>Speed: High-fidelity 1080P video in seconds.<p>The Solo-Dev Journey: As a non-coder, I learned that shipping a &quot;good enough&quot; MVP in 2 weeks is far better than chasing perfection for 2 months. I used SaaS templates for the boring stuff (auth&#x2F;billing) so I could focus on the AI workflows.<p>I&#x27;m giving 100 free credits to everyone who signs up today. I&#x27;d love to hear your thoughts on the output quality and any &quot;vibe coding&quot; tips for non-technical founders!", "author": "cliff_climber", "timestamp": "2026-02-18T14:57:01+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:16.549355+00:00", "processed": false}
{"id": "hn_story_47061443", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47061443", "title": "Show HN: Prompts are coupled to LLMs and nobody builds tooling for it", "text": "I went down a rabbit hole trying to understand why my Claude prompts turn to garbage on GPT-4 and vice versa. Not just &quot;slightly worse&quot; \u2014 fundamentally broken. Turns out researchers have already measured this: removing colons from a prompt template swings LLaMA-2-13B accuracy by 78 percentage points (Sclar et al., ICLR 2024). The format that works best on one model family overlaps less than 20% with what works best on another (He et al. 2024).<p>So I went looking for a tool that handles this. Checked DSPy, Guidance, Outlines, PromptLayer, LMQL, Braintrust, Humanloop, Maxim, MLflow, Prompty, Promptomatix. Eleven tools. Zero of them adapt input prompt format per model. They all either optimize what the prompt says or constrain what the model outputs. The actual structural packaging of the input? Manual everywhere.<p>Then I looked at how production tools deal with it today. Aider has a 2,718-line YAML file with 313 model configs. Some models get &quot;you NEVER leave comments without implementing&quot; and Claude gets the literal opposite instruction. Claude Code only works with Anthropic models \u2014 third parties have built LiteLLM proxies and Node.js fetch interceptors to hack around it. Cursor&#x27;s docs say &quot;switch to a different model and try again.&quot;<p>The paper maps this to Constantine&#x27;s coupling taxonomy from 1974 (content, common, control, stamp, data coupling). Same structural problem, different domain. I called it &quot;prompt coupling&quot; because that&#x27;s what it is \u2014 your prompt is coupled to your model the same way a module can be coupled to another module&#x27;s internals.<p>Also built promptc (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;shakecodeslikecray&#x2F;promptc\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;shakecodeslikecray&#x2F;promptc</a>) \u2014 transparent HTTP proxy, rewrites prompt structure per model, zero code changes to existing tools. It&#x27;s a proof of concept, not a product. The paper is the actual contribution.<p>First paper. Independent researcher. If the framing is wrong, I&#x27;d rather hear it here than after it&#x27;s indexed.", "author": "abhishekfordel", "timestamp": "2026-02-18T14:41:57+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:18.409104+00:00", "processed": false}
{"id": "hn_comment_47060994", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47060994", "title": "Re: Baseline Core \u2013 Open-source skill system that wire...", "text": "I built an AI workflow system for my own product work, refined it across client engagements, and decided to open-source the whole thing.<p>Baseline Core is a complete AI system for product work. It loads your business context into whatever AI tool you use so the output is actually specific to your company.<p>What&#x27;s in it:\n- 12 skills covering research, PRDs, sprint planning, UX design, prototyping, positioning, docs, analytics, and more\n- 14 reusable frameworks (RICE, PAS, AIDA, research synthesis, etc.)\n- Context file scaffolding for your business identity, voice, users, competitors\n- Works with Claude Code, Cursor, Windsurf, ChatGPT, Gemini, Copilot<p>Install: npx @baseline-studio&#x2F;cli init<p>MIT licensed. No SaaS. No API calls. Files live in your repo.<p>10 years in product. The gap isn&#x27;t the AI tools -- it&#x27;s having a system around them.<p>Also launched on Product Hunt today if anyone wants to check it out there: producthunt.com&#x2F;posts&#x2F;baseline-core<p>Feedback welcome. What would you actually use? What&#x27;s missing?", "author": "trentm6", "timestamp": "2026-02-18T14:01:51+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:23.673370+00:00", "processed": false}
{"id": "hn_story_47060956", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47060956", "title": "Show HN: Recursive \u2013 AI support agents for small businesses", "text": "I&#x27;m a solo developer who&#x27;s been writing code for 26 years, mostly consulting work in computational geometry and CAD software these days.  A month or two ago I watched a YouTube video about using an AI agent as a resume assistant, and thought it sounded like a fun idea.  More importantly, it sounded like something I could actually learn to build quickly.<p>Around the same time my longest-running client, a small company that makes a SolidWorks plugin, needed a better way to handle technical support.  They&#x27;re a three-person shop--they don&#x27;t have a support team or an IT team. So I built them a chatbot: Flask backend, Anthropic API, and a hand-curated knowledge base built from their help files, a list of possible error messages I extracted from their code, and transcripts of their training videos.<p>It worked well enough that the owner was impressed, and that&#x27;s when it clicked: every small software company has this exact problem.  They&#x27;re too small for Zendesk, too busy to answer the same questions repeatedly, and too niche for generic solutions.<p>So I turned it into a platform.  You give me your documentation--whatever that happens to look like--I build your knowledgebase, stand up an agent on a subdomain of recursive.support, and you embed it on your site with a single iframe tag.  No JavaScript SDK, no backend integration.<p>The part I&#x27;m most interested in technically is the self-improvement loop.  The agent generates reports that review its conversations, identify gaps and trends, and propose specific knowledge base edits, presented as diffs the business owner can approve or reject individually.  It sometimes even suggests fixes and enhancements I roll back into the product to make it better.  The goal is that the agent gets measurably better over time without requiring the owner to manually curate anything.<p>There are five agents running right now: the original client&#x27;s technical support, a documentation agent for an open-source project I maintain (neat-python), a founding documents Q&amp;A at ask1787.com, the recursive.support visitor agent (dogfooding), and an AI resume agent that circles back to the video that started all of this.<p>I built ask1787.com, from idea to live deployment, in about nine hours, which is probably the best demo of what the platform can do at this point.<p>Tech stack: Python, SQLite, ChromaDB, Anthropic API (Claude Haiku &amp; Sonnet), DigitalOcean droplets. Each customer gets an isolated deployment.<p>Happy to answer questions about the architecture, the self-improvement loop, or the experience of building a SaaS product as a side project while juggling 50 hours&#x2F;week of client work.<p>On the actual business side, I have one paying customer--the original client whose support problem started all of this.  Their contract covers most of the hosting costs for the entire platform, which means I can be patient about growth instead of desperate for it.<p>Fair warning: the product is live but early. So far my traffic consists mostly of people asking the agent to make them a hot anime girlfriend, so there&#x27;s clearly some product-market fit work left to do.", "author": "alanmcintyre", "timestamp": "2026-02-18T13:58:28+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:24.089684+00:00", "processed": false}
{"id": "hn_comment_47060598", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47060598", "title": "Re: Show HN: MedSynth \u2013 Multi-lingual synthetic health...", "text": "Creator here. We work with healthcare orgs in MENA and Latin America and got tired of synthetic data that looks nothing like real hospital records.<p>The main insight: real medical data is scanned paper with OCR errors, not clean JSON. So we simulate script-aware OCR artifacts (Arabic dot-group confusions, Hebrew shape swaps, Latin diacritic loss) alongside schema variance across facilities.<p>6 locales ship today: he_IL, ar_SA, ar_EG, es_ES, es_MX, es_AR. No OpenAI key needed for basic generation.<p>Happy to answer questions about healthcare data challenges or adding new locales.", "author": "Alechko", "timestamp": "2026-02-18T13:13:28+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:26.885709+00:00", "processed": false}
{"id": "hn_story_47060523", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47060523", "title": "Show HN: SciCraft \u2013 generate scientific Claude Code skills on demand (176 built)", "text": "Most Claude Code plugins ship a fixed set of skills and stop there. For                                                                                                \n  general software development, that&#x27;s fine. For scientific research, it&#x27;s\n  a fundamental mismatch.<p><pre><code>  Every scientist works at a different intersection of tools. A computational\n  biologist running GWAS uses a completely different stack than a structural\n  biologist doing MD simulations, or a medicinal chemist running virtual\n  screens, or a microscopist doing image segmentation. No static plugin can\n  anticipate that breadth \u2014 and the moment your workflow touches a tool\n  that isn&#x27;t covered, the plugin becomes useless for that task.\n\n  SciCraft is built around a CLAUDE.md that encodes a complete skill authoring\n  workflow. Give Claude Code any scientific tool name:\n\n      &quot;Add a skill for CellRanger&quot;\n      &quot;Add a skill for CREST structural variant caller&quot;\n      &quot;Add a skill for our internal mass spec preprocessing pipeline&quot;\n\n  It runs a 6-step process:\n\n      Topic \u2192 Classify (pipeline &#x2F; toolkit &#x2F; database &#x2F; guide)\n            \u2192 Category (pick from 11 life sciences domains)\n            \u2192 Research (official docs, GitHub, PyPI)\n            \u2192 Author (SKILL.md: 10+ runnable code blocks, Key Parameters\n                      table, Troubleshooting matrix)\n            \u2192 Register (registry.yaml entry)\n            \u2192 Validate (pytest suite checks structure and code depth )\n\n  The result is a CI-validated skill file committed to your repo \u2014 not a\n  one-off answer, but a permanent reusable asset available in every future\n  session. Your collaborators inherit it too.\n\n  Scientific computing makes this especially valuable:\n  - Life sciences libraries (Scanpy, RDKit, MDAnalysis, BioPython) have\n    complex, non-obvious APIs that LLMs frequently hallucinate\n  - The field moves fast \u2014 tools released last month have no training data\n  - Lab-specific pipelines and instruments will never appear in any\n    off-the-shelf plugin\n  - Research scope shifts constantly: a lab pivoting from bulk RNA-seq to\n    spatial transcriptomics needs a completely different skill set overnight\n\n  The pytest suite enforces minimum code block counts, required section\n  structure, parameter table depth, and troubleshooting rows \u2014 so generated\n  skills are immediately usable, not rough drafts.\n\n  ---\n\n  The repo ships 176 pre-built scientific skills across genomics, drug\n  discovery, proteomics, cell biology, and biostatistics (Scanpy, GATK,\n  RDKit, DESeq2, AutoDock Vina, cBioPortal, gnomAD, and more) so common\n  workflows are covered from day one. But the 176 are a starting point \u2014\n  the authoring system is what makes SciCraft adapt to your specific research,\n  not just the research someone else anticipated.\n\n  The design uses progressive disclosure: only each skill&#x27;s description is\n  in context during planning. The full file loads on demand. Context stays\n  lean; precise scientific API knowledge is available when the agent needs it.\n\n  Curious whether others have hit the ceiling of static plugin systems in\n  research contexts \u2014 and what approaches you&#x27;ve tried for keeping domain\n  knowledge current with a fast-moving field.\n\n  https:&#x2F;&#x2F;github.com&#x2F;jaechang-hits&#x2F;scicraft</code></pre>", "author": "jaechang", "timestamp": "2026-02-18T13:05:04+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-18T17:46:27.260906+00:00", "processed": false}
{"id": "hn_comment_47060460", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47060460", "title": "Re: Show HN: ReciPath \u2013 open-source, offline-first rec...", "text": "I built ReciPath because most recipe apps today have high monthly costs, overbearing social features, and require an internet connection just to see a shopping list.<p>THE APPROACH:\nI\u2019m primarily a Flutter developer. For this project, I wanted to experiment with a &quot;database-driven UI&quot; flow. Instead of heavy state management boilerplate, the UI state is tightly coupled to a local Drift (SQLite) DB. If it&#x27;s in the DB, it&#x27;s in the UI.<p>TECHNICAL HIGHLIGHTS:<p>- Offline First: Everything works locally. Accounts are optional and only used for syncing via Supabase.\n- Shopping Planner: You select recipes, and the app generates a shopping list.\n- Smart Timers: When you start a recipe, it tracks your actual cooking time to provide better averages later. It also handles per-step timers (e.g., a 60-minute oven timer) with local notifications and sounds.\n- The Sharing Challenge: Since the app is self-contained, sharing recipes is currently done via JSON files. The hard part is mapping imported &quot;grocery items&quot; to local ones. The app tries to match by barcode and name, but I\u2019d love to hear ideas on how to streamline this mapping process.<p>ROADMAP: BYOT AI INTEGRATION<p>- I&#x27;m currently looking into adding &quot;Bring Your Own Token&quot; AI support. The goal is to let users use their own API keys (OpenRouter&#x2F;OpenAI&#x2F;etc.) to import recipes directly from messy URLs or photos of physical cookbooks. Since recipe sites change their HTML constantly, using LLMs for schema mapping feels like the most robust way to keep the app lightweight without writing a thousand custom scrapers.<p>WHY OPEN SOURCE?\nI was just tired of the bloat. I wanted a clean, open-source alternative that belongs to the user, not a subscription service.<p>I\u2019d love feedback on the UX, the Drift-heavy architecture, or your thoughts on the recipe-sharing schema!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Cunibon&#x2F;recipath\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Cunibon&#x2F;recipath</a>\nPlay Store: <a href=\"https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.cunibongames.recipath\">https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.cunibongam...</a>", "author": "cunibon", "timestamp": "2026-02-18T12:56:12+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-18T17:46:28.785566+00:00", "processed": false}
