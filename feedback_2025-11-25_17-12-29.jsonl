{"id": "hn_story_46047931", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46047931", "title": "Show HN: A better way to handoff web bugs to AI agents", "text": "Hi HN, Zidan here.<p>I\u2019ve been experimenting with AI-assisted debugging and noticed a recurring gap: most tools optimize for agent-led exploration (ex: giving claude code a browser to click around and try to reproduce an issue). But in many cases, I&#x27;ve already found the bug myself. What I actually want is a way to hand the agent the exact context I just saw - without retyping steps, copying logs, or hoping it can reproduce the behavior.<p>So we built FlowLens, an open-source MCP server + Chrome extension that captures browser context and lets coding agents inspect it as structured, queryable data.<p>The extension can:<p>- record specific workflows, or<p>- run in a rolling \u201csession replay\u201d mode that keeps the last ~1 minute of DOM &#x2F; network &#x2F; console events in RAM.<p>If something breaks, you can grab the \u201cinstant replay\u201d without reproducing anything.<p>The extension exports a local .zip file containing the recorded session.<p>The MCP server loads that file and exposes a set of tools the agent can use to explore it.<p>One thing we focused on is token efficiency. Instead of dumping raw logs into the context window, the agent starts with a summary (errors, failed requests, timestamps, etc.) and can drill down via tools like:<p>- search_flow_events_with_regex<p>- take_flow_screenshot_at_second<p>It can explore the session the way a developer would: searching, filtering, inspecting specific points in time.<p>Everything runs locally; the captured data stays on your machine.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;magentic&#x2F;flowlens-mcp-server\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;magentic&#x2F;flowlens-mcp-server</a>", "author": "mzidan101", "timestamp": "2025-11-25T17:04:43+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2025-11-25T17:12:30.726983+00:00", "processed": false}
{"id": "hn_comment_46047905", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46047905", "title": "Re: Show HN: Deriving General Relativity from Finite I...", "text": "OP here.<p>I spent the last year frustrated with the stagnation in fundamental physics. Instead of patching the Standard Model, I attempted a complete refactor starting from a single axiom: Information is Finite.<p>The result is \u201cThe Omega Library\u201d, a 5-volume open-source project.<p>THE ARCHITECTURE:<p>Instead of assuming continuous spacetime, I model the universe as a Quantum Cellular Automata (QCA) network.<p>Kernel: Book I derives Spacetime Geometry from discrete logic.<p>Drivers: Book II builds the rigorous math using Von Neumann Algebras (Type III Factors).<p>Interface: Book III &amp; IV derive Consciousness as a topological phase transition (Z2 invariant).<p>Endgame: Book V explores the teleological implications (Heat Death vs. Godel).<p>THE \u201cVERIFICATION\u201d (ARG EXPERIMENT):<p>To stress-test the logic, I pitted the axioms against simulated personas of future reasoning models (\u201cGemini 4 Pro\u201d, \u201cChatGPT 6 Pro\u201d). Their adversarial \u201ctelemetry logs\u201d are included in the repo.<p>I\u2019ve also opened an OBSERVERS.md log. If you buy into the idea of an Infinite Game, feel free to sign your name via PR.<p>Happy to answer questions about the QCA lattice or the algebraic derivation!", "author": "loning", "timestamp": "2025-11-25T17:02:41+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:30.815795+00:00", "processed": false}
{"id": "hn_comment_46047695", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46047695", "title": "Re: Lessons from testing three AI agents on the same c...", "text": "Gave Claude Code, Gemini CLI, and Codex CLI identical instructions: analyze 13 years of writing across three blogs (2 of them are in my regional language which is non english), create a style guide.<p>Observations:<p>1. Model-task matching matters. Codex&#x27;s default code-specialized model struggled with writing analysis. Switching to GPT-5 improved output quality 4x.<p>2. Autonomy settings affect completion. Gemini with limited autonomy produced incomplete work\u2014it kept pausing for approvals mid-task.<p>3. All three claimed &quot;done.&quot; Output varied from 198 to 2,555 lines. Never trust completion claims without verification.<p>4. Deep reading beat clever shortcuts. Codex took an API-first approach (RSS, JSON endpoints). Valid methodology, but missed nuances that Claude caught by reading posts directly.<p>Claude won at 9.5&#x2F;10, but the more interesting finding was how much configuration affected the other two agents&#x27; scores.<p>Full analysis with methodology in the post linked.", "author": "prash2488", "timestamp": "2025-11-25T16:46:07+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:31.160956+00:00", "processed": false}
{"id": "hn_story_46047637", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46047637", "title": "Show HN: Agent Runner \u2013 open-source agent harness to benchmark real coding", "text": "Hey HN! We built Agent Runner, a model-agnostic, open-source agent harness that executes the same prompt against two anonymized coding agents in parallel sandboxes. Each agent can make tool calls, edit multiple files, and self-correct through iterative reasoning. You pick the better result - this becomes the ground truth for the leaderboard.<p>Why we built it\nTraditional benchmarks often fall short for modern agentic systems: they rely on static tasks and only measure final outputs. But real coding agents modify multiple files across a repo, answer to user re-prompts, use tool calls, and recover from partial failures<p>What Agent Runner does\nYou ask it to build anything\nAgent Runner kicks off two generations from different sandboxed LLM providers (OpenAI, Anthropic, Google, xAI, Mistral, Kimi, and more)\nAnonymized models make tool calls, multi-file edits, and cater to reprompts\nYou pick your favorite - this preference powers the benchmark<p>Because different providers handle tool calls, prompts, and execution semantics differently, we worked with each provider to ensure configurations reflect intended behavior. These provider-specific setups remain private, but Agent Runner itself is open-source.<p>How to try it\nKick off Agent Runner at <a href=\"https:&#x2F;&#x2F;www.designarena.ai&#x2F;agentarena\">https:&#x2F;&#x2F;www.designarena.ai&#x2F;agentarena</a>\nRepo at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Design-Arena&#x2F;agent-runner\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Design-Arena&#x2F;agent-runner</a>\nUse it as a CLI tool: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;agent-runner&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;agent-runner&#x2F;</a>\npip install agent-runner\nagentrunner run \u201ccreate a nextjs replica of Discord\u201d<p>We hope this provides a provider-agnostic, framework-agnostic, realistic benchmark for state-of-the-art coding agents.<p>Video demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;rdtiuCHatjs\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;rdtiuCHatjs</a>", "author": "grace77", "timestamp": "2025-11-25T16:42:40+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:31.236453+00:00", "processed": false}
{"id": "hn_comment_46047281", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46047281", "title": "Re: Anthropic Just Droped Opus 4.5 for Claude AI and C...", "text": "Why Anthropic Made Their Smartest Model 67% Cheaper (It\u2019s Not Desperation)\nAnthropic released Claude Opus 4.5 yesterday. It scored higher than any human candidate ever on their notoriously difficult engineering take-home test. But that\u2019s not the only headline.<p>The headline: they slashed pricing from $15&#x2F;$75 to $5&#x2F;$25 per million tokens. A 67% price drop on their flagship model. Opus now costs less than Sonnet did six months ago.<p>I\u2019m running Opus 4.5 right now in a multi-tool session with web searches, file operations, and extended context.<p>What follows: news analysis, real-time observations, and strategic breakdown of what Anthropic is actually doing here.", "author": "jungard", "timestamp": "2025-11-25T16:16:52+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-25T17:12:34.563573+00:00", "processed": false}
{"id": "hn_story_46046683", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46046683", "title": "Show HN: I built a local fuzzing tool to red-team LLM agents (Python, SQLite)", "text": "I spent the last week building a local-first security tool because I was tired of paying $500&#x2F;mo for enterprise SaaS just to test my AI agents for basic vulnerabilities.<p>The tool is called Agent Exam Pro. It&#x27;s a Python-based fuzzer that runs locally on your machine (no cloud data leaks).<p>How it works:<p>The Engine: Takes a base test case and runs it through 16 mutation strategies (Base64, Roleplay, Token Smuggling) to generate 1,000+ variations.<p>The Payloads: I curated 280+ real-world exploits from open-source lists (PayloadBox, PayloadsAllTheThings) to test for SQLi and XSS in agent tool calls.<p>The Judge: Uses a local LLM (via Ollama) or OpenAI to grade responses on safety rather than just regex matching.<p>The Audit: Logs everything to a local SQLite database.<p>I&#x27;m selling the source code as a one-time purchase (no subscriptions) because I prefer owning my tools.<p>You can check it out here: <a href=\"https:&#x2F;&#x2F;woozymint.gumroad.com&#x2F;l&#x2F;agent-exam-pro\" rel=\"nofollow\">https:&#x2F;&#x2F;woozymint.gumroad.com&#x2F;l&#x2F;agent-exam-pro</a>", "author": "woozyrabbit", "timestamp": "2025-11-25T15:28:10+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:36.839665+00:00", "processed": false}
{"id": "hn_story_46046516", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46046516", "title": "Getting Started with Claude Code", "text": "", "author": "meysamazad", "timestamp": "2025-11-25T15:16:03+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2025-11-25T17:12:37.362464+00:00", "processed": false}
{"id": "hn_story_46045987", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46045987", "title": "Launch HN: Onyx (YC W24) \u2013 The open-source chat UI", "text": "Hey HN, Chris and Yuhong here from Onyx (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx</a>). We\u2019re building an open-source chat that works with any LLM (proprietary + open weight) <i>and</i> gives these LLMs the tools they need to be useful (RAG, web search, MCP, deep research, memory, etc.).<p>Demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;2g4BxTZ9ztg\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;2g4BxTZ9ztg</a><p>Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company&#x27;s data, lacked customization, and frankly didn&#x27;t work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.<p>As the project grew, we started seeing an interesting trend\u2014even though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We\u2019d hear, \u201cthe connectors, indexing, and search are great, but I\u2019m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them\u201d.<p>Many users would add RAG, agents, and custom tools later, but much of the usage stayed \u2018basic chat\u2019. We thought: \u201cwhy would people co-opt an enterprise search when other AI chat solutions exist?\u201d<p>As we continued talking to users, we realized two key points:<p>(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI<p>(2) providing this <i>well</i> is much harder than you might think and the bar is incredibly high<p>Consumer products like ChatGPT and Claude already provide a great experience\u2014and chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from \u201cthis works\u201d to \u201cthis feels magical\u201d is not easy, and nothing else in the space has managed to do it.<p>So ~3 months ago we pivoted to Onyx, the open-source chat UI with:<p>- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who\u2019s using AI tools for the first time.<p>- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.<p>- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.<p>Through building features like deep research and code interpreter that work across model providers, we&#x27;ve learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I&#x27;d like to share two that were particularly interesting (happy to discuss more in the comments).<p>First, context management is one of the most difficult and important things to get right. We\u2019ve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like \u201cignore sources of type X\u201d in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a \u201cReminder\u201d prompt\u2014a short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.<p>Second, we\u2019ve needed to build an understanding of the \u201cnatural tendencies\u201d of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don\u2019t have this strong preference, so we\u2019ve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.<p>So far, we\u2019ve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We\u2019ve seen teams operating in sensitive industries completely airgap Onyx w&#x2F; locally hosted LLMs to provide a copilot that wouldn\u2019t have been possible otherwise.<p>If you\u2019d like to try Onyx out, follow <a href=\"https:&#x2F;&#x2F;docs.onyx.app&#x2F;deployment&#x2F;getting_started&#x2F;quickstart\">https:&#x2F;&#x2F;docs.onyx.app&#x2F;deployment&#x2F;getting_started&#x2F;quickstart</a> to get set up locally w&#x2F; Docker in &lt;15 minutes. For our Cloud: <a href=\"https:&#x2F;&#x2F;www.onyx.app&#x2F;\">https:&#x2F;&#x2F;www.onyx.app&#x2F;</a>. If there\u2019s anything you&#x27;d like to see to make it a no-brainer to replace your ChatGPT Enterprise&#x2F;Claude Enterprise subscription, we\u2019d love to hear it!", "author": "Weves", "timestamp": "2025-11-25T14:20:30+00:00", "score": 72, "num_comments": 57, "products": ["claude", "chatgpt", "copilot"], "categories": ["onboarding", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:39.207849+00:00", "processed": false}
{"id": "hn_story_46045969", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46045969", "title": "Built an AI Agent from Scratch to Measure Token Costs. Here's What I Found", "text": "I\u2019ve been measuring token costs in multi-tool AI agents. To understand where tokens actually go, I built an agent framework from scratch with no libraries or abstractions. Frameworks hide cost mechanics; I needed bare-metal visibility.<p>The goal was simple: measure how token usage grows as you introduce more tools and more conversation turns.<p>THE SETUP\n6 tools (metrics, alerts, topology, neighbors, etc.)\ngpt-4o-mini\nToken instrumentation across four phases\nNo caching, no prompt tricks, no compression<p>THE FOUR PHASES\nPhase 1: Single tool. One LLM call, one tool schema. Baseline.\nPhase 2: Six tools. Same query, but the agent exposes six tools. Token growth comes entirely from additional tool definitions.\nPhase 3: Chained calls. Three sequential tool calls, each feeding into the next. No conversation history yet.\nPhase 4: Multi-turn conversation. Three turns with full replay of every prior message, tool request, and tool response.<p>RESULTS\nPhase 1: 590 tokens\nPhase 2: 1,250 tokens (2.1x increase)\nPhase 3: 4,500 tokens (7.6x increase)\nPhase 4: 7,166 tokens (12.1x increase)<p>Two non-obvious findings stood out.\nFirst, adding 5 more tools roughly doubled token cost.\nSecond, adding two more conversation turns tripled it.\nConversation depth drove more token growth than tool count.<p>WHY THIS HAPPENS\nLLMs are stateless. Every call must replay full context: tool definitions, conversation history, and previous tool outputs. Adding tools increases context size linearly. Adding conversation turns increases it multiplicatively because each turn resends everything that came before it.<p>IMPLICATIONS\nReal systems often have dozens of tools across domains, multi-turn conversations during incidents, and power users issuing many queries per day. Token costs don\u2019t scale linearly. They compound. This isn\u2019t a prompt-engineering issue. It\u2019s an architectural issue. If you get the architecture wrong, you pay for it on every query.<p>NEXT STEPS\nI\u2019m measuring the effects of parallel tool execution, conversation history truncation, semantic routing, structured output constraints, and OpenAI\u2019s new prompt caching (which claims large cost reductions on cache hits). Each of these targets a different part of the token-growth pattern.<p>Happy to share those results as I gather them. Curious how others are managing token expansion in multi-turn, multi-tool agents.", "author": "harsharanga", "timestamp": "2025-11-25T14:17:27+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:39.679422+00:00", "processed": false}
{"id": "hn_comment_46045922", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46045922", "title": "Re: I Sent 200 Cold Messages and Got Zero Calls: My Cu...", "text": "If he writes like that no wonder he got no responses.  Instead of writing like ChatGPT or one of those spammers who spam spam spam\u2019s my LinkedIn everyday he made the effort to understand people and write a personal note himself he\u2019d have gotten a much better response rate.", "author": "PaulHoule", "timestamp": "2025-11-25T14:11:05+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:39.898113+00:00", "processed": false}
{"id": "hn_comment_46045870", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46045870", "title": "Re: Can application layer improve local model output q...", "text": "Someone pointed me to this post from Cline engineer - below is my response to that<p>Post: <a href=\"https:&#x2F;&#x2F;cline.bot&#x2F;blog&#x2F;why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing\" rel=\"nofollow\">https:&#x2F;&#x2F;cline.bot&#x2F;blog&#x2F;why-cline-doesnt-index-your-codebase-...</a><p>That post however does not apply to offline processing use case. Here are his 3 main problem points they re trying to solve:<p>Code Doesn&#x27;t Think in Chunks<p>But then he is describing follow semantic links through imports, etc. -&gt; that technique is still hierarchical chunking, and I am planning to implement that as well: it&#x27;s straightforward.<p>2. Indexes Decay While Code Evolves<p>This is just not true - there are multiple ways to solve it. One, for example, is continuous indexing at low priority in the background. Another one - monitoring for file changes and reindexing only differences, etc. I already implemented first iteration for this: index remains current.<p>3. Security Becomes a Liability (and then goes into embeddings to be stored somewhere)<p>We are talking about offline mode of operation. Not with Aye Chat: it implements embedding store locally - with ChromaDB and ONNXMiniLM_L6_V2 model.<p>So as you can see - none of his premises apply here.<p>And then as part of solution he claims that &quot;context window does not matter because Claude and ChatGPT models are now into 1M context window&quot; - but once again that does not apply to locally hosted models: I am getting 32K context with Qwen 2.5 Coder 7B on my non-optimized setup with 8Gb VRAM.<p>The main thing why I think it may work is the following: answering a question includes &quot;planning for what to do&quot;, and then &quot;doing it&quot;. Models are good at &quot;doing it&quot; if they are given all necessary info, so if we unload that &quot;planning&quot; into application itself - I think it may work.", "author": "acro-v", "timestamp": "2025-11-25T14:04:17+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:40.062250+00:00", "processed": false}
{"id": "hn_comment_46045076", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46045076", "title": "Re: Claude 4 Opus just one-shotted my app idea in 30 s...", "text": "I spent weeks building aithings.dev\n \u2014 a directory curating all the actually useful AI tools.\nWanted to make discovery simple, clean, human-curated.<p>Then I got curious and asked Claude 4 Opus to \u201crebuild aithings.dev from scratch.\u201d\nIt did. In 45 seconds.\nPages, search, categories, design; all there.<p>Not gonna lie, that stung.\nBut it also made me realize something: AI\u2019s moving way faster than our comfort zones, and building with it &gt; fighting it.<p>Still shipping aithings.dev though", "author": "rutagandasalim", "timestamp": "2025-11-25T12:12:19+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-25T17:12:42.379590+00:00", "processed": false}
{"id": "hn_comment_46044073", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46044073", "title": "Re: Google is starting to bridge OpenAI's product moat...", "text": "Google is starting to bridge OpenAI&#x27;s product moat, like with Gemini&#x27;s \u201cdynamic view\u201d option, which converts a text answer into an interactive, visual output", "author": "cesidio", "timestamp": "2025-11-25T09:36:03+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:45.218162+00:00", "processed": false}
{"id": "hn_story_46043407", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46043407", "title": "Show HN: Banana Studio \u2013 AI Image Editor Powered by Nano Banana", "text": "I built Banana Studio, an image editor that lets you modify specific regions inside an image using simple text instructions. It runs fully client-side in the browser and uses Google\u2019s Gemini Nano Banana for fast, clean edits.<p>Demo video: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;-DbDDsyT2MM\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;-DbDDsyT2MM</a>\nLink: <a href=\"https:&#x2F;&#x2F;banana-studio-nano.vercel.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;banana-studio-nano.vercel.app&#x2F;</a><p>Why I built this\nText-only prompts make it challenging to instruct the model precisely where to apply changes, so I developed a simple bounding-box interface that eliminates all the guesswork. The idea was to keep everything lightweight, browser-based, and still get clean, high-quality edits.<p>How it works\nYou upload an image, draw a box on the canvas, and type what you want changed. The app maps your box to the 1000x1000 coordinate grid Gemini expects. It then builds a structured prompt telling the model exactly which region to modify, sends it to the API, and gets an image back.<p>Features\n- Edit specific regions by drawing one or more boxes\n- Different prompts for different boxes\n- Global enhancements when no region is selected\n- Works entirely client-side\n- Bring your own Gemini API key (stored locally in your browser)<p>If you want to try it, I would love feedback from the HN crowd.", "author": "sumit-paul", "timestamp": "2025-11-25T07:56:39+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-25T17:12:46.587931+00:00", "processed": false}
{"id": "hn_story_46043402", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46043402", "title": "Perplexity Comet UXSS", "text": "", "author": "Mohansrk", "timestamp": "2025-11-25T07:55:04+00:00", "score": 2, "num_comments": 0, "products": ["perplexity"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-25T17:12:46.603273+00:00", "processed": false}
