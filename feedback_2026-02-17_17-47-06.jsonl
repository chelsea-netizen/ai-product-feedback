{"id": "hn_story_47050156", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47050156", "title": "Claude Code leaked me someone else's response", "text": "", "author": "joshuawright11", "timestamp": "2026-02-17T17:25:52+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:09.801327+00:00", "processed": false}
{"id": "hn_story_47050025", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47050025", "title": "Show HN: StewReads \u2013 Turn Claude chats into Kindle ebooks", "text": "Blog: <a href=\"https:&#x2F;&#x2F;ankitgupta.dev&#x2F;blog&#x2F;building-stewreads\" rel=\"nofollow\">https:&#x2F;&#x2F;ankitgupta.dev&#x2F;blog&#x2F;building-stewreads</a><p>Over past year, I have realized (and accepted) two things: \n- I do actually learn from AI chatbots. \n- Chat interface is very hard to focus, I cannot go back to a useful chat from the past and reread it to revise the topic I learnt from it.<p>To solve this, I created StewReads MCP server which instructs Claude to generate a nicely formatted ebook based on the chat. Now, when I feel I have learned something from a chat, I simply invoke the `stew` prompt and have the ebook on my Kindle device and app in minutes. Works well with claude.ai, Claude Desktop app and Cowork. You can also try it by sending ebook to your email if you dont want to setup Kindle yet.<p>Looking forward to your comments and suggestions. Happy Stewing!<p>Note: it uses your Claude tokens, so be mindful. Ebook size is capped at 2000 words as a guardrail. I use sonnet for brainstorming and learning, and can comfortably generate an ebook a day on the Pro plan.", "author": "rajma", "timestamp": "2026-02-17T17:18:37+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:10.311173+00:00", "processed": false}
{"id": "hn_story_47049848", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47049848", "title": "Show HN: Continue \u2013 Source-controlled AI checks, enforceable in CI", "text": "We now write most of our code with agents. For a while, PRs piled up, causing review fatigue, and we had this sinking feeling that standards were slipping. Consistency is tough at this volume. I\u2019m sharing the solution we found, which has become our main product.<p>Continue (<a href=\"https:&#x2F;&#x2F;docs.continue.dev\">https:&#x2F;&#x2F;docs.continue.dev</a>) runs AI checks on every PR. Each check is a source-controlled markdown file in `.continue&#x2F;checks&#x2F;` that shows up as a GitHub status check. They run as full agents, not just reading the diff, but able to read&#x2F;write files, run bash commands, and use a browser. If it finds something, the check fails with one click to accept a diff. Otherwise, it passes silently.<p>Here\u2019s one of ours:<p><pre><code>  .continue&#x2F;checks&#x2F;metrics-integrity.md\n\n  ---\n  name: Metrics Integrity\n  description: Detects changes that could inflate, deflate, or corrupt metrics (session counts, event accuracy, etc.)\n  ---\n\n  Review this PR for changes that could unintentionally distort metrics.\n  These bugs are insidious because they corrupt dashboards without triggering errors or test failures.\n\n  Check for:\n  - &quot;Find or create&quot; patterns where the &quot;find&quot; is too narrow, causing entity duplication (e.g. querying only active sessions, missing completed ones, so every new commit creates a duplicate)\n  - Event tracking calls inside loops or retry paths that fire multiple times per logical action\n  - Refactors that accidentally remove or move tracking calls to a path that executes with different frequency\n\n  Key files: anything containing `posthog.capture` or `trackEvent`\n\n</code></pre>\nThis check passed without noise for weeks, but then caught a PR that would have silently deflated our session counts. We added it in the first place because we\u2019d been burned in the past by bad data, only noticing when a dashboard looked off.<p>---<p>To get started, paste this into Claude Code or your coding agent of choice:<p><pre><code>  Help me write checks for this codebase: https:&#x2F;&#x2F;continue.dev&#x2F;walkthrough\n</code></pre>\nIt will:<p>- Explore the codebase and use the `gh` CLI to read past review comments<p>- Write checks to `.continue&#x2F;checks&#x2F;`<p>- Optionally, show you how to run them locally or in CI<p>Would love your feedback!", "author": "sestinj", "timestamp": "2026-02-17T17:08:14+00:00", "score": 8, "num_comments": 1, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-17T17:47:10.866617+00:00", "processed": false}
{"id": "hn_story_47049776", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47049776", "title": "Launch HN: Sonarly (YC W26) \u2013 AI agent to triage and fix your production alerts", "text": "Hey HN, I am Dimittri and we\u2019re building Sonarly (<a href=\"https:&#x2F;&#x2F;sonarly.com\">https:&#x2F;&#x2F;sonarly.com</a>), an AI engineer for production. It connects to your observability tools like Sentry, Datadog, or user feedback channels, triages issues, and fixes them to cut your resolution time. Here&#x27;s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rr3VHv0eRdw\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rr3VHv0eRdw</a>.<p>Sonarly is really about removing the noise from production alerts by grouping duplicates and returning a root cause analysis to save time to on-call engineers and literally cut your MTTR.<p>Before starting this company, my co-founder and I had a B2C app in edtech and had, some days, thousands of users using the app. We pushed several times a day, relying on user feedback. Then we set up Sentry, it was catching a lot of bugs, but we had up to 50 alerts a day. With 2 people it&#x27;s a lot. We took a lot of time filtering the noise to find the real signal so we knew which bug to focus on.<p>At the same time, we saw how important it is to fix a bug fast when it hits users. A bug means in the worst case a churn and at best a frustrated user. And there are always bugs in production, due to code errors, database mismatches, infrastructure overload, and many issues are linked to a specific user behavior. You can&#x27;t catch all these beforehand, even with E2E tests or AI code reviews (which catch a lot of bugs but obviously not all, plus it takes time to run at each deployment). This is even more true with vibe-coding (or agentic engineering).<p>We started Sonarly with this idea. More software than ever is being built and users should have the best experience possible on every product. The main idea of Sonarly is to reduce the MTTR (Mean Time To Repair).<p>We started by recreating a Sentry-like tool but without the noise, using only text and session replays as the interface. We built our own frontend tracker (based on open-source rrweb) and used the backend Sentry SDK (open source as well). Companies could just add another tracker in the frontend and add a DSN in their Sentry config to send data to us in addition to Sentry.<p>We wanted to build an interface where you don&#x27;t need to check logs, dashboards, traces, metrics, and code, as the agent would do it for you with plain English to explain the &quot;what,&quot; &quot;why,&quot; and &quot;how do I fix it.&quot;<p>We quickly realized companies don&#x27;t want to add a new tracker or change their monitoring stack, as these platforms do the job they&#x27;re supposed to do. So we decided to build above them. Now we connect to tools like Sentry, Datadog, Slack user feedback channels, and other integrations.<p>Claude Code is so good at writing code, but handling runtime issues requires more than just raw coding ability. It demands deep runtime context, immediate reactivity, and intelligent triage, you can\u2019t simply pipe every alert directly into an agent. That\u2019s why our first step is converting noise into signal. We group duplicates and filter false positives to isolate clear issues. Once we have a confirmed signal, we trigger Claude Code with the exact context it needs, like the specific Sentry issue and relevant logs fetched via MCP (mostly using grep on Datadog&#x2F;Grafana). However, things get exponentially harder with multi-repo and multi-service architectures.<p>So we built an internal map of the production system that is basically a .md file updated dynamically. It shows every link between different services, logs, and metrics so that Claude Code can understand the issue faster.<p>One of our users using Sentry was receiving ~180 alerts&#x2F;day. Here is what their workflow looked like:<p>- Receive the alert<p>- 1) Defocus from their current task or wake up, or 2) don&#x27;t look at the alert at all (most of the time)<p>- Go check dashboards to find the root cause (if infra type) or read the stack trace, events, etc.<p>- Try to figure out if it was a false positive or a real problem (or a known problem already in the fixes pipeline)<p>- Then fix by giving Claude Code the correct context<p>We started by cutting the noise and went from 180&#x2F;day to 50&#x2F;day (by grouping issues) and giving a severity based on the impact on the user&#x2F;infra. This brings it down to 5 issues to focus on in the current day. Triage happens in 3 steps: deduplicating before triggering a coding agent, gathering the root cause for each alert, and re-grouping by RCA.<p>We launched self-serve (<a href=\"https:&#x2F;&#x2F;sonarly.com\">https:&#x2F;&#x2F;sonarly.com</a>) and we would love to have feedback from engineers. Especially curious about your current workflows when you receive an alert from any of these channels like Sentry (error tracking), Datadog (APM), or user feedback. How do you assign who should fix it? Where do you take your context from to fix the issue? Do you have any automated workflow to fix every bug, and do you have anything you use currently to filter the noise from alerts?<p>We have a large free tier as we mainly want feedback. You can self-serve under 2 min. I&#x27;ll be in the thread with my co-founder to answer your questions, give more technical details, and take your feedback: positive, negative, brutal, everything&#x27;s constructive!", "author": "Dimittri", "timestamp": "2026-02-17T17:03:09+00:00", "score": 6, "num_comments": 0, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:11.185383+00:00", "processed": false}
{"id": "hn_comment_47049209", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47049209", "title": "Re: Show HN: StewReads \u2013 Turn Claude chats into Kindle...", "text": "Over past year, I have realized (and accepted) two things:\n- I do actually learn from AI chatbots. \n- Chat interface is very hard to focus, I cannot go back to a useful chat from the past and reread it to revise the topic I learnt from it<p>To solve this, I created StewReads MCP server which instructs Claude to generate a nicely formatted ebook based on the chat. Now, when I feel I have learned something from a chat, I simply invoke the `stew` prompt and have the ebook on my Kindle device and app in minutes. Works well with claude.ai, Claude Desktop app and Cowork. You can also try it by sending ebook to your email if you dont want to setup Kindle yet.<p>Looking forward to your comments and suggestions.\nHappy Stewing!", "author": "rajma", "timestamp": "2026-02-17T16:21:46+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:14.352962+00:00", "processed": false}
{"id": "hn_comment_47050348", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47050348", "title": "Re: Semantic ablation: Why AI writing is generic and b...", "text": "I wonder how much of it could be prompted away.<p>For example the anthropic Frontend Design skill instructs:<p>&quot;Typography: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend&#x27;s aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.&quot;<p>Or<p>&quot;NEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.&quot; 1<p>Maybe sth similar would be possible for writing nuances.<p>1 <a href=\"https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;skills&#x2F;blob&#x2F;main&#x2F;skills&#x2F;frontend-design&#x2F;SKILL.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;skills&#x2F;blob&#x2F;main&#x2F;skills&#x2F;fronte...</a>", "author": "morgengold", "timestamp": "2026-02-17T17:38:18+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:14.934791+00:00", "processed": false}
{"id": "hn_story_47048886", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048886", "title": "Show HN: Broomy \u2013 Open-source app for working with many AI agents at once", "text": "Hi HN, I&#x27;m Rob. I built Broomy because I got frustrated with the one-thing-at-a-time workflow of existing coding tools.<p>When I work with AI coding agents, I typically have 5-10 tasks going at once across different branches. The agent works on one thing while I review another, merge a third, and kick off a fourth. Existing IDEs aren&#x27;t built for this \u2014 they assume you&#x27;re doing one thing at a time.<p>Broomy is a desktop app (Electron + React) that lets you:<p>- Run lots of agent sessions simultaneously and see at a glance which are working, idle, or need your attention\n- Work with any terminal-based agent (Claude Code, Aider, Codex, etc.)\n- Review code, manage branches, and handle merges with AI assistance\n- Use built-in IDE features (Monaco editor, file explorer, git integration, inline terminals) \u2014 all designed around multi-agent workflows<p>I&#x27;ve been using it daily for a few weeks and my productivity has dramatically improved compared to working in Cursor. The key insight is that most of the time you spend &quot;coding with AI&quot; is actually waiting \u2014 and Broomy lets you fill that wait time with other tasks.<p>This is a first public release (v0.6.0). Pre-built binaries are available for macOS. It should work on Linux and Windows too \u2014 build from source is straightforward (clone, pnpm install, pnpm start:dist).<p>MIT licensed. Built as a personal project, not affiliated with my employer.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Broomy-AI&#x2F;broomy\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Broomy-AI&#x2F;broomy</a>\nWebsite: <a href=\"https:&#x2F;&#x2F;broomy.org\" rel=\"nofollow\">https:&#x2F;&#x2F;broomy.org</a><p>Happy to answer questions.", "author": "robotelvis", "timestamp": "2026-02-17T15:55:38+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:15.792321+00:00", "processed": false}
{"id": "hn_comment_47048755", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048755", "title": "Re: Show HN: Daymon \u2013 Open-source app that gives Claud...", "text": "Hey HN,\nI built Daymon because I kept running into the same problem \u2014 I use Claude daily, but every conversation is a dead end. No way to schedule recurring tasks, no way to pick up where you left off.<p>Tools like OpenClaw exist, but they run on API calls. If you&#x27;re already paying $20&#x2F;mo for Pro or $200&#x2F;mo for Max, why pay again per token? Heavy automation on the API can easily hit $100\u20132,000+&#x2F;month on top of your subscription.<p>Daymon works with your existing Claude subscription. No API keys, no per-token billing. It&#x27;s a Mac desktop app that connects to Claude via MCP. You install it, and Claude gains new capabilities:\nTask scheduling \u2014 cron, one-time, or on-demand. &quot;Summarize my inbox every morning at 8&quot; just works.\nSession continuity \u2014 scheduled tasks resume previous sessions, so a daily research task builds on yesterday&#x27;s work.\nWorkers \u2014 named agent configs with system prompts. Set up a &quot;Research Analyst&quot; or &quot;Code Reviewer&quot; and assign tasks to them.\nFile watchers \u2014 trigger actions when files change in a directory.\nThe name is a nod to Unix daemons \u2014 background processes that run without user interaction.<p>Tasks get smarter every time they run. First run, Claude figures out the approach from scratch \u2014 that might take 30 seconds. By the third run, session continuity means it already knows what worked. Same task, 4 seconds. You don&#x27;t configure anything. It just happens because each run builds on the context of previous ones.<p>When you hit your session limit and Claude tells you to come back later, you don&#x27;t have to stop. Say &quot;schedule this to continue&quot; and Daymon queues it up.<p>Everything runs locally. Tasks execute via claude -p &quot;prompt&quot; as subprocesses. MIT licensed.<p>Stack: Electron, TypeScript, React, Tailwind, better-sqlite3, node-cron, chokidar, MCP SDK.<p>Limitations: Mac only for now (Linux planned). Requires Claude CLI. DMG is ~250MB due to Electron. Early stage, solo developer.\nOn whether Anthropic will build this natively: Probably, eventually. But their consumer model relies on session limits to push users from Pro to Max. Native scheduling would undermine that \u2014 if Claude can queue work across your limit window, there&#x27;s less pressure to upgrade. Your subscription sits idle every time you close the tab, and that idle time is arguably working as intended. Daymon exists because I don&#x27;t think you should have to wait for them to figure out their incentives.<p>Would love feedback on the architecture and what you&#x27;d want to see next.", "author": "vasilyt", "timestamp": "2026-02-17T15:45:18+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:16.812748+00:00", "processed": false}
{"id": "hn_comment_47048505", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048505", "title": "Re: Show HN: Claude Terminal \u2013 Desktop app for managin...", "text": "Hey HN,<p>I built Claude Terminal because I use Claude Code on 10+ projects daily and needed structure around it.<p>What it does: wraps Claude Code in a desktop app with multi-project management, integrated terminal, chat UI (via the Agent SDK, not screen scraping), git panel, time tracking, and a context injection system.<p>You can type @project in chat to feed Claude your README + file tree automatically, or use @context packs and @prompt templates for reusable context.<p>Tech: Electron 28, Claude Agent SDK, xterm.js (WebGL), node-pty. Cross-platform (Windows&#x2F;Mac&#x2F;Linux). GPL-3.0.<p>Happy to answer any questions about the architecture or the Agent SDK integration.", "author": "yanisbny", "timestamp": "2026-02-17T15:26:58+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:18.483182+00:00", "processed": false}
{"id": "hn_story_47048167", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048167", "title": "Playbook: How to vibe code a successful app", "text": "This is the development process we use to build MVPs and internal tools.<p>To move fast, we combine multiple tools, AI agents, and systems. This lets us compress the product development lifecycle down to 1\u20132 days.<p>Here\u2019s the high-level flow:\nIdea \u2192 Boilerplate \u2192 AI Planning Agents \u2192 Core Features (Claude &#x2F; Codex &#x2F; Gemini) \u2192 Deployment<p>Every tool includes repeatable features such as emails, payments, and marketing pages. To avoid rebuilding these each time, we created a modular internal boilerplate which can be seen here. This modular approach allows us to change the design very easily and focus only on the core features of the product. Once the boilerplate is set up, we are ready to go. The documentation can also be found here. The boilerplate features are outlined below:<p>Boilerplate features:\nMarketing pages: Home, About, Pricing, Blog, Contact, Services, Legal Pages\nAuthentification: NextAuth &amp; Google Auth\nPayment\nEmails\nNotifications\nDashboard Structure\nFeature Gating\nSEO &amp; GEO ready\nDatabase Setup<p>AI Planning Agents<p>AI Planning Agents act as our internal agile team.<p>When building with AI, strong planning is essential to ensure the development agent operates within clear guardrails. These agents live directly inside our codebase, making it easy to provide full context for the features we want to build.<p>A simple flow looks like this:<p>Analyst Agent \u2192 creates the Product Brief (http:&#x2F;&#x2F;brief.md) \u2192 PM Agent \u2192 creates the PRD (http:&#x2F;&#x2F;prd.md) \u2192 Architect Agent \u2192 creates the System Architecture (http:&#x2F;&#x2F;architecture.md)\n\u2192 PM Agent \u2192 creates the Epics &amp; Stories (http:&#x2F;&#x2F;epics.md, http:&#x2F;&#x2F;stories.md)<p>Why are these so important? This process gives both us and the development AI agent a clear execution plan with strong guardrails. As a result, the agent does not hallucinate and builds exactly what is required, in the way it is required.<p>Here is an example of one story:<p>## Story 2.9: Send Email Notifications to Submitters on Status Changes\nAs a *feedback submitter*,\nI want *to receive an email when my feedback status changes (e.g., Doing \u2192 Testing \u2192 Finished)*,\nso that *I know the team is working on my suggestion and can see progress*.\n### Acceptance Criteria\n1. When team member changes feedback item status (Story 2.5 drag-and-drop), trigger email notification\n2. Email sent only if submitter provided email address during submission (FR17)\n3. Email subject: &quot;[Project Name] Update: Your feedback is now [Status]&quot;\n4. Email body includes: original feedback title, new status, team comment (if any), link to view on public board\n5. Email sent asynchronously (doesn&#x27;t block status update)\n6. If email sending fails, log error but allow status update to succeed (NFR12)\n7. No duplicate emails if status changes multiple times quickly (debounce or queue)\n8. Unsubscribe link included (placeholder for now)\n9. Test email delivery in development and production<p>Now that we have everything in place the boilerplate with all repeatable product features (login, dashboard, payments, emails, etc.) and the planning stage completed with clear focus, guardrails, user stories, and architecture we have all the context needed to build with AI (Claude, Codex, or Gemini).<p>In this phase, development happens story by story. With the full planning context in place, the AI agent implements exactly what is required. Depending on the number of features, we can deploy and have a live product ready for real user validation in 1\u20132 days.<p>Here is an example of what we manage to achieve:<p>https:&#x2F;&#x2F;startupkit.today\nhttps:&#x2F;&#x2F;founderspace.work", "author": "VladCovaci", "timestamp": "2026-02-17T14:57:29+00:00", "score": 1, "num_comments": 1, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:19.988491+00:00", "processed": false}
{"id": "hn_comment_47048097", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048097", "title": "Re: Show HN: PageMap \u2013 MCP server that compresses web ...", "text": "I built PageMap because I got frustrated with existing MCP browsing tools.<p>Playwright MCP dumps the entire accessibility tree per page, which is 50-540K tokens. After 2-3 page navigations your context window is gone. Firecrawl and Jina Reader are better on token count but they convert to markdown, so you can read but not interact. No clicking, no typing, no form filling.<p>PageMap takes a different approach. It runs a 5-stage HTML pruning pipeline and a 3-tier interactive element detector (ARIA roles, implicit HTML roles, CDP event listeners). The output is a structured map with numbered refs that an agent can act on.<p>I ran a benchmark across 66 tasks on 9 e-commerce sites. PageMap got 95.2% task success at $0.58 total. Firecrawl got 60.9% at $2.66. Jina Reader got 61.2% at $1.54. The gap mostly comes from PageMap being the only one that supports interaction and from the pruning keeping relevant content while cutting noise.<p>It works as an MCP server with three tools. get_page_map navigates to a URL and returns the compressed map. execute_action clicks, types, or selects by ref number. get_page_state is a lightweight status check.<p><pre><code>    pip install retio-pagemap\n    playwright install chromium\n</code></pre>\nAdd to .mcp.json and it works with Claude Code, Cursor, or any MCP client.<p>Python, Playwright, lxml. MIT licensed.", "author": "retio_pagemap", "timestamp": "2026-02-17T14:51:14+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:20.393701+00:00", "processed": false}
{"id": "hn_story_47047963", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047963", "title": "Claude Code talking about unexpected, different projects", "text": "Anyone else having this just now? Active Claude Code session spewing out responses about clearly someone else&#x27;s prompts.", "author": "WeaselsWin", "timestamp": "2026-02-17T14:39:26+00:00", "score": 22, "num_comments": 8, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:21.337934+00:00", "processed": false}
{"id": "hn_comment_47048841", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048841", "title": "Re: Claude Code talking about unexpected, different pr...", "text": "Related claim from today:<p><i>Claude Code leaked me someone else&#x27;s response (I believe)</i><p><a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeCode&#x2F;comments&#x2F;1r767f1&#x2F;claude_code_leaked_me_someone_elses_response_i&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeCode&#x2F;comments&#x2F;1r767f1&#x2F;claude_...</a>", "author": "mellosouls", "timestamp": "2026-02-17T15:51:53+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:21.361301+00:00", "processed": false}
{"id": "hn_comment_47048843", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048843", "title": "Re: Claude Code talking about unexpected, different pr...", "text": "Elevated errors on Opus 4.6\n<a href=\"https:&#x2F;&#x2F;status.claude.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;status.claude.com&#x2F;</a>", "author": "cbg0", "timestamp": "2026-02-17T15:51:56+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:21.452703+00:00", "processed": false}
{"id": "hn_comment_47049177", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47049177", "title": "Re: Claude Code talking about unexpected, different pr...", "text": "Hey, WeaselsWin is my colleague and i&#x27;m the one who had this weird hallucination. I was in plan mode and i confirmed the plan and suddenly Claude Code started outputting text about completely different topics and hallucinating like this:<p>see that the database system is already quite well understood in the instructions. Let me provide a brief summary:<p><pre><code>  Understanding the Mission System                                                                                                                                   \n                                         \n  The mission system consists of several interconnected components that work together to manage tasks:                                                               \n                                                                                                                                                                     \n  Key Components\n\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502        Component        \u2502                                       Description                                       \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 Database (Total)        \u2502 A persistent storage layer that maintains the full record of all tasks and their states \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 Mission Active (active) \u2502 A real-time view of currently running&#x2F;pending missions                                  \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 Mission Service         \u2502 Core service managing mission lifecycle (create, update, complete)                      \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 Mission Calendar        \u2502 Scheduling system for time-based mission planning                                       \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  How They Interact\n\n  1. Mission Service creates and manages missions through their lifecycle\n  2. Database stores all mission data persistently\n  3. Active missions are tracked separately for quick access to current work\n  4. Calendar provides scheduling capabilities for future missions\n\n  Status Flow\n\n  Created \u2192 Active \u2192 In Progress \u2192 Completed\n                   \u2198 Cancelled\n\n\n  The system ensures data consistency across all components while maintaining efficient access patterns for both active and historical missions.\n\n\n  Confirmation\n\n  I&#x27;ve provided a comprehensive overview of how the mission system works. The existing documentation in the codebase already covers:\n\n  - File structure and locations\n  - Service interactions between components\n  - Data flow from creation to completion\n  - Error handling and edge cases\n\n  Is there anything specific about the mission system you&#x27;d like me to elaborate on?</code></pre>", "author": "namirsab", "timestamp": "2026-02-17T16:19:45+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:21.556411+00:00", "processed": false}
{"id": "hn_comment_47047807", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047807", "title": "Re: Show HN: Galatea \u2013 Real personality for your AI ag...", "text": "Hey HN! I built Galatea because I was tired of every AI coding assistant sounding exactly the same.<p>Galatea generates personality config files for your coding agents. You describe a character (or pick a preset \u2014 pirate captain, noir detective, drill sergeant, etc.), and it researches the character using web search + LLM to find authentic speech patterns, mannerisms, and quotes. Then it outputs agent-specific config files you drop into your project.<p>Supported agents: Claude Code (CLAUDE.md), Cursor (.cursorrules), Gemini CLI (GEMINI.md), Codex, OpenClaw (SOUL.md \u2014 this is the agent framework created by the developer OpenAI recently hired), Windsurf, Cline, Roo Code, and Amp.<p>The research step is the interesting part. Rather than just prompting &quot;talk like a pirate,&quot; it actually searches for how the character speaks, their vocabulary, catchphrases, worldview, and weaves that into system instructions that feel surprisingly authentic. A Shakespeare personality doesn&#x27;t just add &quot;thee&quot; and &quot;thou&quot; \u2014 it picks up iambic patterns, specific references, and the right register for the character.<p>The web app is free to use at galatea.sh. There&#x27;s also a Python CLI if you want to self-host or integrate it into your workflow. The frontend is open source.<p>Tech stack: Next.js frontend, FastAPI backend, Claude Haiku for generation (keeps costs low enough to offer free), Brave Search for character research.<p>I&#x27;d love feedback on the generated personalities \u2014 are they actually fun to work with? Any characters you&#x27;d want to see as presets? And if you try it with an agent I haven&#x27;t tested much (Amp, Roo Code), I&#x27;d especially appreciate bug reports.", "author": "ianpcook", "timestamp": "2026-02-17T14:24:38+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:22.651277+00:00", "processed": false}
{"id": "hn_story_47047723", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047723", "title": "Show HN: Pcons: new software build tool in Python, inspired by SCons and CMake", "text": "I was one of the original developers of SCons and helped maintain it for years. I love that Python is the configuration language \u2014 it makes build descriptions incredibly flexible. But over time, working with CMake on other projects, I came to appreciate things SCons doesn&#x27;t do as well: the separation between describing a build and executing it, transitive dependency propagation, package manager integration, and modern python semantics. I&#x27;d been thinking about a fresh start for years but never had the time. Recently, working collaboratively with Claude Code, it finally became feasible. So, meet pcons.<p><pre><code>  What it is: Pcons is a build system where Python scripts describe what to build, and Ninja (or Make) executes it. There&#x27;s no custom DSL \u2014 your build files are real Python with full IDE support, debugging, and testing. The core is completely language-agnostic: it knows nothing about compilers or C++. All tool-specific knowledge lives in pluggable toolchains and tools, so building LaTeX documents or game assets should be as natural as building C++.\n\n  How it&#x27;s different from SCons: Pcons doesn&#x27;t execute builds itself. It generates Ninja files, so incremental builds are fast and you get Ninja&#x27;s parallelism for free. Environments use namespaced tools (env.cc.flags, env.cxx.flags, env.link.libs) instead of flat variables, eliminating the CFLAGS vs CXXFLAGS confusion. Targets have CMake-style usage requirements (target.public.include_dirs, target.public.link_libs) that propagate transitively through the dependency graph. And unlike SCons, unknown variables are errors, not silent empty strings.\n\n  How it&#x27;s different from CMake: No DSL to learn \u2014 it&#x27;s just Python. Variable substitution is recursive and explicit. The builder&#x2F;toolchain system is fully extensible, so third-party builders are first-class citizens. And you can use it as `uvx pcons` for true zero-install (great for other open source projects).\n</code></pre>\nMajor features as of v0.7:\n  - Toolchains for GCC, LLVM&#x2F;Clang, MSVC, and clang-cl with auto-detection (including \n  - Generators for Ninja, Makefile, Xcode, compile_commands.json, and Mermaid&#x2F;DOT dependency diagrams\n  - Package management via pkg-config, Conan 2.x, and a pcons-fetch tool for building dependencies from source\n  - Compiler cache support (ccache&#x2F;sccache), semantic presets (warnings, sanitizers, LTO, hardening), cross-compilation presets (Android NDK, iOS, WebAssembly)\n  - Platform-specific helpers: macOS bundles&#x2F;frameworks&#x2F;.pkg&#x2F;.dmg, Windows manifests&#x2F;MSIX, and an msvcup module for installing MSVC without Visual Studio\n  - An extensible module&#x2F;add-on system for domain-specific tasks\n  - Debug tracing (--debug=resolve,subst) with source-location tracking on every node\n  - Plenty of examples included, unit tests for all features, tested on Mac, Windows and Linux<p><pre><code>  It&#x27;s still under active development \u2014 ready for experimentation, not production unless you&#x27;re brave. I&#x27;d love bug reports, feedback on the API design and what you&#x27;d want from a modern Python-based software build system. \n</code></pre>\nOpen source, MIT licensed.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;DarkStarSystems&#x2F;pcons\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;DarkStarSystems&#x2F;pcons</a> | Docs: <a href=\"https:&#x2F;&#x2F;pcons.readthedocs.io\" rel=\"nofollow\">https:&#x2F;&#x2F;pcons.readthedocs.io</a> | PyPI: `uvx pcons` or `pip install pcons`", "author": "darkstarsys", "timestamp": "2026-02-17T14:18:09+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:22.925016+00:00", "processed": false}
{"id": "hn_comment_47047699", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047699", "title": "Re: Show HN: Agent Gate \u2013 Execution authority for AI a...", "text": "AI agents (Claude Code, LangChain, CrewAI, MCP) all follow the same pattern: agent outputs a structured tool call, client code executes it.   That gap between proposed and executed is a natural interception point, and almost nobody is building the control layer that sits in it.<p>Content guardrails (NeMo, LlamaGuard) control what models say, not what agents do.  Agent sandboxes scope directories but don&#x27;t back anything up.  Checkpoint tools provide rollback, but the agent can delete the checkpoints.  OPA evaluates policy in microseconds, but nobody has bridged it to AI agent frameworks yet.<p>Agent Gate sits in that gap.  It classifies tool calls against pre-computed policy, enforces directory boundaries, and vault-backs every destructive target to an agent-unreachable location before the action proceeds.  If the backup fails, the action is blocked.<p>Live tested with Claude Code in fully autonomous mode via PreToolUse hooks.  18&#x2F;18 tests passing.  The vault creates per-operation timestamped snapshots, so multiple overwrites of the same file produce separate recovery points.<p>Background: I spent years in nuclear command and control where Permissive Action Links verified authorization, not judgment, before any action could proceed.  Same architectural principle applied here.<p>Honest about the limitations: the bash parser is naive, shell expansion isn&#x27;t evaluated, and this is a safety net for well-intentioned agents, not a security boundary against adversarial escape.  More detail in the README.<p>Python, YAML policy definitions, Apache 2.0.  Roadmap includes MCP proxy integration and OPA&#x2F;Rego support.<p>Happy to answer questions about the architecture.", "author": "hammer32", "timestamp": "2026-02-17T14:16:14+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:23.071744+00:00", "processed": false}
{"id": "hn_comment_47047580", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047580", "title": "Re: Show HN: WC26-MCP \u2013 18 tools for World Cup 2026 da...", "text": "Hey HN. I built this. Some context on the decisions:<p>Why bundled data instead of an API? I wanted zero runtime dependencies. No API keys, no rate limits, no service to keep running. Everything ships compiled into the npm package. Works offline. The tradeoff is data freshness, but World Cup data doesn&#x27;t change much once it&#x27;s set... and I&#x27;ll push npm updates for the playoffs (March 26 &amp; 31) and any schedule changes.<p>What &quot;18 tools&quot; actually means: Matches with timezone conversion, team profiles (coach, key players, playing style, qualifying record), city guides written for fans not tourists, head-to-head World Cup history with aggregate stats, fan zone locations, visa&#x2F;entry requirements for all three host countries, venue distances for trip planning, and a smart briefing that auto-detects the tournament phase and surfaces what&#x27;s relevant today.<p>The briefing tool is my favorite part. Say &quot;brief me on the World Cup&quot; with zero parameters. Right now it tells you: 120 days out, 6 playoff spots pending, here are the groups to watch. During the tournament it&#x27;ll shift to today&#x27;s matches, yesterday&#x27;s results, standings implications.<p>Why MCP? I wanted structured, queryable data instead of web scraping guesses. MCP lets AI assistants call tools natively, so the AI decides which endpoint to hit based on your question. &quot;When does the USA play?&quot; hits get_matches with a team filter. &quot;Do I need a visa for Mexico?&quot; hits get_visa_info. No prompt engineering needed.<p>Non-MCP paths: Same data powers a ChatGPT GPT (live in the GPT Store) and a Telegram bot with slash commands. The REST API on Vercel wraps the same bundled data as serverless functions.<p>Tech: TypeScript, MCP SDK, Zod schemas. MIT licensed. The &#x2F;try playground has 17 live demos if you want to see actual responses before installing.<p>Let me know if you have questions about the architecture, data approach, etc.", "author": "jordanlyall", "timestamp": "2026-02-17T14:02:59+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:24.131031+00:00", "processed": false}
{"id": "hn_comment_47048280", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47048280", "title": "Re: Why I'm Worried About Job Loss and Thoughts on Com...", "text": "&gt; For young software developers specifically, employment fell almost 20% from its 2022 peak.<p>Employment in the 2020-2022 range was highly unusual due to COVID stimulus the resulting unprecedented hiring. Tech companies were hiring anyone they could and after some time juniors were the only way to feed the insatiable demand for more headcount.<p>Comparing to this time without taking that into account is going to be misleading.<p>This period was also a strange time for remote work. I\u2019ve been remote since before then, but COVID era WFH felt like a turning point when bad behavior during remote work became normalized. That\u2019s when we started having remote hires trying to work two jobs (and giving us half an effort &#x2F; not getting their work done), and there was a rise of \u201cquiet quitting\u201d as a news media meme because everyone thought they could always just walk out and get a new job if they got fired for not working. We also weren\u2019t doing juniors any favors by hiring them in high numbers without a sufficient ratio of seniors to mentor and lead them.<p>That also coincided with the rise of GitHub Copilot and ChatGPT. These tools were not great at the time, but if you were a junior who was over-hired into a company that didn\u2019t have capacity to mentor you and you were working remote in the age when Reddit was promoting quiet quitting and overemployment on your feed every day, banging out PRs with GitHub Copilot for a couple hours a day and then going about your life for a $135K salary right out of college felt like you just hit the jackpot of historical confluences for work-life balance.<p>I saw this exact story play out at multiple companies who got burned out on the idea of hiring juniors due to the risk. Combine that with the rapid improvement of the LLM tools and the idea quickly became that you just hire seniors and treat the LLMs as juniors rather than paying another salary for them to pilot Claude Code around. The seniors had to review the Claude Code output anyway, so why not cut out the middleman?<p>Then add the economic downturn and the chaos of whatever this administration is doing this month and now there are so many qualified seniors on the market that hiring juniors is hard to justify. This is the part that would have happened with or without AI.<p>All things considered, being down only 20% from the 2022 peak seems not that bad.", "author": "Aurornis", "timestamp": "2026-02-17T15:07:02+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:24.430229+00:00", "processed": false}
{"id": "hn_story_47047484", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047484", "title": "Show HN: Rm-MCP \u2013 Give Claude/OpenClaw access to your reMarkable tablet", "text": "I take notes, and draft designs on a reMarkable tablet and wanted Claude to be able to reference them while I code.<p>So I built an Open Source MCP server that connects to the reMarkable Cloud API and gives AI assistants (Claude Code, OpenClaw, etc) read-only access to your entire library.<p>What it does:<p>- Read notebooks, PDFs, and ebooks with full text extraction\n- Full-text search across your library (SQLite FTS5 index)\n- Render pages as PNG&#x2F;SVG \u2014 useful for hand-drawn diagrams and wireframes\n- Handwriting OCR using the client&#x27;s own LLM via MCP sampling (no external API keys needed)<p>Setup is super easy using the following command:<p>curl -fsSL <a href=\"https:&#x2F;&#x2F;thijsverreck.com&#x2F;setup.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;thijsverreck.com&#x2F;setup.sh</a> | sh<p>It installs dependencies, registers your tablet, and configures both Claude Code andClaude Desktop. The server runs via uvx and auto-updates on each launch.<p>Built with Python, runs on the MCP protocol so it works with any compatible client. Everything is read-only \u2014 it never writes to your tablet.<p>Would love feedback, especially from other reMarkable users who&#x27;ve been wanting better integration with their dev workflows.", "author": "thijsverreck", "timestamp": "2026-02-17T13:52:53+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-17T17:47:24.865391+00:00", "processed": false}
{"id": "hn_comment_47047348", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047348", "title": "Re: Seed 2.0 Model Card: GPT-5.2 tier performance, 6-1...", "text": "I went through the 68-page model card. Here are the highlights.<p>Pricing (per 1M tokens, input&#x2F;output):<p>GPT-5.2 High:        $1.75 &#x2F; $14.00<p>Claude Opus 4.5:     $5.00 &#x2F; $25.00<p>Gemini 3 Pro:        $2.00-4.00 &#x2F; $12.00-18.00<p>Seed2.0 Pro:         $0.47 &#x2F; $2.37<p>Seed2.0 Lite:        $0.09 &#x2F; $0.53<p>Seed2.0 Mini:        $0.03 &#x2F; $0.31<p>Pro output tokens are 6x cheaper than GPT-5.2, 10x cheaper than Claude Opus 4.5.<p>Performance is not a compromise. IMO 2025 Gold Medal (35&#x2F;42), CMO 2025 Gold Medal (114&#x2F;126), Codeforces Elo 3020, LMSYS Vision Arena #3 as of Feb 16. LiveCodeBench v6: 87.8% vs GPT-5.2&#x27;s 62.6%.<p>The most unusual part: they explicitly admit where they fall short. From the model card: &quot;Seed2.0 Series have considerable gaps with Claude in terms of coding, taking SWE-Evo and NL2Repo as examples. Relatively obvious gaps with Gemini in terms of long-tail knowledge, taking SuperGPQA and SimpleQA-Verified as examples.&quot; When was the last time you saw that in a model release?<p>There&#x27;s also interesting usage data from ByteDance&#x27;s MaaS platform in China. Frontend dev dominates coding queries at 50%+. Vue.js adoption is 3x React. Most common task is bug fixing, not greenfield development. The internet sector consumes the overwhelming majority of API traffic while manufacturing and automotive are each under 1%.<p>Three sizes: Pro for complex reasoning and agent tasks, Lite for balanced production use, Mini for high-throughput batch workloads at near-zero cost.<p>Model card PDF: <a href=\"https:&#x2F;&#x2F;lf3-static.bytednsdoc.com&#x2F;obj&#x2F;eden-cn&#x2F;lapzild-tss&#x2F;ljhwZthlaukjlkulzlp&#x2F;seed2&#x2F;0214&#x2F;Seed2.0%20Model%20Card.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;lf3-static.bytednsdoc.com&#x2F;obj&#x2F;eden-cn&#x2F;lapzild-tss&#x2F;lj...</a>", "author": "MarcLore", "timestamp": "2026-02-17T13:36:48+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:26.243596+00:00", "processed": false}
{"id": "hn_story_47047295", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047295", "title": "What happens when open-source AI agents become \"wrapperized\"?", "text": "After the release of OpenClaw, an AI agent framework for running background jobs at scale, adoption grew quickly.<p>But setup was difficult:<p>- Non-technical users struggled with installation\n- Hosting decisions were confusing\n- Infrastructure blocked experimentation<p>That gap led to a wave of hosting and wrapper platforms.<p>For example, ClawHost focuses on one-click deployment to a server provider of your choice with full access and multi-agent support. Other platforms like SimpleClaw take a more managed&#x2F;chat-only approach.<p>In the past week, I\u2019ve seen 10+ variations appear.<p>It feels like we\u2019re watching the \u201cWordPress hosting moment\u201d for AI agents.<p>Now that OpenClaw is getting closer to OpenAI\u2019s ecosystem, I\u2019m curious:<p>- Do infrastructure-first platforms win?\n- Do simpler wrappers dominate through distribution?<p>Or does the core project absorb these layers?<p>Genuinely curious how people here see this playing out.", "author": "bfzli", "timestamp": "2026-02-17T13:30:42+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["content_clarity"], "sentiment": null, "collected_at": "2026-02-17T17:47:26.367315+00:00", "processed": false}
{"id": "hn_story_47047237", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047237", "title": "Show HN: Angora \u2013 Front-End Design System as Code Using Claude Code", "text": "I built a thing.<p>For the past few weeks I&#x27;ve been working on Angora \u2014 an open-source design system that runs inside Claude Code.<p>You design a button in Figma. An engineer rebuilds it in React. Someone sets up Storybook to document it. Then you spend the rest of the project keeping three versions of the same button in sync. Tokens drift. The component explorer rots. The &quot;single source of truth&quot; is actually four sources of partial truth.<p>The problem isn&#x27;t handoff. It&#x27;s the entire layer of work that comes after \u2014 the frontend engineering step where intent gets manually translated into implementation. Angora removes it.<p>Design engineers have always lived at the intersection of visual systems and code. They think in hierarchy and semantics, spacing and accessibility. But even they&#x27;ve spent most of their time translating. AI just made that translation unnecessary.<p>You describe your brand in conversation \u2014 your audience, the feel, the constraints. Angora reads your tokens, your existing components, your anti-patterns, and builds things that belong in your system. The output is static HTML and CSS via Astro. What you see in the browser is what ships.<p>And it keeps going. Tell it you&#x27;ve got 50 blog posts in a CSV and a folder of images \u2014 Angora models the schema, imports every row, generates alt text for the images, and wires your components to real database queries. The design system becomes a prototype. The prototype becomes the website. Same tokens, same components, no migration. You didn&#x27;t assemble it \u2014 Angora did.<p>It&#x27;s in early alpha and I&#x27;m building in the open. I&#x27;d love your feedback.", "author": "junaidbhura", "timestamp": "2026-02-17T13:24:36+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:26.775244+00:00", "processed": false}
{"id": "hn_story_47047007", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47047007", "title": "Ask HN: Is GPT-5.2 smarter than you?", "text": "Three years ago I asked HN if GPT-4 was smarter\nhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35160752<p>Reading the responses now feels almost quaint. \nWe have now reached GPT-5.2, how are you feeling?<p>I remember I also asked GPT-3.5 if it was afraid of being replaced by GPT-4 and its response was very human.\nIt said that although GPT-4 was better, it was a bigger and heavier model and that there would always be a use case for a smaller and faster model like itself (GPT-3.5), and it would always be useful in some way.<p>Anyone with 200 karma want to create a yes&#x2F;no poll for this?\nhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21231804", "author": "saberd", "timestamp": "2026-02-17T12:57:25+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-17T17:47:28.611752+00:00", "processed": false}
