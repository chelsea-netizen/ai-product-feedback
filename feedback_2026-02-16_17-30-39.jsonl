{"id": "hn_story_47037709", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47037709", "title": "Show HN: AsdPrompt \u2013 Vimium-style keyboard navigation for AI chat responses", "text": "I use Claude throughout the day and kept getting annoyed by the same thing: selecting text from responses with the mouse. Overshoot, re-select, copy, click input, paste. Especially bad in long conversations where you want to reference something from 30 turns ago.<p>asdPrompt is a Chrome extension that adds hint-based navigation (like Vimium) to AI chat interfaces. Cmd+Shift+S activates the overlay, hint labels appear next to every text block. Type a letter to select a block, then keep typing to drill down: block \u2192 sentence \u2192 word. Enter copies, or you can press an action key (e, d, x) to inject a follow-up prompt (&quot;elaborate on [selection]&quot;) directly into the chat input.<p>Works on claude.ai, chatgpt.com, and gemini.google.com. Adapts to light&#x2F;dark themes. Free. Built the initial MVP in 2 days using Claude Code \u2014 the adapter architecture, NLP segmentation pipeline, and Playwright test harness would have taken a month without it.<p>Tech details for the curious: site-specific DOM parsers behind an adapter interface, text segmentation via compromise.js with regex fallbacks for technical content (paths, camelCase break NLP libraries), bounding rectangles calculated via Range API + TreeWalker, overlay isolated in Shadow DOM. Tested with Playwright visual regression.<p>The landing page has an interactive tutorial where you can try the full drill-down mechanic without installing. Happy to talk about the implementation.", "author": "contrary2belief", "timestamp": "2026-02-16T17:28:32+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:39.862096+00:00", "processed": false}
{"id": "hn_comment_47037465", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47037465", "title": "Re: Flare: Visual CSS editor that generates prompts fo...", "text": "Have been talking to more designers recently that are starting to experiment with claude code for prototyping.\nA common pattern was that removing the coding step was a wow moment, but tweaking designs was hard.<p>Cursors design mode solves more or less solves this for cursor, but we need something generic. Flare is an attempt of making a general solution for this problem, simply integrating into any app and giving you your changes as a ready-to-paste prompt.<p>There&#x27;s plenty of potential for expanding this, text-editing, more css compatibility, adding new components, mcp server for directly injecting the changes and more.<p>Would love to hear your feedback and thoughts!", "author": "joshuaknauber", "timestamp": "2026-02-16T17:05:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:40.310152+00:00", "processed": false}
{"id": "hn_story_47037280", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47037280", "title": "Show HN: CabbageSEO: Check if AI mentions your business, then fix it if not", "text": "I built a tool that scans AI platforms with buyer questions relevant to your domain and shows you whether they mention you or not.<p>Enter your domain, it generates queries based on your space, sends them to ChatGPT, Perplexity, and Google AI, then scores you out of 100 based on how often you show up in the responses.<p>The part I think is actually useful: it doesn&#x27;t just tell you the problem. It shows you which queries you&#x27;re missing from, why, and gives you fix pages (structured content designed to be citable by LLMs) and weekly action plans.<p>Free scan on the homepage, no signup needed.<p>Tech: Next.js, Supabase, OpenAI API, Perplexity API, Google AI API.<p><a href=\"https:&#x2F;&#x2F;www.cabbageseo.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cabbageseo.com</a>", "author": "arjun060601", "timestamp": "2026-02-16T16:53:11+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt", "perplexity"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:40.773786+00:00", "processed": false}
{"id": "hn_story_47037267", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47037267", "title": "Show HN: Comfy Pilot \u2013 MCP server that lets Claude Code edit ComfyUI workflows", "text": "MCP server + embedded terminal that gives Claude Code direct access to ComfyUI&#x27;s workflow graph. It can search available nodes, create&#x2F;connect&#x2F;delete them, set values, run the queue, and see image outputs. The workflow is basically a JSON DAG, so each edit maps cleanly to a tool call.", "author": "0xConstantine", "timestamp": "2026-02-16T16:51:51+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:40.788577+00:00", "processed": false}
{"id": "hn_story_47036960", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47036960", "title": "Show HN: Million Dollar Chat", "text": "Inspired by the Million Dollar Homepage, this is the Million Dollar Chat. People fill the chat&#x27;s one million character brain, one character at a time. The Million Dollar Homepage of the AI age.<p>My initial design used one million tokens but I quickly discovered that tokens are not made equal which made it very difficult to reason about. Eventually, I settled on one million characters.<p>The chat has a few different capabilities, for example, you can ask it to navigate to a position for you (e.g: &quot;jump to the final character&quot;) and it can search within the context. I have more things to add, like the ability to play music from the songs included in its context.<p>Other visitor&#x27;s cursors can be seen in real-time when they are adding to the chat&#x27;s brain.<p>Despite the fact that this is an AI project, I built it by hand. I tried out Claude Code and Codex but neither produced code I was happy with.<p>The current model is openai&#x2F;gpt-4.1-nano. I figure, people paying to add characters will subsidise chatter&#x27;s free access to the model.", "author": "shrink", "timestamp": "2026-02-16T16:26:36+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:41.463828+00:00", "processed": false}
{"id": "hn_story_47036656", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47036656", "title": "Show HN: Multi-provider iOS usage alerts for AI subscription caps", "text": "I built AI Usage Tracker, an iOS app that warns you before AI subscription limits cut you off mid-session (e.g. 5-hour windows, weekly caps).\nI hit this daily while coding: I\u2019d be deep in a session and suddenly hit the cap. Dashboards exist, but they\u2019re not glanceable and there are no practical alerts&#x2F;widgets.\nSupports multiple providers in a single screen - Anthropic, OpenAI, MiniMax, Z.ai, Kimi, Codex<p>Features:<p>- 5-hour window + weekly status (simple gauges). Makes easy to plan your workload across providers<p>- reset countdown timers<p>- Home Screen + Lock Screen widgets<p>- configurable alerts (e.g. 75%, 90%)<p>- multi-provider tracking<p>Privacy &#x2F; how it works:<p>- no accounts, no analytics, no servers; everything runs on-device<p>- API-key providers: paste an API key (stored in iOS Keychain)<p>- dashboard-only providers: sign in via an embedded web view OR paste an existing session token; the app reads the same usage info shown in the provider dashboard<p>- connectors may break if dashboards&#x2F;endpoints change<p>Not a bypass \u2014 it only provides status + alerts so you can plan sessions.<p>I\u2019d love feedback on:<p>- which thresholds are actually useful<p>- % remaining vs time remaining<p>- security&#x2F;UX tradeoffs: embedded login vs session-token paste", "author": "afonsoduarte", "timestamp": "2026-02-16T15:59:18+00:00", "score": 1, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:42.186509+00:00", "processed": false}
{"id": "hn_story_47036011", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47036011", "title": "Show HN: API router that picks the cheapest model that fits each query", "text": "I got frustrated paying $60&#x2F;M tokens for reasoning queries when a $0.80&#x2F;M model gives comparable results for most of them. So I built Komilion \u2014 a model router that classifies each API request and routes it to a cheaper model that fits.<p>- Drop-in replacement for the OpenAI SDK (change one line: base_url)\n- Each query gets classified (regex fast path + lightweight LLM classifier) and matched against ~390 models\n- Three tiers (Frugal&#x2F;Balanced&#x2F;Premium) to control the quality-cost tradeoff\n- Automatic failover if a provider goes down\n- Cost metadata in every response<p>The routing logic is benchmark-driven (LMArena, Artificial Analysis), not ML-based \u2014 simpler to debug and reason about. The regex fast path handles ~60% of requests in under 5ms with zero API calls.<p>Example: a customer support bot doing 10K conversations&#x2F;month went from ~$250&#x2F;mo (everything pinned to Opus 4.6) to ~$40&#x2F;mo with routing. Most conversations were FAQ-level questions that a smaller model handled fine.<p>Stack: Next.js, Vercel, Neon PostgreSQL, OpenRouter upstream. Hosting cost: ~$20&#x2F;month.<p>We ran a head-to-head benchmark: same 15 prompts through Opus, GPT-4o, Gemini Pro, and the router. Simple tasks cost 66% less with routing. Complex tasks produced 2x more detailed output because the router picked specialized models per task type. Full data: <a href=\"https:&#x2F;&#x2F;dev.to&#x2F;robinbanner&#x2F;we-benchmarked-4-ai-api-strategies-with-real-money-the-results-changed-how-we-think-about-model-5coa\" rel=\"nofollow\">https:&#x2F;&#x2F;dev.to&#x2F;robinbanner&#x2F;we-benchmarked-4-ai-api-strategie...</a><p>Architecture writeup: <a href=\"https:&#x2F;&#x2F;dev.to&#x2F;robinbanner&#x2F;inside-komilions-architecture-how-we-route-ai-requests-across-394-models-3e5g\" rel=\"nofollow\">https:&#x2F;&#x2F;dev.to&#x2F;robinbanner&#x2F;inside-komilions-architecture-how...</a> \u2014 there&#x27;s a free tier if you want to try it.", "author": "robinbanner", "timestamp": "2026-02-16T15:11:25+00:00", "score": 1, "num_comments": 1, "products": ["chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:44.143744+00:00", "processed": false}
{"id": "hn_comment_47036018", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47036018", "title": "Re: Show HN: API router that picks the cheapest model ...", "text": "Backstory: I was building a customer support AI for a client last year. We started with Claude Opus for everything because it worked great. The bill was $250&#x2F;month for maybe 10K conversations.<p>Then I looked at the actual queries. 70% were things like &quot;what are your hours?&quot; and &quot;how do I return something?&quot; \u2014 questions where a $0.80&#x2F;M-token model gives the same answer as a $15&#x2F;M-token model. But about 5% were genuinely complex (multi-step troubleshooting, product comparisons requiring reasoning) where Opus was noticeably better.<p>I started manually routing: simple patterns to a cheap model, everything else to Opus. The bill dropped to $40&#x2F;month with no quality complaints from users. But maintaining the routing logic across projects got tedious \u2014 every new app needed the same classification + model selection + failover logic.<p>So I built Komilion to package it up. The classification runs in two stages:<p>1. A regex fast path catches ~60% of requests instantly (greetings, FAQ patterns, simple classification tasks). Zero API calls, under 5ms.<p>2. For the rest, a lightweight LLM classifier determines task type and complexity, then matches against a routing table built from LMArena and Artificial Analysis benchmark data.<p>What surprised me in the benchmark data: complex tasks through the router actually produced MORE detailed output than any single pinned model (6,614 chars avg vs 3,573 for Opus). The router selects specialized models per task type rather than using a generalist model for everything.<p>Stack: Next.js on Vercel, Neon PostgreSQL, OpenRouter upstream. Total hosting cost ~$20&#x2F;month. It&#x27;s a solo project.<p>The thing I&#x27;d do differently: I should have started with the benchmark data instead of building the product first. The numbers make the case better than any feature list.<p>Happy to answer technical questions about the routing logic, benchmark methodology, or anything else.", "author": "robinbanner", "timestamp": "2026-02-16T15:11:36+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:44.177427+00:00", "processed": false}
{"id": "hn_comment_47035608", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47035608", "title": "Re: Pentagon Threatens Anthropic Punishment...", "text": "&quot;Defense Secretary Pete Hegseth is &#x27;close&#x27; to cutting business ties with Anthropic and designating the AI company a &#x27;supply chain risk&#x27; \u2014 meaning anyone who wants to do business with the U.S. military has to cut ties with the company, a senior Pentagon official told Axios.&quot;", "author": "defmacr0", "timestamp": "2026-02-16T14:43:25+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:45.379316+00:00", "processed": false}
{"id": "hn_story_47035304", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47035304", "title": "Show HN: Claude Battery \u2013 usage at a glance. A minimalist macOS menu bar widget", "text": "Hi HN, this is nothing fancy, but a tool I built for myself as a minimalist way to track usage. Also (and probably more importantly), colleagues who are marketers, writers, designers, and other non-engineering backgrounds who are&#x2F;becoming power users of Claude Cowork or Claude Code and needed to keep better watch of usage.<p>Once Opus 4.6 landed, I was quickly aware I needed to keep an eye on usage as I capped out session limits faster than ever. I got frustrated checking usage manually and then explored the other apps and widgets out there. They&#x27;re really good, and some are great, but they&#x27;re just so feature-heavy and complex with that ICP in mind I mentioned earlier.<p>Tokens just don&#x27;t feel like anything to me.... I&#x27;d watch them tick over in the thousands and then millions. So I just ignored them as I was planning and then inverted the usage metrics that Claude provides (i.e. start at 100% and not 0%), which helped me land on a battery concept. This felt good and definitely made sense to the people I asked. Then I was focused on adding only the bare minimum features... or &quot;Simplify, and add lightness&quot; in the words of Colin Chapman.<p>Anyway, that&#x27;s the story and yes, the app is largely vibe coded before folks start to go digging through commits. I quite enjoyed the process and I wouldn&#x27;t have hand-coded something like this myself (the issue-pain wouldn&#x27;t have met the effort-required threshold). If anyone is curious, my workflow and tools used were Claude Code, with ui-ux-pro-max for design, heavy usage of compound-engineering (plan &gt; work &gt; review &gt; compound). Strongly recommend this plugin. I also used Condcutor on and off, but 80% of the work ended up just being done with CC in iTerm2. It handled the agent teams much better.<p>Let me know if you have any bugs or feedback.", "author": "Reebz", "timestamp": "2026-02-16T14:21:45+00:00", "score": 1, "num_comments": 4, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-16T17:30:46.243085+00:00", "processed": false}
{"id": "hn_story_47035076", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47035076", "title": "AI-powered Git CLI that generates commit messages automatically", "text": "I got tired of context-switching to write commit messages and PR descriptions,\nso I built gut \u2013 a CLI that uses AI to handle the boring parts of git workflows.<p>Examples:\n  gut commit     \u2192 generates commit message from staged diff\n  gut pr         \u2192 generates PR title and description\n  gut review     \u2192 AI code review of your changes\n  gut find &quot;login bug&quot; \u2192 finds commits by vague description\n  gut stash      \u2192 stash with auto-generated name<p>It focuses only on git operations, so responses come back in seconds.\nBYOK (Gemini, OpenAI, or Anthropic). Keys stored in system keychain.<p>Customizable via .gut&#x2F; templates per project.<p>GitHub: https:&#x2F;&#x2F;github.com&#x2F;user&#x2F;gut\nnpm: npm install -g gut-cli", "author": "gitton-dev", "timestamp": "2026-02-16T14:04:38+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:46.880447+00:00", "processed": false}
{"id": "hn_story_47035002", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47035002", "title": "Show HN: Codex HUD \u2013 Claude-HUD Style Status Line for Codex CLI", "text": "I built Codex HUD to make Codex CLI sessions easier to monitor without leaving the terminal.\n  It adds a real-time status line with:<p><pre><code>  - active model\n  - project + git branch&#x2F;dirty state\n  - 5h and 7d usage bars\n  - automatic Spark vs default limit selection\n\n  Quick install:\n\n  git clone https:&#x2F;&#x2F;github.com&#x2F;anhannin&#x2F;codex-hud.git\n  cd codex-hud&#x2F;Codex-HUD\n  .&#x2F;install.sh\n\n  Feedback I\u2019m looking for:\n\n  - portability across Linux distros&#x2F;shell setups\n  - readability on narrow terminal widths\n  - edge cases in usage&#x2F;rate parsing\n\n  Repo issues are welcome if you hit bugs.</code></pre>", "author": "anhm720", "timestamp": "2026-02-16T13:58:26+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:47.023261+00:00", "processed": false}
{"id": "hn_story_47034875", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034875", "title": "Show HN: Kai \u2013 A Telegram bot that turns Claude Code into a personal dev asst", "text": "I built Kai because I wanted Claude Code&#x27;s full capabilities - shell access, file editing, git, web search - available from my phone, without being tied to a terminal.<p>Kai is a Telegram bot that wraps a persistent Claude Code process. You send messages in Telegram, and Claude responds with full tool access: it can read and edit files, run commands, manage git branches, search the web, and work across multiple projects. Responses stream back in real time. Everything runs on your own machine.<p>*How I actually use it:* I point Kai at a project workspace and use it as a dev assistant. It has the full context of whatever repo it&#x27;s looking at - it can read and write code, check git status, run tests, make commits. Switching between projects is a Telegram command. I can be away from my desk and tell it &quot;fix the failing CI on the web repo&quot; or &quot;add input validation to the signup form&quot; and it just does it.<p>*Background:* I originally ran an instance of an open-source bot framework, but shut it down after a few days due to security concerns. I rebuilt from scratch on top of Claude Code&#x27;s CLI, which handles sandboxing and tool execution properly.<p>*No AI API keys required:* Kai doesn&#x27;t call the Anthropic API directly - it wraps a logged-in Claude Code session, so there are no API keys to manage and no per-token costs beyond your existing Claude Code subscription. The original design eliminated all API keys after security problems with another bot framework that managed them insecurely. Now that Kai runs on a trustworthy local foundation, optional service integrations are safe.<p>*Privacy angle:* Kai runs locally - on a Mac mini in my case. Conversations, credentials, and project files never leave the machine. There&#x27;s no server component, no cloud relay. Your Telegram messages go to your machine, and Claude Code handles the rest through Anthropic&#x27;s API directly.<p>*External services without MCP:* Kai has a declarative HTTP service layer for connecting to any REST API. You define services in a YAML config - URL, method, auth type - and Kai makes the HTTP calls directly. No plugins, no third-party server processes, no executable code. API keys stay in your `.env` and are never touched by intermediary code. Ships with a Perplexity config for web search, but the same pattern works for weather APIs, notification services (Pushover, ntfy), home automation, translation, or anything else with a REST endpoint. Entirely optional - Kai works fine without it.<p>*Some things it can do:*<p>- Connect to external REST APIs via declarative config (search, weather, notifications, etc.)\n- Transcribe voice messages locally (whisper.cpp) and respond with voice (Piper TTS)\n- Run scheduled jobs and reminders\n- Receive GitHub webhooks (push, PR, issue notifications)\n- Stream responses in real time (message updates every 2s)\n- Switch between workspaces and models via Telegram commands<p>It&#x27;s a single Python package, about 1700 lines across 11 modules. Runs as a launchd&#x2F;systemd service. Setup is: clone, pip install, set two env vars (Telegram token + your user ID), and `make run`.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dcellison&#x2F;kai\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dcellison&#x2F;kai</a><p>Happy to answer any questions about the setup or architecture.", "author": "dcellison", "timestamp": "2026-02-16T13:47:46+00:00", "score": 1, "num_comments": 1, "products": ["claude", "perplexity"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:47.190961+00:00", "processed": false}
{"id": "hn_comment_47037167", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47037167", "title": "Re: Show HN: Kai \u2013 A Telegram bot that turns Claude Co...", "text": "I have also been thinking about how to make claude more accessible to the less than super-adept web designer. I&#x27;d like to know how it is being received?", "author": "novatrope", "timestamp": "2026-02-16T16:43:10+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:47.205631+00:00", "processed": false}
{"id": "hn_story_47034849", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034849", "title": "Ask HN: What happens after the AI bubble bursts?", "text": "I keep hearing we\u2019re in an AI bubble, but I\u2019m struggling to visualize the day after scenario.<p>If the bubble pops (meaning these massive compute costs never turn into actual profits and the VC money dries up) what does the tech landscape look like?<p>A lot of us use Copilot, Claude, or ChatGPT daily for coding and docs. If the subsidized cheap access vanishes because these companies can&#x27;t eat the losses anymore, do the tools just disappear? Because if a tool like Claude Code (or any other LLM) suddenly cost $1,000 a month to reflect what it actually costs to run, would people keep paying for it out of pocket? Would their companies?<p>I\u2019m especially curious to hear from anyone who lived through 2000 or 2008. Does a postbubble world mean we just abandon the tech entirely or is it a move toward expensive solutions?", "author": "101008", "timestamp": "2026-02-16T13:44:31+00:00", "score": 5, "num_comments": 4, "products": ["claude", "chatgpt", "copilot"], "categories": ["naming_terminology"], "sentiment": null, "collected_at": "2026-02-16T17:30:47.234263+00:00", "processed": false}
{"id": "hn_story_47034752", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034752", "title": "Show HN: 2d platformer game built with Codex (zero code)", "text": "Hi HN!<p>On Sunday I spent a couple of hours building a short 2d platformer (&quot;Prince of Persia&quot; style). What&#x27;s interesting is how I built it. I went for a zero-code approach, and built the whole thing using OpenAI Codex CLI and agent skills (with the <i>progressive disclosure</i> paradigm).<p>You can play the game here: <a href=\"https:&#x2F;&#x2F;acatovic.github.io&#x2F;gothicvania-codex-demo&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;acatovic.github.io&#x2F;gothicvania-codex-demo&#x2F;</a><p>You can see the full code, agent skills and a complete writeup here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;acatovic&#x2F;gothicvania-codex-demo\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;acatovic&#x2F;gothicvania-codex-demo</a><p>Some takeaways:<p>* This was one of the most enjoyable experiences ever!<p>* Applying harness engineering with progressive disclosure is incredibly powerful - I treated my SKILL.md as simply a ToC (a &quot;skills map&quot;) and took it from there<p>* Implement -&gt; Evaluate loops are key - I used Playwright and an evaluation checklist and the agent built and corrected automagically<p>* I used PROGRESS.md as a memory&#x2F;log mechanism for the agent, and a way to minimize context noise<p>* The game dev agent was steered by the DESIGN-DOCUMENT.md, stipulating game objectives, layout and mechanics<p>* I used progressive prompting - I built up the game piece wise - starting with basic player mechanics, then adding tiles, NPCs, interactions, sounds, menus - one prompt at a time<p>Zero code written by me. Never even looked at the game engine (Phaser) API - just gave the skills a link to the documentation. The future is here!<p>Credits to ansimuz (gothicvania assets) and Pascal Belisle (music).<p>*NOTE:* The assets were *NOT* created by AI. Backgrounds and probably tiles you could generate with AI, but sprites are not quite there yet (I tried a number of different models). Something to explore fully in the future.<p>Enjoy and let me know what you think!", "author": "armcat", "timestamp": "2026-02-16T13:34:40+00:00", "score": 4, "num_comments": 4, "products": ["chatgpt"], "categories": ["tone", "navigation"], "sentiment": null, "collected_at": "2026-02-16T17:30:47.757595+00:00", "processed": false}
{"id": "hn_story_47034485", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034485", "title": "Show HN: InitRunner \u2013 YAML to AI Agent with RAG, Memory, and an API", "text": "I wanted a way to prototype an agent and have it serving requests in minutes, InitRunner is a YAML-first platform where one config file gives you a working agent with RAG, memory, and an API endpoint.<p>apiVersion: initrunner&#x2F;v1\nkind: Agent\nmetadata:\n  name: acme-support\n  description: Support agent for Acme Corp\nspec:\n  role: You are a support agent for Acme Corp.\n  model:\n    provider: openai\n    name: gpt-4o-mini\n  ingest:\n    sources:\n      - .&#x2F;docs&#x2F;*&#x2F;<i>.md\n      - .&#x2F;knowledge&#x2F;*&#x2F;</i>.pdf\n  memory:\n    max_memories: 1000<p>initrunner ingest agent.yaml\ninitrunner run agent.yaml -i\ninitrunner serve agent.yaml --port 3000<p>Three commands: ingest your docs, test interactively, serve over HTTP. The agent gets search_documents, remember, and recall tools auto-registered. No code to wire up.<p>Point Open WebUI or any OpenAI client at localhost:3000&#x2F;v1 and you have a full chat interface over your knowledge base with persistent memory across sessions.<p>Built on PydanticAI, SQLite + sqlite-vec. No Redis, no Postgres, no infra.<p>curl -fsSL <a href=\"https:&#x2F;&#x2F;initrunner.ai&#x2F;install.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;initrunner.ai&#x2F;install.sh</a> | sh", "author": "Asciilotle", "timestamp": "2026-02-16T13:04:09+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:48.517640+00:00", "processed": false}
{"id": "hn_story_47034185", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034185", "title": "Show HN: KanVibe \u2013 Kanban board that auto-tracks AI agents via hooks", "text": "I run multiple Claude Code agents in parallel across different branches. Checking each tmux session one by one to see which agent was working, waiting for input, or done was painful.<p>KanVibe is a self-hosted Kanban board for this. Three things it does:<p>- *Browser terminals*: Every task card has a live terminal (xterm.js). Click a task, see its output. No tmux attach needed.\n- *Hook-driven status tracking*: Claude Code Hooks auto-move cards across the board (PROGRESS \u2192 PENDING \u2192 REVIEW). Zero manual updates.\n- *Git worktree automation*: Create a task with a branch name \u2192 worktree + terminal session auto-created. Move to DONE \u2192 everything auto-cleaned.<p>Setup: `git clone` + `bash start.sh`. Requires Node.js 22+, tmux&#x2F;zellij, and Docker.<p>Built with Next.js 16, React 19, PostgreSQL, xterm.js, and WebSocket. AGPL-3.0 licensed.", "author": "rookedsysc", "timestamp": "2026-02-16T12:27:38+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:49.415947+00:00", "processed": false}
{"id": "hn_comment_47034062", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034062", "title": "Re: I received several friends' condolences written wi...", "text": "<i>I immediately remembered myself writing birthday congrats with LLMs and myself pushing every email through Claude, putting linguistic perfection over authenticity.</i><p>Being charitable, one could argue that you spent extra time because you cared - which, hopefully, is what your friends are doing. Some people send sympathy cards from Hallmark for the same reason - to express what they find difficult to express. Is it really any different? Something to think about in this age of LLMs.", "author": "taylodl", "timestamp": "2026-02-16T12:11:08+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-16T17:30:50.520812+00:00", "processed": false}
{"id": "hn_story_47033722", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47033722", "title": "Show HN: Claude Relay \u2013 Web UI for Claude Code, zero install, push notifications", "text": "I built a local relay server that puts Claude Code in your browser.<p>No signup, no install, no cloud. Just &quot;npx claude-relay&quot;.<p>The problem: Claude Code runs in the terminal. When it needs approval for a command, you have to be staring at that terminal. Walk away for coffee, and it sits there waiting.<p>claude-relay runs a local WebSocket server that streams Claude Code&#x27;s output to a browser tab. When approval is needed, you get a push notification on your phone. Tap to approve or deny.<p>Technical choices:<p>Built on Anthropic&#x27;s Agent SDK (TypeScript)<p>WebSocket streaming, not polling<p>Web Push API for mobile notifications (no app install)<p>Everything runs locally \u2014 no data leaves your machine<p>PIN-based auth for the web UI<p>It also supports multiple sessions (one per git worktree), so you can run parallel Claude Code instances from one dashboard.<p>Setup: npx claude-relay", "author": "chadbyte", "timestamp": "2026-02-16T11:21:11+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:50.760554+00:00", "processed": false}
{"id": "hn_comment_47034401", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47034401", "title": "Re: Anthropic tries to hide Claude's AI actions. Devs ...", "text": "the hiding stuff is weird because the whole reason you&#x27;d want to see what Claude is doing isn&#x27;t just curiosity - it&#x27;s about catching when it goes off the rails before it makes a mess. like when it starts reading through your entire codebase because it misunderstood what you asked for, or when it&#x27;s about to modify files you didn&#x27;t want touched. the verbose mode fix is good but honestly this should&#x27;ve been obvious from the start - if you&#x27;re letting an AI touch your files, you want to know exactly which files. not because you don&#x27;t trust the tool in theory but because you need to verify it&#x27;s doing what you actually meant, not what it thinks you meant. abstractions are great until they hide the thing that&#x27;s about to break your build", "author": "the_harpia_io", "timestamp": "2026-02-16T12:54:37+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-16T17:30:51.014903+00:00", "processed": false}
{"id": "hn_comment_47035660", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47035660", "title": "Re: Anthropic tries to hide Claude's AI actions. Devs ...", "text": "&quot;Hiding&quot; is doing some heavy lifting here. You can run --json and see everything pretty much (besides the system prompt and tool descriptions)....<p>I love the terminal more than the next guy but at some point it feels like you&#x27;re looking at production nginx logs, just a useless stream of info that is very difficult to parse.<p>I vibe coded my own ADE for this called OpenADE (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;bearlyai&#x2F;openade\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;bearlyai&#x2F;openade</a>) it uses the native harnesses, has nice UIs and even comes with things like letting Claude and Codex work together on plans. Still very beta but has been my daily driver for a few weeks now.", "author": "parhamn", "timestamp": "2026-02-16T14:47:33+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:51.148290+00:00", "processed": false}
{"id": "hn_comment_47033594", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47033594", "title": "Re: Show HN: ClawSouls \u2013 Open registry of shareable pe...", "text": "My thesis: changing soul is the future of prompt engineering.<p>Right now, prompt engineering means re-explaining your preferences every session. A soul packages that into installable markdown files \u2014 personality, style, behavior rules \u2014 that persist across sessions and are shareable like any other code.<p>Built this in 2 weeks as a solo dev. 79 curated souls so far. The spec is intentionally simple \u2014 just markdown files \u2014 so it works with any LLM and any platform.<p>Also worth noting: Anthropic recently published their official Skill spec for Claude. Skills define workflows (WHAT to do). Souls define persona (WHO does it). They&#x27;re complementary layers \u2014 we were already building this before the guide came out.<p>Happy to answer questions about the spec design or soul creation process.", "author": "tomleelive", "timestamp": "2026-02-16T11:02:27+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-16T17:30:51.305054+00:00", "processed": false}
{"id": "hn_story_47033385", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47033385", "title": "Show HN: Vocalinux // 100% offline voice typing for Linux", "text": "Show HN: Vocalinux \u2013 100% offline voice typing for Linux\nI built this because I wanted voice dictation without sending my voice \ndata to cloud services.\nVocalinux is a privacy-focused, open-source dictation tool that runs \nentirely on your Linux machine:\n- Local speech recognition (whisper.cpp, VOSK, or OpenAI Whisper)\n- Works offline, no network required\n- Universal compatibility (X11&#x2F;Wayland, any app)\n- Voice commands: &quot;period&quot;, &quot;delete that&quot;, &quot;new line&quot;\nInstallation: one-line curl command with auto-detection for GPU&#x2F;CPU\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jatinkrmalik&#x2F;vocalinux\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jatinkrmalik&#x2F;vocalinux</a>\nQuestions and feedback welcome!", "author": "jatinkrmalik", "timestamp": "2026-02-16T10:32:03+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-16T17:30:51.644667+00:00", "processed": false}
