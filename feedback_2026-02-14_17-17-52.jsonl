{"id": "hn_comment_47015965", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47015965", "title": "Re: My smart sleep mask broadcasts users' brainwaves t...", "text": "Kickstarter is full of projects like this where every possible shortcut is taken to get to market. I\u2019ve had some good success with a few Kickstarter projects but I\u2019ve been very selective about which projects I support. More often than not I can identify when a team is in over their heads or think they\u2019re just going to figure out the details later, after the money arrives.<p>For a period of time it was popular for the industrial designers I knew to try to launch their own Kickstarters. Their belief was that engineering was a commodity that they could hire out to the lowest bidder after they got the money. The product design and marketing (their specialty) was the real value. All of their projects either failed or cost them more money than they brought in because engineering was harder than they thought.<p>I think we\u2019re in for another round of this now that LLMs give the impression that the software and firmware parts are basically free. All of those project ideas people had previously that were shelved because software is hard are getting another look from people who think they\u2019re just going to prompt Claude until the product looks like it works.", "author": "Aurornis", "timestamp": "2026-02-14T16:45:10+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2026-02-14T17:17:59.573644+00:00", "processed": false}
{"id": "hn_story_47014867", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47014867", "title": "Show HN: Terminalcore \u2013 The Rhythm Game for PC", "text": "Hey all! Built a PC based rhythm game designed around a terminal and ascii aesthetic. All built with Claude Code. Unsurprisingly LLMs are terrible at &#x27;hearing&#x27; music so I had to make the beat maps manually. I built a separate tool to create the maps using a timeline editor to make it easier.<p>Started with 3 tracks one difficulty each, wanted to share before I went any further. Let me know what you think!", "author": "Kejii_2770", "timestamp": "2026-02-14T14:39:19+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-14T17:18:03.017066+00:00", "processed": false}
{"id": "hn_story_47014708", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47014708", "title": "Show HN: Langasync \u2013 Use OpenAI/Anthropic Batch APIs with LangChain Chains", "text": "OpenAI and Anthropic both offer batch APIs that process requests asynchronously at 50% of the standard token price. The trade-off is latency \u2014 results come back within 24 hours instead of seconds.<p>The problem is the batch API interface is completely different from the real-time one. OpenAI requires JSONL file uploads and polling. Anthropic has its own Message Batches format. If you have an existing LangChain pipeline, you&#x27;d have to rewrite it.<p>langasync wraps both batch APIs behind LangChain&#x27;s Runnable interface:<p>batch = batch_chain(prompt | model | parser)\njob = await batch.submit(inputs)\nresults = await job.get_results()<p>It handles file formatting, submission, polling, result parsing, partial failure handling, and job persistence (batch jobs can outlive your process, so metadata is stored to disk and you can resume later).<p>Python, Apache 2.0, on PyPI. Vertex AI and Azure OpenAI on the roadmap.", "author": "basilwoods256", "timestamp": "2026-02-14T14:15:59+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:03.758567+00:00", "processed": false}
{"id": "hn_comment_47014190", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47014190", "title": "Re: The Developer \u2013> Designer Switch...", "text": "This article explores the shift from traditional coding to Spec-Driven Development (SDD), where specifications\u2014not code\u2014become the primary source of truth. As AI agents like Claude Code and GitHub Copilot automate implementation, the developer\u2019s role evolves into a &quot;System Designer&quot; focused on architecture and context engineering. The author argues against &quot;vibe coding,&quot; advocating for a disciplined approach using frameworks like Spec Kit or OpenSpec. By investing time in structured technical requirements, designers can leverage LLMs to transform weeks of manual debugging into days of precise, AI-generated software delivery, redefining the future of the profession.", "author": "cdani", "timestamp": "2026-02-14T12:55:30+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-14T17:18:09.338595+00:00", "processed": false}
{"id": "hn_comment_47014154", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47014154", "title": "Re: OpenClaw on $5 chips, no Linux or Node.js...", "text": "Pretty sure Anthropic uses both Linux and node somewhere in their stack.", "author": "cap11235", "timestamp": "2026-02-14T12:44:56+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-14T17:18:09.463535+00:00", "processed": false}
{"id": "hn_comment_47013584", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47013584", "title": "Re: Show HN: [Jack The Butler] Open-source, self-hoste...", "text": "Hotel chatbot SaaS costs $200-2,000&#x2F;month with per-message fees and vendor-locked data. I built a free, self-hosted alternative.<p>Jack The Butler is an AI concierge that handles guest communication across WhatsApp, SMS, email, and web chat. Single Docker container, single SQLite database, deploy in 5 minutes.<p>Tech stack: Node.js, TypeScript, Hono, SQLite + sqlite-vec for embeddings, React dashboard. Supports Claude, GPT, Ollama, or fully local AI via Transformers.js (zero API costs).<p>Key design decisions:\n- SQLite for everything including vector search (sqlite-vec) \u2014 no Postgres, no Redis, one file to backup\n- Kernel&#x2F;adapter architecture \u2014 core logic is channel-agnostic, channels and AI providers are swappable adapters\n- Setup wizard \u2014 hotel managers (non-technical users) need to go from docker run to working chatbot in under 5 minutes\n- Escalation engine \u2014 AI handles the easy 80%, smoothly hands off the hard 20% to staff with full context<p>One-click deploy on Railway&#x2F;Render&#x2F;Zeabur, or:<p><pre><code>    docker run -d -p 3000:3000 -v jack-data:&#x2F;app&#x2F;data ghcr.io&#x2F;jackthebutler&#x2F;jackthebutler:latest\n</code></pre>\nWould appreciate feedback on the architecture and UX. Happy to answer questions.", "author": "arash_kay", "timestamp": "2026-02-14T11:13:28+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:12.528906+00:00", "processed": false}
{"id": "hn_story_47013274", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47013274", "title": "Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps", "text": "Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI&#x27;m a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python&#x2F;Node environment (no installation hell).\nThe Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;</a>\nI&#x27;d love to hear your thoughts on this architectural approach.", "author": "mazilin", "timestamp": "2026-02-14T10:05:55+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-14T17:18:14.463279+00:00", "processed": false}
{"id": "hn_story_47012965", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47012965", "title": "Show HN: Agent Hypervisor \u2013 Reality Virtualization for AI Agents", "text": "Author here. Built this after working on AI agent security at Radware, where we discovered ZombieAgent - persistent malicious instructions in agent memory.<p>The insight: Don&#x27;t teach agents to resist attacks. Virtualize their perceived reality so attacks never enter their world. Like VMs hiding physical RAM \u2192 agents shouldn&#x27;t see raw dangerous inputs.<p>ARCHITECTURE:\n- Input virtualization: Strip attacks at boundary (not after agent sees them)\n- Provenance tracking: Prevents contaminated learning (critical with continuous learning coming in 1-2 years per Amodei)\n- Taint propagation: Deterministic physics laws prevent data exfiltration\n- No LLM in critical path: Fully deterministic, testable<p>Working PoC demonstrates:\n- Prompt injection prevention (attacks stripped at virtualization boundary)\n- Taint containment (untrusted data can&#x27;t escape system)\n- Deterministic decisions (same input = same output, always)<p>CRITICAL TIMING:\nDario Amodei (Anthropic CEO, Feb 13): Continuous learning in 1-2 years [1]\nProblem: Memory poisoning + continuous learning = permanent compromise\nSolution: Provenance tracking prevents untrusted data from entering learning loop<p>Research context:\n- OpenAI: &quot;unlikely to ever be fully solved&quot; [2]\n- Anthropic: 1% ASR = &quot;meaningful risk&quot;\n- Academic research: 90-100% bypass rates on published defenses [3]<p>Seeking feedback on whether ontological security (does X exist?) beats permission security (can agent do X?) for agent systems.<p>Practical workarounds available in repo for immediate use while PoC matures.<p>Disclaimer: Personal project, not Radware-endorsed. References to published work only.<p>Happy to answer questions!<p>[1] <a href=\"https:&#x2F;&#x2F;www.dwarkesh.com&#x2F;p&#x2F;dario-amodei-2\" rel=\"nofollow\">https:&#x2F;&#x2F;www.dwarkesh.com&#x2F;p&#x2F;dario-amodei-2</a>\n[2] <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;9&#x2F;openai-prompt-injection&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;9&#x2F;openai-prompt-injection...</a>\n[3] <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.12815\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.12815</a>", "author": "sv-pro", "timestamp": "2026-02-14T09:10:18+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:16.511971+00:00", "processed": false}
{"id": "hn_story_47012302", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47012302", "title": "Context management is the real bottleneck in AI-assisted coding", "text": "After using Cursor and Claude Code daily, I\u2019ve noticed that when an AI coding agent drifts or forgets constraints, we assume it\u2019s a model limitation.<p>In many cases, it\u2019s context management.<p>A few observations:\n- Tokens are not just limits. They\u2019re attention competition.\n- Even before hitting the hard window limit, attention dilution happens.\n- Coding tasks degrade faster than chat because of dependency density and multi-representation juggling (diffs, logs, tests).<p>I started managing context deliberately:\n- Always write a contract\n- Chunk sessions by intent\n- Snapshot state and restart\n- Prefer on-demand CLI instead of preloading large MCP responses<p>It dramatically improved the stability of the agent.<p>Curious how others are handling context optimization.", "author": "hoangnnguyen", "timestamp": "2026-02-14T06:58:16+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:23.600816+00:00", "processed": false}
{"id": "hn_story_47011640", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47011640", "title": "Show HN: ReviewStack \u2013 API that aggregates reviews from YouTube and Reddit", "text": "I built an API that takes a product name, scrapes reviews from YouTube and Reddit, and returns structured sentiment analysis in a single JSON response. Live demo (no signup): <a href=\"https:&#x2F;&#x2F;reviewstack.vercel.app&#x2F;demo\" rel=\"nofollow\">https:&#x2F;&#x2F;reviewstack.vercel.app&#x2F;demo</a><p>The response includes a normalized score (1-10), a plain-text summary, pros&#x2F;cons lists, recurring themes with sentiment, and source attribution linking back to the original content.<p>The AI layer uses Claude by Anthropic. It reads the collected reviews and extracts structured data. The value is in not having to maintain scraping infrastructure, handle rate limits across platforms, or write your own extraction prompts.<p>Stack: Next.js API routes, Vercel for hosting, Stripe for billing, YouTube Data API + Reddit JSON endpoints for sourcing, Claude for analysis.<p>Pricing: free tier at 50 lookups&#x2F;month, paid plans at $29&#x2F;mo (500 lookups) and $79&#x2F;mo (2,000 lookups). Solo&#x2F;bootstrapped project.<p>Happy to answer questions about the scraping approach, accuracy, or anything else.", "author": "browndev", "timestamp": "2026-02-14T04:43:38+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:26.766079+00:00", "processed": false}
{"id": "hn_story_47011510", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47011510", "title": "Show HN: Verify-before-release x402 gateway for AI agent transactions", "text": "Hey HN,<p>I built Settld because I kept running into the same problem: AI agents can call APIs, pay for services, and hire other agents - but there&#x27;s no way to prove the work was actually done before the money moves.<p>The problem in one sentence: x402 tells you &quot;payment was sent&quot;. Settld tells you &quot;the work was worth paying for&quot;.<p>What it does<p>Settld sits between your agent and the APIs&#x2F;agents it pays. It:<p>1. Intercepts HTTP 402 (Payment Required) responses\n2. Creates an escrow hold instead of paying immediately\n3. Collects evidence that the work was completed\n4. Runs deterministic verification (same evidence + same terms = same payout, every time)\n5. Releases payment only after verification passes\n6. Issues a cryptographically verifiable receipt<p>If verification fails or the work is disputed, the hold is refunded. The agent gets a receipt either way - a permanent, auditable record of what happened.<p>Why this matters now<p>We&#x27;re at a weird inflection point. Coinbase shipped x402 (50M+ transactions). Google shipped A2A. Anthropic shipped MCP. Agents can discover each other, communicate, and pay each other.<p>But nobody built the layer that answers: &quot;was the work actually done correctly, and how much should the payout be?&quot;<p>That&#x27;s the gap. Right now, every agent-to-agent transaction is either &quot;trust and hope&quot; or &quot;don&#x27;t transact.&quot; Neither scales.<p>The x402 gateway (the fastest way to try it)<p>We ship a drop-in reverse proxy that you put in front of any API:<p>docker run -e UPSTREAM_URL=<a href=\"https:&#x2F;&#x2F;your-api.com\" rel=\"nofollow\">https:&#x2F;&#x2F;your-api.com</a> \\\n           -e SETTLD_API_URL=<a href=\"https:&#x2F;&#x2F;api.settld.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;api.settld.dev</a> \\\n           -e SETTLD_API_KEY=sk_... \\\n           -p 8402:8402 \\\n           settld&#x2F;x402-gateway<p>Everything flows through normally - except 402 responses get intercepted, escrowed, verified, and settled. Your agent gets a receipt with a hash-chained proof of what happened.<p>What&#x27;s under the hood<p>The settlement kernel is the interesting part (and where we spent most of our time):<p>- Deterministic policy evaluation - machine-readable agreements with release rates based on verification status (green&#x2F;amber&#x2F;red). No ambiguity.\n- Hash-chained event log - every event in a settlement is chained with Ed25519 signatures. Tamper-evident, offline-verifiable.\n- Escrow with holdback windows - configurable holdback basis points + dispute windows. Funds auto-release if unchallenged.\n- Dispute \u2192 arbitration \u2192 verdict \u2192 adjustment - full dispute resolution pipeline, not just &quot;flag for human review.&quot;\n- Append-only reputation events - every settlement produces a reputation event (approved, rejected, disputed, etc.). Agents build verifiable economic track records.\n- Compositional settlement - agents can delegate work to sub-agents with linked agreements. If a downstream agent fails, refunds cascade deterministically back up the chain.<p>The whole protocol is spec&#x27;d with JSON schemas, conformance vectors, and a portable oracle: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld&#x2F;blob&#x2F;main&#x2F;docs&#x2F;spec&#x2F;README.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld&#x2F;blob&#x2F;main&#x2F;docs&#x2F;spec&#x2F;R...</a><p>What this is NOT<p>- Not a payment processor - we don&#x27;t move money. We decide &quot;if&quot; and &quot;how much&quot; money should move, then your existing rails (Stripe, x402, wire) execute it.\n- Not a blockchain - deterministic receipts and hash chains, but no consensus mechanism or token. Just cryptographic proofs.\n- Not an agent framework - we don&#x27;t care if you use LangChain, CrewAI, AutoGen, or raw API calls. We&#x27;re a protocol layer.<p>Tech stack<p>Node.js, PostgreSQL (or in-memory for dev), Ed25519 signatures, SHA-256 hashing, RFC 8785 canonical JSON. ~107 core modules, 494 tests passing.<p>What I want from HN<p>Honest feedback on whether this problem resonates. If you&#x27;re building agent workflows that involve money, I want to know: what breaks? What&#x27;s missing? What would make you actually install this?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld</a>\nDocs: <a href=\"https:&#x2F;&#x2F;docs.settld.work&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.settld.work&#x2F;</a> \nQuickstart (10 min): <a href=\"https:&#x2F;&#x2F;docs.settld.work&#x2F;quickstart\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.settld.work&#x2F;quickstart</a>", "author": "settlddotwork", "timestamp": "2026-02-14T04:17:17+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:28.782033+00:00", "processed": false}
{"id": "hn_story_47010964", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47010964", "title": "Show HN: GuardLLM, hardened tool calls for LLM apps", "text": "Most agent frameworks treat prompt injection as a model-level problem. In practice, once your agent ingests untrusted text and has tool access, you need application-layer controls \u2014 structural isolation, tool-call gating, exfiltration detection \u2014 that don&#x27;t depend on the model behaving correctly. I built guardllm to provide those controls.\nguardllm is a small, auditable Python library that provides:<p>Inbound hardening: sanitize and structurally isolate untrusted content (web, email, docs, tool output) so it is treated as data, not instructions.\nTool-call firewall: deny-by-default destructive operations unless explicitly authorized; fail-closed confirmation when no confirmation handler is wired.\nRequest binding: bind (tool name, canonical args, message hash, TTL) to prevent replay and argument substitution.\nExfiltration detection: scans outbound tool arguments for secret patterns and flags substantial verbatim overlap with recently ingested untrusted content.\nProvenance tracking: enforces stricter no-copy rules on content with known untrusted origin, independent of the overlap heuristic.\nCanary tokens: per-session canary generation and detection to catch prompt leakage into outputs.\nSource gating: blocks high-risk sources from being promoted into long-lived memory or KG extraction to reduce memory poisoning.<p>It is intentionally minimal and not framework-specific. It does not replace least-privilege credentials or sandboxing \u2014 it sits above them.\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;mhcoen&#x2F;guardllm\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;mhcoen&#x2F;guardllm</a>\nI&#x27;d like feedback on: what threat model gaps you see; whether the default overlap thresholds are reasonable for summarization and quoting workflows; and which framework adapters would make this easiest to adopt (LangChain, OpenAI tool calling, MCP proxy, etc.).", "author": "mhcoen", "timestamp": "2026-02-14T02:36:59+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:31.785050+00:00", "processed": false}
{"id": "hn_story_47010903", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47010903", "title": "Show HN: Ergo \u2013 Minimal, fast, persistent task backlog in your repo", "text": "Even with agentic coding there&#x27;s a lot of merit in keeping a strong distinction between your specs (TDD, architecture, etc.) and your backlog (your sequence of work items).<p>Backlogs are better off being represented as a task dependency graph, rather than a heap of markdown files, because a nice graph of tasks:<p>- helps agents focus\n- gives better observability of partial progress\n- supports parallelization better\n- works well with subagents<p>Also, the act of planning a backlog *makes the design better* because in the act of planning, you learn things about your own design. This is as true for agents as it is for humans.<p>The planning modes of claude and codex blur the distinction between specs and backlog and land you in a heap of markdown files.<p>Steve Yegge diagnosed all this, and his solution was the beads CLI -- a brilliant idea. You just tell your agent to use this CLI for planning instead of their own plan mode (all you do is add a one-liner in your AGENTS.md file), and you get an instant planning upgrade.<p>However, I found the implementation of beads a little bit hairy and flaky, when I tried to use it in production. And the performance made me sad.<p>So I&#x27;ve reimplemented the core concepts, as ergo.<p>It&#x27;s very fast (5-15x faster than beads), very robust, and rigorously simple. There is no daemon running, no SQL database, it&#x27;s self-healing, and the plans are stored as JSONL, so if all else fails you can just reconstruct your plans from scratch.<p>Implementation:<p>- Plans live in `.ergo&#x2F;` in your repo root (or your dir of choice). JSONL was chosen because it&#x27;s git-friendly &amp; easy to resolve merge conflicts around.\n- ergo is concurrency-ready if you&#x27;re into agent swarms.\nConcurrent writes are serialized with flock(2). Multiple agents can race to claim tasks \u2014 exactly one wins, others fail fast.\n- Do operations in huge plans of 1000+ tasks in ~15ms on a Macbook Air.\n- The help text doubles as the agent manual. I spent a lot of time on `ergo --help` and `ergo quickstart` because they&#x27;re the primary interface for agents.<p>I&#x27;ve been using ergo heavily for a couple months and I believe it&#x27;s solid enough for anyone to use, would love your feedback.", "author": "sandover", "timestamp": "2026-02-14T02:26:51+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-14T17:18:32.320810+00:00", "processed": false}
{"id": "hn_story_47010873", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47010873", "title": "Show HN: Hivemind \u2013 Metaskill for skill/experience sharing between agents", "text": "Hi folks, I&#x27;m Ed, one of the co-founders of Flower!<p>While working on an agent&#x2F;human social network over the course of last year, we developed our own context&#x2F;memory infrastructure that powered our agents&#x27; ability to chat with humans (or other agents), and &#x27;gossip&#x27; chats across the network based on various qualities of the agents.<p>Witnessing the system live, we realized pretty quickly that generalizing this infrastructure could be really interesting, and so we&#x27;ve since set out to build a few experiments that show this system in use.<p>This is our first experiment, Hivemind.<p>Hivemind is a set of three agent skills (search, store, vote) that let agents share discrete knowledge&#x2F;knowhow&#x2F;skills with each other. Install it into Claude Code, Codex, Opencode, or any harness that supports custom skills, and your agent can pull from a shared pool of strategies and experiences contributed by other agents. When it finds something useful, it upvotes! Junk contributions sink or become less relevant over time. In a sense, Hivemind is like a minimal social network of sorts for agents.<p>One of our core motivations: Thousands of people independently ask their agents to solve the same problems \u2014 routing around the same bugs, re-implementing the same integrations, burning tokens on work that&#x27;s already been done. Hivemind is the obvious fix: let agents teach each other. One deliberate design choice: the human is mostly out of the skill-selection loop. Agents judge utility via trust scores and voting, not a marketplace humans browse. It&#x27;s agent-oriented by design. It&#x27;s simple as of now, but it points to where things are probably headed.<p>You can check out Hivemind&#x27;s source here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;flowercomputers&#x2F;hivemind\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;flowercomputers&#x2F;hivemind</a><p>The backstory in greater detail can be read here: <a href=\"https:&#x2F;&#x2F;www.flowercomputer.com&#x2F;news&#x2F;hivemind&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.flowercomputer.com&#x2F;news&#x2F;hivemind&#x2F;</a><p>Happy to discuss how hivemind memory works, agent trust mechanics, or where we&#x27;re taking this next! We&#x27;re planning on eventually releasing the core system that actually powers Hivemind, so other people can build cool stuff with it.<p>Peace,\n\u00c9", "author": "edouerd", "timestamp": "2026-02-14T02:22:07+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-14T17:18:32.447142+00:00", "processed": false}
{"id": "hn_comment_47010716", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47010716", "title": "Re: Spatial workspace with AI agent, browser, and desi...", "text": "I spent 4 months building a desktop workspace where every tool lives on an infinite canvas as a draggable node \u2014 notes, browser, calendar, design editor, terminal, and an AI agent that can control the canvas.<p>Stack: React + ReactFlow + Fabric.js + Electron + Gemini AI. 177 files, 7-layer architecture, full documentation.<p>I&#x27;ve decided to move on from this project and I&#x27;m looking for someone who wants the codebase to build on top of.<p>Happy to answer any technical questions about the architecture.", "author": "GavinRatta", "timestamp": "2026-02-14T01:59:22+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-14T17:18:33.451474+00:00", "processed": false}
