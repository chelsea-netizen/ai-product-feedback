{"id": "hn_story_46767903", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46767903", "title": "Show HN: Chord: Clawdbot alternative with a security layer", "text": "Hey HN, I built this because I liked the idea of agents controlling a computer (like Clawdbot), but I was uncomfortable giving them unrestricted shell access.<p>So I build Chord, it uses the same underlying agent framework as Clawdbot, so it can do most of the same jobs. The key difference is that I added a security layer. Commands are analyzed by an AI before execution. This does use extra tokens, but you can run the analysis with cheap models (e.g. Gemini Flash) to keep costs low.<p>The security layer can block risky commands and provides a security audit log of everything the agent tries to do.<p>Right now, Chord only supports Telegram as the control interface. I\u2019ve built all the core parts, and I\u2019ll add smaller features next.<p>I\u2019d really appreciate any feedback.", "author": "arctanx", "timestamp": "2026-01-26T16:45:24+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-26T17:21:40.188087+00:00", "processed": false}
{"id": "hn_comment_46767374", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46767374", "title": "Re: I Rebuilt My AI Podcast App in 14 Days. I'm Terrif...", "text": "I have complicated feelings about AI-generated content. I&#x27;ve argued that AI should amplify expertise, not replace it.<p>So why did I just spend two weeks rebuilding DIAL\u00d8GUE\u2014an AI podcast generator?<p>The honest answer: I got hooked.<p>After using Claude Code to redesign my site in 3 days, I couldn&#x27;t stop. The speed was intoxicating.<p>That curiosity led to 119 commits and some uncomfortable thoughts about my daughter&#x27;s future.<p>Here&#x27;s what haunts me:<p>DIAL\u00d8GUE v1 \u2192 6 months\nSTRA\u0166UM (2-3x more complex) \u2192 75 days\nDIAL\u00d8GUE v2 \u2192 14 days<p>484 files changed. 89,000+ lines. Code I personally wrote: ~0<p>I have a teenage daughter. Smart, curious, hardworking.<p>And I have no idea what to tell her about her future.<p>The skills I learned over 18 years in advertising\u2014strategic thinking, understanding human psychology\u2014those still matter. But the execution skills? AI can do that now. Often better than I could. Getting better every month.<p>I used to think &quot;critical thinking&quot; was the answer.<p>But AI can give you 50-70% of the critical thinking for any problem. The floor has been raised so high that &quot;I can think critically&quot; isn&#x27;t the differentiator it used to be.<p>What&#x27;s left? Taste? Judgment? Maybe. But I&#x27;m not confident enough to bet my daughter&#x27;s career on it.<p>I&#x27;m excited about what I built. But I&#x27;m also scared. Not of the technology. Of the pace.<p>Society isn&#x27;t ready. Our education systems aren&#x27;t ready. None of it is ready.<p>I&#x27;m not ready. And I&#x27;m one of the people building these tools.<p>Full breakdown above", "author": "chandlernguyen", "timestamp": "2026-01-26T16:07:36+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:43.196401+00:00", "processed": false}
{"id": "hn_comment_46767265", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46767265", "title": "Re: Show HN: Lexray \u2013 60 second contract screening for...", "text": "Hey HN,<p>I&#x27;m Tomasz, former Microsoft&#x2F;Auth0 engineer and founder. I built Lexray to solve a problem I&#x27;ve had for years: understanding contract risk without hiring a lawyer for every agreement.<p>WHAT IT DOES<p>Upload a contract PDF (NDA, MSA, client agreement, vendor contract) \u2192 AI scans for risk patterns \u2192 Returns plain-English explanations in 60 seconds.<p>Flags:\n- IP clauses that claim more than deliverables (e.g., &quot;work created during the term&quot; vs &quot;for this project&quot;)\n- Auto-renewals with short notice (90-day notice buried on page 12)\n- Net-60&#x2F;Net-90 payment terms hidden in fine print\n- Unlimited indemnification (uncapped liability)\n- Overly broad non-competes<p>WHY I BUILT IT<p>I&#x27;ve signed hundreds of contracts as a freelancer, contractor, and startup founder. Every single time: &quot;What am I missing?&quot;<p>Most contracts are fine. But the risky ones cost thousands. I&#x27;ve missed auto-renewal deadlines, signed overly broad IP clauses, and lost sleep over clauses I didn&#x27;t fully understand.<p>Lawyers are $500&#x2F;hour. Most freelance contracts don&#x27;t justify that cost. But signing blindly is how you lose money.<p>TECHNICAL APPROACH<p>- Next.js + TypeScript + Tailwind\n- AWS cloud: AppRunner, SQS, Lambda, DynamoDB\n- Google Auth via Auth0\n- Anthropic Claude API for contract analysis (tested vs OpenAI, Claude performed better on legal nuance)\n- Privacy-first architecture: Files encrypted in transit, deleted right after analysis (&lt;60 seconds)\n- Zero data retention, no model training on uploads, no third-party sharing<p>TRACTION (LAUNCHED 5 DAYS AGO)<p>- 40+ users analyzed contracts\n- Real testimonials:\n  - &quot;Lexray is pretty cool! And, I am a lawyer!&quot; (Chief Legal Officer, 200-person startup)\n  - &quot;Lexray spotted a ton of issues in a contract we had that standard AI tools missed.&quot; (Jeffrey Doehler, Partner at Lead Cookie)\n  - &quot;This scratches a real itch \u2014 the 60-second turnaround and plain-English output are exactly what makes this usable.&quot; (Indie Hackers user)\n  - &quot;This is a product that solves a pain that is acute and widespread.&quot; (Venture Builder &amp; Investor)\n- Free during beta<p>WHAT I&#x27;D LOVE FEEDBACK ON<p>1. *Timing problem:* People like the idea but don&#x27;t have a contract to review RIGHT NOW. How do I stay top-of-mind for when they actually need it?<p>2. *Trust barrier:* How do I convince strangers to upload confidential documents? Even with encryption&#x2F;deletion guarantees, it&#x27;s a big ask.<p>3. *Analysis accuracy:* If you try it, how good is the analysis? False positives&#x2F;negatives? Anything it missed that a human would catch?<p>4. *Positioning:* Is &quot;triage before lawyer&quot; the right framing? Or should this be positioned differently?<p>Try it: <a href=\"https:&#x2F;&#x2F;lexray.io\" rel=\"nofollow\">https:&#x2F;&#x2F;lexray.io</a><p>Happy to answer questions about the tech stack, privacy model, business approach, or share specific examples of what it catches.<p>---<p>EDIT (SINCE PEOPLE WILL ASK)<p>*Privacy&#x2F;security technical details:*\n- Upload: HTTPS to AWS load balancer, VPN later\n- Processing: In-memory only, never written to disk\n- Deletion: Immediate after analysis (&lt;60 seconds)\n- Logs (CloudWatch): Metadata only (timestamp, file size), no contract content\n- Training: Never used for model training (explicit in Claude API terms)\n- Audit: Happy to show the deletion code if anyone wants to verify<p>I&#x27;m a solo founder with zero interest in your confidential data. The entire business model is helping you understand contracts, not harvesting them.<p>*Liability question (since it&#x27;ll come up):*\nThis is a screening tool, not legal advice. Explicit disclaimer on site. Like TurboTax isn&#x27;t liable if you file taxes wrong, I&#x27;m not liable for missed risks. This supplements legal review, doesn&#x27;t replace it.<p>*Why not open source:*\nConsidered it. Prompts are my competitive advantage right now, and I worry about forks that might not respect privacy (storing user contracts). Might open-source parts later (e.g., contract parsing utilities).", "author": "janczukt", "timestamp": "2026-01-26T16:00:28+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:43.977059+00:00", "processed": false}
{"id": "hn_comment_46766802", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46766802", "title": "Re: Google AI Overviews cite YouTube more than any med...", "text": "Heavy Gemini user here, another observation: Gemini cites lots of &quot;AI generated&quot; videos as its primary source, which creates a closed loop and has the potential to debase shared reality.<p>A few days ago, I asked it some questions on Russia&#x27;s industrial base and military hardware manufacturing capability, and it wrote a very convincing response, except the video embedded at the end of the response was an AI generated one. It might have had actual facts, but overall, my trust in Gemini&#x27;s response to my query went DOWN after I noticed the AI generated video attached as the source.<p>Countering debasement of shared reality and NOT using AI generated videos as sources should be a HUGE priority for Google.<p>YouTube channels with AI generated videos have exploded in sheer quantity, and I think majority of the new channels and videos uploaded to YouTube might actually be AI; &quot;Dead internet theory,&quot; et al.", "author": "abixb", "timestamp": "2026-01-26T15:27:34+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:49.221910+00:00", "processed": false}
{"id": "hn_comment_46766617", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46766617", "title": "Re: Google AI Overviews cite YouTube more than any med...", "text": "It&#x27;s tough convincing people that Google AI overviews are often very wrong. People think that if it&#x27;s displayed so prominently on Google, it must be factually accurate right?<p>&quot;AI responses may include mistakes. Learn more&quot;<p>It&#x27;s not mistakes, half the time it&#x27;s completely wrong and total bullshit information. Even comparing it to other AI, if you put the same question into GPT 5.2 or Gemini, you get much more accurate answers.", "author": "jdlyga", "timestamp": "2026-01-26T15:13:57+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:49.444547+00:00", "processed": false}
{"id": "hn_story_46765666", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46765666", "title": "Ask HN: Where is software engineering moving towards in the next years?", "text": "Since at least half a year now, I&#x27;m often times asking myself where we&#x27;re moving towards regarding software engineering. Regarding my spare time projects I&#x27;m nowadays using Cursor&#x2F;Claude Code to work on my vision (a database system since 2013 as a continuation of a project at the University of Konstanz) to do big refactorings I always wanted to do, but never found the drive to start as it would have been a major multi-year effort. Now, in the age of AI agents it&#x27;s really impressive, as of course there are often times very repetitive patterns, but also regarding other issues I never had the time (and skills?) to solve myself. Of course, sometimes the tests make no sense, it&#x27;s going haywire sometimes (for instance rather deleting tests or &quot;simplify&quot; them, instead of fixing real production code issues...). But on the other hand I built a full frontend with the help of AI agents (and I&#x27;m a backend engineer, always have been with a little embedded software engineering expertise).<p>That said, whenever I find some time, I can work on my vision much more efficiently (mostly as a product owner + architect in one person rather than writing everything &quot;by hand&quot;). So, I of course wonder if our jobs are safe in the future. I think you&#x27;ll always have to heavily guide the agents and stop them immediately whenever they&#x27;re about to get haywire and thus you have to have the skills of a senior software engineer, but on the other hand I&#x27;m sure that small teams of senior engineers can be much more efficient than before. So, either it&#x27;s that you&#x27;ll need less software engineers at some point, or if it&#x27;s rather that you can deliver products faster with more ideas implemented or simply that new ideas can be explored much more efficiently as before =&gt; more small startups?). I really don&#x27;t know...", "author": "lichtenberger", "timestamp": "2026-01-26T13:56:11+00:00", "score": 2, "num_comments": 2, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-26T17:21:51.627327+00:00", "processed": false}
{"id": "hn_story_46765489", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46765489", "title": "Show HN: wt \u2013 lightweight Git worktree orchestrator for parallel coding agents", "text": "I built wt to manage the coordination overhead of running multiple AI coding agents (Claude Code, Codex, etc.) concurrently on the same repository.<p>The problem: I&#x27;d spin up 3-4 agents working on different features simultaneously, then conflict on files, and resolving those conflicts burns agent context. Git worktrees solve the isolation problem but the native CLI is verbose, lacks primitives for managing multiple sessions, and I&#x27;d have to manage persistence (folders to store the trees) separately.<p>wt wraps git worktree in an interface designed for this workflow:<p><pre><code>  wt new feature&#x2F;auth    # creates worktree + spawns subshell\n  (wt:feature&#x2F;auth) $ claude\n  exit\n  git merge feature&#x2F;auth\n</code></pre>\nAlso integrates with tmux to coordinate agent sessions\u2014wt session watch shows which agents are actively processing vs idle by monitoring pane output buffers.<p>There&#x27;s a &#x2F;do skill for Claude Code that implements issue-driven workflows: &#x2F;do gh 123 fetches the GitHub issue, creates a worktree with a branch derived from the issue, and populates the agent context with the description.<p>Written in Rust. Binaries for macOS&#x2F;Linux.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;pld&#x2F;wt\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;pld&#x2F;wt</a><p>Blog post with more detail: <a href=\"https:&#x2F;&#x2F;peet.ldee.org&#x2F;general&#x2F;2026&#x2F;01&#x2F;26&#x2F;wt-git-worktree-orchestrator.html\" rel=\"nofollow\">https:&#x2F;&#x2F;peet.ldee.org&#x2F;general&#x2F;2026&#x2F;01&#x2F;26&#x2F;wt-git-worktree-orc...</a>", "author": "pldpld", "timestamp": "2026-01-26T13:39:08+00:00", "score": 3, "num_comments": 2, "products": ["claude"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:52.449899+00:00", "processed": false}
{"id": "hn_comment_46766259", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46766259", "title": "Re: After two years of vibecoding, I'm back to writing...", "text": "I came to &quot;vibe coding&quot; with an open mind, but I&#x27;m slowly edging in the same direction.<p>It is hands down good for code which is laborious or tedious to write, but once done, obviously correct or incorrect (with low effort inspection). Tests help but only if the code comes out nicely structured.<p>I made plenty of tools like this, a replacement REPL for MS-SQL, a caching tool in Python, a matplotlib helper. Things that I know 90% how to write anyway but don&#x27;t have the time, but once in front of me, obviously correct or incorrect. NP code I suppose.<p>But business critical stuff is rarely like this, for me anyway. It is complex, has to deal with various subtle edge cases, be written defensively (so it fails predictably and gracefully), well structured etc. and try as I might, I can&#x27;t get Claude to write stuff that&#x27;s up to scratch in this department.<p>I&#x27;ll give it instructions on how to write some specific function, it will write this code but not use it, and use something else instead. It will pepper the code with rookie mistakes like writing the same logic N times in different places instead of factoring it out. It will miss key parts of the spec and insist it did it, or tell me &quot;Yea you are right! Let me rewrite it&quot; and not actually fix the issue.<p>I also have a sense that it got a lot dumber over time. My expectations may have changed of course too, but still. I suspect even within a model, there is some variability of how much compute is used (eg how deep the beam search is) and supply&#x2F;demand means this knob is continuously tuned down.<p>I still try to use Claude for tasks like this, but increasingly find my hit rate so low that the whole &quot;don&#x27;t write any code yet, let&#x27;s build a spec&quot; exercise is a waste of time.<p>I still find Claude good as a rubber duck or to discuss design or errors - a better Stack Exchange.<p>But you can&#x27;t split your software spec into a set of SE questions then paste the code from top answers.", "author": "rich_sasha", "timestamp": "2026-01-26T14:47:45+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:52.700912+00:00", "processed": false}
{"id": "hn_story_46765448", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46765448", "title": "Show HN: Was tired of drowning in HN comments, so I built an AI Chief of Staff", "text": "I&#x27;ve been lurking on HN for years. You know the drill: interesting headline, 200+ comments, you dive in thinking &quot;I&#x27;ll just skim for 5 minutes&quot;... and an hour later you&#x27;re 36 chambers deep in a thread about memory allocation patterns in Postgres and you&#x27;ve completely forgotten what the original article was about.<p>I don&#x27;t just want a &quot;summary&quot; (which usually just shortens the noise). I want the meta-consensus: &quot;What is the actual trade-off being debated? Who is winning the argument? Why does this matter?&quot;<p>So I built HNSignals. Think of it less like a &quot;summarizer&quot; and more like a Chief of Staff who reads the entire thread for you and hands you a one-page executive brief.<p>How it works:\n1. Filters: Shows trending stories (50+ comments) where the discussion has heated up.\n2. Extracts: An AI (Qwen 3 via Venice.ai) reads the top comments.\n3. Structures: Instead of a wall of text, you get 4 specific signals:\n    - The Hook: Why you should care.\n    - The Gist: The core technical facts.\n    - The Debate: The actual friction point (e.g., &quot;Rust vs. C++ safety&quot;).\n    - The Verdict: The community consensus.<p>Why I&#x27;m showing this (Beta): Most AI tools just shorten the text. I&#x27;m trying to extract the signal. It&#x27;s a work in progress - the AI sometimes gets too clever, and I&#x27;m still tuning the cache strategy. I&#x27;d love feedback on whether this structured approach is actually better than a standard &quot;TL;DR.&quot;<p>Bonus meta-game: If this Show HN gets 50+ comments and makes it onto HNSignals itself, I&#x27;ll read the AI&#x27;s analysis of people analyzing my analyzer.\n(P.S. Please go easy on the intentional stress testing - my Lambda inference budget is finite!)<p>Try it: <a href=\"https:&#x2F;&#x2F;hnsignals.com\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com</a><p>Example output\nThe Heartbleed Bug (2014): <a href=\"https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;7548991\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;7548991</a>\nAsk HN: What is the most unethical thing you&#x27;ve done as a programmer? (2018): <a href=\"https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;17692005\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;17692005</a>\nComparing the Same Project in Rust, Haskell, C++, Python, Scala and OCaml (2019): <a href=\"https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;20192645\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;20192645</a>\nOpenAI&#x27;s GPT-3 may be the biggest thing since Bitcoin (2020): <a href=\"https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;23885684\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;23885684</a>\nApple, What Have You Done? (2026): <a href=\"https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;46763592\" rel=\"nofollow\">https:&#x2F;&#x2F;hnsignals.com&#x2F;signal&#x2F;46763592</a>", "author": "rektlessness", "timestamp": "2026-01-26T13:35:16+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["content_clarity", "response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:52.975855+00:00", "processed": false}
{"id": "hn_comment_46765751", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46765751", "title": "Re: Vibe coding kills open source...", "text": "I am a huge proponent of using AI tools for software development. But until I see a vibe coded replacement for the Linux kernel, PostgreSQL, gcc, git or Chromium, I am just going to disagree with this premise. If I am on a system without Python installed, I don&#x27;t see Claude saying, oh, you don&#x27;t need to download it, I&#x27;ll write the Python interpreter for you.", "author": "cheema33", "timestamp": "2026-01-26T14:03:39+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-26T17:21:55.618213+00:00", "processed": false}
{"id": "hn_comment_46765629", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46765629", "title": "Re: Vibe coding kills open source...", "text": "I have been trying to use Claude code to help improve my opensource Java NLP location library.<p>However trying to get it to do anything other than optimise code or fix small issues it struggles. It struggles with high level abstract issues.<p>For example I currently have an issue with ambiguity collisions e.g.<p>Input: &quot;California&quot;<p>Output: &quot;California, Missouri&quot;<p>California is a state but also city in Missouri - <a href=\"https:&#x2F;&#x2F;github.com&#x2F;tomaytotomato&#x2F;location4j&#x2F;issues&#x2F;44\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tomaytotomato&#x2F;location4j&#x2F;issues&#x2F;44</a><p>I asked Claude several times to resolve this ambiguity and it suggested various prioritisation strategies etc. however the resulting changes broke other functionality in my library.<p>In the end I am redesigning my library from scratch with minimal AI input. Why? because I started the project without the help of AI a few years back, I designed it to solve a problem but that problem and nuanced programming decisions seem to not be respected by LLMs (LLMs dont care about the story, they just care about the current state of the code)", "author": "tomaytotomato", "timestamp": "2026-01-26T13:52:54+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:55.646453+00:00", "processed": false}
{"id": "hn_story_46764860", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46764860", "title": "Show HN: MCP server that surfaces human experts inside ChatGPT", "text": "Built an MCP server that connects ChatGPT to async expert Q&amp;A. When someone asks a professional question needing human judgment, it surfaces relevant experts with pricing and response times.<p>Working in dev mode, submitted to ChatGPT marketplace.<p>What we learned building it:<p>1. ChatGPT requires `search` + `fetch` tools - could not find in MCP spec, undocumented until you hit the error<p>2. Tool descriptions = discovery. ChatGPT matches user intent to your descriptions. No algorithm docs. Treat it like SEO.<p>3. Dev Mode is buried: Settings \u2192 Connectors \u2192 Advanced \u2192 Developer Mode<p>4. Docs are split: Anthropic owns MCP spec, OpenAI owns ChatGPT-specific requirements. You need both.<p>5. Cold start problem applies: if you return no results, ChatGPT learns not to call you<p>Stack: TypeScript, Vercel, Xano<p>Happy to share more on the build if useful.", "author": "bogdanmp", "timestamp": "2026-01-26T12:31:11+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-26T17:21:57.663839+00:00", "processed": false}
