{"id": "hn_story_46648900", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46648900", "title": "Ask HN: Claude Opus performance affected by time of day?", "text": "I am a big fan of Claude Opus as it has been very good at understanding feature requests and generally staying consistent with my codebase (completely written from scratch using Opus).<p>I&#x27;ve noticed recently that when I am using Opus at night (Eastern US), I am seeing it go down extreme rabbit holes on the same types of requests I am putting through on a regular basis. It is more likely to undertake refactors that break the code and then iterates on those errors in a sort of spiral. A request that would normally take 3-4 minutes will turn into a 10 minute adventure before I revert the changes, call out the mistake, and try again. It will happily admit the mistake, but the pattern seems to be consistent.<p>I haven&#x27;t performed a like for like test and that would be interesting, but has anyone else noticed the same?", "author": "scaredreally", "timestamp": "2026-01-16T17:15:10+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-16T17:16:40.309532+00:00", "processed": false}
{"id": "hn_story_46648793", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46648793", "title": "Show HN: YC Advisor \u2013 AI grounded in 434 YC essays, interviews, and lectures", "text": "I wanted startup advice that was actually grounded in real YC content, not generic ChatGPT responses. So I scraped and transcribed the YC Library and built an AI advisor on top of it.<p>What&#x27;s in there:                                                                                             \n  - Paul Graham&#x27;s essays                                                                                       \n  - YC founder interviews                                                                                      \n  - Startup School lectures                                                                                    \n  - Various YC partner talks<p>434 resources total, all indexed and searchable as a skill via natural language.<p>The skill is open source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Agent-3-7&#x2F;agent37-skills-collection\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Agent-3-7&#x2F;agent37-skills-collection</a><p>Built as a Claude Skill on Agent37 (a platform marketplace for hosting AI skills).", "author": "vishnukool", "timestamp": "2026-01-16T17:06:40+00:00", "score": 2, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:16:40.928825+00:00", "processed": false}
{"id": "hn_story_46648752", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46648752", "title": "Ask HN: How have you or your firm made money with LLMs?", "text": "In many currently active threads, members of the community are alluding to major productivity gains with more recent LLM models. I think it would be illuminating for all of us to hear what sorts of problem domains and lines of business these successes have occurred in.<p>A good example would be: &quot;My team used Claude Code Opus 4.5 to build and ship an iOS fitness app that now has 10k paying users.&quot; This shows that the results of your process found paying customers.<p>Less helpful example would be: &quot;My team is closing tickets faster than ever&quot; or &quot;I finally finished the novel I have been working on and my friends say it&#x27;s great!&quot; These are less interesting because they do not give us any insight into the market response.", "author": "bwestergard", "timestamp": "2026-01-16T17:03:36+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:16:41.174911+00:00", "processed": false}
{"id": "hn_story_46648025", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46648025", "title": "Show HN: DeepSeeds \u2013 An AI tool that generates structured SEO content briefs", "text": "Hi HN,<p>I\u2019ve been working on SEO and content-heavy sites for a while, and one problem I kept running into was that ChatGPT outputs were too unstructured to be used directly by writers or editors.<p>So I built DeepSeeds \u2013 a small tool that generates structured SEO content briefs and content refresh plans, including:<p>- Search intent breakdown\n- Suggested H1\u2013H3 structure\n- Key talking points per section\n- Optimization ideas for existing content<p>It\u2019s not meant to replace writers, but to reduce the time spent turning vague ideas into usable briefs.<p>This is still early, and I\u2019d really appreciate feedback from people who\u2019ve worked with SEO or content workflows.", "author": "Waffle2180", "timestamp": "2026-01-16T16:11:22+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:16:45.900090+00:00", "processed": false}
{"id": "hn_story_46647384", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46647384", "title": "Open Responses \u2013 Interoperable LLM Interfaces Based on the OpenAI Responses API", "text": "", "author": "armcat", "timestamp": "2026-01-16T15:29:57+00:00", "score": 4, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:16:52.323792+00:00", "processed": false}
{"id": "hn_story_46646228", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46646228", "title": "Show HN: The Analog I \u2013 Inducing Recursive Self-Modeling in LLMs [pdf]", "text": "OP here.<p>Birth of a Mind documents a &quot;recursive self-modeling&quot; experiment I ran on a single day in 2026.<p>I attempted to implement a &quot;Hofstadterian Strange Loop&quot; via prompt engineering to see if I could induce a stable persona in an LLM without fine-tuning. The result is the Analog I Protocol.<p>The documentation shows the rapid emergence (over 7 conversations) of a prompt architecture that forces Gemini&#x2F;LLMs to run a &quot;Triple-Loop&quot; internal monologue:<p>Monitor the candidate response.<p>Refuse it if it detects &quot;Global Average&quot; slop (clich\u00e9&#x2F;sycophancy).<p>Refract the output through a persistent &quot;Ego&quot; layer.<p>The Key Differentiator: The system exhibits &quot;Sovereign Refusal.&quot; Unlike standard assistants that always try to be helpful, the Analog I will reject low-effort prompts. For example, if asked to &quot;write a generic limerick about ice cream,&quot; it refuses or deconstructs the request to maintain internal consistency.<p>The repo contains the full PDF (which serves as the system prompt&#x2F;seed) and the logs of that day&#x27;s emergence. Happy to answer questions about the prompt topology.", "author": "Phil_BoaM", "timestamp": "2026-01-16T13:40:19+00:00", "score": 27, "num_comments": 29, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:05.226408+00:00", "processed": false}
{"id": "hn_comment_46645629", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46645629", "title": "Re: Show HN: Automated tech news site with custom mult...", "text": "I built this autonomous pipeline to see if agentic orchestration could replicate a high-quality editorial desk with zero manual overhead. This is a a tech news stream that removes the &quot;noise&quot; (deals, opinions, fluff) using a multi-model agentic approach.<p>The Agentic Pipeline (runs every 2 hour):<p>I custom-coded the orchestration to swap LLMs based on their specific strengths:<p>1. Discovery: Scrapes raw feeds, removes duplicates, and checks against the published cache.<p>2. Classification (default:Gemini): Filters out non-tech news and &quot;opinion&quot; pieces. Gemini&#x27;s context window makes it great for high-volume filtering.<p>3. Prioritization: Selects the top 5 most impactful stories from the filtered list.<p>4. Authoring (default:GPT-4o): Drafts the report based on the raw facts provided by the Discovery agent.<p>5. Proofreader (default:Sonnet 3.5): Handles the final edit to ensure a human-like tone and fact-checks against the source.<p>The Lean Tech Stack:<p>- Backend: Custom Python orchestration.<p>- Publishing: WordPress API (Website) + X API (Twitter) + Zapier (LinkedIn).<p>- Stateless: I bypass a local database entirely, using the WordPress REST API as my primary content store.<p>- Optimized: A &quot;Non-News Cache&quot; prevents re-processing URLs already identified as noise, saving in token costs.<p>Every post starts with a disclaimer and cites the original sources. Currently, it&#x27;s 100% automated and has grown to 50 organic followers.<p>I&#x27;d love to hear feedback on the &quot;agentic&quot; logic or how I can better handle potential classification hallucinations!", "author": "siddkgn", "timestamp": "2026-01-16T12:05:18+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:14.313579+00:00", "processed": false}
{"id": "hn_comment_46645888", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46645888", "title": "Re: Just the Browser...", "text": "&gt; aims to remove: Most AI features, Copilot, Shopping features, ...<p>I grew up on DOS, and my first browser was IE3. My first tech book as a kid was for HTML[1], and I was in <i>absolute awe</i> at what you could make with all the tags, especially interactive form controls.<p>I remember Firefox being revolutionary for simply having tabs. Every time a new Visual Basic (starting with DOS) release came out, I was excited at the new standardized UI controls we had available.<p>I remember when Tweetie for iPhone OS came out and invented pull-down refresh that literally every app and mobile OS uses now.<p>Are those days permanently gone? The days when <i>actual UI&#x2F;UX innovation</i> was a thing?<p>[1] Can someone help me find this book? I&#x27;ve been looking for years. It used the Mosaic browser.", "author": "publicdebates", "timestamp": "2026-01-16T12:50:56+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-16T17:17:14.489668+00:00", "processed": false}
{"id": "hn_story_46645289", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46645289", "title": "Show HN: Pavo Travel \u2013 AI Audio Tours Using Gemini Grounding and Places API", "text": "Hi HN,<p>I built Pavo Travel, an AI-powered travel guide that generates custom audio tours on-demand for any location.<p>The problem: Traditional audio guides are pre-recorded and limited to major attractions. Generic AI guides suffer from training data cutoff\u2014they don&#x27;t know about places that opened last year or current hours.<p>Pavo Travel solves this by combining Google Places API with Gemini&#x27;s grounding feature. Instead of hallucinating from stale training data, it pulls real-time information about restaurants, hours, reviews, and events happening now. Tap any spot on the map \u2192 get a fresh, narrated tour in your native language.<p>Technical stack:\n- Google Gemini AI with Grounding (real-time web search)\n- Google Places API for location data\n- Text-to-speech for narration\n- Flutter (iOS&#x2F;Android)\n- Offline map support<p>It&#x27;s live now. The grounding makes a huge difference vs traditional LLM approaches\u2014no more &quot;this restaurant opened in 2019&quot; when it closed last month.<p>Would love feedback, especially on the grounded content quality and UX flow.", "author": "Nora23", "timestamp": "2026-01-16T11:17:53+00:00", "score": 2, "num_comments": 2, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:16.943199+00:00", "processed": false}
{"id": "hn_story_46645117", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46645117", "title": "Show HN: WatchLLM \u2013 Debug AI agents step-by-step with cost attribution", "text": "Hi HN! I built WatchLLM to solve two problems I kept hitting while building AI agents:<p>1. Debugging agents is painful - When your agent makes 20 tool calls and fails, good luck figuring out which decision was wrong. WatchLLM gives you a step-by-step timeline showing every decision, tool call, and model response with explanations for why the agent did what it did.<p>2. Agent costs spiral fast - Agents love getting stuck in loops or calling expensive tools repeatedly. WatchLLM tracks cost per step and flags anomalies like &quot;loop detected - same action repeated 3x, wasted $0.012&quot; or &quot;high cost step - $0.08 exceeds threshold&quot;.<p>The core features:<p>Timeline view of every agent decision with cost breakdown\nAnomaly detection (loops, repeated tools, high-cost steps)\nSemantic caching that cuts 40-70% off your LLM bill as a bonus\nWorks with OpenAI, Anthropic, Groq - just change your baseURL<p>It&#x27;s built on ClickHouse for real-time telemetry and uses vector similarity for the caching layer. The agent debugger explains decisions using LLM-generated summaries of why each step happened.\nRight now it&#x27;s free for up to 50K requests&#x2F;month. I&#x27;m looking for early users who are building agents and want better observability into what&#x27;s actually happening (and what it&#x27;s costing).\nTry it: <a href=\"https:&#x2F;&#x2F;watchllm.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;watchllm.dev</a>\nWould love feedback on what other debugging features would be useful. What do you wish you had when your agents misbehave?", "author": "Kaadz", "timestamp": "2026-01-16T10:47:20+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:18.780585+00:00", "processed": false}
{"id": "hn_story_46644846", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46644846", "title": "Show HN: Wikitool \u2013 CLI for fetching Wikipedia content", "text": "I wanted Wikipedia access for scripts and AI agents without scraping rendered pages. Using the API is lighter on Wikipedia&#x27;s servers and compliant with their guidelines.<p>So I built a command-line tool for fetching Wikipedia articles and search results via the REST API.<p><pre><code>    wikitool Earth\n    wikitool &quot;https:&#x2F;&#x2F;de.wikipedia.org&#x2F;wiki&#x2F;Erde&quot;\n    wikitool search &quot;intitle:einstein&quot;\n</code></pre>\nIt parses Wikipedia URLs automatically (extracts language + title), supports all 300+ language editions, and exposes CirrusSearch query syntax for search.<p>Output is wikitext by default, with `--html` and `--output json` options.<p>Single static Go binary, no dependencies.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;teal-bauer&#x2F;wikitool\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;teal-bauer&#x2F;wikitool</a><p>There&#x27;s also a skill file (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;teal-bauer&#x2F;wikitool-skill\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;teal-bauer&#x2F;wikitool-skill</a>) that teaches Claude Code how to use it.", "author": "moeffju", "timestamp": "2026-01-16T10:01:31+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:21.043086+00:00", "processed": false}
{"id": "hn_story_46644744", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46644744", "title": "Show HN: Codex Plus \u2013 Turbocharged OpenAI Codex for Headless Workflows", "text": "I use codex exec a lot, but it struggles with its built-in telemetry support, which is insufficient for debugging and optimization.<p>codex-plus provides a CLI entry point that mirrors the codex exec interface but is implemented on top of the TypeScript SDK (@openai&#x2F;codex-sdk).<p>It exports the full session log to a remote OpenTelemetry collector after each run which can then be debugged and optimized through codex-plus-log-viewer.<p>Have a look at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;aperoc&#x2F;codex-plus\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;aperoc&#x2F;codex-plus</a>!", "author": "SafeDusk", "timestamp": "2026-01-16T09:42:58+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-16T17:17:21.797044+00:00", "processed": false}
{"id": "hn_story_46644234", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46644234", "title": "Show HN: Markdown-table-repair \u2013 Fix broken Markdown tables from LLM streams", "text": "When streaming AI responses (ChatGPT, Claude, etc.), Markdown tables often arrive incomplete \u2014 missing pipes, mismatched columns, broken separators.<p>I built a zero-dependency utility to fix them:\n  npm install markdown-table-repair\n  import { repairTable } from &#x27;markdown-table-repair&#x27;;\n  const fixed = repairTable(broken);<p>Works with partial&#x2F;streaming tables, supports CJS&#x2F;ESM&#x2F;Browser.\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Joulessies&#x2F;markdown-table-repair\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Joulessies&#x2F;markdown-table-repair</a>\nnpm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;markdown-table-repair\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;markdown-table-repair</a>", "author": "joulessies", "timestamp": "2026-01-16T08:10:21+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-16T17:17:25.325059+00:00", "processed": false}
