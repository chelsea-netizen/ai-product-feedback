{"id": "hn_story_46355848", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355848", "title": "Show HN: Utter \u2013 System-wide dictation on macOS with AI prompts (free / BYOK)", "text": "Hi HN,<p>I built Utter, a native macOS dictation app, and wanted to share it here to get feedback.<p>The motivation was that Apple Dictation works for short notes, but for longer or technical input it often produces a wall of text that takes more time to clean up than typing. I wanted dictation that could understand context and produce structured output directly.<p>Utter works system-wide: you press a global hotkey, speak, and the text is inserted directly at your cursor in any app. Before insertion, the dictated text can optionally be processed through a custom AI prompt (fully user-defined).<p>Some details:<p>- System-wide dictation (works in any text field)\n- Custom prompts to turn speech into emails, structured Markdown, summaries, JSON, etc.\n- Bring-your-own API keys (OpenAI, Anthropic, etc.), so it\u2019s free to use\n- Optional hosted models if you don\u2019t want to manage keys\n- Privacy-first: no accounts, no data retention, keys stored locally\n- Searchable audio + transcript history\n- iOS companion app with a custom keyboard, synced via iCloud<p>My main use cases are note-taking, email, and coding. For example, I often dictate rough thoughts while walking and have them converted into clean Markdown, or dictate rough prompts into terminal and turn them into structured prompts with file references.<p>Link: <a href=\"https:&#x2F;&#x2F;utter.to\" rel=\"nofollow\">https:&#x2F;&#x2F;utter.to</a><p>I\u2019d really appreciate feedback \u2014 especially from people who use dictation or voice input regularly, or who\u2019ve tried building similar workflows.<p>Thanks!", "author": "helro", "timestamp": "2025-12-22T16:53:40+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["content_clarity", "response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:53.345526+00:00", "processed": false}
{"id": "hn_story_46355452", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355452", "title": "Show HN: I made a puzzle game without writing any code", "text": "This is the first project I haven&#x27;t written a single line of code. The entire codebase was prompt generated in Cursor using mostly Claude Sonnet 4.5.<p>It&#x27;s also the first time I&#x27;m genuinely happy with the end result from AI coding.<p>What do you think?", "author": "ediblepython", "timestamp": "2025-12-22T16:23:57+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["onboarding", "response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:54.095589+00:00", "processed": false}
{"id": "hn_story_46355200", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355200", "title": "Show HN: I built a linter for landing page conversion", "text": "Hey HN,<p>I&#x27;m Nik and I&#x27;ve worked 8 years working in Marketing at High Growth Startups. I\u2019ve spent years fixing landing pages for my campaigns, and I realized most bad conversion rates come from structural errors, not just bad copy. (Still copy remains the major part of conversions)<p>I built Landkit Audit to act as a Linter for conversion.<p>How it works:<p>Ingestion: It fetches your site and converts the DOM into a high-fidelity semantic map. This strips away the design noise to reveal the actual information hierarchy your user is navigating.<p>The Linting Rules: It runs this structure against 50+ heuristics derived from direct response frameworks (Cialdini, Fogg, LIFT).<p>Heuristic Analysis: It flags specific &#x27;violations&#x27; like:<p>Visual Hierarchy: H1s that fail to pass the 5-second test (inferred).<p>Friction: Forms that ask for high-commitment data before establishing value.<p>Anxiety: Missing trust signals near payment triggers.<p>The Stack:<p>Frontend: React + Framer Motion (for the Terminal visualization).<p>Backend: Supabase Edge Functions.<p>Analysis: Gemini Pro 2.5 (great at logical reasoning&#x2F;inference).<p>The hardest part was tuning the prompt to be critical rather than nice. Most LLMs default to being supportive; I had to prompt engineer a persona that acts more like a brutal senior editor.<p>Try it here: <a href=\"https:&#x2F;&#x2F;landkit.pro&#x2F;audit\" rel=\"nofollow\">https:&#x2F;&#x2F;landkit.pro&#x2F;audit</a><p>It\u2019s free to run the audit. I\u2019d love to know if the Linting errors it finds on your projects feel accurate.", "author": "nikhonit", "timestamp": "2025-12-22T16:03:17+00:00", "score": 1, "num_comments": 1, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:55.110178+00:00", "processed": false}
{"id": "hn_comment_46355402", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355402", "title": "Re: Ask HN: Why Did Python Win?...", "text": "Because not many people prioritize syntax design like GvR. Even now if someone releases a new programming language most people will ask what features it has, how fast it is, how fast is the package manager etc. Because these questions are simple yes and no ones. Unlike syntax design choices.<p>Even if they ask about the syntax design people just dismiss their question with saying &quot;syntax is not important&quot;. Python did the opposite, it focused on syntax over everything else. That caught on with beginners and now here we are.<p>Of course with AI Python got even more popular, but even before ChatGPT was released it was already dominant.", "author": "nromiun", "timestamp": "2025-12-22T16:18:47+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-22T17:10:55.527502+00:00", "processed": false}
{"id": "hn_comment_46355014", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355014", "title": "Re: Runiq \u2013 A local, sovereign runtime for AI Agents (...", "text": "Hi HN \u2014 I built Runiq: a local \u201csovereign runtime\u201d that lets LLM agents (Claude Desktop, local Llama, etc.) use hardened tools to interact with your OS, instead of executing arbitrary shell&#x2F;Python.<p>Runiq implements Anthropic\u2019s Model Context Protocol (MCP) and exposes a small set of controlled capabilities:<p>Stealth Chromium browser for scraping&#x2F;automation (aimed to survive common bot checks)<p>File operations and local workflow tools<p>Human-in-the-loop security: native OS popups block risky actions (write&#x2F;delete&#x2F;etc.) until you approve<p>It ships as a single static Go binary (no venv&#x2F;daemon). It\u2019s localhost-only and auditable; if you pair it with a local model, nothing leaves your machine. There\u2019s also an optional Python adapter to use the same tool interface with OpenAI&#x2F;Groq&#x2F;LangChain-style agents.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;qaysSE&#x2F;runiq\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;qaysSE&#x2F;runiq</a><p>I\u2019d love feedback on the MCP implementation in Go, and on the security&#x2F;UX tradeoffs for permission-gated agent actions.", "author": "QaysHaji", "timestamp": "2025-12-22T15:42:55+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-22T17:10:56.051793+00:00", "processed": false}
{"id": "hn_story_46354972", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46354972", "title": "Show HN: Real-time voice AI agent console with 133ms latency (YC assessment)", "text": "Hi HN,<p>Built a real-time voice AI agent console for a YC W25 startup assessment (Freya Voice). Focus was on production-ready implementation with minimal latency.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;05sanjaykumar&#x2F;Freya-Voice-YC25-Assessment\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;05sanjaykumar&#x2F;Freya-Voice-YC25-Assessment</a><p>Key specs:\n- 133ms average latency (voice input \u2192 AI response \u2192 audio output)\n- LiveKit for WebRTC streaming\n- Next.js frontend + Python FastAPI backend\n- Multi-stage Docker deployment\n- Full observability and session management\n- In-memory storage for speed (design trade-off for assessment scope)<p>Tech stack:\n- Frontend: Next.js, TypeScript, LiveKit client SDK\n- Backend: FastAPI, LiveKit server SDK, OpenAI\n- Infrastructure: Docker multi-stage builds, production configs<p>Design decisions I made:\n- Voice-first interface (no text fallback) to match real-world use case\n- In-memory session storage (speed over persistence for MVP)\n- LiveKit over WebSocket (proven real-time infrastructure)\n- Concurrent audio processing to hit latency targets<p>Built in ~1 week for the assessment. Didn&#x27;t land the role (extremely competitive) but learned a ton about real-time systems and WebRTC optimization.<p>Happy to discuss the latency optimization techniques or design trade-offs!", "author": "sanjaykumar584", "timestamp": "2025-12-22T15:38:58+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:56.185860+00:00", "processed": false}
{"id": "hn_comment_46355611", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46355611", "title": "Re: Scaling LLMs to Larger Codebases...", "text": "This highlights a missing feature of LLM tooling, which is asking questions of the user. I&#x27;ve been experimenting with Gemini in VS Code, and it just fills in missing information by guessing and then runs off writing paragraphs of design and a bunch of code changes that could have been avoided by asking for clarification at the beginning.", "author": "smallerize", "timestamp": "2025-12-22T16:36:44+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-22T17:10:56.272361+00:00", "processed": false}
{"id": "hn_comment_46354279", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46354279", "title": "Re: Leveraging AI as an infinitely patient teacher...", "text": "Are you using claude GUI or is this claude code? Is the interaction happening purely over the TUI interface or is claude also looking at code you&#x27;ve written so far (assuming you&#x27;re in a socratic style dialogue).", "author": "checker659", "timestamp": "2025-12-22T14:16:36+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-22T17:10:58.762374+00:00", "processed": false}
{"id": "hn_story_46353821", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46353821", "title": "Show HN: Python Local Sandbox Code Execution (Podman and Uv)", "text": "The core idea: @sandbox(dependencies=[&quot;pandas&quot;]) turns any function into one that runs inside an isolated Podman container with dependency caching built in on uv. You call it like a normal function, but the code executes with no access to your host filesystem, credentials, or processes.<p>from pctx_sandbox import sandbox<p>@sandbox(dependencies=[&quot;requests&quot;])\ndef fetch_url(url: str) -&gt; str:\n    import requests\n    return requests.get(url).text<p>result = fetch_url(&quot;<a href=\"https:&#x2F;&#x2F;example.com\" rel=\"nofollow\">https:&#x2F;&#x2F;example.com</a>&quot;)  # runs in container<p>Technical details:<p>- Uses rootless Podman for container isolation (all the Linux namespace stuff: PID, mount, network, user)\n- Maintains a warm pool of workers per dependency set, so there&#x27;s no cold-start penalty after the first call\n- Dependencies are cached and installed once per unique combination\n- Resource limits enforced via cgroups<p>The security model is &quot;defense in depth&quot; \u2013 it&#x27;s container isolation, not a VM, so it&#x27;s not a perfect security boundary. But it&#x27;s good enough that I&#x27;m comfortable letting Claude use it on my machine.<p>Would love feedback. Thanks!", "author": "pmkelly4444", "timestamp": "2025-12-22T13:02:44+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:59.470027+00:00", "processed": false}
{"id": "hn_story_46353782", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46353782", "title": "Show HN: NICH \u2013 Browser-based tool to anonymize AI-conversations", "text": "I built NICH after realising I couldn&#x27;t use ChatGPT for my conflict research work without risking data leaks.<p>It&#x27;s a browser extension that:\n- Anonymises names, emails, and addresses in one click\n- Preserves context for AI to understand\n- Restores original data in AI responses\n- 100% browser-based (no cloud, data never leaves your device)<p>Built it for researchers, lawyers, HR professionals or simply anyone handling confidential data who wants AI assistance without compliance nightmares.<p>Free to use: <a href=\"https:&#x2F;&#x2F;www.nichtech.uk\" rel=\"nofollow\">https:&#x2F;&#x2F;www.nichtech.uk</a><p>Would love feedback from the HN community!", "author": "akryshtal", "timestamp": "2025-12-22T12:55:12+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:10:59.579365+00:00", "processed": false}
{"id": "hn_comment_46351788", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46351788", "title": "Re: Agent Skills for Context Engineering...", "text": "I&#x27;ve been building multi-agent systems for the past year and kept running into the same problems: context windows filling up with tool outputs, agents losing track of information buried in the middle of long conversations, supervisors becoming bottlenecks as they accumulated state from all workers.<p>The solutions to these problems are scattered across research papers, framework docs, and production war stories. I collected and synthesized them into a set of &quot;Agent Skills&quot; - structured instructions that agents can load on demand when working on relevant tasks.<p>7 skills covering context engineering fundamentals:<p>- \\context-fundamentals\\: What context actually is (system prompts, tool definitions, retrieved docs, message history, tool outputs) and why context quality matters more than context length<p>- \\context-degradation\\: The failure modes - lost-in-middle (10-40% accuracy drop for middle content), context poisoning (hallucinations that compound), context distraction (irrelevant info consuming attention budget)<p>- \\multi-agent-patterns\\: Supervisor vs swarm vs hierarchical architectures, when to use each, and the &quot;telephone game&quot; problem where supervisors paraphrase sub-agent responses incorrectly<p>- \\memory-systems\\: Why vector stores lose relationship information, when to use knowledge graphs, and how temporal validity prevents outdated facts from conflicting with new ones<p>- \\tool-design\\: The consolidation principle (if a human can&#x27;t say which tool to use, an agent can&#x27;t either), error messages that enable recovery, response format options for token efficiency<p>- \\context-optimization\\: Compaction triggers, observation masking (tool outputs can be 80%+ of token usage), KV-cache optimization<p>- \\evaluation\\: Multi-dimensional rubrics instead of single metrics, LLM-as-judge for scale, human review for edge cases<p>It uses Anthropic&#x27;s open Agent Skills format. Each skill is a folder with a SKILL.md file containing instructions. Progressive disclosure - agents load only skill names&#x2F;descriptions at startup, full content loads when activated for relevant tasks.<p>Works with Claude Code, Cursor, or any agent that supports skills&#x2F;custom instructions.<p>Would appreciate feedback, especially from anyone running multi-agent systems in production. What patterns are you seeing that aren&#x27;t captured here?", "author": "youraimarketer", "timestamp": "2025-12-22T06:08:56+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:11:05.706471+00:00", "processed": false}
{"id": "hn_story_46351360", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46351360", "title": "Show HN: Spring AI Playground \u2013 No-code MCP tool studio and agentic chat", "text": "Hi HN \u2014 I just shipped the first feature update for Spring AI Playground since it became an official Spring AI Community incubating project.<p>The goal is to treat MCP tools as runtime entities you can build, inspect, and iterate on live\u2014without rebuilds or redeployments.<p>What\u2019s in this update:<p>- No-code &#x2F; low-code Tool Studio: create AI-callable tools in the browser using JavaScript (ECMAScript 2023) and run them sandboxed in the JVM (GraalVM Polyglot).<p>- Live built-in MCP server: tools are evaluated and registered dynamically to an embedded MCP server, becoming immediately available (no restart).<p>- MCP inspection &amp; debugging: inspect registered tools, schemas&#x2F;parameters, and execution results to understand agent behavior.<p>- Agentic chat: test end-to-end flows that combine LLM reasoning, MCP tools, and optional RAG context in one UI.<p>It also ships with working example tools meant to be copied&#x2F;modified as templates:<p>- googlePseSearch - Google PSE web search (API key)<p>- extractPageContent - Extract clean text from URLs (RAG prep)<p>- buildGoogleCalendarCreateLink - Generate calendar add links<p>- sendSlackMessage - Slack webhook messaging<p>- openaiResponseGenerator - OpenAI API calls (API key)<p>- getWeather - wttr.in weather<p>- getCurrentTime - ISO-8601 time<p>Everything runs local-first with Ollama by default (OpenAI-compatible APIs supported). No cloud required.<p>Local-first by default using Ollama and OpenAI-compatible endpoints&#x2F;config, so it can run without required cloud services.<p>GitHub: \n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;spring-ai-community&#x2F;spring-ai-playground\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;spring-ai-community&#x2F;spring-ai-playground</a><p>Question for folks building with MCP&#x2F;agents: what inspection&#x2F;debugging workflows do you wish every MCP client&#x2F;UI supported (e.g., clear schema views, tool-call tracing, reproducible runs, etc.)?", "author": "hjm1980", "timestamp": "2025-12-22T04:41:20+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-22T17:11:06.492295+00:00", "processed": false}
