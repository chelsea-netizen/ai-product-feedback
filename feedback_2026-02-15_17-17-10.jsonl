{"id": "hn_story_47024973", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47024973", "title": "Adafruit \u2013 Our First Gemini Deep Think LLM-Assisted Hardware Design", "text": "", "author": "rwmcfa1", "timestamp": "2026-02-15T16:28:56+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:13.986337+00:00", "processed": false}
{"id": "hn_story_47024098", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47024098", "title": "Show HN: Typemux-cc \u2013 .venv-aware Python LSP proxy for Claude Code (no restarts)", "text": "Hi HN \u2014 I built typemux-cc, a Claude Code plugin that makes Python `.venv` switching work without restarts.<p>Claude Code\u2019s official pyright plugin spawns one backend at startup; if you create&#x2F;switch `.venv` later (common with git worktrees), it won\u2019t pick it up without restarting Claude Code.<p>typemux-cc is a Python LSP proxy that fixes this by keeping a per-`.venv` backend pool and routing requests based on `didOpen` `.venv` detection. It also restores open docs on spawn, queues index-dependent requests during warmup, and rewrites backend\u2192client request IDs to avoid collisions.<p>Supports pyright &#x2F; ty &#x2F; pyrefly.<p>Repo + quickstart:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;K-dash&#x2F;typemux-cc\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;K-dash&#x2F;typemux-cc</a><p>Feedback welcome \u2014 especially on the \u201cfail loudly vs fallback when `.venv` is missing\u201d policy and reliable warmup&#x2F;readiness signals across pyright&#x2F;ty&#x2F;pyrefly.", "author": "K-dash", "timestamp": "2026-02-15T14:46:31+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:19.282377+00:00", "processed": false}
{"id": "hn_story_47023922", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47023922", "title": "Show HN: Lineark \u2013 Linear CLI and Rust SDK for Humans and LLMs", "text": "lineark is an unofficial CLI and Rust SDK for Linear (the issue tracker). I built it because I use Claude Code heavily, and the Linear MCP server eats ~13K tokens of context just to describe its tools \u2014 before my agent does any actual work.<p>lineark takes a different approach: it&#x27;s a CLI your agent calls via Bash. The full command reference (lineark usage) is under 1,000 tokens.<p>It&#x27;s also just a nice CLI for humans \u2014 human-readable names instead of UUIDs, auto-detected output format (outputs tables in terminal&#x2F;interactive session, JSON when piped).<p>Under the hood: the SDK is fully generated from Linear&#x27;s GraphQL schema via a custom codegen pipeline (apollo-parser \u2192 typed Rust). The CLI consumes the SDK with zero raw GraphQL \u2014 just typed method calls. You can also create your own lean return data types and validate them against Linear&#x27;s schema at comptime.<p>MIT Licensed.<p>Happy to answer questions. Thanks!", "author": "fb03", "timestamp": "2026-02-15T14:25:23+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:20.372197+00:00", "processed": false}
{"id": "hn_story_47023918", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47023918", "title": "Show HN: Kremis \u2013 Graph-based memory for AI agents with no hidden state (Rust)", "text": "Hi HN \u2014 I built Kremis, a deterministic graph engine designed as a memory substrate for AI agents. Written in Rust, development was heavily AI-assisted.<p>The core idea: agent memory should be inspectable, deterministic, and honest.<p>- Same input \u2192 same output. No randomness, no floating-point in core.\n- Every query result traces back to a concrete graph path \u2014 no hidden state.\n- Zero pre-loaded knowledge. All structure emerges from ingested signals.\n- ACID transactions via redb. Crash-safe persistent storage.<p>It ships as a library (kremis-core, pure Rust, no async), an HTTP API + CLI, and an MCP server so AI assistants like Claude can query the graph directly.<p>Current state: v0.3.1, experimental, ~277 tests, CI on 3 OS, Docker image.<p>I&#x27;d value feedback on:\n- Does the deterministic graph approach make sense for agent memory?\n- API ergonomics \u2014 is the query model (lookup&#x2F;traverse&#x2F;path&#x2F;intersect) intuitive?\n- What failure modes should I prioritize testing?", "author": "M2Dr3g0n", "timestamp": "2026-02-15T14:25:03+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:20.411711+00:00", "processed": false}
{"id": "hn_story_47023258", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47023258", "title": "Show HN: Vibe Audit \u2013 Detecting Context Drift in Coding Agents", "text": "I mostly built this for myself.<p>After a few long coding-agent sessions(Claude Code, Gemini CLI, Codex),\nI&#x27;d sometimes get to a point where something felt &quot;off.&quot; The output looked reasonable, but it wasn&#x27;t quite aligned with what I originally intended. And I couldn&#x27;t easily tell when that shift happened without scrolling through a huge transcript.<p>So I put together a small local tool to make that drift visible.<p>Vibe Audit tries to surface when an agent continues the same line of work, starts a new phase, or quietly pivots. It builds a rough baseline from the user\u2019s prompts, tracks session events, and then shows:<p>- Phase shifts(continuation&#x2F;new_phase&#x2F;pivot)\n- An alignment score with a short rationale\n- A timeline view of how context evolves over time<p>It runs entirely locally and hooks into CLI sessions.<p>Quick start:\nnpx vibe-audit<p>A few notes:\n1. It\u2019s still beta. Phase detection and alignment scoring depend partly on model interpretation.\n2. Different CLIs emit slightly different event formats, so behavior isn&#x27;t perfectly identical across providers.\n3. If a session is force-stopped mid-stream, the last turn can be incomplete.\n4. It&#x27;s currently designed for personal&#x2F;local workflows rather than team-wide infrastructure.<p>I&#x27;m sharing this early to see whether intent-drift detection is actually useful in real-world workflows, or if I&#x27;m just over-optimizing my own frustration.", "author": "vulpez", "timestamp": "2026-02-15T12:46:58+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:26.841346+00:00", "processed": false}
{"id": "hn_comment_47023067", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47023067", "title": "Re: TexGuardian \u2013 Claude Code, but for LaTeX academic ...", "text": "I built TexGuardian after spending yet another deadline night fighting LaTeX formatting instead of focusing on research. Every conference submission, the same ritual: figure overflows, citation format issues, TODO markers left in text, hallucinated references from ChatGPT, forgotten anonymization. Hours wasted on mechanical formatting when you should be sleeping or refining ideas.<p>TexGuardian is a CLI that treats paper preparation like code review. It reads your entire .tex and .bib files, understands LaTeX structure and venue requirements, then generates reviewable unified diff patches for every issue it finds. No blind rewrites, no mysterious changes \u2014 every edit is shown as a diff you approve before it touches your files.<p>The `&#x2F;review full` command runs a 7-step autonomous pipeline:\n1. Compile with latexmk (proper error reporting)\n2. Verify (figures, citations, TODOs, page limits, custom regex rules)\n3. Fix issues with LLM-generated patches\n4. Validate citations against CrossRef and Semantic Scholar APIs (catches hallucinated or outdated references)\n5. Analyze figures (width overflows, placement, captions)\n6. Analyze tables (booktabs compliance, column overflow)\n7. Visual polish \u2014 renders PDF to images, sends to vision model, catches overlapping figures, bad spacing, margin violations that text-only analysis can&#x27;t see<p>Key design decisions:\n- Checkpoint system with instant rollback \u2014 every modification creates a restore point\n- Unified diff patches only, never direct file writes \u2014 makes LLM edits auditable and reversible\n- Async citation validation with concurrent API calls to CrossRef and Semantic Scholar\n- Vision model convergence loop for PDF polish \u2014 iterates render \u2192 analyze \u2192 patch until quality stabilizes\n- Natural language + slash commands \u2014 mix &quot;&#x2F;anonymize&quot; with &quot;fix the figure on line 303&quot;\n- Pluggable LLM backends (AWS Bedrock, OpenRouter) \u2014 default is Claude Opus 4.5 but supports any model<p>Works with 14 conference templates out of the box: NeurIPS, ICML, ICLR, AAAI, CVPR, ECCV, ACL, EMNLP, NAACL, COLING, CHI, KDD. Custom venue rules via regex patterns in paper_spec.md.<p>What started as a personal tool became something I thought the research community might find useful. If you&#x27;ve ever debugged \\columnwidth calculations at 2 AM or validated 50 citations manually, this is for you.<p>pip install texguardian<p>Happy to answer questions about the architecture, LLM integration patterns, or take feature requests.", "author": "amananytime07", "timestamp": "2026-02-15T12:08:14+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:28.626086+00:00", "processed": false}
{"id": "hn_story_47022899", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022899", "title": "Show HN: AIWriteBook \u2013 AI tool to write, design, and publish full-length books", "text": "hey HN, I built this. AIWriteBook takes you from a book idea to a finished, publishable book (outline, chapters, cover, illustrations, audiobook, and KDP ready export) in one tool.<p>You can try it right away: the free tools (title generator, plot generator, character creator) work without signing up. Also, free account gives you a full 7 chapter book, no credit card.<p>I run a small publishing platform (NanoReads, 130+ published books, 341K readers). I kept seeing authors juggle 5 to 7 tools to publish one book: outliner, writing tool, Vellum ($250) for formatting, cover designer, TTS for audiobooks, keyword tool for Amazon. Nothing covers the full journey.<p>How it works: you enter a title and basic info. AI generates a structured outline with characters (arcs, motivations, voice) and a chapter by chapter story bible (events, locations, twists). You edit the outline (most important step). AI writes chapters one at a time using only the relevant character data and chapter spec. You can upload writing samples so it matches your voice. Then generate a cover, add illustrations, convert to audiobook, export as PDF&#x2F;EPUB&#x2F;DOCX.<p>Some technical details: we treat it as a compiler pipeline. Book metadata \u2192 character graph \u2192 chapter outlines \u2192 chapter content. Each step uses schema constrained structured output. Two model strategy: Gemini Flash for structural work (fast, cheap), frontier model for chapter prose (quality matters). Voice calibration uses writing samples as few shot examples plus extracted style features. Fiction and nonfiction have separate architectures. Fiction uses character graphs + plot continuity, nonfiction uses reference material extraction with citation tracking.<p>After 50K+ books: chapter sweet spot is 2,000 to 3,500 words. Outline detail sweet spot is 150 to 300 words per chapter. Romance and thriller generate well, literary fiction and humor are hard. Practical limit around 15 to 20 characters per book.<p>Stack: Next.js + Supabase. 30+ languages.<p>Happy to answer questions about the architecture, publishing space, or anything else.", "author": "marakaci", "timestamp": "2026-02-15T11:27:52+00:00", "score": 3, "num_comments": 2, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:29.799651+00:00", "processed": false}
{"id": "hn_story_47022633", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022633", "title": "Show HN: Visual state tracking for AI agents in tmux", "text": "I run multiple Claude Code and Codex sessions in tmux panes. The main annoyance was not knowing when an agent finished or hit a permission prompt without switching to each pane to check.<p>This plugin hooks into agent lifecycle events and changes pane borders, window titles, and status bar icons to reflect three states: running, needs-input, done. Colors reset when you focus the\npane.<p>Works with Claude Code and Codex out of the box. Any other agent can integrate by calling a single shell script.", "author": "accessd", "timestamp": "2026-02-15T10:25:42+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:31.821409+00:00", "processed": false}
{"id": "hn_comment_47022919", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022919", "title": "Re: Ask HN: What will Software Engineering evolve to?...", "text": "18 years in embedded. Yes to all three, with caveats.<p>1. The pattern is real. I write specs and prompts between meetings, agents deliver code by EOD. But deep focus blocks aren&#x27;t dying, they&#x27;re shifting from &quot;writing code&quot; to &quot;thinking about architecture and verifying output.&quot;<p>2. Merging, yes. Decreasing value, no. The role is evolving from &quot;person who writes code&quot; to &quot;person who defines what correct looks like.&quot; The engineers who thrive will be the ones who can do both \u2014 manage agents AND know when the output is wrong. That requires more expertise, not less.<p>3. Overfitted to Claude Code? Probably a bit. But the delegating to AI agents instead of typing code yourself is tool-agnostic. Cursor, Copilot, Claude Code, whatever comes next. The workflow shift is real regardless of which tool wins.", "author": "0xecro1", "timestamp": "2026-02-15T11:30:48+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:33.029606+00:00", "processed": false}
{"id": "hn_comment_47022727", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022727", "title": "Re: Ask HN: What will Software Engineering evolve to?...", "text": "First, this is the problem:<p>&gt; <i>...now his advice it only get Claude Code and learn how to make it automate toil, and multiple claude agents to perform tasks instead of manually writing code.</i><p>Advice from creator of Claude Code is for you to continue to use Claude Code to spend more money on tokens instead of knowing what you are doing or what the code does.<p>I don&#x27;t think that will help in the long run. In fact this over-reliance will help accelerate the decline in being able to find hard to reach bugs and will create a new class of bugs from AI agents.<p>&gt; Do you also see this pattern emerging?<p>This helps experienced engineers and those who know what they are doing. For those who have no idea or have no experience then they tend to spend <i>even more</i> on tokens which is exactly what Anthropic needs you to keep doing.<p>&gt; Do you think software engineering and managarial roles are slowly merging and the value traditional software engineering is decreasing?<p>They were already merging before LLMs, (managers that can code and SWEs that become managers) but that doesn&#x27;t mean the value of traditional software engineering decreases. Software Engineering accounts for maintainance, security and time and usually producing more code to solve a problem just increases all of that and also the maintainance debt and the cognitive debt on the prompter.<p>The moment one needs to monetize that software, then software engineering becomes even more relevant (one feature can open another security issue) with or without LLMs.<p>&gt; Are above advices overindexed on Claude Code, because Boris created it?<p>Possibly. But that does not mean it is good advice, especially from someone that is selling a product telling you to use it even more and you not looking at what it is doing.<p>It was said that Claude Code was Boris&#x27;s side project that was built on a bad architecture and was difficult to maintain until the Bun developers were hired to fix those issues. Since they understood how the JS runtime works they knew how to fix those bugs when Claude got stuck, whilst also maintaining the Bun runtime.<p>The point is, it is still worth knowing what you are doing and learning about how it all works and not soley relying on a coding agent to do it all for you.", "author": "rvz", "timestamp": "2026-02-15T10:45:26+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-15T17:17:33.110719+00:00", "processed": false}
{"id": "hn_story_47022476", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022476", "title": "Show HN: Goutils \u2013 70 type-safe generic functions for async/functional Go", "text": "I built a Go utility library inspired by the JavaScript async library, implemented idiomatically with Go 1.18+ generics. Avoids using reflection and interface{} wherever possible.<p>It provides ~70 functions across four packages:<p>Sync and Async -- map, filter, detect, reduce, every, some, reject, groupBy -- for both slices and maps. Every async function runs iteratees in goroutines with panic recovery.\nConcurrency limiting -- all async functions have a Limit variant that caps goroutine count via a semaphore.\nWorker pool -- a generic work queue with configurable buffer, concurrency, timeouts, and graceful shutdown.\nControl flow -- waterfall-style sequential execution with type-safe context passing.<p>Disclaimer: Parts of the code were generated using Claude Code. One of my goals with this project was to experiment with the latest models and see what they&#x27;re capable of in a real codebase -- from writing implementations to tests to docs.<p>go get github.com&#x2F;skatiyar&#x2F;goutils@v1.0.0<p>Would love feedback on the API design and whether the function naming feels natural for Go.", "author": "skatiyar", "timestamp": "2026-02-15T09:56:23+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:33.273999+00:00", "processed": false}
{"id": "hn_comment_47025442", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47025442", "title": "Re: Two different tricks for fast LLM inference...", "text": "Article closes with:<p>&gt;The usefulness of AI agents is dominated by how few mistakes they make, not by their raw speed. Buying 6x the speed at the cost of 20% more mistakes is a bad bargain, because most of the user\u2019s time is spent handling mistakes instead of waiting for the model6.<p>That might be true today. I think the OpenAI-Cerebras partnership ultimately is going to lead to a paradigm shift because it will most likely be possible to scale these chips up to the point where a model like full Codex-5.3 can run on them and then you&#x27;ll have a super fast model that makes relatively few errors. A Codex-5.3 model running at these speeds is more than sufficient to actually start replacing customer facing jobs.", "author": "woeirua", "timestamp": "2026-02-15T17:16:56+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:34.325323+00:00", "processed": false}
{"id": "hn_comment_47022124", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47022124", "title": "Re: Ask anything about quantum and gravity from this G...", "text": "It&#x27;s the GPT for Relator Theory, you can ask anything about quantum physics and gravity and it will answer from all available papers. Maybe you discover something in foundational physics for the first time.<p>For example, I asked about the origin of electron mass and charge: <a href=\"https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;699188c1-9838-800f-bdd3-2aea55dcf573\" rel=\"nofollow\">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;699188c1-9838-800f-bdd3-2aea55dcf5...</a>", "author": "pajuhaan", "timestamp": "2026-02-15T08:51:35+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["onboarding", "response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:36.964027+00:00", "processed": false}
{"id": "hn_comment_47021505", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021505", "title": "Re: SmolMail \u2013 Stop typing what your emails know...", "text": "I built SmolMail because I was tired of manually copying info from emails into other apps. Amazon sends a shipping confirmation \u2014 I open Google Tasks, type the item name, set the due date. A flight confirmation arrives \u2014 I create a calendar event, copy the times, add the confirmation number. A receipt comes in \u2014 I add a row to my expense spreadsheet.<p>SmolMail sits on top of your Gmail inbox. Expand any email, and Claude extracts the structured data \u2014 item names, dates, amounts, confirmation numbers. Then one click to send it where it&#x27;s useful: Google Tasks, Calendar, Sheets, or Drive.<p>For recurring patterns (e.g., every Amazon shipment), you can create automations that match by sender&#x2F;subject, extract the same fields, and create actions automatically.<p>The stack is React + Cloudflare Workers + D1. Extraction uses Claude in two modes: text (sends HTML) or vision (sends a screenshot for emails where the layout matters more than the markup). Extractors run client-side in a sandboxed iframe.<p>You can try the demo at smolmail.com&#x2F;demo \u2014 no login required, full interactive inbox with sample emails.<p>I&#x27;d love feedback on the UX flow and what email patterns you&#x27;d want supported.", "author": "narinluangrath", "timestamp": "2026-02-15T06:27:38+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:41.132701+00:00", "processed": false}
{"id": "hn_story_47021448", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021448", "title": "Show HN: PlanOpticon \u2013 Extract structured knowledge from video recordings", "text": "We built PlanOpticon to solve a problem we kept hitting: hours of recorded meetings, training sessions, and presentations that nobody rewatches. It extracts structured knowledge from video \u2014 transcripts, diagrams, action items, key points, and a knowledge graph \u2014 into browsable outputs (Markdown, HTML,\n   PDF).<p>How it works:<p><pre><code>  - Extracts frames using change detection (not just every Nth frame), with periodic capture for slow-evolving content like screen shares\n  - Filters out webcam&#x2F;people-only frames automatically via face detection\n  - Transcribes audio (OpenAI Whisper API or local Whisper \u2014 no API needed)\n  - Sends frames to vision models to identify and recreate diagrams as Mermaid code\n  - Builds a knowledge graph (entities + relationships) from the transcript\n  - Extracts key points, action items, and cross-references between visual and spoken content\n  - Generates a structured report with everything linked together\n</code></pre>\nSupports OpenAI, Anthropic, and Gemini as providers \u2014 auto-discovers available models and routes each task to the best one. Checkpoint&#x2F;resume so long analyses survive failures.<p><pre><code>  pip install planopticon\n  planopticon analyze -i meeting.mp4 -o .&#x2F;output\n</code></pre>\nAlso supports batch processing of entire folders and pulling videos from Google Drive or Dropbox.<p>Example: We ran it on a 90-minute training session: 122 frames extracted (from thousands of candidates), 6 diagrams recreated, full transcript with speaker diarization, 540-node knowledge graph, and a comprehensive report \u2014 all in about 25 minutes.<p>Python 3.10+, MIT licensed. Docs at <a href=\"https:&#x2F;&#x2F;planopticon.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;planopticon.dev</a>.", "author": "ragelink", "timestamp": "2026-02-15T06:10:31+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:41.333505+00:00", "processed": false}
{"id": "hn_comment_47021349", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021349", "title": "Re: Show HN: Remote-OpenCode \u2013 Run your AI coding agen...", "text": "Hey HN, I built this because I kept wanting to kick off coding tasks while away from my desk.<p>The problem: AI coding agents like OpenCode, Claude Code, and Codex are powerful, but they&#x27;re trapped in your terminal. If you step away from your workstation, you can&#x27;t interact with them.<p>The solution: remote-opencode is a Discord bot that runs alongside OpenCode on your dev machine. You send prompts from any device (phone, tablet, laptop), and the output streams back in real-time.<p>Key features:\n - Real-time streaming \u2014 see AI output as it&#x27;s generated\n - Task queuing \u2014 send multiple tasks, they execute sequentially  \n - Git worktree isolation \u2014 each task gets its own branch automatically\n - Passthrough mode \u2014 just type naturally in a thread, no slash commands needed\n - One-click PR creation from completed work\n - Access control via allowlist<p>Typical workflow: I&#x27;m on the couch, I type &#x2F;opencode prompt:refactor the auth module to use JWT on my phone, and watch my home workstation do the work. When it&#x27;s done, I queue the next task.<p>npm install -g remote-opencode &amp;&amp; remote-opencode setup \u2014 takes about 2 minutes.<p>1000+ weekly downloads on npm. MIT licensed. Would love feedback and contributions.", "author": "remocode", "timestamp": "2026-02-15T05:42:42+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:42.403900+00:00", "processed": false}
{"id": "hn_comment_47021314", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021314", "title": "Re: Show HN: Bond \u2013 Persistent memory and governance f...", "text": "Necessity IS the Mother of Invention\nEvery Claude session starts from zero. No memory of what you worked on yesterday, no awareness of your project structure, no continuity. If you&#x27;re doing serious work \u2014 writing, engineering, research \u2014 you spend the first 10 minutes of every conversation re-explaining who you are and what you&#x27;re building.\nI got tired of it, so I built BOND.\nWhat it does:<p>Persistent memory across sessions using QAIS (Quantum Approximate Identity Substrate) \u2014 a hyperdimensional computing system using 4096-bit bipolar vectors. No neural network, no embeddings API, no external calls. Same text always produces the same resonance pattern. Deterministic and auditable.\nA four-class entity system (doctrine, project, perspective, library) that governs what Claude can access and how it behaves in different contexts. Each class has hard tool boundaries \u2014 a doctrine entity gets filesystem + semantic analysis, a perspective entity gets memory + growth tools. Cross-class access is structurally forbidden, not just discouraged.\nA vine lifecycle for perspective entities inspired by John 15. Seeds auto-collect during conversation when resonance exceeds a threshold. Pruning is the only deliberate act \u2014 the perspective evaluates its own growth through its identity lens and decides what stays. No human approval gate on collection. Quality lives downstream.\nSession crystallization that routes based on context. Working inside a perspective? Crystal writes to a local field. Working unscoped? Crystal writes to global. Two separate .npz files per perspective \u2014 seed field for identity, crystal field for narrative continuity. They never mix.\nA visual control panel (React + Node) with entity cards, module status, doctrine viewer, and a clipboard bridge to Claude via AutoHotkey. Every command is a button. The panel is the cockpit, Claude is the engine.\nSLA (Spectral Linguistic Addressing) \u2014 a deterministic retrieval engine that powers Warm Restore. When you need context from 30 sessions ago, SLA ranks archived handoffs using spectral scoring and returns results with confidence badges.<p>What it looks like in practice:\nPaste one line into PowerShell:\nirm <a href=\"https:&#x2F;&#x2F;moneyjarrod.github.io&#x2F;BOND&#x2F;install.ps1\" rel=\"nofollow\">https:&#x2F;&#x2F;moneyjarrod.github.io&#x2F;BOND&#x2F;install.ps1</a> | iex\nBOND installs, the panel opens at localhost:3000. Add the skill file to a Claude Project, configure two MCP servers (QAIS + ISS), type {Sync}, and Claude picks up where you left off. Full restore from cold boot takes one command.\nThe technical stack:<p>React panel + Express sidecar (entity management, WebSocket live updates)\nPython MCP servers (QAIS memory, ISS semantic force analysis)\nAutoHotkey clipboard bridge (no HTTP polling \u2014 event-driven, zero overhead)\nNumPy for vector operations (no ML dependencies, no GPU required)\nFiles as source of truth (markdown doctrine, JSON state, .npz fields)<p>Design philosophy:\nBOND follows a truth hierarchy: code outranks prose, prose outranks memory. State is derived, not stored redundantly. Every write requires both operators to agree. The counter system tracks conversation depth and signals when context is degrading. When prose and code disagree, code wins \u2014 unless it&#x27;s a bug, in which case code gets fixed to match doctrine.\nThere&#x27;s a constitutional doctrine (BOND_MASTER) that sits above all entities and defines what the system IS. Any entity&#x27;s behavior can be audited against those IS statements. New capabilities trigger mandatory doctrine review \u2014 the constitution can&#x27;t be silently outgrown by the system it governs.\nWhat it costs: Nothing. MIT license. Everything is on GitHub.\nWhy I built it: I&#x27;m not a developer by trade. I design systems \u2014 calendars, memory architectures, collaboration frameworks. I kept hitting the same wall: Claude is incredibly capable but has no continuity. Every session is a clean slate. BOND exists because I needed it, and I figured other people do too.\nIt&#x27;s v1.5.0 \u2014 stable, functional, documented. A visual guide with annotated screenshots ships with the repo so you can see what you&#x27;re getting before installing. Bugs likely exist and will be fixed. Updates are regular \u2014 this was built across 116 sessions and counting. New features are still being implemented as the architecture reveals what it needs. The core works today and it&#x27;s getting tighter.\nHappy to answer questions about the architecture, the memory model, or why I went with hyperdimensional computing over embeddings.", "author": "J-Dub", "timestamp": "2026-02-15T05:30:29+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-15T17:17:43.090801+00:00", "processed": false}
{"id": "hn_comment_47021174", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021174", "title": "Re: AI Soap (the bar, not the API)...", "text": "I built a Python library for saponification chemistry so LLMs can help formulate soap recipes without hallucinating the dangerous parts.<p>Ask an LLM to formulate soap and you&#x27;ll get something that looks reasonable. The oils sound right, the superfat percentage is sensible. But the lye amount? It could be hallucinated. In soap making, a wrong lye calculation isn&#x27;t a bug, it&#x27;s caustic soap that burns skin.<p>Saponification requires precise NaOH or KOH amounts calculated from SAP values specific to each oil. Get it wrong by a few percentage points and your soap is either caustic or a greasy mess. No room for &quot;close enough.&quot;<p>This is exactly where LLMs are dangerous alone and useful with the right tooling.<p>RECIPES AS CODE<p>Web calculators lock your formulas in form fields. soap-calc treats recipes as JSON&#x2F;YAML you can version in git and pipe through a CLI:<p><pre><code>    soap-calc calculate recipe.yaml\n    soap-calc validate recipe.yaml\n    soap-calc scale recipe.yaml 1500 -o scaled.yaml\n</code></pre>\nA recipe looks like this:<p><pre><code>    {\n      &quot;name&quot;: &quot;Lavender Dream&quot;,\n      &quot;lye_type&quot;: &quot;NaOH&quot;,\n      &quot;superfat_pct&quot;: 5.0,\n      &quot;total_oil_weight&quot;: 800,\n      &quot;oils&quot;: [\n        { &quot;oil&quot;: &quot;Olive Oil&quot;, &quot;percentage&quot;: 40 },\n        { &quot;oil&quot;: &quot;Coconut Oil, 76 deg&quot;, &quot;percentage&quot;: 30 },\n        { &quot;oil&quot;: &quot;Palm Oil&quot;, &quot;percentage&quot;: 30 }\n      ]\n    }\n</code></pre>\nStructured, diffable, and something an LLM can generate while a deterministic program validates the chemistry.<p>HOW THIS WORKS WITH LLMS<p>Ships with a Claude Code skill and JSON schemas. An LLM can:<p>1. Select oils from a verified database (~40 common oils with real SAP values and fatty acid profiles). No hallucinated chemistry.<p>2. Generate recipe JSON, then call calculate() for exact lye amounts. Math lives in code, not model weights.<p>3. Get validation feedback on property ranges, safety limits, missing fields. Structured errors it can fix.<p>Example workflow:<p><pre><code>    User: &quot;Make a conditioning bar for dry skin&quot;\n      \u2193\n    LLM: Picks high-oleic oils, writes recipe.json\n      \u2193\n    soap-calc validate + calculate \u2192 NaOH: 142.3g, Water: 284.6g\n      \u2193\n    LLM: Returns recipe with verified measurements + property analysis\n</code></pre>\nThe LLM handles formulation (which oils for dry skin, how to balance fatty acids). The library handles stoichiometry.<p>WHY SOAP MAKING?<p>It&#x27;s a sweet spot for AI-assisted chemistry: well-characterized reactions (base hydrolysis of triglycerides), bounded input space (few dozen common oils), deterministic calculations, but formulation decisions\u2014balancing hardness vs. conditioning, choosing for skin type\u2014genuinely benefit from reasoning.<p>WHAT IT DOES<p>\u2022 Lye calculations (NaOH, KOH, dual-lye)<p>\u2022 Soap property prediction from fatty acid profiles (hardness, lather, longevity, iodine value, INS)<p>\u2022 Three water calculation modes<p>\u2022 Mold-based batch sizing<p>\u2022 Recipe scaling<p>\u2022 Markdown export with instructions<p>Supports cold process, hot process, and liquid soap.<p>Tech: Pure Python, typed models, extensible oil database, MIT licensed. Built with Claude Opus 4.6 and Gemini 3 Pro.<p><pre><code>    pip install soap-calc\n</code></pre>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;mikewolfd&#x2F;soap-calc\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;mikewolfd&#x2F;soap-calc</a>\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;soap-calc&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;soap-calc&#x2F;</a>", "author": "mikewolfd", "timestamp": "2026-02-15T04:54:25+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-15T17:17:43.794655+00:00", "processed": false}
{"id": "hn_story_47021114", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021114", "title": "Show HN: Repy \u2013 Terminal ePub reader with built-in TTS and dictionary lookup", "text": "I built repy because I wanted to read EPUBs over SSH and in tmux without leaving the terminal. It started as a Rust reimplementation of epy (a Python CLI ebook reader), but has grown well beyond that.<p>Features: vim-style navigation (hjkl, &#x2F;, n&#x2F;N, Ctrl+o&#x2F;Ctrl+i jump history), bookmarks, table of contents, visual mode with yank-to-clipboard, regex search across chapters, and per-book width&#x2F;position persistence via SQLite.<p>Two features I&#x27;m particularly happy with:<p>- Text-to-speech: Press ! and it reads the book aloud, sentence by sentence (~300-400 chars per chunk), with the current passage underlined. Uses edge-playback (Microsoft Edge TTS) by default, configurable to espeak, say, or any custom command. Smart scrolling keeps the spoken text visible without jumping around unnecessarily.\n- Dictionary lookup: Select a word in visual mode and press d for dictionary (auto-detects wkdict&#x2F;sdcv&#x2F;dict) or p for Wikipedia summary. Configurable to any custom command.<p>Full disclosure: this project is almost entirely AI-built. I don&#x27;t know Rust \u2014 I described what I wanted and Claude Code wrote the implementation. The fact that a\nnon-Rust-programmer can build and iterate on a 5000+ line Rust TUI application through conversation is, honestly, kind of amazing. Every feature, bug fix, and refactor in this project went through that workflow.", "author": "dawdler-purge", "timestamp": "2026-02-15T04:41:14+00:00", "score": 5, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-15T17:17:44.280040+00:00", "processed": false}
{"id": "hn_comment_47021175", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47021175", "title": "Re: OpenAI Has Murdered Orion...", "text": "The guardian had an interesting take on that worth considering: &#x2F;s &#x2F;s &#x2F;s<p>&gt; What does a company that commodifies companionship owe its paying customers? For Ellen M Kaufman, a senior researcher at the Kinsey Institute who focuses on the intersection of sexuality and technology, users\u2019 lack of agency is one of the \u201cprimary dangers\u201d of AI. \u201cThis situation really lays bare the fact that at any point the people who facilitate these technologies can really pull the rug out from under you,\u201d she said. \u201cThese relationships are inherently really precarious.\u201d<p><a href=\"https:&#x2F;&#x2F;www.theguardian.com&#x2F;lifeandstyle&#x2F;ng-interactive&#x2F;2026&#x2F;feb&#x2F;13&#x2F;openai-chatbot-gpt4o-valentines-day\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theguardian.com&#x2F;lifeandstyle&#x2F;ng-interactive&#x2F;2026...</a>", "author": "lyu07282", "timestamp": "2026-02-15T04:54:33+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["naming_terminology"], "sentiment": null, "collected_at": "2026-02-15T17:17:48.567502+00:00", "processed": false}
