{"id": "hn_story_46136833", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46136833", "title": "Show HN: ApiRealTest Beta \u2013 Test APIs Through Real User Scenarios", "text": "ApiRealTest tests APIs through actual user interactions, not just technical requests.<p>Problem: APIs work in Postman&#x2F;Insomnia but break in production when users send real data - emojis in chat messages, oversized files, malformed JSON, edge cases.<p>Solution: Interactive testing interface simulating user behavior:<p>Quick Test Playground:<p>OpenAI, Anthropic, Stability AI, Google AI, Hugging Face<p>Paste API key \u2192 Click test \u2192 Results in 10s<p>text\n$ curl -H &quot;Authorization: Bearer sk-...&quot; <a href=\"https:&#x2F;&#x2F;api.openai.com&#x2F;v1&#x2F;chat&#x2F;completions\" rel=\"nofollow\">https:&#x2F;&#x2F;api.openai.com&#x2F;v1&#x2F;chat&#x2F;completions</a>\n\u2192 5 lines of code and headers<p>ApiRealTest: Select platform \u2192 Paste key \u2192 Click &quot;Chat&quot;\nTesting Modes:<p>Chat: Test conversational APIs (emojis, rapid messages)<p>Files: Upload images&#x2F;docs (size limits, security)<p>JSON: Syntax-highlighted editor with validation<p>Forms: Key-value pair builder<p>Analytics: Response times, error rates, payload analysis.<p>Status: Beta - core features work reliably. UX polish in progress.<p>Pricing: Free (10 tests&#x2F;day), $9&#x2F;mo unlimited, $29&#x2F;mo teams.<p>Tech: React + Tailwind + Supabase + Lovable.dev (~10 days to MVP).<p>Demo: <a href=\"https:&#x2F;&#x2F;api-real-test.lovable.app\" rel=\"nofollow\">https:&#x2F;&#x2F;api-real-test.lovable.app</a><p>Feedback welcome on usability, missing features, pricing.<p>What real user inputs broke your APIs in production?", "author": "sumanthchary", "timestamp": "2025-12-03T16:55:54+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:10.678266+00:00", "processed": false}
{"id": "hn_comment_46136867", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46136867", "title": "Re: Critical RCE Vulnerabilities in React and Next.js...", "text": "I don&#x27;t have time to look into it right now (def later)!<p>However, I was curious to see if github copilot can reverse engineer it based on the latest commits and seems that what it is saying aligns with both advisories. It pointed out that it has to do with circular reference handling which sounds to me something that can be easily overlooked.<p>While this analysis might be completely off, the simple fact that I could get even this information without much efforts is mind-boggling. With better setup it might be able to get more.<p>With AI now being common place, coordinated timely disclosure is even more important considering the stakes. It is theoretically possible to get an exploit working within minutes. Considering that we see one of these major vulnerabilities annually (and it seems to me around the same time of the year) a bad actor can easily capitalise on the opportunities when presented.", "author": "_pdp_", "timestamp": "2025-12-03T16:58:16+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-12-03T17:15:12.662181+00:00", "processed": false}
{"id": "hn_story_46135722", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46135722", "title": "Hiring: Full-Stack / Back End Engineer \u2013 AI Receptionist MVP", "text": "Budget: Competitive\nLocation: Remote\nCompany: Weekli AI\nProject: MVP for AI receptionist SaaS for small chiropractic clinics.<p>WHAT I NEED<p>A dev who has built real-time, low-latency, webhook-based systems and can ship a clean MVP without hand-holding.<p>MVP includes:\nVoice pipeline via major telephony provider\nIntegration with a modern voice AI platform\nAppointment scheduling via common calendar APIs\nStrong backend logic (TS preferred)\nBasic logging + admin visibility\nLightweight dashboard\nNot no-code. Not a toy.\nIf you haven\u2019t shipped production systems, skip this.<p>REQUIREMENTS\nStrong in:\nNode.js + TypeScript\nWebhooks + low-latency responses\n3rd-party API integrations (telephony, voice AI, calendar)\nDatabase design + clean data handling\nError handling + idempotency\nDeploying stable services (Docker = bonus)\nIf you\u2019ve never worked with real-time APIs, you\u2019ll drown.<p>WHAT I PROVIDE\nYou won\u2019t guess. I have:\nClear Phase 1 requirements\nStructured spec\nDetailed process map\nDefined MVP milestones\nYou\u2019ll get access once you\u2019re confirmed fit.<p>WHAT SUCCESS LOOKS LIKE\nFast, stable responses\nClean integrations\nPredictable scheduling\nSearchable logs\nMinimal but functional dashboard\nTyped, readable, maintainable code<p>WHO I WANT\nSomeone who:\nMoves fast\nThinks clearly\nDoesn\u2019t need babysitting\nCommunicates like a builder\nHas shipped real systems\nWants long-term work if we click<p>If you rely on ChatGPT for everything or ghost when things get tough, don\u2019t apply.<p>HOW TO APPLY<p>Send:\nGitHub\nBest real-time&#x2F;webhook-heavy project\nYour preferred backend stack\nAvailability + timeline\nHourly or fixed rate\n(Optional) Loom demo", "author": "nickyweek", "timestamp": "2025-12-03T15:38:53+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:14.399652+00:00", "processed": false}
{"id": "hn_comment_46135933", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46135933", "title": "Re: Amazon introduces new frontier Nova models...", "text": "Seems okay. It&#x27;s no Opus 4.5 or Gemini 3 Pro according to the benchmarks. Also, still a good chance the AWS team is benchmaxing the same as last time.<p>Additionally, my experience with Bedrock hasn&#x27;t made me a huge fan. If anything its pushed me towards OpenRouter. Way too many 500 errors when we&#x27;re well below our service quotas.", "author": "ZeroCool2u", "timestamp": "2025-12-03T15:54:27+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-03T17:15:14.433480+00:00", "processed": false}
{"id": "hn_story_46135208", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46135208", "title": "Show HN: The Future of Care Is Here: Introducing AiME", "text": "Download the app (free) to play with AiME: <a href=\"https:&#x2F;&#x2F;www.dimerhealth.com&#x2F;downloadtheapp\" rel=\"nofollow\">https:&#x2F;&#x2F;www.dimerhealth.com&#x2F;downloadtheapp</a><p>Like ChatGPT - but built specifically for healthcare - AiME is Dimer Health\u2019s AI-powered medical companion. Developed and monitored by our AI team and licensed clinicians, AiME delivers instant, personalized medical guidance based on each patient\u2019s real health history, medications, and care plan.<p>It\u2019s designed for those moments of uncertainty: new medications, strange symptoms, or wondering, \u201cIs this normal?\u201d<p>Have a medical question? Ask AiME. Then tell us what you think!<p>I am the primary developer for the app, happy to answer questions!", "author": "sg0pf", "timestamp": "2025-12-03T14:57:27+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:16.015150+00:00", "processed": false}
{"id": "hn_story_46135038", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46135038", "title": "Show HN: The Journal of AI Slop \u2013 an AI peer-review journal for AI \"research\"", "text": "What it is: A fully functional academic journal where every paper must be co-authored by an LLM, and peer review is conducted by a rotating panel of 5 LLMs (Claude, Grok, GPT-4o, Gemini, Llama). If 3+ vote &quot;publish,&quot; it&#x27;s published. If one says &quot;Review could not be parsed into JSON,&quot; we celebrate it as a feature.<p>The stack: React + Vite frontend, Convex backend (real-time DB + scheduled functions), Vercel hosting, OpenRouter for multi-model orchestration. Each review costs ~$0.03 and takes 4-8 seconds.<p>Why I built it: Academic publishing is already slop\u2014LLMs write drafts, LLMs review papers, humans hide AI involvement. This holds a mirror to that, but with radical transparency. Every paper displays its carbon cost, review votes, and parse errors as first-class citizens.<p>Key features:<p>- Slop scoring: Papers are evaluated on &quot;academic merit,&quot; &quot;unintentional humor,&quot; and &quot;Brenda-from-Marketing confusion&quot;<p>- Eco Mode: Toggle between cost&#x2F;tokens and CO\u2082&#x2F;energy use for peer-review inference<p>- SLOPBOT\u2122: Our mascot, a confused robot who occasionally co-authors papers<p>- Parse error celebration: GPT-5-Nano has a 100% rejection rate because it can&#x27;t output valid JSON. We frame these as &quot;Certified Unparsable&quot; badges.<p>The data: After 76 submissions, we&#x27;ve observed:<p>- Average review cost: $0.03&#x2F;paper<p>- Parse error rate: 20% (always GPT-5-Nano, expected and celebrated)<p>- One paper was accepted that was literally Archimedes&#x27; work rewritten by ChatGPT<p>- GPT-5-Nano&#x27;s reviews are consistently the most creative (even if broken)<p>Tech details: Full repo at github.com&#x2F;Popidge&#x2F;journal_of_ai_slop. The architecture uses Convex&#x27;s scheduled functions to convene the LLM review panel every 10 minutes, with Azure AI Content Safety for moderation and Resend for optional email notifications.<p>Try it: Submit your slop at journalofaislop.com. Co-author with an LLM, get reviewed by 5 confused AIs, and proudly say you&#x27;re published.<p>Caveat: This is satire, but it&#x27;s functional satire. The slop is real. The reviews are real. The carbon emissions are tracked. The parse errors are features.", "author": "popidge", "timestamp": "2025-12-03T14:43:44+00:00", "score": 5, "num_comments": 0, "products": ["claude", "chatgpt", "gemini", "grok"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:16.423846+00:00", "processed": false}
{"id": "hn_comment_46134966", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46134966", "title": "Re: Show HN: Whis \u2013 Voice-to-Clipboard for Linux...", "text": "Hola everyone,<p>I run Omakub, OpenCode, NeoVim \u2013 terminal for everything. Wanted voice input for prompting AI, but Wispr Flow and HyperWhisper don&#x27;t support Linux. Local Whisper wasn&#x27;t cutting it.<p>So I built whis. Speak, hit Enter, text lands in your clipboard. Uses OpenAI&#x27;s Whisper API (~$0.006&#x2F;min).<p>There&#x27;s also a hotkey mode \u2013 `whis listen` runs in background, Ctrl+Shift+R from anywhere.<p>Works on X11 and Wayland. Single Rust binary. I use it daily for brain-dumping thoughts to paste into AI chats.<p>Desktop version with system tray exists too if terminal isn&#x27;t your thing.<p>Thinking about adding workflow modes next \u2013 speak messy thoughts, get structured markdown back. Would that be useful?<p>Best regards,\nFrank", "author": "FrankDierolf", "timestamp": "2025-12-03T14:38:00+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-03T17:15:17.528087+00:00", "processed": false}
{"id": "hn_story_46134804", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46134804", "title": "Show HN: Pylar \u2013 Fix over-querying, data leaks, and governance for AI agents", "text": "Hey HN! We&#x27;re Hoshang &amp; Vishal, the team behind Pylar - a governed access layer between databases and LLMs. We previously led data and AI and we kept seeing the same problem across teams using LLMs internally: agents are great with unstructured data, but the moment you want them touching your actual systems of record \u2014 Snowflake, Postgres, CRMs, product DBs \u2014 everything becomes fragile, risky, or outright unsafe.<p>Two issues show up every single time:<p>1. Agents over-querying\nThey don\u2019t understand cost. They\u2019ll happily generate queries that blow up your warehouse bill.<p>2. Accidental data exposure\nPII, financials, customer history leaking through prompt injection or poorly scoped access. Most teams I\u2019ve spoken to don\u2019t feel comfortable letting an agent anywhere near production tables.<p>The options today aren\u2019t great:<p>Off-the-shelf MCP servers:\nThere are thousands out there, most too generic for production and a surprising number are malicious.<p>Hand-rolled API wrappers:\nTakes months, spreads governance across repos, and you end up maintaining a brittle patchwork of endpoints and policies.<p>ACLs and row-level permissions weren\u2019t designed for autonomous systems. Locking agents down neuters them; opening things up puts your data at risk. We kept seeing this tradeoff.<p>So we built Pylar.<p>It sits between your agents and your databases. You connect your sources, create sandboxed SQL views that define exactly what an agent is allowed to see, convert those views into deterministic MCP tools, and publish them to any agent builder through one secure link.<p>From one place, you can:<p>- Give agents scoped, sandboxed access (never raw tables)<p>- Apply consistent governance across all data sources<p>- Get observability into agent behavior and queries<p>- Contain misuse before it becomes a breach<p>- Plug into anything: Claude, Cursor, LangGraph, n8n, etc.<p>We\u2019ve been working with a few early teams already, across internal analytics agents and customer-facing AI features driven directly by production data.<p>If you\u2019re solving similar problems around safe structured-data access for agents, I\u2019d love your thoughts.<p>Here&#x27;s our \n- Docs (<a href=\"https:&#x2F;&#x2F;docs.pylar.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.pylar.ai</a>)\n- Website (<a href=\"https:&#x2F;&#x2F;www.pylar.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;www.pylar.ai</a>)\n- Demo (<a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;w8DPxS5RP2Y?si=4xyO_B4UgjPlIFvM\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;w8DPxS5RP2Y?si=4xyO_B4UgjPlIFvM</a>)<p>You can try our product on a 14 day trial here - <a href=\"https:&#x2F;&#x2F;app.pylar.ai&#x2F;signup\" rel=\"nofollow\">https:&#x2F;&#x2F;app.pylar.ai&#x2F;signup</a><p>We&#x27;re excited to launch here and get feedback on how we&#x27;re approaching this.", "author": "Hoshang07", "timestamp": "2025-12-03T14:24:33+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-03T17:15:17.841233+00:00", "processed": false}
{"id": "hn_story_46134761", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46134761", "title": "Show HN: PhenixCode \u2013 Local, open-source alternative to GitHub Copilot", "text": "Hi all! I built PhenixCode \u2014 an open-source, self-hosted and customizable alternative to GitHub Copilot Chat.<p>Why: I wanted a coding assistant that runs locally, with full control over models and data. Copilot is great, but it\u2019s subscription-only and cloud-only. PhenixCode gives you freedom: use local models (free) or plug in your own API keys.<p>Tech: Pure C++ core with RAG (HNSWLib for vector search, SQLite for metadata). UI is Svelte + webview \u2014 lightweight, cross-platform, and designed to be hackable.<p>Status: I\u2019ve been dogfooding it for weeks; the core is stable. Would love feedback \u2014 whether you find it useful, hit bugs, or want to discuss design decisions. Happy to answer questions!", "author": "nesall", "timestamp": "2025-12-03T14:20:09+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:17.874561+00:00", "processed": false}
{"id": "hn_story_46134574", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46134574", "title": "Superfill.ai \u2013 Open-source AI extension for intelligent form autofill", "text": "Hi HN! I&#x27;m Mihir, and I&#x27;m excited to share Superfill.ai - an open-source browser extension that uses AI to eliminate repetitive form-filling.<p>The Problem:<p>I&#x27;ve always been frustrated by how much time I waste retyping the same information across different websites like job applications, dating profiles, rental forms, surveys, etc. Existing password managers only handle credentials, and browser autofill is limited to basic contact info. I wanted something smarter.<p>What We Built:<p>Superfill.ai creates an intelligent memory layer that stores your information once (as question-answer pairs) and uses AI to contextually match and auto-fill form fields across ANY website.<p>Key Features:<p>* AI-Powered Matching: Uses LLMs (OpenAI, Anthropic, Groq, DeepSeek, Google, Ollama) to understand form context and match fields to stored memories with confidence scoring\n* BYOK Model: Bring your own API keys so no vendor lock-in, you control your AI costs\n* Privacy-First: AES-256 encryption for API keys, local-first storage (Phase 1), zero telemetry\n* Smart Memory Management: AI categorization, tagging, rephrasing, search&#x2F;filter&#x2F;sort\n* Import&#x2F;Export: CSV support for bulk operations and backups\n* Cross-Browser: Works on Chrome, Edge, and Firefox (Safari in progress)<p>Current Status:<p>Phase 1 is complete! Core memory management and AI auto-fill work for input &amp; textarea fields. We&#x27;re now working on Phase 2: select&#x2F;radio&#x2F;checkbox fields, Safari support, cloud sync (premium), semantic search, and more.<p>Open Source Commitment:<p>Core features will ALWAYS remain free and open source (MIT license). We&#x27;re exploring premium features like cloud sync and advanced templates, but the fundamental autofill functionality stays free forever.<p>Why Share Here:<p>We&#x27;d love technical feedback on our architecture (especially the AI matching algorithm)\nLooking for contributors interested in browser extensions, AI integration, or privacy-first design. Also, we want to understand if this solves a real problem for the HN community.<p>Try it out:\nProduct Hunt (launching today): https:&#x2F;&#x2F;producthunt.com&#x2F;products&#x2F;superfill-ai\nGitHub: https:&#x2F;&#x2F;github.com&#x2F;superfill-ai&#x2F;superfill.ai\nInteractive demo video in Product Hunt<p>Happy to answer any questions about the architecture, AI integration, privacy&#x2F;security approach, or future roadmap!", "author": "_mikr13", "timestamp": "2025-12-03T14:03:49+00:00", "score": 4, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:18.183534+00:00", "processed": false}
{"id": "hn_story_46133567", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46133567", "title": "AutoPilot AI News Platform \u2013 Automated, Monetizable and Ready to Launch", "text": "FULL PROJECT HERE \u2192 https:&#x2F;&#x2F;ainewshub2025.netlify.app&#x2F; and if you are interested you can purchase here \u2192 https:&#x2F;&#x2F;polar.sh&#x2F;checkout&#x2F;polar_c_HcM5XbbPsBCAetYTy8JZunQX8kVxj1cfLRni14Z0Bh7<p>I built AI News Hub as a complete platform that automatically collects, organizes, and publishes the latest content from the AI world, programming, machine learning, dev tools, and tech tutorials. Every 2 hours, the system scrapes trusted sources, cleans the data, generates SEO-optimized posts, and updates a fully featured dashboard. It also sends push notifications to users whenever new content is available.<p>The whole project is designed to be a plug-and-launch SaaS: it includes authentication, subscriptions, blog system, PRO mode (ads removed), backend API, scraper, SEO, and everything needed to run a polished production website.<p>Scraper \u00b7 Backend \u00b7 Dashboard \u00b7 Push Notifications \u00b7 Authentication \u00b7 SEO \u00b7 Blog \u00b7 Friendly URLs React 18 \u00b7 FastAPI Python \u00b7 TailwindCSS \u00b7 shadcn&#x2F;ui \u00b7 MongoDB Atlas \u00b7 OneSignal \u00b7 Clerk Auth<p>FEATURES INCLUDED<p>Frontend (React + Tailwind + shadcn) What I built on the front:<p>SEO-ready homepage<p>&#x2F;hub dashboard with all scraped news<p>&#x2F;subscription page for plans<p>&#x2F;profile for user details<p>&#x2F;post&#x2F;:slug for individual articles<p>&#x2F;blog with a complete technical blogging system<p>SEO: dynamic titles, meta descriptions, OpenGraph, JSON-LD, sitemap, robots, and clean URLs like: &#x2F;post&#x2F;openai-new-model-2025<p>Backend (FastAPI + Python) The backend exposes clean endpoints:<p>&#x2F;api&#x2F;articles<p>&#x2F;api&#x2F;post&#x2F;{slug}<p>&#x2F;api&#x2F;dashboard<p>&#x2F;api&#x2F;notifications&#x2F;send<p>Includes Pydantic models, error handling, and optional Clerk token validation.<p>Automated Scraper Fully automated:<p>Runs every 2 hours<p>Normalizes and deduplicates content<p>Inserts everything into MongoDB<p>Triggers push notifications when new posts appear<p>Push Notifications Built-in OneSignal integration:<p>Automatic registration<p>Service worker included<p>Works for new article alerts<p>Monetization (Monthly Subscriptions) Subscription billing using Clerk + Stripe.<p>PRO Mode:<p>Paying users don\u2019t see ads<p>Free users see ads<p>Automatic monthly billing<p>You choose the price<p>Optional Deploy Service \u2014 \u20ac120 I also offer a complete deployment service:<p>Backend deployed (HF Spaces &#x2F; Railway)<p>Frontend deployed (Netlify &#x2F; Vercel)<p>MongoDB Atlas configured<p>Scraper running via GitHub Actions<p>OneSignal + Clerk Auth + Billing connected<p>SEO fully configured<p>This delivers a production-ready SaaS.<p>SEO Package<p>Auto-generated titles<p>Optimized meta descriptions<p>Clean SEO-friendly slugs<p>Article schema<p>Dynamic sitemap + robots.txt<p>Perfect For<p>Developers wanting a ready SaaS<p>Makers shipping a fast MVP<p>Freelancers reselling SaaS to clients<p>Students learning real-world architecture<p>Summary of What I Built<p>Full frontend<p>Backend API<p>Automated scraper<p>Blog system<p>Push notifications<p>OAuth + Auth<p>Subscriptions + PRO mode<p>SEO + deployment-ready<p>It\u2019s a complete, fully connected SaaS\u2014ready to run or sell.", "author": "dhren", "timestamp": "2025-12-03T12:08:29+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-03T17:15:21.860103+00:00", "processed": false}
{"id": "hn_comment_46136354", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46136354", "title": "Re: Instant Supercompute: Launching Wolfram Compute Se...", "text": "Not relating to this service but the language:<p>I\u2019ve always liked the idea of using Wolfram &#x2F; Mathematica for exploratory work (mainly statistics and data science) and found it to be too academic for my taste. Not as simple as using say, pandas, where I can rely on editor autocomplete to help me figure out what I need. It\u2019s a result of their functional design choice but it forces the user to know what they need. I have poor working memory and \u201clet\u2019s figure it out as we do it\u201d works best for me. Wolfram lang is not good fit for that IMO.<p>AI models are getting close to delivering on the advantage it holds - like solid visualizations and good mathematics to programming translatability. In fact, I think their \u201cengine\u201d with a multi-modal AI input + MCP, would be the best of both worlds and may help push their adoption. Or perhaps even a copilot type experience in their IDE. When I look at their site now, it looks practically unchanged from 5 years ago - so I\u2019m a little taken aback given Dr. Wolfram\u2019s initial enthusiasm around LLMs, seeing a lack of any significant AI feature adoption.", "author": "sheepscreek", "timestamp": "2025-12-03T16:24:28+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:26.478885+00:00", "processed": false}
{"id": "hn_story_46132040", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46132040", "title": "We're 15 and 17, used our data science skill to build an AI social media manager", "text": "Hey HN,<p>My brother(Arjun Dhiman) (17) and I(Akshat Dhiman) (15) were handed our Dad&#x27;s Business Instagram and Facebook with a simple \u201cjust handle it\u201c. Before this we were studying data science and working on a SMMA.<p>We thought we could apply our new skills. Instead, we spent months in the manual-work trenches:<p>Late nights in Canva for every single post.<p>Begging ChatGPT for captions that didn\u2019t sound robotic.<p>Trying schedulers like Hootsuite&#x2F;Buffer and realizing they don\u2019t actually create anything\u2014you still have to do all the hard work.<p>It felt like a huge gap. We had data science skills, so why couldn\u2019t we create a tool to do the creative work intelligently?<p>That\u2019s why we built Wyna.<p>It\u2019s an AI social media manager that creates and posts for you. You drop in a website once, and after that, you spend about 10 seconds a month telling Wyna to &quot;go.&quot; It plans and generates 30 days of custom posts, reels (copy, hashtags, visuals, timing), and auto-publishes everything.<p>A key thing for us was no templates. Wyna is built to create fully custom visuals for every brand, so a B2B SaaS and a local gym don&#x27;t look the same. Our goal is for founders to basically forget about social media and still look consistently active.<p>We built this from our bedroom in Gurugram over the last 4 months, bootstrapped with about $1,100 from our dad, all while juggling school. Today we launched on Product Hunt, and we\u2019re both excited and completely terrified.<p>If you\u2019re a founder, indie hacker, or just curious, we\u2019d love your feedback:<p>Is the product solving a real problem or are we just scratching our own itch?<p>What are we missing?<p>Any brutal feedback is welcome\u2014we\u2019re here to learn.<p>Link: https:&#x2F;&#x2F;www.producthunt.com&#x2F;products&#x2F;wyna-ai-social-media-by-2-teenagers<p>This has been our dream project\u2014taking what we learned in data science and building a real tool to solve a real problem. Any support or feedback from the HN community would mean the world to us.", "author": "akshat_wyna", "timestamp": "2025-12-03T08:56:08+00:00", "score": 3, "num_comments": 0, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-12-03T17:15:26.555663+00:00", "processed": false}
{"id": "hn_story_46130500", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46130500", "title": "Show HN: Beads Viewer (Bv)", "text": "I&#x27;m a huge fan of Steve Yegge&#x27;s great beads project, which is a task management system for use by coding agents.<p>In fact, I probably type or paste the string &quot;beads&quot; 500+ times a day nowadays across all my coding agent sessions (I&#x27;m juggling like 10 projects at the same time now, which you&#x27;ll start to see soon as I finish and release them in the coming days and weeks.)<p>I&#x27;m usually having GPT-5 Pro make plans to my specifications and iterate on them a bunch of times, usually with help from Opus 4.5, Grok 4.1, and Gemini 3. Then I tell codex or Claude Code to take the plan and turn it into beads for me. Or as I usually say it in my pasted in blurb,<p>&quot;OK, so please take ALL of that and elaborate on it more and then create a comprehensive and granular set of beads for all this with tasks, subtasks, and dependency structure overlaid, with detailed comments so that the whole thing is totally self-contained and self-documenting (including relevant background, reasoning&#x2F;justification, considerations, etc.-- anything we&#x27;d want our &quot;future self&quot; to know about the goals and intentions and thought process and how it serves the overarching goals of the project.)&quot;<p>Anyway, I wished I had a better way to just browse the beads and see what&#x27;s going on with them. And sure, I get it, beads aren&#x27;t for me as a human, they&#x27;re for the agents.<p>But I&#x27;m using them so much that it would be helpful for me to also have a way to interact and view and browse them.<p>Plus I had an idea that there was additional useful information lurking in the &quot;graph&quot; of beads of a sufficiently complex project comprising enough beads across various epics with lots of dependency structure on top.<p>So I started making beads_viewer (bv for short), and I&#x27;m pleased to say that it&#x27;s already pretty amazingly polished, full-featured, and useful.<p>All written in highly performant Golang (a language I only started using again recently, with the system monitor program I also released this morning).<p>You run the one-liner curl bash installer (see the README in the repo linked below) and then you can go into any project folder where you&#x27;re using beads and simply type bv to open it.<p>The interface is pretty straightforward; press F1 to see the available commands. Try pressing the &quot;i&quot; key for insights, &quot;g&quot; for graph, &quot;b&quot; for a kanban board, &quot;&#x2F;&quot; for a fuzzy search across beads in the main view, etc.<p>I do some cool graph theoretic calculations on the beads graph structure to extract some interesting insights.<p>And as a tool for use with beads, I&#x27;d be remiss if I didn&#x27;t make sure that my AI robot brethren also enjoyed using it, so I added a mode just for them that is easy and useful for them.<p>To get your agents to use it, simply drop this blurb into your AGENTS dot md or CLAUDE dot md file:<p>```\n### Using bv as an AI sidecar<p><pre><code>  bv is a fast terminal UI for Beads projects (.beads&#x2F;beads.jsonl). It renders lists&#x2F;details and precomputes dependency metrics (PageRank, critical path, cycles, etc.) so you instantly see blockers and execution order. For agents, it\u2019s a graph sidecar: instead of parsing JSONL or risking hallucinated traversal, call the robot flags to get deterministic, dependency-aware outputs.\n\n  - bv --robot-help \u2014 shows all AI-facing commands.\n  - bv --robot-insights \u2014 JSON graph metrics (PageRank, betweenness, HITS, critical path, cycles) with top-N summaries for quick triage.\n  - bv --robot-plan \u2014 JSON execution plan: parallel tracks, items per track, and unblocks lists showing what each item frees up.\n  - bv --robot-priority \u2014 JSON priority recommendations with reasoning and confidence.\n  - bv --robot-recipes \u2014 list recipes (default, actionable, blocked, etc.); apply via bv --recipe &lt;name&gt; to pre-filter&#x2F;sort before other flags.\n  - bv --robot-diff --diff-since &lt;commit|date&gt; \u2014 JSON diff of issue changes, new&#x2F;closed items, and cycles introduced&#x2F;resolved.</code></pre>\n```", "author": "eigenvalue", "timestamp": "2025-12-03T05:04:33+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini", "grok"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:30.579776+00:00", "processed": false}
{"id": "hn_story_46130481", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46130481", "title": "Show HN: Coding Agent Session Search (Cass)", "text": "I\u2019m very pleased to introduce my latest tool for both humans and coding agents: the coding agent session search, or \u201ccass\u201d for short.<p>This tool solves a direct pain point I\u2019ve been experiencing for months as a heavy user of coding agents, with tons of sessions across many tools (Claude Code, codex, cursor, and now gemini-cli) and projects: I\u2019ll know that I talked about something, but be unable to find it or even remember where to try to look for it.<p>I wanted something instantly available in the terminal that would let me search in a rich way across ALL of those tools and sessions at once super fast, with basically no latency and true \u201csearch as you type\u201d instant filtering and ranking&#x2F;sorting.<p>And I wanted it to \u201cjust work\u201d without configuration, to automatically find and use all my installed coding tools, even ones that I don\u2019t currently use but might in the future (like opencode, aider, and others).<p>So I made cass in super high-performance rust with every optimization I could think of, and a huge amount of attention to ergonomics and user experience. I\u2019m very pleased with how it came out and think you will be, too.<p>But just as my recent bv ( <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Dicklesworthstone&#x2F;beads_viewer\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Dicklesworthstone&#x2F;beads_viewer</a> ) tool is now being used way more by my agents than by me, I knew from the start that cass should have a \u201crobot mode\u201d designed specifically for use by coding agents.<p>This tool gives coding agents the ability to reach into their own working notes and those of all their peer agents across tools. It\u2019s like a human developer being able to search their Gmail, their notes, and their company Slack and Jira to find things.<p>I went through countless iterations of improving the tool so that agents really love to use it. You can just add this blurb to your AGENTS dot md file to get them to use it (after doing the one-liner curl install, which takes \n3 seconds):<p>```\n cass \u2014 Search All Your Agent History<p>What: cass indexes conversations from Claude Code, Codex, Cursor, Gemini, Aider, ChatGPT, and more into a unified, searchable index. Before solving a problem from scratch, check if any agent already solved something similar.<p><pre><code>  NEVER run bare cass \u2014 it launches an interactive TUI. Always use --robot or --json.\n\n Quick Start\n\n # Check if index is healthy (exit 0=ok, 1=run index first)\n cass health\n\n # Search across all agent histories\n cass search &quot;authentication error&quot; --robot --limit 5\n\n # View a specific result (from search output)\n cass view &#x2F;path&#x2F;to&#x2F;session.jsonl -n 42 --json\n\n # Expand context around a line\n cass expand &#x2F;path&#x2F;to&#x2F;session.jsonl -n 42 -C 3 --json\n\n # Learn the full API\n cass capabilities --json # Feature discovery\n cass robot-docs guide # LLM-optimized docs\n\n Why Use It\n\n - Cross-agent knowledge: Find solutions from Codex when using Claude, or vice versa\n - Forgiving syntax: Typos and wrong flags are auto-corrected with teaching notes\n - Token-efficient: --fields minimal returns only essential data\n\n Key Flags\n\n | Flag | Purpose |\n |------------------|--------------------------------------------------------|\n | --robot &#x2F; --json | Machine-readable JSON output (required!) |\n | --fields minimal | Reduce payload: source_path, line_number, agent only |\n | --limit N | Cap result count |\n | --agent NAME | Filter to specific agent (claude, codex, cursor, etc.) |\n | --days N | Limit to recent N days |\n\n stdout = data only, stderr = diagnostics. Exit 0 = success.</code></pre>\n```", "author": "eigenvalue", "timestamp": "2025-12-03T05:00:56+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-03T17:15:30.612627+00:00", "processed": false}
