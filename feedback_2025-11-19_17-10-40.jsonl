{"id": "hn_story_45981800", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45981800", "title": "Show HN: Vaporwave Life", "text": "I was running some experiments to test Gemini 3 and I really liked how it turned out so I thought I would share.<p>I adjusted the vertical alignment of the sun, because LLMs still aren&#x27;t good at spatial relationships, and GPT5.1 implemented the responsive design and the volume slider as the API I was using was getting overloaded.<p>The full setup was Opencode + Gemini 3 (zen) + GPT 5.1 Codex.", "author": "rootforce", "timestamp": "2025-11-19T16:52:00+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-19T17:10:40.932968+00:00", "processed": false}
{"id": "hn_story_45981310", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45981310", "title": "Show HN: ChunkBack \u2013 A Fake LLM API server for testing apps without paying", "text": "Hi HN,<p>I&#x27;ve been working with LLMs in production for a while both as a solo dev building apps for clients and working at an AI startup. The one thing that always was a pain was to pay OpenAI&#x2F;Gemini&#x2F;Anthropic a few dollars a month just for me to say &quot;test&quot; or have a CI runner validate some UI code. So I built this server called ChunkBack, that mocks the popular llm provider&#x27;s functionality but allows you to type in a deterministic language:<p>`SAY &quot;cheese&quot;` or `TOOLCALL &quot;tool_name&quot; {} &quot;tool response&quot;`<p>I&#x27;ve had to work in some test environments and give good results for experimenting with CI, but it&#x27;s still an early project so would love feedback and more testers on.", "author": "forthwall", "timestamp": "2025-11-19T16:12:33+00:00", "score": 4, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-19T17:10:41.877105+00:00", "processed": false}
{"id": "hn_story_45980887", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45980887", "title": "Ask HN: Gemini 3 and the stagnation of coding agents, what gives?", "text": "Gemini 3 is cool. Sure. Gemini 3 seems to be a strong model capable at everything you&#x27;d want. Long context, good ui design, good awareness of the codebase, and a strong ability to make decisions.<p>What is strange to me is that despite all of this, and despite changes for GPT5-codex, claude 4.5 etc.<p>We still seem to see limitations in coding agents. Where are the coding agents that I can actually work with for 30 hours? Where are the coding agents that I can treat as a thought partner?<p>The dream seems to slowly be moving further away from believability despite actually getting closer to said goal.<p>What gives? Why are we not seeing true improvements across the board? Why is UX still stuck at &quot;Chatbot in a loop with tools&quot;?", "author": "akira_067", "timestamp": "2025-11-19T15:36:40+00:00", "score": 3, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-19T17:10:43.374148+00:00", "processed": false}
{"id": "hn_story_45980760", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45980760", "title": "Launch HN: Mosaic (YC W25) \u2013 Agentic Video Editing", "text": "Hey HN! We\u2019re Adish &amp; Kyle from Mosaic (<a href=\"https:&#x2F;&#x2F;mosaic.so\">https:&#x2F;&#x2F;mosaic.so</a>). Mosaic lets you create and run your own multimodal video editing agents in a node-based canvas. It\u2019s different from traditional video editing tools in two ways: (1) the user interface and (2) the visual intelligence built into our agent.<p>We were engineers at Tesla and one day had a fun idea to make a YouTube video of Cybertrucks in Palo Alto. We recorded hours of cars driving by, but got stuck on how to scrub through all this raw footage to edit it down to just the Cybertrucks.<p>We got frustrated trying to accomplish simple tasks in video editors like DaVinci Resolve and Adobe Premiere Pro. Features are hidden behind menus, buttons, and icons, and we often found ourselves Googling or asking ChatGPT how to do certain edits.<p>We thought that surely now, with multimodal AI, we could accelerate this process. Better yet, an AI video editor could automatically apply edits based off what it sees and hears in your video. The idea quickly snowballed and we began our side quest to build \u201cCursor for Video Editing\u201d.<p>We put together a prototype and to our amazement, it was able to analyze and add text overlays based on what it saw or heard in the video. We could now automate our Cybertruck counting with a single chat prompt. That prototype is shown here: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GXr7q7Dl9X0\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GXr7q7Dl9X0</a>.<p>After that, we spent a chunk of time building our own timeline-based video editor and making our multimodal copilot powerful and stateful. In natural language, we could now ask chat to help with AI asset generation, enhancements, searching through assets, and automatically applying edits like dynamic text overlays. That version is shown here: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;X4ki-QEwN40\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;X4ki-QEwN40</a>.<p>After talking to users though, we realized that the chat UX has limitations for video: (1) the longer the video, the more time it takes to process. Users have to wait too long between chat responses. (2) Users have set workflows that they use across video projects. Especially for people who have to produce a lot of content, the chat interface is a bottleneck rather than an accelerant.<p>That took us back to first principles to rethink what a \u201cnon-linear editor\u201d really means. The result: a node-based canvas which enables you to create and run your own multimodal video editing agents. <a href=\"https:&#x2F;&#x2F;screen.studio&#x2F;share&#x2F;SP7DItVD\" rel=\"nofollow\">https:&#x2F;&#x2F;screen.studio&#x2F;share&#x2F;SP7DItVD</a>.<p>Each tile in the canvas represents a video editing operation and is configurable, so you still have creative control. You can also branch and run edits in parallel, creating multiple variants from the same raw footage to A&#x2F;B test different prompts, models, and workflows. In the canvas, you can see inline how your content evolves as the agent goes through each step.<p>The idea is that canvas will run your video editing on autopilot, and get you 80-90% of the way there. Then you can adjust and modify it in an inline timeline editor. We support exporting your timeline state out to traditional editing tools like DaVinci Resolve, Adobe Premiere Pro, and Final Cut Pro.<p>We\u2019ve also used multimodal AI to build in visual understanding and intelligence. This gives our system a deep understanding of video concepts, emotions, actions, spoken word, light levels, shot types.<p>We\u2019re doing a ton of additional processing in our pipeline, such as saliency analysis, audio analysis, and determining objects of significance\u2014all to help guide the best edit. These are things that we as human editors internalize so deeply we may not think twice about it, but reverse-engineering the process to build it into the AI agent has been an interesting challenge.<p>Some of our analysis findings:\nOptimal Safe Rectangles: <a href=\"https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage1.png\" rel=\"nofollow\">https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage1.png</a>\nVideo Analysis: <a href=\"https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage2.png\" rel=\"nofollow\">https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage2.png</a>\nSaliency Analysis: <a href=\"https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage3.png\" rel=\"nofollow\">https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage3.png</a>\nMean Movement Analysis: <a href=\"https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage4.png\" rel=\"nofollow\">https:&#x2F;&#x2F;assets.frameapp.ai&#x2F;mosaicresearchimage4.png</a><p>Use cases for editing include: - Removing bad takes or creating script-based cuts from videos &#x2F; talking-heads - Repurposing longer-form videos into clips, shorts, and reels (e.g. podcasts, webinars, interviews) - Creating sizzle reels or montages from one or many input videos - Creating assembly edits and rough cuts from one or many input videos - Optimizing content for various social media platforms (reframing, captions, etc.) - Dubbing content with voice cloning and lip syncing.<p>We also support use cases for generating content such as motion graphic animations, cinematic captions, AI UGC content, adding contextual AI-generated B-Rolls to existing content, or modifying existing video footage (changing lighting, applying VFX).<p>Currently, our canvas can be used to build repeatable agentic workflows, but we\u2019re working on a fully autonomous agent which will be able to do things like: style transfer using existing video content, define its own editing sequence &#x2F; workflow without needing a canvas, do research and pull assets from web references, and so on.<p>You can try it today at <a href=\"https:&#x2F;&#x2F;edit.mosaic.so\">https:&#x2F;&#x2F;edit.mosaic.so</a>. You can sign up for free and get started playing with the interface by uploading videos, making workflows on the canvas, and editing them in the timeline editor. We do paywall node runs to help cover model costs. Our API docs are at <a href=\"https:&#x2F;&#x2F;docs.mosaic.so\">https:&#x2F;&#x2F;docs.mosaic.so</a>. We\u2019d love to hear your feedback!", "author": "adishj", "timestamp": "2025-11-19T15:28:04+00:00", "score": 28, "num_comments": 16, "products": ["chatgpt", "copilot"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-19T17:10:43.502799+00:00", "processed": false}
{"id": "hn_comment_45981753", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45981753", "title": "Re: Launch HN: Mosaic (YC W25) \u2013 Agentic Video Editing...", "text": "&gt; We got frustrated trying to accomplish simple tasks in video editors like DaVinci Resolve and Adobe Premiere Pro. Features are hidden behind menus, buttons, and icons, and we often found ourselves Googling or asking ChatGPT how to do certain edits.<p>Hidden behind a UI? Most of the major tools like blade, trim, etc. are right there on the toolbars.<p>&gt; We recorded hours of cars driving by, but got stuck on how to scrub through all this raw footage to edit it down to just the Cybertrucks.<p>Scrubbing is the easiest part. Mouse over the clip, it starts scrubbing!<p>I\u2019m being a bit tongue in cheek and I totally agree there is a learning curve to NLE\u2019s but those complaints were also a bit striking to me.", "author": "BolexNOLA", "timestamp": "2025-11-19T16:48:33+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["onboarding", "navigation"], "sentiment": null, "collected_at": "2025-11-19T17:10:43.591170+00:00", "processed": false}
{"id": "hn_comment_45979532", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45979532", "title": "Re: Show HN: tweakcc (OSS)\u2013customize Claude Code's sys...", "text": "Author here.  tweakcc is a CLI to customize Claude Code (system prompts, themes, \u201cthinking\u201d verbs&#x2F;spinner, toolsets, etc.).  It also enables native LSP and adds &#x2F;title or &#x2F;rename to manually name sessions.<p>Try it now:\n  npx tweakcc\n  # reapply your changes after CC updates:\n  npx tweakcc --apply<p>What\u2019s new in 3.x:\n\u2022 Native (binary) CC installs supported (Windows&#x2F;macOS&#x2F;Linux)\n\u2022 &#x2F;toolset support\n\u2022 Manual session naming: &#x2F;title \u201cMy Session\u201d (or &#x2F;rename)\n\u2022 Makes Claude Code\u2019s native LSP work out of the box\n\u2022 Expands thinking blocks by default<p>Related discussion:<p><a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1odd0pw&#x2F;removed_most_of_claude_codes_system_prompt_and_it&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1odd0pw&#x2F;removed_m...</a><p><a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1otdfo9&#x2F;lsp_is_coming_to_claude_code_and_you_can_try_it&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1otdfo9&#x2F;lsp_is_co...</a><p><a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1ozge01&#x2F;claude_code_now_unofficially_supports_custom&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1ozge01&#x2F;claude_co...</a><p><a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1ov5g4s&#x2F;tweakcc_301_cc_native_support_lsp_toolsets_show&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ClaudeAI&#x2F;comments&#x2F;1ov5g4s&#x2F;tweakcc_3...</a>", "author": "bl-ue", "timestamp": "2025-11-19T13:55:08+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-19T17:10:46.611897+00:00", "processed": false}
{"id": "hn_comment_45979407", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45979407", "title": "Re: EU Regulators Announce List of Critical ICT Third-...", "text": "direct link (PDF): <a href=\"https:&#x2F;&#x2F;www.esma.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;2025-11&#x2F;List_of_designated_CTPPs.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;www.esma.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;2025-11&#x2F;List_...</a><p><pre><code>  \u2212 Accenture plc  \n  \u2212 Amazon web Services EMEA Sarl \n  \u2212 Bloomberg L.P. \n  \u2212 Capgemini SE \n  \u2212 Colt Technology Services \n  \u2212 Deutsche Telekom AG  \n  \u2212 Equinix (EMEA) B.V. \n  \u2212 Fidelity National Information Services, Inc. \n  \u2212 Google Cloud EMEA Limited \n  \u2212 International Business Machine Corporation \n  \u2212 InterXion HeadQuarters B.V. \n  \u2212 Kyndryl Inc. \n  \u2212 LSEG Data and Risk Limited \n  \u2212 Microsoft Ireland Operations Limited \n  \u2212 NTT DATA Inc. \n  \u2212 Oracle Nederland B.V.  \n  \u2212 Orange SA \n  \u2212 SAP SE \n  \u2212 Tata Consultancy Services Limited</code></pre>", "author": "das_keyboard", "timestamp": "2025-11-19T13:43:27+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-19T17:10:47.021012+00:00", "processed": false}
{"id": "hn_story_45978523", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45978523", "title": "Show HN: Sidely a minimal ChatGPT sidebar for Chrome (no back end no injections)", "text": "I made a small Chrome extension because switching tabs to ChatGPT all day was getting annoying. Sidely opens your existing ChatGPT session in the Chrome side panel.<p>No backend, no tracking, no page injections. Just a lightweight shortcut to ChatGPT.<p>Would appreciate feedback on the UX or anything that feels rough.<p>Chrome Web Store:\n<a href=\"https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;sidely-chatgpt-sidebar&#x2F;ibgipmeolfponfpmjhflfgkbcecpmcoo\" rel=\"nofollow\">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;sidely-chatgpt-side...</a>", "author": "parasochka", "timestamp": "2025-11-19T11:59:31+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-19T17:10:49.962573+00:00", "processed": false}
{"id": "hn_comment_45978765", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45978765", "title": "Re: Phoenix Creator Argues Elixir Is AI's Best Languag...", "text": "In an ironic twist, Claude tells me it is Rust because of the error messages.<p>Each project I have tried a different language.<p>It liked Racket but didn&#x27;t think Typed Racket as really worth it.<p>Erlang worked out well.<p>It does pretty good at C#.<p>But don&#x27;t take my word for it<p>&gt; would you prefer erlang, rust, racket or c#<p>\u25cf Interesting comparison - these are very different tools. My preference would depend heavily on the\n  problem:<p>For What We Just Did [polling an API]<p>I&#x27;d pick Erlang - and here&#x27;s why this specific project validates that choice:<p><pre><code>  1. Long-running stateful service: Needs to run 24&#x2F;7 polling aircraft data\n  2. Built-in state management: Mnesia for regions, rules, recent sightings\n  3. Concurrent by default: Multiple aircraft being processed, periodic polling, web server - all\n  concurrent without thinking about it\n  4. Reliability matters: Missing aircraft alerts due to crashes would be bad; OTP supervision handles\n  this\n</code></pre>\nBut Generally?<p>Rust would be my favorite overall:\n  - Compile-time correctness catches whole classes of bugs that runtime systems miss\n  - Performance without compromise - no GC pauses, predictable behavior\n  - Modern ergonomics - cargo, excellent error messages, strong type inference\n  - Growing ecosystem - tokio for async, axum for web, no longer as sparse as it was<p>The catch: Rust&#x27;s learning curve is real, and for rapid prototyping it can be slower.<p>Racket is fascinating for:\n  - Language-oriented programming - when you need to build DSLs\n  - Exploratory work - REPL-driven development is wonderful\n  - Education&#x2F;research - the language tower concept is unique<p>But it&#x27;s too niche for production systems most of the time.<p>C# I&#x27;d choose when:\n  - Enterprise integration is critical - existing .NET infrastructure\n  - Team familiarity - large pool of developers\n  - Rapid development with good tooling - Visual Studio, LINQ, async&#x2F;await<p>But it feels heavy and tied to the Microsoft ecosystem.<p>The Honest Answer<p>For systems that must not fail (telecom, distributed databases, message queues): Erlang<p>For performance-critical systems where correctness matters (OS components, embedded, infrastructure):\n  Rust<p>For most other things (web apps, APIs, tools, scripts): I&#x27;d probably reach for something lighter like<p>Go or Python rather than any of these four.", "author": "delaminator", "timestamp": "2025-11-19T12:27:24+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages", "onboarding", "response_quality"], "sentiment": null, "collected_at": "2025-11-19T17:10:50.081526+00:00", "processed": false}
{"id": "hn_story_45978455", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=45978455", "title": "Microsoft E Anthropic", "text": "Microsoft has announced a new strategic partnership with Anthropic, marking the startup&#x27;s models&#x27; entry into Microsoft Foundry for the first time.<p>The agreement also includes a robust financial commitment: Anthropic will acquire $30 billion in computing capacity on Azure, in addition to contracting up to 1 gigawatt of additional processing power.<p>With the change, Microsoft Foundry clients will have direct access to the startup&#x27;s cutting-edge models \u2014 including Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. Despite this, Anthropic will maintain Amazon as its primary cloud provider and training partner.", "author": "jonasthimoteo", "timestamp": "2025-11-19T11:50:06+00:00", "score": 5, "num_comments": 2, "products": ["claude"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2025-11-19T17:10:50.187174+00:00", "processed": false}
