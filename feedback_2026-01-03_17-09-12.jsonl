{"id": "hn_story_46478789", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46478789", "title": "Show HN: I built a 30x faster svelte-check in 2 days with AI", "text": "I built a Rust drop-in replacement for svelte-check that&#x27;s 10-30x faster for Svelte 5 projects.<p>What it does:<p>- Parses Svelte files with a custom Rust parser\n- Transforms them to TSX in parallel using Rayon\n- Runs type-checking via Microsoft&#x27;s tsgo (the native Go port of TypeScript)\n- Maps errors back to original .svelte locations via source maps<p>Why it&#x27;s fast:<p>The official svelte-check uses TypeScript&#x27;s Language Service API optimized for IDEs with persistent connections. Great for autocomplete but slow for batch CLI checks.<p>svelte-check-rs writes real TSX files to disk and runs tsgo as a standalone compiler. This enables incremental builds with persistent .tsbuildinfo, so subsequent runs only re-check changed files.<p>Benchmarks on a 650-file SvelteKit monorepo (M4 Max):<p><pre><code>  Cold: 17.5s vs 39.6s (2.3x faster)\n  Warm: 1.3s vs 39.4s (30x faster)\n  Iterative: 2.5s vs 39.8s (16x faster)\n</code></pre>\nThe AI part:<p>I built this in ~2 days using Claude Code (Opus 4.5) and Codex CLI (GPT-5.2 xhigh). The entire Svelte parser, TSX transformer, diagnostics engine, and CLI were written entirely by AI. I focused on architecture decisions and testing against real codebases while the models handled the implementation.<p>My motivation was actually to make AI coding agents more effective. When agents write code, they need to verify it works, and waiting 40 seconds for type-checking kills the feedback loop. With 1-2 second checks, agents can iterate much faster and catch their own mistakes immediately on our large and growing production SvelteKit codebase.<p>Website: <a href=\"https:&#x2F;&#x2F;svelte-check-rs.vercel.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;svelte-check-rs.vercel.app&#x2F;</a>", "author": "gmaster1440", "timestamp": "2026-01-03T16:51:41+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-03T17:09:14.144612+00:00", "processed": false}
{"id": "hn_story_46478740", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46478740", "title": "Show HN: Underpriced AI \u2013 Snap a photo, get instant resale value with AI", "text": "<p><pre><code>  Hey HN,\n\n  I built Underpriced AI to solve a problem I had as a part-time reseller: standing in a thrift store trying to figure out if something is worth buying.\n\n  How it works:\n  - Snap a photo of any item\n  - AI identifies the brand, model, maker, era, etc.\n  - Pulls recent sold prices from eBay and other marketplaces\n  - Gives you an instant valuation with confidence score\n\n  You can also generate SEO-optimized eBay listings and publish directly from the app.\n\n  Tech stack: Next.js, Claude API for vision&#x2F;analysis, eBay API for market research and listing.\n\n  The &quot;Quick Scan&quot; feature is designed for mobile \u2013 get a price check in seconds while you&#x27;re out sourcing.\n\n  Free tier available. Would love feedback from anyone in the reselling space or who&#x27;s worked on similar pricing&#x2F;valuation problems.\n\n  https:&#x2F;&#x2F;underpricedai.com</code></pre>", "author": "fkratzer", "timestamp": "2026-01-03T16:47:38+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-03T17:09:14.177866+00:00", "processed": false}
{"id": "hn_comment_46478066", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46478066", "title": "Re: Google engineer says Claude Code built in one hour...", "text": "in that one year, more was accomplished than writing a body of code.<p>people learned, explored concepts, and discovered lateral associations, developed collective actions, consolidated future solidarity.<p>claude just output some code.", "author": "rolph", "timestamp": "2026-01-03T15:56:13+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-03T17:09:16.966879+00:00", "processed": false}
{"id": "hn_comment_46478607", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46478607", "title": "Re: Google engineer says Claude Code built in one hour...", "text": "I\u2019m deeply skeptical of these claims.<p>Every time someone says \u201cAI built in an hour what took us a year,\u201d what they really mean is that humans spent a year doing the hard thinking and the AI merely regurgitated it at silicon speed. Which is, of course, completely different from productivity.<p>Also, if it truly took your team a year, that probably says more about your process than about AI. But not in a way that threatens my worldview. In a different way. A safer way.<p>Let\u2019s be clear: writing the code is the easy part. The real work is the meetings, the alignment, the architectural debates, the Jira grooming, the moral struggle of choosing snake_case vs camelCase. Claude didn\u2019t do any of that. Therefore it didn\u2019t actually do anything.<p>I, personally, have spent years cultivating intuition, judgment, and taste. These are things that cannot be automated, except apparently by a probabilistic text model that keeps outperforming me in domains I insist are \u201csubtle.\u201d<p>Sure, the output works. Sure, it passes tests. Sure, it replaces months of effort. But it doesn\u2019t understand what it\u2019s doing. Unlike me, who definitely understands everything I copy from Stack Overflow.<p>Also, I tried AI last year and it hallucinated once, so I\u2019ve concluded the entire field has plateaued permanently. Technology famously never improves after an early bad demo.<p>Anyway, I remain unconcerned. If AI really were that powerful, it would have already made me irrelevant, and since I still have a job, this must all be hype. QED.<p>Now if you\u2019ll excuse me, I need to spend the afternoon explaining why a tool that just invalidated a year of human labor is \u201cjust autocomplete.\u201d", "author": "threethirtytwo", "timestamp": "2026-01-03T16:37:50+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-03T17:09:17.105141+00:00", "processed": false}
{"id": "hn_story_46477061", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46477061", "title": "Show HN: CCC \u2013 Control Claude Code Sessions Remotely via Telegram", "text": "I built ccc to control Claude Code sessions from my phone via Telegram. It lets you start sessions remotely, get notifications when Claude finishes tasks, and seamlessly switch between phone and PC.<p>Features:\n- 100% self-hosted, runs on your machine\n- Multi-session support with Telegram topics\n- Voice messages (transcribed with Whisper)\n- Image attachments for Claude to analyze\n- tmux integration for session persistence<p>Built with Go. Would love feedback!", "author": "kidandcat", "timestamp": "2026-01-03T14:28:44+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-03T17:09:19.734155+00:00", "processed": false}
{"id": "hn_comment_46475832", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46475832", "title": "Re: The fear of not growing due to AI...", "text": "So basically, I feel trapped in this AI world, and from what I can see on Reddit I\u2019m not the only one, which makes me feel better tbh.<p>I started learning to code by myself pretty recently, around 2022, and if I\u2019m not wrong, I tried ChatGPT for the first time as a coding helper in mid-2023. At that moment I had very basic knowledge, but enough to barely understand what the AI was throwing at me. Still, that felt like the first line of coke for an addict I was fascinated by how fast I was now able to solve problems.<p>Newbie bugs that took me days to solve were now done by AI in a matter of minutes. However, the barrier was still there: there was no MCP, you needed to copy-paste from VS Code to the chat, so many times you still had to put in some effort to fix things.<p>Now, with Cursor, Copilot, and so on, everything has changed drastically. These days, I sometimes spend the whole day writing either in English or Spanish but not really coding. I do read code, but it\u2019s weird when I write more than four or five lines of code myself in a day.<p>So I need to ask: how good or bad is this behavior?<p>It doesn\u2019t seem very good because you get lazy, but on the other hand you focus more on architecture, code cleaning tasks, reviewing, etc. And was this really what I wanted when I started? I wanted to look like a hacker, not like a bored police officer staring at a security monitor.<p>It\u2019s easy to say: \u201cThen stop using AI tools and start doing some real coding yourself.\u201d Yeah, sure but what if you work at a startup and everything is for yesterday? And not only that, but the whole market has now adapted to the speed AI tools gave us. Nobody expects a new feature to take 2\u20134 weeks anymore, but 1\u20132 days.<p>Everything is going so fast that you simply can\u2019t stop and say, \u201cOkay, I will change my habits so even if I\u2019m slower, my coding skills will grow.\u201d Well, maybe just maybe you can do that in your free time, but even then you feel stupid going that slow when you know that with a simple prompt everything is done.<p>What do you think? What can we, the new developers, do to keep growing our knowledge without losing that AI speed?", "author": "rawraul", "timestamp": "2026-01-03T12:34:52+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "copilot"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2026-01-03T17:09:23.311471+00:00", "processed": false}
{"id": "hn_comment_46478108", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46478108", "title": "Re: 'Chinese Peptides' Are the Latest Biohacking Trend...", "text": "There are peptide raves ?\n\u201cGray-market peptides have flooded some corners of the tech scene recently, showing up in hacker houses, start-up offices and even \u201cpeptide raves\u201d sponsored by suppliers\u201d<p>So now AI researchers are peptide junkies ?\n\u201cIn the backyard of a San Francisco Victorian, tech workers in their 20s and 30s chatted \u2026 One artificial intelligence founder mentioned buying cheap drugs directly from Chinese manufacturers. A group \u2026 share their own sources for the medication they use for weight loss, productivity, and fitness\u201d<p>\u201cPeople are trying BPC-157 and TB-500 for healing injuries by stimulating new blood vessel growth, oxytocin for improving eye contact (one OpenAI researcher called it \u201cOzempic for autism\u201d),\u201d<p>I understand FDA takes time and the current FDA trying to cancel Tylenol I crazy. But injecting substances from china in the name for growth hack sounds crazy.", "author": "bicepjai", "timestamp": "2026-01-03T15:59:06+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-01-03T17:09:30.609106+00:00", "processed": false}
{"id": "hn_comment_46474367", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46474367", "title": "Re: Ask HN: Do you prefer AI coding in an IDE or CLI? ...", "text": "I do a lot of AI coding<p>Receipts: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;lawless-m?tab=repositories\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;lawless-m?tab=repositories</a><p>I started in Cursor - the tab completion is superb. As an assistant to the coder it is incredible.<p>But then I started to lean on Sonnet more and more. I expressed my ideas and they came alive.<p>As I got better at prompting I can code at the speed of thought. So I switched to Claude Code entirely. I\u2019m a Max 200 customer now.<p>On Windows I still use VS Code because of the built in file browser and terminals don\u2019t play nice with the Windows ecosystem. It helps to keep the windows organised. It\u2019s also nice to have a few extensions like markdown renderer, graphviz viewer, png preview etc. I don\u2019t use any of the IDE parts of the IDE.<p>On Linux I just use the terminal. I use i3-wm and have multi terminals each with a different instance of Claude.<p>I\u2019m usually working on 2-3 codebases at a time and swap between them to give a new prompt.<p>I also run a Whisper server and have built a voice-keyboard program. It has some built in tool prompts \u201cbrowse\u201d launches a web browser, \u201cdesk 1\u201d changes to virtual desktop 1, that kind of thing. It\u2019s TheHand repo in my GitHub.<p>So I bounce from Cc to Cc and speak a new prompt, even to Windows as that\u2019s via RDP and TheHand can type into it.<p>Then there\u2019s Claude Code on the phone apps, so I can work on GitHub code with my phone wherever I am and not need a constant network - i have a terminal app on the phone too but it\u2019s a bit scrolly - a phone emulating a serial console emulating a teletypewriter emulating a punch card system is so far beyond parody nearly everyone thinks it\u2019s sensible!<p>I would switch to a Claude Code based editing system in a heartbeat, once someone build such a thing.", "author": "delaminator", "timestamp": "2026-01-03T09:07:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-03T17:09:31.176022+00:00", "processed": false}
{"id": "hn_comment_46473472", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46473472", "title": "Re: Programmatic Tool Calling for Agents...", "text": "Hey all :)<p>I&#x27;ve been working on an open source implementation of Programmatic Tool Calling for Agents, based on cloudflare&#x27;s codemode &amp; a few anthropic articles, and although i think it can be very powerful in certain usecases, there are some challenges that i would love to have your thoughts on<p>Instead of traditional agents that burn tens of thousands of tokens loading all tool definitions upfront and compound context with sequential calls, this approach lets agents discover only the tools they need from a file tree of TypeScript SDKs, then write code to one-shot tasks in a single pass.<p>Although having an agent execute code seems like its ideal as LLMs are great at writing code, there are a few big challenges that i have faced below<p>The main challenges w&#x2F; Programmatic Tool Calling:<p>- Output Schemas from the Tools<p>MCP servers or most tool definitions almost never define output schemas, and without knowing what a tool returns, the model hallucinates property names, like think of &#x27;task.title&#x27; vs &#x27;task.name&#x27; as an example, and the script fails at runtime because it has too guess the shape of the output of a tool. I&#x27;m working around this by the classifying tools and by actually calling the tools to infer schemas, but it&#x27;s really hacky because a single sample misses optional fields, and testing write + destructive tools means creating real or destroying data which is an approach i really dislike and don&#x27;t think is viable<p>- Tool Outputs Are Often Plain Strings (returns unstructured data)<p>Even with perfect schemas and defined shapes, most MCP tools return markdown blobs or plain strings meant for LLM inference. No JSON, no fields to index into and just text. If majority of your tools return in just strings (even when listing data) the main value of codecall is lost because you can&#x27;t write deterministic code against unstructured data in a string. You&#x27;re forced back into traditional agent behavior where the LLM interprets text. If you don&#x27;t control the server or the tool definitions, there&#x27;s no fix i can really think of.<p>- Input&#x2F;Output examples for each Tool (Amplified w&#x2F; Programmatic Tool Calling)<p>The final challenge is that JSON Schema defines structure but not usage patterns. Take that support ticket API example: the schema tells you due_date is a string, but not whether it wants &quot;2024-11-06&quot; or &quot;Nov 6, 2024&quot;. It says reporter.id is a string, but is that a UUID or &quot;USR-12345&quot;? When should reporter.contact be populated? How do escalation.level and priority interact? (got this example from an anthropic article covering this)<p>In traditional tool calling, the model can learn these patterns through trial and error across multiple turns. It tries something, gets an error or unexpected result, and adjusts for the rest But with programmatic tool calling, the model writes a script that might call create_ticket 50 times in a loop for different users. If it misinterprets the date format or ID convention in the first call, all 50 calls fail and so on.<p>-------------<p>Although all of these could be fixed by just setting them manually by the user, is there a reliable way we can get the Output Schemas and generate Input&#x2F;Output examples for each Tool, without actually calling the tool, and without having a user manually input the data?<p>If anybody is interested, or has any thoughts on Tool Calling for Agents and has any ideas please feel free to share!", "author": "zekejohn", "timestamp": "2026-01-03T07:06:01+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-03T17:09:34.222003+00:00", "processed": false}
{"id": "hn_comment_46475595", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46475595", "title": "Re: Show HN: uvx ptn, scan a QR, get a terminal in you...", "text": "I\u2019m also vibing from the iphone. Termius connects via ssh to remote server where I run claude code. Ssh connects also over a wireguard connection. So ports are not an issue because they are all available via wg in a secure way. Additionally I have code server running there automatically port forwards and giving me ssl. So when I run \u201cpnpm dev\u201d in tmux in ssh then I access it via <a href=\"https:&#x2F;&#x2F;3000.dev.mydomain.com\" rel=\"nofollow\">https:&#x2F;&#x2F;3000.dev.mydomain.com</a> which works great for development.", "author": "kosolam", "timestamp": "2026-01-03T12:00:42+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-03T17:09:41.882159+00:00", "processed": false}
{"id": "hn_comment_46472600", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46472600", "title": "Re: Proteus: The AI-native editor for multimodal creat...", "text": "I&#x27;m building Proteus, an open-source multimodal editor (think Figma meets Notion, but AI-native) where *AI writes most of the code* while I focus on architecture, technical decisions, and quality control.<p>*Why this matters:*<p>In 2025, tools like Cursor and Claude can write good enough code in 80% of scenarios. The question isn&#x27;t &quot;Can AI code?&quot; but &quot;What becomes valuable when AI can code?&quot; I believe it&#x27;s *system design, technical decision-making, and end-to-end ownership*\u2014not just knowing APIs.<p>*What makes this different:*<p>- *AI-native from day one*: Every architectural decision prioritizes AI-friendliness. This isn&#x27;t AI bolted on later\u2014it&#x27;s designed for AI collaboration from the first line.\n- *Fully transparent*: All code, architecture decisions, and lessons learned are public. I&#x27;m documenting the entire journey in weekly technical articles.\n- *Real editor, not a toy*: Phase 1 is complete with a working demo. You can create shapes, text, images, transform them, copy&#x2F;paste, undo&#x2F;redo\u2014all the core editor capabilities.\n- *Learning resource*: If you want to understand how editors work (scene graphs, rendering, interaction systems) or how to structure code for AI collaboration, this is a live case study.<p>*Current status:*<p>Phase 1: Core editing (scene graph, rendering, interaction, tools)  \n Phase 2: Multimodal elements (video, audio, web embeds)  \n Phase 3: AI Agent integration (natural language \u2192 editor actions)  \n Phase 4: Real-time collaboration<p>*Try it:* [Live Demo](<a href=\"https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;</a>)  \n*Code:* [GitHub](<a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus</a>)  \n*Articles:* [Tech Blog](<a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles</a>) (4 articles so far, covering architecture, rendering, interaction design)<p>*The experiment:* What happens when you stop reviewing AI&#x27;s code and instead focus entirely on architecture, problem diagnosis, and guiding AI through testing and context-building? That&#x27;s what I&#x27;m exploring here.<p>Would love feedback from the HN community\u2014especially from those building complex frontend apps or thinking about AI-native development workflows.<p>---<p>## Alternative Shorter Version (if character limit is an issue)<p>*Title:* Proteus: An AI-native multimodal editor where AI writes 80% of the code<p>*Description:*<p>Building an open-source editor (Figma + Notion, AI-native) where AI writes most code while I focus on architecture and decisions.<p>*Why:* In 2025, AI can code\u2014so what becomes valuable? System design, technical decisions, and ownership.<p>*What&#x27;s different:*<p>- AI-native from day one (not bolted on)\n- Fully transparent (all code + articles public)\n- Real editor (Phase 1 complete, working demo)\n- Learning resource (how editors work, AI-native architecture)<p>*Status:* Phase 1  | Phase 2-4<p>*Demo:* <a href=\"https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;</a>  \n*Code:* <a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus</a>  \n*Articles:* <a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles</a><p>Experimenting with: What happens when you stop reviewing AI code and focus on architecture + problem diagnosis?", "author": "gezilinll", "timestamp": "2026-01-03T03:46:50+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-03T17:09:42.985041+00:00", "processed": false}
{"id": "hn_comment_46472147", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46472147", "title": "Re: Google AI Overviews put people at risk of harm wit...", "text": "These AI Overviews are awful. I&#x27;ve been documenting the ones I&#x27;ve gotten over the past few months. Examples:<p>- 2025-09-19. My query: &quot;is mics an abbreviation for micrograms.&quot; AI Overview: &quot;No, MICs is not an abbreviation for micrograms; it is an abbreviation for Minimum Inhibitory Concentration.&quot;<p>- 2025-09-19. My query: &quot;75 mics of medication.&quot; AI Overview: &quot;When discussing medication, &#x27;mics&#x27; is a common abbreviation for micrograms (mcg).&quot;<p>- 2025-11-03. My query: &quot;copilot &#x27;replace string in file&#x27;.&quot; AI Overview: &quot;While Copilot in tools like Visual Studio Code can assist with code generation and refactoring, its primary function is not directly to perform &#x27;replace string in file&#x27; operations across an entire project.&quot; (&quot;Replace string in file&quot; is the name of an operation that Copilot performs, and I was looking for more info about how it works.)<p>- 2025-11-22. My query: &quot;u2 &#x27;spirits move you&#x27;.&quot; AI Overview: &quot;The phrase &#x27;spirits move you&#x27; is not a direct U2 song title, but it likely refers to their song &#x27;With or Without You,&#x27; a famous track from their album <i>The Joshua Tree</i>.&quot; (Who said anything about it being a &quot;direct U2 song title&quot;? It&#x27;s a lyric from &quot;Mysterious Ways.&quot;)<p>It&#x27;s so frequently wrong and so frequently makes insulting assumptions that it&#x27;s worse than worthless. And when you click the &quot;Dive deeper in AI mode&quot; button at the bottom, the new response often contradicts the old one. Just garbage.", "author": "brushfoot", "timestamp": "2026-01-03T02:22:28+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-03T17:09:46.691235+00:00", "processed": false}
{"id": "hn_comment_46471287", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46471287", "title": "Re: Solving Agent Context Loss: A Beads and Claude Cod...", "text": "I wrote this because I kept hitting the same wall with AI coding assistants. Small tasks work fine, medium ones when planned properly. But when I tried building something real, like a real new service in a real production system it was always difficult to keep an agent like Claude Code on track throughout an entire feature implementation.<p>After recently finding Beads here on HN, my entire development workflow changed (again). I realized that context is state, I am a developer who knows how to handle state.<p>Naturally I pieced together a couple of existing Claude Code skills, and wrote a couple of my own, and ended up with a workflow that actually delivers on automating the entire idea to shipping pipeline.<p>- Brainstorming produces a design doc\n- Design becomes an implementation plan\n- Plan converts to a Beads epic with inferred dependencies\n- Epic executes autonomously with two-stage review per task<p>I&#x27;m sharing it on HN because I suspect others are hitting similar problems and working around them in ad-hoc ways.<p>Nothing groundbreaking, but it actually works.<p><a href=\"https:&#x2F;&#x2F;jx0.ca&#x2F;solving-agent-context-loss&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;jx0.ca&#x2F;solving-agent-context-loss&#x2F;</a>", "author": "jarredkenny", "timestamp": "2026-01-03T00:28:09+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-03T17:09:47.807610+00:00", "processed": false}
