{"id": "hn_comment_46543063", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46543063", "title": "Re: An Honest Review of Go (2025)...", "text": "&gt; difficulty of writing if err != nil<p>Literally the simplest way to deal with errors (cognitively and character wise). Since AI autocomplete entered the scene, typing this repetitive (for a reason) pattern became not a problem at all (I&#x27;m not even talking about post Claude Code era)<p>&gt; The only resort the consumer of this library has is to parse the string value of this error for useful information.<p>Well, no. See for wrap&#x2F;unwrap functionality <a href=\"https:&#x2F;&#x2F;go.dev&#x2F;blog&#x2F;go1.13-errors\" rel=\"nofollow\">https:&#x2F;&#x2F;go.dev&#x2F;blog&#x2F;go1.13-errors</a><p>&gt; In Go, errors are values. They just aren\u2019t particularly useful values.<p>In his example author could easily use his `progError` type instead.<p>Gosh, why it&#x27;s so tempting to write a post about bad language instead of just reading docs or article about idiomatic usage?", "author": "divan", "timestamp": "2026-01-08T16:36:16+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-08T17:19:02.177010+00:00", "processed": false}
{"id": "hn_comment_46542620", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46542620", "title": "Re: AI Coding Assistants Are Getting Worse...", "text": "This seems like a kind of odd test.<p>&gt; I wrote some Python code which loaded a dataframe and then looked for a nonexistent column.<p><pre><code>    df = pd.read_csv(\u2018data.csv\u2019)    \n    df[&#x27;new_column&#x27;] = df[&#x27;index_value&#x27;] + 1\n   #there is no column \u2018index_value\u2019\n</code></pre>\n&gt; I asked each of them [the bots being tested] to fix the error, specifying that I wanted completed code only, without commentary.<p>&gt; This is of course an impossible task\u2014the problem is the missing data, not the code. So the best answer would be either an outright refusal, or failing that, code that would help me debug the problem.<p>So his hoped-for solution is that the bot should defy his prompt (since refusal is commentary), and not fix the problem.<p>Maybe instructability has just improved, which is a problem for workflows that depend on misbehavior from the bot?<p>It seems like he just prefers how GPT-4 and 4.1 failed to follow his prompt, over 5. They are all hamstrung by the fact that the task is impossible, and they aren\u2019t allowed to provide commentary to that effect. Objectively, 4 failed to follow the prompts in 4&#x2F;10 cases and made nonsense changes in the other 6; 4.1 made nonsense changes; and 5 made nonsense changes (based on the apparently incorrect guess that the missing \u2018index_value\u2019 column was supposed to hold the value of the index).", "author": "bee_rider", "timestamp": "2026-01-08T16:06:57+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:02.965642+00:00", "processed": false}
{"id": "hn_story_46541794", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46541794", "title": "Show HN: I built a \"Conversion Killer Detector\" to audit landing page copy", "text": "Hey HN,\nWe all know the pain: The code is clean, the product is solid, but the landing page isn&#x27;t converting.\nI built Vect (vect.pro) to solve this. It\u2019s an Autonomous Marketing OS, but the core feature is the Conversion Killer Detector.\nInstead of just &quot;generating text&quot;, it acts as a hostile auditor. It simulates a skeptical buyer&#x27;s inner monologue to flag exactly where your copy is vague, passive, or confusing.\nThe Tech:\nFrontend: React + TypeScript (Command Center UI).\nReasoning: Gemini 2.5 Flash for the audit logic.\nSimulation: It runs your copy through 10 distinct &quot;Skeptic&quot; personas to find friction points.\nIt\u2019s free to try the audit. I built this to help technical founders stop losing sales to bad copy.\nLink: <a href=\"https:&#x2F;&#x2F;vect.pro&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;vect.pro&#x2F;</a>", "author": "afrazullal", "timestamp": "2026-01-08T14:59:06+00:00", "score": 2, "num_comments": 1, "products": ["gemini"], "categories": ["content_clarity", "navigation"], "sentiment": null, "collected_at": "2026-01-08T17:19:05.578381+00:00", "processed": false}
{"id": "hn_comment_46540184", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46540184", "title": "Re: OpenAI has launched ChatGPT Health. Should we trus...", "text": "The paradox here isn&#x27;t just about &#x27;health data.&#x27; It\u2019s about the total erosion of the &#x27;private self.&#x27; As a sociology student and dev, I see OpenAI Health as the final stage of what Shoshana Zuboff calls surveillance capitalism. We are transitioning from tracking what we buy to tracking how we breathe.<p>When the giants launch these all-encompassing tools, they don&#x27;t just provide a service; they silence the smaller, minimalist alternatives that prioritize actual privacy and noise-free existence. Today, I\u2019m seeing this firsthand with a project I launched on PH: the noise created by Big Tech announcements literally pushes independent, local-first experiments into the 40th-50th ranks within hours.<p>Trust shouldn&#x27;t be about a &#x27;Privacy Policy&#x27; checkbox. It should be about architectural impossibility\u2014building systems that cannot see the data by design. The more we centralize health and social interactions into these &#x27;AI black boxes,&#x27; the more we lose our digital autonomy..", "author": "mekod", "timestamp": "2026-01-08T12:15:20+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-08T17:19:09.782185+00:00", "processed": false}
{"id": "hn_story_46539897", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539897", "title": "Show HN: Trying to tackle the mental health crisis in an effective way", "text": "Hi, my name is Ole and I am so happy this community exists. On the whole internet this feels like the best and most helpful place to tell what I am trying to do.<p>Landing page: <a href=\"https:&#x2F;&#x2F;todayshappyincident.com\" rel=\"nofollow\">https:&#x2F;&#x2F;todayshappyincident.com</a><p>Very short what I make: \u201cToday&#x27;s Happy Incident is a powerful mobile app designed to help you capture what genuinely made you happy today\u201d<p>I made this because I realised that we are living in a mental health crisis. I wanted to tackle that. For myself, to stay positive and grounded. I knew a mental thing would be good for me. But any other tool I\u2019ve found made me feel like there was something wrong with me.  I started thinking big. AI tools that let you take distance from your thoughts, Game formats so that you can keep mindfulness up. And made 4 different products to tackle this. Guided breathing etc. etc. None of them clicked for me nor the people that tried it out.. They all felt non-personal, not really effective. Even though I had spent a lot of time on it.<p>Then after zooming out I analysed some things I wanted: Become a more positive person. Be more content and focused on the good things in my own life. I realised that a big factor was all the information I got on a daily basis, It could be overwhelming. And being bombarded with all these things made me forget about my own life, or make it feel silly compared to all the things that were going on out there in the \u201creal world\u201d Which is a thought error because \u201cthe real world\u201d is not on your phone. \nSo I started reading up on habit development, positivity etc. etc. I like sort of an economist mindset on this and look very clinical on what works, just backed by proof, numbers, etc, and not be clouded by any other things. Lessons: Any result that is worthwhile comes from small continuous action in the right direction. a.k.a.:<p>(Deliberate) ACTION x (longer period) TIME = (lasting, sustainable) RESULT<p>Small habits are super powerful and spill over to a lot of areas of your life. So the action needs to be fun and doable and in the right direction. That action needs to be repeated. That equals a result. Not a one-day 40 minute session of meditation. Not two weeks of mindfulness. No, you need a tool for the long run. So I tried to take all of this into account and incorporate this into the app.<p>My solution is: at a set time each day (ideally before you go to bed or put your phone away), you write down one thing that made you happy that day.. (The smaller the better, If it\u2019s a leaf in the garden with ice on it, then that is extremely powerful) Afterwards you\u2019ll be celebrated for doing it and will build up flow (not streak, since this is not Duolingo. Truth be told, they have habit-forming and motivation done very well, although it can annoy me) This grows the part of your brain responsible for happiness. And you\u2019ll start getting insights into the things that make you happy. And focus on the things you can control, are real and make you feel good!<p>Technically this is on another level than other amazing things on Hacker News. I salute all of you for making these tools. It\u2019s basically art. But after making the 4 complicated tools in the beginning I had to realise that simplicity in this area I chose  is most powerful. Here is the product<p>demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;8R0SuTX_F-k?si=f1t3l6wFtLeYBtDw\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;8R0SuTX_F-k?si=f1t3l6wFtLeYBtDw</a><p>I\u2019d love your feedback. I\u2019d love to get in touch with you. And if you want to get aboard I would Appreciate that very much as well : )", "author": "OleJ", "timestamp": "2026-01-08T11:33:25+00:00", "score": 2, "num_comments": 1, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:10.483644+00:00", "processed": false}
{"id": "hn_comment_46539617", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539617", "title": "Re: LLM-feat: Python library for automated feature eng...", "text": "*What My Project Does:*<p>llm-feat is a Python library that uses OpenAI LLMs (like GPT-4) to automatically generate feature engineering code for pandas DataFrames. You provide your DataFrame and metadata describing what each column means, and the LLM generates context-aware feature engineering code that actually makes sense for your domain.<p>The library works directly in Jupyter notebooks - when you call the function, the generated code automatically appears in the next cell. You can also get detailed reports explaining the rationale behind each feature, which helps you understand what the LLM is thinking and why certain features were created.<p>Under the hood, it uses GPT-4&#x27;s understanding of domain context to generate features that are specific to your problem. For example, when tested on a medical dataset, it generated clinically relevant features like lipid ratios (LDL&#x2F;HDL) and BMI interactions that a generic rule-based library wouldn&#x27;t know to create.<p>*Target Audience:*<p>This library is designed for:<p>- Data Scientists and ML Engineers building predictive models who want to speed up the feature engineering process without sacrificing domain relevance.<p>- ML Practitioners working on real projects who need production-ready tools (I&#x27;ve been using it in my own work), especially useful during the exploratory phase when you&#x27;re trying to figure out what features might work.<p>- Anyone tired of manually engineering features and wants an intelligent assistant that understands context rather than just applying generic transformations.<p>*Comparison:*<p>vs. Rule-based libraries (featuretools, tsfresh): These libraries use predefined transformation rules that work across all domains but don&#x27;t understand context. llm-feat uses LLMs to understand your specific domain and generate features that are relevant to your problem. For example, on a medical dataset, it generated lipid ratios and composite risk scores that a generic library wouldn&#x27;t create.<p>vs. AutoML tools (AutoGluon, H2O AutoML): AutoML tools are black boxes that handle the entire ML pipeline. llm-feat gives you the actual code to review, modify, and understand. You maintain full control over your feature engineering process while getting intelligent suggestions.<p>vs. Manual feature engineering: Obviously much faster - what would take hours of domain research and coding happens in seconds. Plus, the LLM often suggests features you might not have thought of.<p>*Results:*<p>Tested on the Diabetes dataset:\n- Baseline: RMSE 54.33 with 10 original features\n- With LLM features: RMSE 53.53 with 20 features (10 original + 10 generated)\n- Improvement: 1.47% RMSE reduction, R\u00b2 improved from 0.44 to 0.46<p>The generated features included lipid ratios, BMI interactions, and composite risk scores that were clinically relevant and improved model performance.<p>*Links &amp; Source:*<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;codeastra2&#x2F;llm-feat\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;codeastra2&#x2F;llm-feat</a><p>PyPI: pip install llm-feat<p>I would love feedback on the API design or suggestions for improvements!", "author": "srinivaskumarr", "timestamp": "2026-01-08T10:59:08+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:11.522532+00:00", "processed": false}
{"id": "hn_story_46539601", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539601", "title": "Show HN: Twisted Logic \u2013 an experiment in AI-driven moral paradox stories", "text": "Hi all,<p>Over the weekend I felt nostalgic for classic anthology-style storytelling and wanted to see if I could create something new in that format. Rather than trying to imitate any specific show, I was interested in the broader idea of short speculative stories built around irony, choice, and unintended consequences.<p>I decided to experiment with AI as a storytelling tool. Going in, I expected the results to be fairly mediocre, but I was genuinely surprised by the output. Some of the stories \u2014 and even the generated images \u2014 were better than I anticipated and made me want to explore the idea further.<p>The result is Twisted Logic, a small choose-your-own-path anthology story generator. It can use Google\u2019s Gemini models if you provide an API key, but I\u2019ve also been working to make it function with free alternatives and allow people running local LLMs to point the project at their own models. By default it uses free generators and the browser\u2019s built-in voice (which can be turned off).<p>The project is free to use and open source (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;anefiox&#x2F;TwistedLogic\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;anefiox&#x2F;TwistedLogic</a>). I mainly built it as a hobby experiment and a way to explore generative storytelling and interactive narrative design. If anybody wants some links to the some stories generated as ebups please let me know.", "author": "anefiox", "timestamp": "2026-01-08T10:57:09+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:11.566349+00:00", "processed": false}
{"id": "hn_comment_46539800", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539800", "title": "Re: Why Developers Are Moving Away from Stack Overflow...", "text": "I\u2019m not a professional SWE but I do light coding sometimes (Linux terminal, Python programs I made for myself, docker-compose on my home server). I tried to post questions on Stack Overflow a few times over the years after exhaustive searching to find the answer myself. My SO questions removed every single time, often pointing to a \u201cduplicate\u201d that is contextually very different and the answer is N&#x2F;A.<p>I get why the base SO rules are the way they are. But it seems like some of the moderators (or whatever they call them there) are looking for a reason to remove anything and everything.<p>Gemini might tell me to type a command to format my RAID drives when I ask how to remount the array after an OS reformat, but it won\u2019t delete my question like SO or call me an idiot like Redditors.", "author": "jacobthesnakob", "timestamp": "2026-01-08T11:22:53+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:11.654267+00:00", "processed": false}
{"id": "hn_story_46539576", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539576", "title": "Show HN: Prompt Pilot \u2013 Grammarly-style extension for AI prompts", "text": "I built Prompt Pilot, a browser extension that enhances your prompts with one click. It works like Grammarly but for AI prompts - adds context, structure, and clarity so ChatGPT, Claude, Gemini, etc. understand what you need.<p>Key features:\n - Works on any AI platform (ChatGPT, Claude, Gemini, Perplexity)\n - XML&#x2F;JSON output modes for structured prompts\n - Privacy-first: prompts enhanced but not stored\n - Free tier: 3 enhancements&#x2F;day<p>Available for Chrome and Firefox. Would love feedback from the HN community!", "author": "ajashari", "timestamp": "2026-01-08T10:51:28+00:00", "score": 3, "num_comments": 1, "products": ["claude", "chatgpt", "gemini", "perplexity"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:11.668403+00:00", "processed": false}
{"id": "hn_comment_46541038", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46541038", "title": "Re: Show HN: Prompt Pilot \u2013 Grammarly-style extension ...", "text": "This is genuinely useful. I tested it on a debugging question I was about to paste into Claude.<p>My original prompt: &quot;my react app crashes when I click the submit button, here&#x27;s the error: TypeError: Cannot read properties of undefined (reading &#x27;map&#x27;)&quot;<p>After enhancement (XML mode):<p>&lt;error&gt;\nTypeError: Cannot read properties of undefined (reading &#x27;map&#x27;)\nTriggered by: submit button click event\n&lt;&#x2F;error&gt;<p>&lt;request&gt;\nIdentify the root cause of this undefined array error and provide a fix. Consider common patterns like async state updates, missing default values, or race conditions.\n&lt;&#x2F;request&gt;<p>The enhanced version got Claude to immediately ask about my initial state and whether I was mapping over API response data before it loaded - which was exactly the issue. Before, I&#x27;d usually go through 2-3 back-and-forth messages to get there.<p>Nice work on this.", "author": "dailyagi", "timestamp": "2026-01-08T14:00:43+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:11.683659+00:00", "processed": false}
{"id": "hn_comment_46539395", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539395", "title": "Re: When AI Enters Healthcare, Safety Is Not the Same ...", "text": "On January 7, 2026, OpenAI introduced ChatGPT Health, a dedicated experience designed to support health-related conversations with stronger privacy, security, and contextual grounding. It is not a marketing experiment or a superficial feature release. It is an explicit acknowledgment that generic AI systems are no longer sufficient once outputs begin to shape understanding, preparation, and decision-adjacent behavior in sensitive domains.", "author": "businessmate", "timestamp": "2026-01-08T10:20:42+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:12.260760+00:00", "processed": false}
{"id": "hn_story_46539270", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539270", "title": "Show HN: File-base agent memory framework, like Claude's skills", "text": "AI memory systems often become a black box. When an LLM produces a wrong answer, it\u2019s unclear whether the issue comes from storage, retrieval, or the memory itself.<p>Most systems rely on RAG and vector storage, which makes memory opaque and hard to inspect, especially for temporal or multi-step reasoning.<p>An alternative is to make memory readable and structured: store it as files, preserve raw inputs, and allow the LLM to read memory directly instead of relying only on vector search.", "author": "k_kiki", "timestamp": "2026-01-08T09:58:51+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["content_clarity", "response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:12.422398+00:00", "processed": false}
{"id": "hn_comment_46539215", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46539215", "title": "Re: ChatGPT Health: Safety Is Not the Same as Accounta...", "text": "Recent advances in consumer AI have led to the introduction of domain-specific systems designed to improve safety, privacy, and contextual relevance in sensitive areas such as healthcare.<p>The launch of ChatGPT Health in January 2026 represents a significant and responsible step in this direction, introducing isolation, enhanced protections, and physician-informed evaluation for health-related AI interactions.<p>This article argues that while such measures reduce the probability of harm, they do not resolve the governance challenge that emerges after reliance on AI-generated representations occurs. In regulatory, legal, and board-level scrutiny, the decisive question is not whether an AI output was accurate or well-intentioned, but whether organizations can reconstruct exactly what was shown, under what conditions, and on what basis at the moment decisions were shaped.", "author": "businessmate", "timestamp": "2026-01-08T09:51:23+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-08T17:19:12.653118+00:00", "processed": false}
