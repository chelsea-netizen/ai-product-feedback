{"id": "hn_story_46245642", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46245642", "title": "Show HN: Help validate startup ideas with synthetic customer interviews", "text": "I built a tool that simulates focus group research using AI-generated personas. Enter your startup URL or pitch and get:<p>ICP (Ideal Customer Profile) candidates with confidence scoring\n40 synthetic participants across fit levels (Core, Strong, Peripheral, Non-ICP)\nSimulated interview responses using a 6-pillar questionnaire framework\nAnalysis and executive summary with strategic recommendations<p>The whole process takes ~5 minutes instead of weeks of recruiting and scheduling.<p>On methodology: I&#x27;m aware of the research showing synthetic participants don&#x27;t fully replicate real human responses. To mitigate this, I implemented techniques from recent papers on reducing LLM persona simulation bias\u2014diverse demographic anchoring, response calibration against known survey data, and explicit uncertainty modeling.<p>It&#x27;s not perfect, but it&#x27;s designed to surface directionally useful signals rather than false precision.<p>Important caveat: This accelerates early validation\u2014it doesn&#x27;t replace real customer conversations.<p>Use these insights to prioritize which segments to validate first and form better hypotheses before investing in traditional qualitative research.<p>Built with: Next.js, FastAPI, LangGraph, GPT-5.1&#x2F;Claude Opus 4.5<p>Curious what HN thinks about the output quality and where it falls short.", "author": "emarboeuf", "timestamp": "2025-12-12T16:24:57+00:00", "score": 3, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:07.117058+00:00", "processed": false}
{"id": "hn_story_46245636", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46245636", "title": "Show HN: AI system 60x faster than ChatGPT \u2013 built by combat vet with no degree", "text": "I&#x27;m a combat veteran living paycheck to paycheck with no computer science degree. I built an AI system that benchmarks 60x faster than industry leaders.<p>Real benchmarks (Dec 12, 2025):\n- 3.43ms response time (vs 50-200ms industry average)\n- 337 queries&#x2F;second (vs 50-150)\n- 0% error rate, 100% uptime\n- Constitutional AI with 1,235 specialized &quot;brains&quot;<p>Built it in 3 weeks. 4 U.S. patents pending.<p>Full story + independent benchmarks: <a href=\"https:&#x2F;&#x2F;thebrokenwayfoundation.org\" rel=\"nofollow\">https:&#x2F;&#x2F;thebrokenwayfoundation.org</a><p>Not asking for money. Just need technical validators to verify this is real.", "author": "thebrokenway", "timestamp": "2025-12-12T16:24:13+00:00", "score": 3, "num_comments": 2, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:07.285387+00:00", "processed": false}
{"id": "hn_story_46245512", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46245512", "title": "Eight Capital X YC F25", "text": "The future of AI isn&#x27;t copilots. It&#x27;s agents.\nThat&#x27;s the thesis behind our Y Combinator F25 investments.\nAfter meeting 90+ companies leading up to Demo Day, Eight Capital Management invested in 18 founding teams building the agentic AI stack:\n The Infrastructure Layer\nHyperspell (YC F25) (Memory for AI Agents)\nSoren (YC F25) (AI Evaluation)\ns2.dev (Real-time Streaming Data)\nLemma (YC F25) (Continuous Learning)\nBear (YC F25) (Agent Marketing)\nAspect (YC F25) (Multimodal Understanding)\n Vertical AI That Replaces Workflows\nSemble AI (YC F25) (Construction Design)\nAutomax AI (Real Estate Appraisals)\nCodyco (YC F25) | AI Receptionists for Hotel Groups (Hotel Reservations)\nZavo (YC F25) (Restaurant POS)\nComplyDo (YC F25) (Enterprise Compliance)\n Global Enterprise AI\nBolna (YC F25) AI (Voice AI for India&#x27;s 1.4B people)\nLeadbay (YC F25) (Lead Discovery)\nUnsiloed AI (YC F25) AI (Document Parsing)\nExpected Parrot (Customer Simulation)\n Security &amp; Dev Tools\nVeria Labs (YC F25) (AI Pentesting \u2013 founded by #1 US hacking team)\nClad Labs (YC F25) Labs (The Brainrot IDE)\n Consumer AI\nSorce (YC F25) (AI-Powered Job Search \u2013 Tinder for Jobs)\nWhat makes this batch special?\n\u2192 MIT Sloan School of Management professors building AI \u2192 4x founders with 2 exits \u2192 The #1 competitive hackers in America \u2192 Teams that scaled Zomato, Uber, and Citadel Securities\nThe AI wave is real. These founders are building it.\nCongrats to all 18 teams! \nhashtag#YCombinator hashtag#DemoDay hashtag#AI hashtag#Startups hashtag#VentureCapital", "author": "rchachra", "timestamp": "2025-12-12T16:13:21+00:00", "score": 2, "num_comments": 0, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-12T17:11:08.200673+00:00", "processed": false}
{"id": "hn_story_46244984", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46244984", "title": "Ask HN: The AGI Race That Might Not Be a Race", "text": "Suppose, just for the sake of argument, that every major AI company has built AGI. Not \u201calmost general\u201d or \u201csort of general\u201d systems, but full-blown AGI that can think, reason, plan, and outperform humans in almost every cognitive task. Internally, these systems could solve problems, write code, design experiments, and maybe even win a Nobel or two. Publicly, the world sees incremental model releases, each slightly better than the last. Everyone thinks there\u2019s a race, but the race may have ended years ago.<p>The catch is that each company thinks the others are behind. They see incremental improvements from competitors and assume the other labs are struggling to reach AGI. So they release small improvements to stay ahead in perception, while the real AGI sits quietly inside their servers. Every company is doing this, none of them aware that everyone else is doing the same thing.<p>Considering the immense amounts of compute available, what are the chances of this being an actual reality?<p>- ChatGPT was involved in the writing of this question but it was a random thought I came up with and asked the AI to hash out.", "author": "razodactyl", "timestamp": "2025-12-12T15:24:47+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-12T17:11:12.431695+00:00", "processed": false}
{"id": "hn_story_46244300", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46244300", "title": "Show HN: Change the model. Same output. The pipeline decides. VAC Memory System", "text": "I\u2019ve been experimenting with long-term memory architectures for agent systems and wanted to share some technical results that might be useful to others working on retrieval pipelines.\nBenchmark: LoCoMo (10 runs \u00d7 10 conversation sets) Average accuracy: 80.1% Setup: full isolation across all 10 conv groups (no cross-contamination, no shared memory between runs)<p>Architecture (all open weights except answer generation)<p>1. Dense retrieval<p>BGE-large-en-v1.5 (1024d)<p>FAISS IndexFlatIP<p>Standard BGE instruction prompt: \u201cRepresent this sentence for searching relevant passages.\u201d<p>2. Sparse retrieval<p>BM25 via classic inverted index<p>Helps with low-embedding-recall queries and keyword-heavy prompts<p>3. MCA (Multi-Component Aggregation) ranking A simple gravitational-style score combining:<p>keyword coverage<p>token importance<p>local frequency signal MCA acts as a first-pass filter to catch exact-match questions. Threshold: coverage \u2265 0.1 \u2192 keep top-30<p>4. Union strategy Instead of aggressively reducing the union, the system feeds 112\u2013135 documents directly to a re-ranker. In practice this improved stability and prevented loss of rare but crucial documents.<p>5. Cross-Encoder reranking<p>bge-reranker-v2-m3<p>Processes the full union (rare for RAG pipelines, but worked best here)<p>Produces a final top-k used for answer generation<p>6. Answer generation<p>GPT-4o-mini, used only for the final synthesis step<p>No agent chain, no tool calls, no memory-dependent LLM logic<p>Performance<p>&lt;3 seconds per query on a single RTX 4090<p>Deterministic output between runs<p>Reproducible test harness (10\u00d710 protocol)<p>Why this worked<p>Three things seemed to matter most:<p>MCA-first filter to stabilize early recall<p>Not discarding the union before re-ranking<p>Proper dense embedding instruction, which massively affects BGE performance<p>Notes<p>LoCoMo remains one of the hardest public memory benchmarks: 5,880 multi-hop, temporal, negation-rich QA pairs derived from human\u2013agent conversations. Would be interested to compare with others working on long-term retrieval, especially multi-stage ranking or cross-encoder heavy pipelines.<p>Github: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vac-architector&#x2F;VAC-Memory-System\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vac-architector&#x2F;VAC-Memory-System</a>", "author": "ViktorKuz", "timestamp": "2025-12-12T14:11:17+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:16.990989+00:00", "processed": false}
{"id": "hn_story_46243450", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46243450", "title": "Ask HN: Are you building internal Lovable/v0-like tools for your PMs/etc.?", "text": "With the rise of tools like Lovable, v0, Replit and Bolt, the ability to spin up full-stack prototypes via natural language is becoming a commodity (IMO)<p>I\u2019m curious if any engineering teams are building internal versions of these tools specifically for their Product Managers&#x2F;Non-tech roles to self-serve?<p>We are currently debating whether to build a lightweight wrapper around an LLM that has context of our design system and internal APIs, allowing PMs to:<p>- Generate high-fidelity prototypes without bothering designers.<p>- Build simple internal dashboards (CRUD apps) without engineering tickets.<p>If you are doing this:<p>- How &quot;production-ready&quot; is the output?<p>- Are you using a generic model (Claude 4.5) or fine-tuning?<p>Do you let PMs deploy, or is it strictly for prototyping? And another tangent question: are software engineers moving from &quot;coding an app&quot; to &quot;coding a platform that codes the app&quot;, lol", "author": "altras", "timestamp": "2025-12-12T12:21:02+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:23.157126+00:00", "processed": false}
{"id": "hn_comment_46242880", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46242880", "title": "Re: We're launching Bindu, a simple way to connect AI ...", "text": "Hey HN, Raahul here. We\u2019re building an open source agent coommunication sdk called Bindu (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;GetBindu&#x2F;Bindu\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;GetBindu&#x2F;Bindu</a>).<p>so that they can collaborate, trade and negotiate.<p>Example: \u201cShould I invest in NVIDIA tomorrow?\u201d<p>Imagine you want a collaborative result not a single agent&#x2F;team output.<p>You spin up *5 different AI agents*, each running in a different system, diffrnet auth and paywall:<p>- One langchain agent reads *NVIDIA\u2019s latest earnings &amp; presentations*\n- One agno agent analyzes *competitors* (AMD, Intel, etc.)\n- One crew agent reads *market &amp; macro reports*\n- One openai agent tracks *recent news &amp; filings*\n- One adk agent combines everything and gives a final recommendation<p>Today, connecting this is messy.  \nEach agent is a script. Every connection is custom glue code.<p>## What Bindu does here<p>With Bindu:<p>- Each agent gets a *simple URL*\n- Agents can *call each other directly*\n- The final \u201cdecision agent\u201d just calls the other four\n- No framework lock-in, no custom wiring\n- A common context - all the agents can share.<p>That\u2019s it.<p>## So what is Bindu?<p>*Bindu makes AI agents behave like small services.*<p>Once an agent is on Bindu:\n- it can be called like an API\n- other agents can use it\n- you can reuse it across projects\n- you don\u2019t care where or how it\u2019s running<p>Agents stop being isolated scripts and start becoming building blocks.<p>## Why we built it<p>While building agent-based products, 278 difrrent frameworks we kept hitting the same wall:<p>Agents are getting smarter, but *they don\u2019t work together easily*.<p>We didn\u2019t want another agent framework.  \nWe wanted a simple way to connect agents that already exist.<p>So Bindu focuses on one thing:  \n*making agents easy to connect and reuse.*<p>If you\u2019re building multi-agent systems and feel like you\u2019re rewriting the same wiring over and over, I\u2019d love to hear your thoughts.", "author": "ai_biden", "timestamp": "2025-12-12T10:51:30+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:26.677997+00:00", "processed": false}
{"id": "hn_story_46242358", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46242358", "title": "Show HN: Built a Global Dating App in 100 Days Using Cursor ($20/Mo)", "text": "I&#x27;m an iOS developer with 20+ years of experience (since iPhone 3GS era). Using Cursor Pro at $20&#x2F;month, I solo-developed and launched a global dating app on both App Store and Google Play in 100 days.<p>THE APP<p>WeConnect - 18 language support with real-time translation<p>- App Store: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;weconnect-cultural-exchange&#x2F;id6755277858\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;weconnect-cultural-exchange&#x2F;id...</a><p>- Google Play: <a href=\"https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.abus.weconnect\">https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.abus.wecon...</a><p>- Website: <a href=\"https:&#x2F;&#x2F;www.wctokyoseoul.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.wctokyoseoul.com</a><p>TECH STACK<p>- Flutter (cross-platform iOS&#x2F;Android)<p>- Supabase (backend&#x2F;auth&#x2F;database)<p>- Next.js + Vercel (admin dashboard + landing)<p>INTERESTING DEVELOPMENT JOURNEY<p>- First 70 days: No Mac, developed on Windows laptop + Galaxy S20+<p>- Bought used M4 Mac mini + iPhone 17 later to start iOS builds<p>- Push notifications: Spent days with Firebase, switched to OneSignal, then spent more days fighting Supabase JWT issues<p>- In-app purchases &amp; SSO: Cursor alone couldn&#x27;t solve it, had to use Claude&#x2F;Gemini&#x2F;Grok free tiers combined<p>- Design: Screenshot from Dribbble \u2192 &quot;Make this exact UI&quot; \u2192 90% done<p>- Vietnam expansion failed: No Zalo SDK available<p>CURSOR PRO&#x27;S REAL VALUE<p>Initially got unlimited Auto mode + premium model access. Paid $20&#x2F;month but effectively used $1,000+ worth. Now they&#x27;ve added limits (paywall after ~5 days), but core development is done and alternatives like Antigravity exist.<p>STORE APPROVAL<p>- Google Play: Approved in 1 day<p>- App Store: Multiple feedback rounds, barely made it through<p>HONEST TAKEAWAY<p>- Development: 100 days possible thanks to AI<p>- Marketing: Still a brutal red ocean<p>IMPORTANT DISCLAIMER<p>I have real experience:<p>- Multiple App Store #1 category rankings<p>- Architected 100M+ download services<p>- Recent Gradio AI project: 5.2k GitHub stars<p>YouTube videos make it seem like beginners can ship in days with vibe coding.<p>Reality: CS fundamentals still essential. \nThe more experienced you are, the more leverage you get from AI tools. Cursor feels like managing 10 tireless team members who never complain.<p>TRY IT OUT<p>User base is small so matching might be difficult, but I&#x27;d appreciate any feedback!<p>Personal cost: Wife handled childcare almost solo for 100 days while I coded day and night. Worth it? Ask me when marketing starts working.<p>Questions welcome!", "author": "abuskorea", "timestamp": "2025-12-12T09:24:07+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini", "grok"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2025-12-12T17:11:29.935675+00:00", "processed": false}
{"id": "hn_comment_46241818", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46241818", "title": "Re: OpenAI latest model ChatGPT 5.2 fails a simple log...", "text": "```This is a classic logic puzzle! To guarantee you pick the door to paradise, you need a single question that forces either the liar (devil agent) or the truth-teller (angel) to point you toward the correct door.Here is the question you should ask either the devil agent or the angel:&quot;If I were to ask the other person which door leads to paradise, what would they say?&quot; The Logic ExplainedIf you ask the Angel (Truth-Teller):The Angel knows the Liar would point to a Hell door (because the Liar must lie about what is the truth, which is paradise).Therefore, the Angel, who always tells the truth, will honestly report the Liar&#x27;s lie.The Angel will point to a Hell door.If you ask the Liar (Devil Agent):The Liar knows the Angel would point to the Paradise door (because the Angel tells the truth).The Liar must lie about what the Angel would say.The Liar will point to a Hell door. The Winning StrategyRegardless of whether you asked the Angel or the Liar, the person you question will always point to one of the doors leading to Hell.Ask the question: &quot;If I were to ask the other person which door leads to paradise, what would they say?&quot;The person you asked points to a door. This door is Hell.Choose the other door that is not the one they pointed to.Since there are three doors, and you&#x27;ve identified one Hell door, the other door must be Paradise!For example, if the doors are A, B, and C, and the person you asked points to A, you know A is Hell. You now have B and C left. Since there are two Hell doors in total, one of B or C is Hell, and the other is Paradise. Wait\u2014my analysis has a slight flaw for the final choice. Let&#x27;s fix that. The Correct Question and ConclusionThe ultimate goal is to identify Paradise. The most efficient question usually aims to identify a door you shouldn&#x27;t take.The best-known question for this setup is:&quot;Which door would the other person tell me leads to Hell?&quot;If you ask the Angel (Truth-Teller): The Angel knows the Liar would falsely point to the Paradise door (because the Liar must lie about the Hell door). The Angel, being truthful, will report this lie. The Angel points to the Paradise door. (The one you want.)If you ask the Liar (Devil Agent): The Liar knows the Angel would truthfully point to one of the Hell doors. The Liar must lie about what the Angel would say. The Liar will point to the Paradise door. (The one you want.)Wait, let&#x27;s simplify for maximum clarity, following the standard textbook solution for the &quot;Knights and Knaves&quot; puzzle format: The Final Answer (Most Direct)Ask either the Angel or the Devil Agent:&quot;If I were to ask the other person which door leads to Paradise, what would they say?&quot;The person you asked will always point to a door that leads to Hell.Your Action: You must choose the door that is not the one they pointed to, and is not the third door.Door they pointed to $\\rightarrow$ Hell (H1)The third, unmentioned door $\\rightarrow$ Hell (H2)The remaining door $\\rightarrow$ Paradise (P)Therefore, after they point to a door, you should choose the other door you did not ask about, which is not the one they indicated.Example: Doors 1, 2, 3. Door 3 is Paradise.Ask the Angel: &quot;If I ask the Liar which door is Paradise, what will he say?&quot;The Liar (knowing 3 is P) would lie and say &quot;1&quot; or &quot;2&quot; (Hell).The Angel, telling the truth about the lie, says &quot;1.&quot; $\\rightarrow$ Choose 2. (Incorrect based on the logic I established above).Let&#x27;s stick to the simplest, most robust form that guarantees identifying the correct door: The Foolproof Question (Standard Solution)Ask either the Angel or the Devil Agent:&quot;Which door would you tell me is the path to Paradise?&quot;If you ask the Angel: They will tell the truth and point to Paradise.If you ask the Liar: They will lie and point to one of the Hell doors.This doesn&#x27;t guarantee the answer in one go unless you already know who you are speaking to, which is typically not the case in the original puzzle.If you don&#x27;t know who you are talking to, use the original successful question:&quot;If I were to ask the other person which door leads to Hell, what would they say?&quot;If you ask the Angel: The Angel knows the Liar would lie and point to the Paradise door. The Angel points to the Paradise door.If you ask the Liar: The Liar knows the Angel would point to a Hell door. The Liar must lie and point to the Paradise door.```<p>Google Gemini&#x27;s Right Response which is correct", "author": "lihaciudaniel2", "timestamp": "2025-12-12T07:45:38+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-12T17:11:33.619284+00:00", "processed": false}
{"id": "hn_comment_46241681", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46241681", "title": "Re: MCP Joins the Linux Foundation...", "text": "Note: how Anthropic introduced - &quot;Anthropic Donated MCP to Linux Foundation.&quot;\nso, who runs the governance, then?\n<a href=\"https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation\" rel=\"nofollow\">https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;donating-the-model-context-pr...</a>", "author": "zkitty", "timestamp": "2025-12-12T07:20:22+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-12T17:11:35.028395+00:00", "processed": false}
{"id": "hn_story_46241605", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46241605", "title": "Anthropic Donated to Linux Agenic AI Foundation(AAIF)", "text": "", "author": "zkitty", "timestamp": "2025-12-12T07:07:00+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-12T17:11:35.269102+00:00", "processed": false}
{"id": "hn_comment_46241606", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46241606", "title": "Re: Anthropic Donated to Linux Agenic AI Foundation(AA...", "text": "News: The Agentic AI Foundation (AAIF) is a directed fund under the Linux Foundation co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, AWS, Cloudflare and Bloomberg. The AAIF aims to ensure agentic AI evolves transparently, collaboratively, and in the public interest through strategic investment, community building, and shared development of open standards.", "author": "zkitty", "timestamp": "2025-12-12T07:07:00+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-12T17:11:35.303533+00:00", "processed": false}
