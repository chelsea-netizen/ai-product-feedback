{"id": "hn_comment_46858504", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858504", "title": "Re: Show HN: Serverless OpenAI Gateway: PII and Cache ...", "text": "&quot;OP here. I built this because I noticed two problems scaling my internal RAG tools:<p>Redundant Costs: Users asking the same questions (or slight variations) were costing me redundant tokens.<p>Compliance Anxiety: I didn&#x27;t want PII (names, emails, IDs) hitting OpenAI&#x2F;DeepSeek servers directly.<p>I looked for existing gateways but most were heavy Docker containers (requiring a VPS). I wanted something &#x27;Zero DevOps&#x27; that could run on the Edge.<p>The Solution: It&#x27;s a lightweight Gateway built with Hono running on Cloudflare Workers.<p>Smart Caching: Hashes the prompt body (SHA-256) and serves from KV if it&#x27;s a hit (&lt;50ms latency).<p>PII Shield: Uses Regex&#x2F;NER to replace sensitive data with placeholders ([EMAIL_1]) before forwarding to the LLM.<p>Re-hydration: When the LLM responds, the Worker puts the real data back into the response, so the user context remains broken.<p>It&#x27;s open-source (MIT). I&#x27;m currently looking for feedback on how to implement semantic caching (Vectorize) to catch non-identical prompts.<p>Happy to answer any questions about the implementation!&quot;", "author": "guimaster97", "timestamp": "2026-02-02T17:19:48+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:06.424490+00:00", "processed": false}
{"id": "hn_comment_46858378", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858378", "title": "Re: Show HN: LogSentinel \u2013 Local, privacy-first log an...", "text": "Hi HN, I&#x27;m Aibek, a sysadmin from Kazakhstan.<p>I built LogSentinel because I needed to analyze Nginx&#x2F;Syslogs logs with AI, but strict data policies prevented me from sending raw logs to OpenAI&#x2F;Claude.<p>How it works:<p><pre><code>    It tails log files in real-time.\n\n    Masks PII (IPs, emails, credit cards) using Regex before inference.\n\n    Sends the sanitized context to a local LLM (Ollama running Llama 3) to find anomalies.\n\n    Stores patterns in SQLite to avoid re-analyzing known errors (caching).\n</code></pre>\nIt&#x27;s an MVP, written in Python. I&#x27;d love to hear your feedback on the architecture or how you handle local log analysis securely.", "author": "aibek_dev", "timestamp": "2026-02-02T17:10:00+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-02T17:30:06.880195+00:00", "processed": false}
{"id": "hn_story_46858093", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858093", "title": "Show HN: Cloud-cost-CLI \u2013 Find cloud $$ waste in AWS, Azure and GCP", "text": "Hey HN! I built a CLI tool to find cost-saving opportunities in AWS, Azure, and GCP.<p>Why?\nExisting cost management tools are either expensive SaaS products or slow dashboards buried in cloud consoles. I wanted something fast, CLI-first, and multi-cloud that I could run in CI&#x2F;CD or my terminal.<p>What it does:\n- Scans your cloud accounts and finds idle VMs, unattached volumes, oversized databases, unused resources\n- Returns a ranked list of opportunities with estimated monthly savings\n- 26 analyzers across AWS, Azure, and GCP\n- Read-only (never modifies infrastructure)<p>Key features:\n\u2022 HTML reports with interactive charts (new in v0.6.2)\n\u2022 AI-powered explanations (OpenAI or local Ollama)\n\u2022 Export formats: HTML, Excel, CSV, JSON, terminal\n\u2022 Multi-Cloud - AWS, Azure, and GCP support (26 analyzers)<p>Quick example:\nnpm install -g cloud-cost-cli\ncloud-cost-cli scan --provider aws --output html<p>Real impact:\nOne scan found $11k&#x2F;year in savings (empty App Service Plan, over-provisioned CosmosDB, idle caches).<p>Technical stack:\n- TypeScript\n- AWS&#x2F;Azure&#x2F;GCP SDKs\n- Commander.js for CLI\n- Chart.js for HTML reports\n- Optional OpenAI&#x2F;Ollama integration<p>Open source (MIT): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vuhp&#x2F;cloud-cost-cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vuhp&#x2F;cloud-cost-cli</a>\nnpm: cloud-cost-cli<p>Would love feedback on:\n1. What features would be most useful?\n2. Should I add historical tracking (trends)?\n3. Any missing cloud providers?<p>Happy to answer questions!", "author": "vuhp", "timestamp": "2026-02-02T16:45:10+00:00", "score": 3, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:08.498135+00:00", "processed": false}
{"id": "hn_story_46857597", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46857597", "title": "Show HN: Workflow Hub, Open library of human-AI workflows you can clone and run", "text": "Hi HN, I\u2019m Hiroki, founder of Epismo.<p>Every day, people share \u201cmust-use\u201d prompts, but copying a single prompt rarely reproduces real outcomes. The missing piece is the workflow: task decomposition, step order, intermediate artifacts, and quality checks.<p>So I built Workflow Hub, an open library of human-AI workflows you can clone and run. Each workflow includes step definitions, inputs, expected artifacts&#x2F;outputs, and verification checks, so you can copy the whole process, not just a prompt. You can clone a workflow, customize it, then execute it in Epismo with the best agent for each step.<p>PH: <a href=\"https:&#x2F;&#x2F;producthunt.com&#x2F;products&#x2F;epismo\" rel=\"nofollow\">https:&#x2F;&#x2F;producthunt.com&#x2F;products&#x2F;epismo</a>\nLink: <a href=\"https:&#x2F;&#x2F;epismo.ai&#x2F;hub\" rel=\"nofollow\">https:&#x2F;&#x2F;epismo.ai&#x2F;hub</a><p>If you have a workflow that\u2019s working well for you, please share it. I\u2019m personally curious what workflows you\u2019re building with Claude Code, Cowork, or OpenClaw.", "author": "hirokiyn", "timestamp": "2026-02-02T16:07:31+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:11.138472+00:00", "processed": false}
{"id": "hn_comment_46858512", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858512", "title": "Re: Ask HN: Who is hiring? (February 2026)...", "text": "Starbridge | Senior Engineers (Kotlin&#x2F;Java&#x2F;React&#x2F;Typescript) | NYC or Remote | Full-time | starbridge.ai Starbridge is building an AI platform that turns large-scale public and enterprise data into reliable sales insights. We are early, moving fast, and building from zero to one, so this role will have huge ownership and product impact.<p>Product Engineer: (React&#x2F;Typescript) who would work closely with product and design to build user-facing parts of the platform. You will craft performant, stable frontends that explain technical concepts to non-technical users and help us iterate fast based on customer feedback.<p>AI Engineer: Applied AI plus strong software engineering. You will build, evaluate, and deploy LLM-driven features like deep document analysis and interactive chat, working with models from OpenAI, Anthropic, and Gemini. Expect hands-on Python, ML system design, experimentation, and production reliability. Bonus for RAG depth and frameworks like LangChain, LlamaIndex, or Hugging Face.<p>Backend Engineer: (looking for Kotlin&#x2F;Java&#x2F;Scala experience). You&#x27;ll work across the backend: building enterprise integrations, large-scale scraping and parsing pipelines, and systems that let users apply LLMs to millions of documents to generate insights at scale.<p>We&#x27;re looking to build our in-person team in NYC but also open to remote!<p>Apply: <a href=\"https:&#x2F;&#x2F;starbridge.ai&#x2F;careers\" rel=\"nofollow\">https:&#x2F;&#x2F;starbridge.ai&#x2F;careers</a> and mention HackerNews or email recruiting@starbridge.ai with your resume.", "author": "melissamrec", "timestamp": "2026-02-02T17:20:21+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:11.784729+00:00", "processed": false}
{"id": "hn_comment_46858502", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858502", "title": "Re: Ask HN: Who is hiring? (February 2026)...", "text": "Mondrio | Software Engineer (Founding Team) | REMOTE (Brazil) | 3-Month Trial-to-Hire<p>B2B SaaS pricing is still guesswork. We\u2019re building the AI-powered monetization operating system to fix it. We are pre-seed, lean (4 people), and shipping to live customers.<p>The Experience: This is a unique &quot;fast-track&quot; for an ambitious junior&#x2F;mid-level engineer. You\u2019ll skip the corporate ladder and learn to build an AI-native company from the ground floor. You will own features end-to-end\u2014no managers, no layers.<p>AI-Native Workflow: We are all-in on Claude Code for scoping and shipping. You get a seat on Day 1. If you aren&#x27;t already 10x-ing your output with AI tools, we\u2019ll teach you. It\u2019s the most essential skill for the next decade of engineering.<p>The Work:<p>Integrations: Build OAuth 2.0 flows and data sync pipelines for pilot customers.<p>Northstar Module: Build a strategic intelligence module from scratch (DB, Backend, Frontend integration. We have most of designs already).<p>AI Personas: Use LLMs to turn raw customer data into actionable pricing strategy.<p>Stack: Python 3.12 (Typed), FastAPI, MongoDB&#x2F;Beanie, React&#x2F;TS, Gemini&#x2F;Claude, Claude Code, Google Cloud, Docker, Pulumi<p>Who You Are: You write clean, typed Python and can navigate a React component. You use AI tools (Cursor&#x2F;Copilot) to move fast but remain the pilot. You care about the &quot;Why&quot; behind the product.<p>Process: Intro call \u2192 Technical session \u2192 Founder chat. Decision in ~7 days.<p>Apply: Send a link to something you\u2019ve built to manon@mondrio.com", "author": "majamondrio", "timestamp": "2026-02-02T17:19:43+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:11.826799+00:00", "processed": false}
{"id": "hn_comment_46858533", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858533", "title": "Re: Ask HN: Who is hiring? (February 2026)...", "text": "Waypoint AI | Senior Backend, Fullstack, Frontend | Prague + REMOTE (CZ) | Full-time | Equity<p>We&#x27;re building Chip \u2014 an AI support engineer that autonomously triages, routes, and resolves complex technical support cases. Think: a teammate that reads every Jira ticket, every Intercom thread, and every runbook, then actually acts on them.<p>Czech-American B2B startup, raised $3.1M. Already in production with Volvo, ClickHouse, and others.<p>We&#x27;re a small eng team where early architectural decisions still matter. We use AI daily as a collaborator (Claude Code) \u2014 not as a gimmick, but because it genuinely makes us faster. We value craft, ownership, and shipping in small slices.<p>Stack: Django + Django Ninja, Postgres, Dramatiq (background jobs), React&#x2F;Next.js&#x2F;TypeScript&#x2F;Tailwind.<p>Hiring for three roles:<p>Senior Backend Engineer (AI Systems) \u2014 Own APIs, data pipelines, and durable workflows. LLM product experience (evals, cost&#x2F;latency, vector search) is a plus. <a href=\"https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;senior-backend-engineer-ai-systems\" rel=\"nofollow\">https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;senior-backend-engineer...</a><p>Fullstack Engineer \u2014 Backend-heavy with enough frontend to be dangerous. End-to-end ownership from schema to UI. <a href=\"https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;fullstack-engineer\" rel=\"nofollow\">https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;fullstack-engineer</a><p>Frontend Developer \u2014 Build interfaces that make complex AI feel simple. React&#x2F;Next.js&#x2F;TS&#x2F;Tailwind. Product-minded, not just pixel-pushing. <a href=\"https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;frontend-developer\" rel=\"nofollow\">https:&#x2F;&#x2F;mywaypoint.ai&#x2F;open-positions&#x2F;frontend-developer</a><p>Office in Prague 7 (Hole\u0161ovice), remote-friendly. Competitive CZ-market comp + meaningful equity.<p>To apply: joinus@mywaypoint.ai \u2014 include a project you shipped end-to-end and how you use AI tooling in your workflow. Mention HN.", "author": "_visgean", "timestamp": "2026-02-02T17:22:20+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:11.866984+00:00", "processed": false}
{"id": "hn_story_46857391", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46857391", "title": "Show HN: Gryph \u2013 Audit Trail for AI Coding Agents (Claude Code, Cursor, Gemini)", "text": "Hi everyone<p>I am the author of Gryph.<p>I have been using AI coding agents daily and realized I had no idea what they were actually doing across sessions. Sure, I could check git diff, but that doesn&#x27;t show:<p>- Files the agent read but didn&#x27;t change<p>- Commands it ran<p>- The sequence of actions in a session<p>- What happened last week when something broke<p>So I built Gryph - a CLI tool that maintains an audit log of all AI agent actions.<p>How it works:<p>- Installs hooks into Claude Code, Cursor, Gemini CLI (and other supported coding agents)<p>- Logs every action to a local SQLite database<p>- Provides rich querying: filter by time, agent, file path, action type<p>Quick demo:<p>$ gryph install\nDiscovering agents...\n  [ok]  Claude Code v2.1.15\n  [ok]  Cursor v2.4.21\nInstallation complete.<p>$ gryph logs --today\n14:32  claude-code  session 7f3a2b1c\n\u251c\u2500 14:32:12  read     src&#x2F;index.ts\n\u251c\u2500 14:32:18  write    src&#x2F;utils&#x2F;helper.ts    +12 -3\n\u2514\u2500 14:32:22  exec     npm test               exit:0<p>$ gryph query --file &quot;<i>.env</i>&quot; --since &quot;7d&quot;\n# See if any agent touched sensitive files<p>Privacy-first:<p>- 100% local - no cloud, no telemetry<p>- Sensitive file patterns are protected (actions logged, content never stored)<p>- Configurable verbosity<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;safedep&#x2F;gryph\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;safedep&#x2F;gryph</a><p>Built with Go. Would love feedback from others using AI coding tools!<p>Previous post by someone else: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46846849\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46846849</a>", "author": "abhisek", "timestamp": "2026-02-02T15:53:47+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["feature_discovery"], "sentiment": null, "collected_at": "2026-02-02T17:30:12.989984+00:00", "processed": false}
{"id": "hn_comment_46857436", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46857436", "title": "Re: Classified Whistleblower Complaint About Tulsi Gab...", "text": "After reading the article:<p>It appears the whistleblower complaint against DNI Tulsi Gabbard, filed in May 2025, has faced an eight-month delay in reaching Congress, far exceeding the typical weeks-long (two to three is the norm) window for such disclosures. One side allegedes &#x27;stonewalling&#x27; while the agency maintains the delay is due to the document&#x27;s extreme classification and complex legal hurdles.<p>Regarding the merits of the case: a representative for the Intelligence Community Inspector General stated that specific allegations against Gabbard were determined to be, &quot;not credible.&quot; However, the whistleblower\u2019s attorney disputes any official credibility determination was ever reached, leaving the status of the complaint in limbo. That said, there&#x27;s absolutely no reason that this should not be shared w&#x2F;Congress in compliance with the norms for this sort of whistleblower complaint.<p>e: typo of limb -&gt; limbo", "author": "garciasn", "timestamp": "2026-02-02T15:57:15+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-02T17:30:13.567261+00:00", "processed": false}
{"id": "hn_comment_46857073", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46857073", "title": "Re: Show HN: File Markers \u2013 Track file status directly...", "text": "Hey HN! Built this on a Saturday to scratch my own itch.<p>I&#x27;m doing a backend codebase migration and kept losing track of which files I&#x27;d reviewed and ported. Tried spreadsheets (got stale), comments like &#x2F;&#x2F; MIGRATED (clutters code), and deleting finished files (TypeScript screamed at me with 200+ errors. Did I keep doing it anyway? Yes.).<p>I just wanted to look at the file tree and see what&#x27;s done.<p>So I built this. Right-click a file, mark it as Done&#x2F;In Progress&#x2F;Pending&#x2F;etc., badge shows up in the Explorer. Comes with 6 built-in markers but you can define your own. Markers persist in .vscode&#x2F;file-markers.json for team sharing or gitignore it for personal use.<p>Vibe coded the whole thing with Claude in one sitting.<p>Feedback and PRs welcome!", "author": "joneldominic", "timestamp": "2026-02-02T15:26:14+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:15.194546+00:00", "processed": false}
{"id": "hn_story_46856941", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46856941", "title": "Show HN: A different approach to intonation training", "text": "Hi guys;\nOver the weekend I&#x27;ve created this using Claude Code. It&#x27;s an ear training app destined to teach intonation and intervals to not so talented musicians like me. I spend many year playing guitar without a clear feeling on what intonation really was. It was after some string tuning exercises that it clicked for me. The freq sliding into the right place and feeling the correctness. I hope this app can helps other to feel that for the first time, or to increase the recognition of less common intervals. Any feedback is appreciated.", "author": "ogig", "timestamp": "2026-02-02T15:16:00+00:00", "score": 4, "num_comments": 1, "products": ["claude"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2026-02-02T17:30:15.388047+00:00", "processed": false}
{"id": "hn_story_46856676", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46856676", "title": "Show HN: Open Deep Research that beat Big Tech now self-verifies claims", "text": "Last week I benchmarked my open-source Deep Research tool against ChatGPT, Perplexity, and Gemini. I caught OpenAI fabricating 4-5 citations that don&#x27;t exist. Gemini reduced real hazard ratios by 30-40%.<p>So I built ASK Mode: every answer gets automatically verified against a second round of sources. Each claim marked [OK], [??], or [NO].<p>- ~400 verified answers for $1\n- 2-3 minutes per query\n- No RLHF nannying - it answers what you ask\n- Full verification report with every response<p>The gap between chat (unverified, stale training data) and deep research (20+ minutes) needed filling.<p>Benchmark proof: <a href=\"https:&#x2F;&#x2F;veritas--test-neocities-org.translate.goog&#x2F;?_x_tr_sl=de&amp;_x_tr_tl=en&amp;_x_tr_hl=de&amp;_x_tr_pto=wapp\" rel=\"nofollow\">https:&#x2F;&#x2F;veritas--test-neocities-org.translate.goog&#x2F;?_x_tr_sl...</a>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;IamLumae&#x2F;Project-Lutum-Veritas\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;IamLumae&#x2F;Project-Lutum-Veritas</a>", "author": "LutumVeritas", "timestamp": "2026-02-02T14:51:35+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt", "gemini", "perplexity"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:17.527347+00:00", "processed": false}
{"id": "hn_story_46856457", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46856457", "title": "Show HN: Vibe code on your mobile device", "text": "I vibed code a package to help you vibe code on your mobile device - so that you don&#x27;t have to. It&#x27;s tunnel claude&#x2F;cursor&#x27;s using ngrok&#x2F;cloudflared and you could access it using a web interface. Has password protection. Please feel free to use&#x2F;hack it. Thanks", "author": "wakandan", "timestamp": "2026-02-02T14:31:06+00:00", "score": 1, "num_comments": 0, "products": ["claude", "grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:19.700750+00:00", "processed": false}
{"id": "hn_comment_46856259", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46856259", "title": "Re: Show HN: Weather Haiku \u2013 AI-generated poetry for a...", "text": "Some notes on trying to get AI to write poetry:<p>Haiku has a strict 5-7-5 syllable structure. I had to make the AI respect that, but also be creative with the vocabulary. Setting the &quot;temperature&quot; setting to the max made for the most interesting poems, but also made the AI go off the rails from the haiku rules. The larger models like Gemini 3, and the &quot;thinking&quot; models, made much more varied poetry, but too way too long to generate the text, making them useless from a UX perspective.<p>As I&#x27;ve understood it, LLMs are probability and pattern matching engines. This is the worst for poetry! Usually we want unexpected metaphors and emotional contrast in poetic language. I think there is still a lot of experimentation to be made, but it&#x27;s also very hard to evaluate poetry. What is &quot;quality&quot; when it comes to haiku?", "author": "minor_drizzle", "timestamp": "2026-02-02T14:13:56+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:21.348925+00:00", "processed": false}
{"id": "hn_story_46855857", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46855857", "title": "Show HN: SlideBot AI \u2013 AI presentation generator built from real business needs", "text": "Hi HN,<p>I built SlideBot AI \u2014 an open-source AI-powered presentation generator that creates professional slides from natural language input.<p>Why I built this:<p>At my company, we spend hours every week creating presentation decks. The existing AI tools either generate generic-looking slides or require too much manual tweaking. I wanted something that:<p>1. Takes a topic&#x2F;outline and generates a complete presentation\n2. Lets you iterate through natural conversation (&quot;make slide 3 more concise&quot;, &quot;add a risk section&quot;)\n3. Supports voice input \u2014 upload a meeting recording and it extracts key points automatically\n4. Maintains consistent brand styling across all slides<p>How it works:<p>- Input your idea (text, outline, or audio recording)\n- AI generates an outline \u2192 you refine it through conversation\n- AI creates a design scheme \u2192 you refine it through conversation  \n- AI generates each slide as a high-quality image\n- Download as a ZIP package<p>Tech stack: React + FastAPI + Google Gemini API<p>What makes it different from other AI slide tools:<p>- Fully open-source (MIT license)\n- Conversational iteration at every step \u2014 not just one-shot generation\n- Voice-to-slides pipeline (meeting recording \u2192 presentation)\n- Born from actual daily business use, not a hackathon project<p>This started as an internal tool and has been used in production for several weeks. The iterative refinement workflow was the key insight \u2014 the first draft is never perfect, but being able to say &quot;add more data to slide 5&quot; or &quot;make the conclusion stronger&quot; makes a huge difference.<p>Would love to hear your feedback. What features would make this more useful for your workflow?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;tonyqinatcmu&#x2F;SlideBot-AI&#x2F;blob&#x2F;main&#x2F;README_EN.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tonyqinatcmu&#x2F;SlideBot-AI&#x2F;blob&#x2F;main&#x2F;README...</a>", "author": "tonyqinatcmu", "timestamp": "2026-02-02T13:33:36+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:23.356000+00:00", "processed": false}
{"id": "hn_story_46855770", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46855770", "title": "Show HN: Nucleus \u2013 enforced permission envelopes for AI agents (Firecracker)", "text": "I\u2019ve been building Nucleus because most \u201cagent security\u201d is still policy-only: a config file that says \u201cdon\u2019t do bad things,\u201d while the agent can still do them.<p>Nucleus is an OSS experiment that pairs a small, compositional permission model with runtime enforcement: *side effects are only reachable through an enforcing tool proxy*, inside a Firecracker microVM. The envelope is *non-escalating*: it can only tighten or terminate, never silently relax.<p>What works today:<p>* MCP tool proxy with *read &#x2F; write &#x2F; run* (enforced inside the microVM)\n* default-deny egress + DNS allowlist + iptables drift detection (fail-closed) on Linux\n* time + budget caps enforced\n* hash-chained audit log + HMAC approval tokens (scoped, expiring) for gated ops<p>What\u2019s missing (being upfront):<p>* web&#x2F;search tools exist in the model but aren\u2019t wired to MCP yet\n* remote append-only audit storage + attestation are still roadmap\n* early&#x2F;rough; targeting \u201csafe to run against sensitive codebases,\u201d not \u201creplace your local terminal\u201d<p>Most of the code was written with Anthropic tools; I\u2019ve been leaning on tests&#x2F;fuzzing&#x2F;proptests to keep it honest.<p>Would love feedback on: (1) dangerous capability combinations beyond the lethal trifecta, (2) what enforcement gaps you\u2019d want closed first, (3) how you\u2019d evaluate this vs gateway-only approaches.", "author": "difc", "timestamp": "2026-02-02T13:25:50+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:24.011674+00:00", "processed": false}
{"id": "hn_story_46855698", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46855698", "title": "Show HN: Make AI motion videos with text", "text": "Saw the remotion claude skills launch earlier, and honestly even though I was surprised how decent some of the results turned out to be I ended up never trying it out with claude code because I knew I&#x27;d have to setup remotion, bundler etc and if I was already doing it once I thought I might as well turn it into a site where anyone could just write messages and get a video without any prerequisites.<p>I also know Claude Code is not something everyone has and setting up remotion is a pain. And one of the biggest lessons I learned from this whole experience is that Opus is actually not that good at design tasks even with the skills, Gemini is what I&#x27;m using for Framecall and even Flash(Fast Mode) produces sometimes better results than Opus, crazy considering the cost difference.<p>Some other things I learned is that motion videos have the same &quot;problem&quot; as writing good code or using claude code as a vibe-coder vs someone who knows the framework they&#x27;re working with. If you just say &quot;Make a nice video about X&quot; its usually a gamble if the end result will be good, same as if you say &quot;Make me x application&quot; with claude code. You need to have a good eye for design and some terminology to know what exactly it is you want to achieve.<p>K2.5, ZLM and most of the open source models were pretty bad at making videos even with the skills so I ended up not adding them as an option.<p>The pricing is there because turns out having 2-5k+ tokens of code output for every animation + 1-2k of tokens for the remotion skills as input is kinda expensive. Would&#x27;ve loved to offer this as just a free product since I made it for fun anyways but oh well.", "author": "mesmertech", "timestamp": "2026-02-02T13:18:14+00:00", "score": 4, "num_comments": 2, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:24.488850+00:00", "processed": false}
{"id": "hn_story_46855664", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46855664", "title": "Show HN: Oh-my-ag. Role-based agent orchestration for Antigravity", "text": "Hi HN,<p>I\u2019ve been using CLI-based agents in real-world full-stack projects, and I kept hitting the same wall: the &quot;long-prompt fragility.&quot; As tasks get complex, agents start ignoring system rules, looping on trivial errors, or losing context mid-workflow.<p>Most people treat these as &quot;model issues,&quot; but I started seeing them as orchestration issues. Instead of cramming every instruction into one massive prompt and hoping the model keeps it all in head, I built oh-my-ag. It\u2019s an orchestration layer for Antigravity that enforces a structural collaboration between specialized agents.<p>The Core Idea: Process over Prompting\nRather than a single &quot;god-agent,&quot; oh-my-ag breaks down the workflow into explicit roles:<p>PM: Handles requirement decomposition and tasking.<p>Dev (FE&#x2F;BE&#x2F;Mobile): Implementation within a strictly scoped domain.<p>QA &amp; Debug: One validates the requirements while the other analyzes failures.<p>Key Technical Features:\nShared Memory (Serena): A persistence layer that keeps decisions and intermediate states consistent, even if you switch models mid-session.<p>Reduced Volatility: By splitting responsibilities, a minor model hallucination in implementation doesn&#x27;t derail the entire PM-level task logic.<p>Parallel Execution: The orchestrator can trigger sub-agents simultaneously where appropriate.<p>Tooling: Built-in support for Gemini&#x2F;Claude&#x2F;Codex CLIs and MCP-scoped tool access.<p>You can try it with a single command: bunx oh-my-ag<p>It\u2019s currently being used in production-level iterations for full-stack web and mobile projects (specifically those built on fullstack-starter). I&#x27;d love to hear your thoughts on how you&#x27;re handling agentic &quot;drift&quot; in your own workflows.", "author": "otti-sister", "timestamp": "2026-02-02T13:14:11+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:24.873830+00:00", "processed": false}
{"id": "hn_comment_46855492", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46855492", "title": "Re: In my Google Calendar, every event is an AI task...", "text": "I use a dedicated Google Calendar to schedule recurring AI tasks for our marketing. Every event is a prompt. At the scheduled time, a Python bot picks \nit up, runs it through Claude with MCP tools (web scraping, search, \nanalytics APIs), and saves results back to the event notes.<p>Recurring events use previous notes as context, so weekly reports  build on each other.<p>Currently running: daily competitor monitoring, sales lead generation, citation gap analysis, newsletter drafts, and article generation.<p>No new interface to learn. Just calendar events.<p>&quot;Generic&quot; (non-marketing) code example: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ihmissuti&#x2F;google-calendar-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ihmissuti&#x2F;google-calendar-agent</a>", "author": "ihmissuti", "timestamp": "2026-02-02T12:54:55+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:27.052943+00:00", "processed": false}
{"id": "hn_comment_46857117", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46857117", "title": "Re: Claude Code is suddenly everywhere inside Microsof...", "text": "Microsoft really needs to get a better handle with the naming conventions.<p>There is Microsoft Copilot, which replaced Bing Chat, Cortana and uses OpenAI\u2019s GPT-4 and 5 models.<p>There is Github Copilot, the coding autocomplete tool.<p>There is Microsoft 365 Copilot, what they now call Office with built in GenAI stuff.<p>There is also a Copilot cli that lets you use whatever agent&#x2F;model backend you want too?<p>Everything is Copilot. Laptops sell with Copilot buttons now.<p>It is not immediately clear what version of Copilot someone is talking about. 99% of my experience is with the Office and it 100% fails to do the thing it was advertised to do 2 years ago when work initially got the subscription. Point it a SharePoint&#x2F;OneDrive location, a handful of excel spreadsheets and pdfs&#x2F;word docs and tell it to make a PowerPoint presentation based on that information.<p>It cannot do this. It will spit out nonsense. You have to hold it by the hand tell it everything to do step by step to the point that making the PowerPoint presentation yourself is significantly faster because you don\u2019t have to type out a bunch of prompts and edit it\u2019s garbage output.<p>And now it\u2019s clear they aren\u2019t even dogfooding their own LLM products so why should anyone pay for Copilot?", "author": "kemotep", "timestamp": "2026-02-02T15:31:05+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:31.444115+00:00", "processed": false}
{"id": "hn_comment_46858354", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46858354", "title": "Re: Claude Code is suddenly everywhere inside Microsof...", "text": "To this day I cannot wrap my head around the fact why did Microsoft allow a culture to grow inside the company (either through hiring, or through despondence) that at best is indifferent towards the company&#x27;s products and at worst openly despises them?<p>I&#x27;m sure no other tech company is like this.<p>I think technologies like the Windows kernel and OS, the .NET framework, their numerous attempts to build a modern desktop UI framework with XAML, their dev tools, were fundamentally good at some point.<p>Yet they cant or wont hire people who would fix Windows, rather than just maintain it, really push for modernization, make .NET actually cool and something people want to use.<p>They&#x27;d rather hire folks who were taught at school that Microsoft is the devil and Linux is superior in all ways, who don&#x27;t know the first thing about the MS tech stack, and would rather write React on the Macbooks (see the start menu incident), rather than touch anything made by Microsoft.<p>It seems somehow the internal culture allows this. I&#x27;m sure if you forced devs to use Copilot, and provided them with the tools and organizational mandate to do so, it would become good enough eventually to not have to force people to use it.<p>My main complaint I keep hearing about Azure (which I do not use at workr)", "author": "torginus", "timestamp": "2026-02-02T17:08:14+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-02T17:30:31.742445+00:00", "processed": false}
{"id": "hn_story_46854851", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46854851", "title": "Ask HN: How do you give AI enough Java-specific context before code generation?", "text": "I\u2019ve been writing Java for 25+ years (mostly enterprise; created pf4j and pippo).<p>When using AI for code generation, I kept seeing the same issues:\nN+1 queries, poor exception handling, Spring pitfalls, and concurrency problems.\nThe output is often almost right, but misses language-specific details.<p>Instead of iterating prompts, I experimented with pre-loading the model\nwith Java-specific guidelines (JPA, Spring, testing, security) as plain\nmarkdown files, so it has domain context upfront.<p>Curious how others handle language-specific context for code generation tools.<p>Repo:\nhttps:&#x2F;&#x2F;github.com&#x2F;decebals&#x2F;claude-code-java", "author": "decebals", "timestamp": "2026-02-02T11:39:33+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:35.603993+00:00", "processed": false}
{"id": "hn_story_46854807", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46854807", "title": "Show HN: Prompt-injection firewall for OpenClaw agents", "text": "People seem to be blindly hooking up their OpenClaw\u2019s to their personal data. So, I built runtime controls to prevent at the least, very simple prompt injection attacks.<p>Once installed, it hooks to Node.js child_process module in the gateway process and listens to tool calls and their response streams. And a fetch hook to monitor user prompts (<i>both could\u2019ve been through fetch, happy to discuss why this whole layer couldn\u2019t just be a proxy</i>).<p>There are two layers of protection:<p><i>First:</i> Whenever there is a read-only tool call whose response an attacker can modify, we extract that part of the json response and send it to a small haiku model to check if it has instruction asking the LLM to do something different<p><i>Second:</i> For when the prompt injection detection fails, we maintain a list of function calls which can write to places that an external actor can access. We prompt the user for explicit permission to go forward through the UI.<p>I would love a discussion on how this second layer could be made better and less frequent by relying on some decision process. My current idea:\nBased on a collected set of \u201ctrusted\u201d context (user prompts, responses from tool calls attackers cannot manipulate), can we detect if this tool call was necessary. There are scenarios where you\u2019d need detection at the parameter-level.<p>Two notes:<p>1) This cannot just be a proxy because you need application level integration to have humans in the loop when needed and push UI controls.<p>2) How i improved accuracy of detecting prompt injection is by selecting only that content from the entire response json that can be manipulated by an external actor. This had to be done for each tool separately. The current implementation is for 2 skills I randomly chose (Notion &amp; Github).<p>P.S.: I maintain one for claude code myself while working: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ContextFort-AI&#x2F;Runtime-Controls\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ContextFort-AI&#x2F;Runtime-Controls</a>, I created this over the weekend OpenClaw", "author": "ashwinr2002", "timestamp": "2026-02-02T11:33:04+00:00", "score": 5, "num_comments": 3, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-02T17:30:35.880928+00:00", "processed": false}
{"id": "hn_comment_46854482", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46854482", "title": "Re: Show HN: Design In The Browser \u2013 Point, click, and...", "text": "Hey everyone, I\u2019m Peter a designer and developer. I made this new tool i call Design In The Browser. I built this because I kept running into the same problem: explaining visual changes. I\u2019d end up constantly taking screenshots, copying them into the terminal, and writing long prompts describing which element, where it is, what to change, then repeating when the AI guessed wrong, when all I really wanted to do was point at it.<p>Design In The Browser lets you click any element on your page and send it directly to Claude Code, Cursor, or Gemini CLI with full context. The AI knows exactly what you\u2019re looking at, so you skip the back-and-forth. It also has an integrated terminal, viewport switcher for responsive testing. A cool thing is that you can also queue prompts while Claude Code is working and batch multiple edits.<p>It\u2019s macOS only for now, free to use, and works with any local dev server. Would love feedback, especially on what features you\u2019d want next.", "author": "curlii", "timestamp": "2026-02-02T10:37:02+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-02T17:30:39.714092+00:00", "processed": false}
