{"id": "hn_comment_46924608", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46924608", "title": "Re: Open-source Claude skill that optimizes Hinge prof...", "text": "I wanted to build something that actually helps people fix their dating profiles. Not tips. A proper process.\nI used Claude to run parallel research agents across the academic literature on dating app behavior \u2014 signaling theory, self-presentation, deception linguistics, mate selection economics. The agents pulled in findings from about 45 papers, and I sorted them into three tiers: peer-reviewed, platform data (Hinge&#x2F;OkCupid&#x27;s own numbers), and conventional wisdom. The research doc in the repo is honest about which is which.\nSome findings that shaped the design:<p>Vague language is a linguistic marker of deception. People who lie in profiles use abstract, generic phrases. People who tell the truth use concrete, specific language. (Toma &amp; Hancock, 2012, Journal of Communication)\nDesirability on dating apps follows a power law. The top profiles get 10-100x the attention of the median. You cannot out-volume this curve. (Bruch &amp; Newman, 2018, Science Advances)\n&quot;I have a great sense of humor&quot; is what signaling theory calls a cheap signal \u2014 anyone can say it. Actually being funny in your prompt is a costly signal \u2014 you need the ability. Costly signals are processed as more credible. (Donath, 2007, building on Zahavi&#x27;s handicap principle)\nCreative, original profile text independently predicted attractiveness ratings beyond photos. (Fiore et al., 2008, CHI)<p>The skill itself runs as an 8-phase process: audit, discovery interview, reality check, photo strategy, copy, settings, implementation, algorithm strategy. The discovery interview is the core \u2014 about 40 structured questions designed to surface specific, hard-to-fake material, then that material gets written into prompts using the signaling framework.\nIt works well within Claude&#x27;s constraints. The skill format turns out to be a good fit for this kind of structured, consultative process \u2014 the conversation architecture maps naturally to an interview that builds on itself.\nMIT licensed. The full research document with citations and evidence tiers is in the repo.\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;b1rdmania&#x2F;hinge-profile-optimizer\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;b1rdmania&#x2F;hinge-profile-optimizer</a>", "author": "birdmania", "timestamp": "2026-02-07T15:27:55+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-07T17:17:31.047159+00:00", "processed": false}
{"id": "hn_comment_46923822", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46923822", "title": "Re: AI Skills Marketplace...", "text": "Hey HN, I created Skly, a marketplace for buying and selling AI skills like prompts, workflows, and system instructions for tools such as Claude, ChatGPT, and Cursor.<p>I got the idea after realizing I was spending hours trying to craft effective prompts. I thought others must be facing the same issue. Why not let people sell what they&#x27;ve created and help others avoid the trial and error?<p>I would appreciate any feedback on the concept and the product.", "author": "briannezhad", "timestamp": "2026-02-07T13:45:33+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:34.693140+00:00", "processed": false}
{"id": "hn_story_46923706", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46923706", "title": "Show HN: CCBot \u2013 Control Claude Code from Telegram via tmux", "text": "", "author": "sixddc", "timestamp": "2026-02-07T13:30:33+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:35.487146+00:00", "processed": false}
{"id": "hn_comment_46923707", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46923707", "title": "Re: Show HN: CCBot \u2013 Control Claude Code from Telegram...", "text": "I built a Telegram bot that lets you monitor and interact with Claude Code sessions running in tmux on your machine.<p>The problem: Claude Code runs in the terminal. When you step away from your computer, the session keeps working but you lose visibility and control.<p>CCBot connects Telegram to your tmux session \u2014 it reads Claude&#x27;s output and sends keystrokes back. This means you can switch from desktop to phone mid-conversation, then tmux attach when you&#x27;re back with full\ncontext intact. No separate API session, no lost state.<p>How it works:<p>- Each Telegram topic maps 1:1 to a tmux window and Claude session\n- Real-time notifications for responses, thinking, tool use, and command output\n- Interactive inline keyboards for permission prompts, plan approvals, and multi-choice questions\n- Create&#x2F;kill sessions directly from Telegram via a directory browser\n- Message history with pagination\n- A SessionStart hook auto-tracks which Claude session is in which tmux window<p>The key design choice was operating on tmux rather than the Claude Code SDK. Most Telegram bots for Claude Code create isolated API sessions you can&#x27;t resume in your terminal. CCBot is just a thin layer over tmux\n  \u2014 the terminal stays the source of truth.<p>CCBot was built using itself: iterating on the code through Claude Code sessions monitored and driven from Telegram.", "author": "sixddc", "timestamp": "2026-02-07T13:30:33+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-07T17:17:35.513259+00:00", "processed": false}
{"id": "hn_comment_46922690", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46922690", "title": "Re: Show HN: MicroClaw \u2013 Agentic AI Assistant for Tele...", "text": "Hi HN,<p>I mostly vibe-built MicroClaw \u2014 a Telegram bot that turns a chat into an agent-style AI assistant.<p>The idea came from nanoclaw, a TypeScript&#x2F;WhatsApp agentic assistant. I liked the concept but wanted something small, hackable, and easy to self-host, so I rewrote it in Rust and used Telegram as the interface.<p>At its core, it runs a full agent loop: Claude can call tools (bash, file ops, web search, etc.), inspect results, and keep iterating until the task is done (up to 25 tool calls per message).<p>Some design choices I\u2019m particularly happy with:\n- Sessions are fully resumable, with complete tool history persisted in SQLite\n- Long-running sessions auto-compact context by summarizing old messages\n- An agent skills system (compatible with Anthropic\u2019s Skills spec) for specialized tasks like PDF&#x2F;DOCX&#x2F;XLSX generation\n- Explicit plan-and-execute flow with todo tracking for multi-step tasks\n- Natural-language scheduled tasks<p>It\u2019s built in Rust with Tokio, teloxide, and direct Anthropic API calls (no SDK wrapper). It\u2019s a single binary, configured with three env vars, and that\u2019s it.<p>Fair warning: this is still a toy &#x2F; experimental project. There\u2019s no sandboxing, permission model, or security hardening \u2014 the agent has full access to bash and the filesystem. Please don\u2019t run it on anything you care about without understanding the risks.<p>Contributions, feedback, and criticism are very welcome.", "author": "everettjf", "timestamp": "2026-02-07T10:12:59+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-07T17:17:40.624191+00:00", "processed": false}
{"id": "hn_story_46922422", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46922422", "title": "Show HN: Crew \u2013 Multi-agent orchestration tool for AI-assisted development", "text": "I built Crew to help manage multiple AI agents working on the same codebase.<p>It has two modes:<p>1. Design mode: Automated Writer \u21c4 Reviewer loops to refine ideas into polished design docs<p>2. Crew mode: Run parallel AI agents (QA, DEV, JANITOR) for continuous code improvement<p>It&#x27;s written in Bash and works with Claude CLI, OpenAI&#x27;s opencode, or Google&#x27;s Gemini.<p>Would love feedback from the HN community!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;garnetliu&#x2F;crew\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;garnetliu&#x2F;crew</a>", "author": "gl2334", "timestamp": "2026-02-07T09:02:43+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:42.716644+00:00", "processed": false}
{"id": "hn_comment_46922639", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46922639", "title": "Re: AI will not save developer productivity...", "text": "This resonates with me for a couple of reasons. One is that despite a good AGENTS.md file and a detailed, specific prompt, I&#x27;ve seen LLM agents generate all sorts of questionable code. From making a mistake, running tests and fixing the mistake meanwhile adding a comment which only makes sense when you read it from the perspective of having seen it make that mistake... As soon as anyone else would read it, there is no context and it can be confusing or misleading...<p>Or naming tests only considering the specific task at hand, which is meaningless when compared to the grand scheme of things.<p>Yesterday I had GitHub ask me to complete a survey on it&#x27;s Copilot coding agent, and it made me realize that some obvious things were missing from my AGENTS.md. Notes that are unnecessary to be written &quot;normally&quot; because it aligns naturally with how human programmers work. When writing a new unit test in a file full of unit tests, I typically copy an existing test which has roughly what I need, paste it and adapt it. Or at least look at existing tests when building a new one. I&#x27;ve seen LLM agents ignore private helper methods and do full integration style tests for new test cases because they don&#x27;t work like that unless specifically instructed...<p>So yes, I definitely feel that AI can increase tech debt big time unless managed carefully - paved roads are the way to go for human developers and AI agents. It does get tricky when you need to branch out and do something new or never considered before though...", "author": "indentit", "timestamp": "2026-02-07T10:00:05+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["content_clarity"], "sentiment": null, "collected_at": "2026-02-07T17:17:43.320676+00:00", "processed": false}
{"id": "hn_comment_46922237", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46922237", "title": "Re: Show HN: Ensemble \u2013 macOS App to Manage Claude Cod...", "text": "Made a thing for fellow Claude Code users.<p>Once you have a few dozen Skills, a handful of MCP servers, and CLAUDE.md files scattered across projects, managing them through ~&#x2F;.claude.json and manual file editing gets old fast.<p>Ensemble is a macOS desktop app that gives you a UI for all of it:<p>- Import and organize Skills, MCPs, and CLAUDE.md files with categories and tags\n- Bundle them into &quot;Scenes&quot; -- reusable config presets for different workflows\n- One-click deploy to any project folder (symlinks for Skills, .mcp.json for MCPs)\n- Finder right-click integration -- &quot;Open with Ensemble&quot; on any folder, syncs config and launches Claude Code in your terminal\n- AI-powered auto-classification if you&#x27;re lazy about organizing (I am)<p>Designed in Pencil.dev, coded with Claude Code, built with Tauri 2 (Rust backend, React frontend). Native macOS window, no Electron.<p>Open source, MIT licensed, free forever.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;O0000-code&#x2F;Ensemble\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;O0000-code&#x2F;Ensemble</a><p>Would love feedback -- especially from people who have accumulated enough Skills&#x2F;MCPs that managing them has become its own problem.", "author": "IO0oI", "timestamp": "2026-02-07T08:19:19+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-07T17:17:43.512324+00:00", "processed": false}
{"id": "hn_story_46922159", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46922159", "title": "Show HN: GTM MCP Server- Let AI Manage Your Google Tag Manager Containers", "text": "I built an MCP server that connects Claude and ChatGPT to the Google Tag Manager API. You can create\n   tags, triggers, variables, audit containers, and publish changes through natural conversation.<p><pre><code>  Try it now (no install needed):\n  - Claude.ai: Settings \u2192 Connectors \u2192 Add https:&#x2F;&#x2F;mcp.gtmeditor.com\n  - Claude Code: claude mcp add -t http gtm https:&#x2F;&#x2F;mcp.gtmeditor.com\n  - ChatGPT: Add MCP integration at platform.openai.com&#x2F;apps with URL https:&#x2F;&#x2F;mcp.gtmeditor.com\n\n  It authenticates with your Google account via OAuth 2.1, so your credentials are never stored on the\n   server.\n\n  What you can do:\n  - &quot;Create a GA4 event tag for form submissions&quot;\n  - &quot;Audit this container for issues and duplicates&quot;\n  - &quot;Set up ecommerce tracking for purchases&quot;\n  - &quot;Publish the changes we just made&quot;\n\n  It supports all GTM entity types including server-side containers (clients, transformations). There\n  are 40+ tools covering full CRUD, versioning, publishing, built-in variable management, and\n  Community Template Gallery imports.\n\n  Some things I learned building this:\n\n  Google&#x27;s API has undocumented behaviors that took a while to figure out. Transformation types\n  (tf_allow_params, tf_exclude_params, tf_augment_event) aren&#x27;t documented anywhere \u2014 I discovered\n  them through trial and error. Each type uses different parameter table keys, and passing an unknown\n  type returns HTTP 500 instead of 400. The autoEventFilter field on click&#x2F;form triggers is silently\n  dropped by the API (returns 200 OK but doesn&#x27;t persist).\n\n  I also built a companion repo with LLM-optimized GTM API documentation\n  (https:&#x2F;&#x2F;github.com&#x2F;paolobietolini&#x2F;gtm-api-for-llms) \u2014 structured as an installable skill for Claude\n   Code and Codex, so the AI knows the correct parameter formats, validation rules, and workflow\n  patterns.\n\n  Built with Go, deployed as a single Docker container. The MCP protocol makes it work across Claude\n  and ChatGPT without any client-specific code.\n\n &#x2F;s Thank you for your attention to this matter</code></pre>", "author": "paolobietolini", "timestamp": "2026-02-07T08:01:42+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:43.806629+00:00", "processed": false}
{"id": "hn_comment_46921360", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46921360", "title": "Re: Forcing Rust: How Big Tech Lobbied the Government ...", "text": "Getting some strong ChatGPT vibes from the overall sectioning and some stylistic flags, e.g. the &quot;This isn&#x27;t X, it&#x27;s Y&quot; meme appears many times as an intro to paragraphs or sections, e.g. &quot;This isn\u2019t a conspiracy. It\u2019s something more mundane and more durable: structural incentive alignment&quot;. There are lots of (spaced) em-dashes, and the overall rhythm, tone, and length of things is very ChatGPT.<p>The way the references are sort of lazily clustered also to me strongly looks like they could have been pasted from a ChatGPT Extended Thinking sidebar: if you were doing this kind of research organically, you&#x27;d just more clearly be able to link your references to each clause that is is relevant, with appropriate enumeration. I would bet with about 90% certainty that this was mostly done via ChatGPT with Extended Thinking.<p>There is also not much discussion and&#x2F;or consideration that, well, perhaps Rust is being adopted because it actually does provide strong guarantees in combination with things like being modern, having cargo, being fast, and etc. bla bla bla. The proposed alternatives of ADA, modern C++, and hardware optimization just feel laughably out of touch.<p>It&#x27;s a weak post overall, but I do really appreciate the documentation of some of the financial ties involved in supporting &#x2F; boosting Rust.", "author": "D-Machine", "timestamp": "2026-02-07T04:42:34+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-07T17:17:51.018280+00:00", "processed": false}
{"id": "hn_comment_46921129", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46921129", "title": "Re: Hello world does not compile...", "text": "The anti-AI crowd proves that they do need replacing as programmers since it was user error. Opus 4.6&#x2F;ChatGPT 5.3 xhigh is superior to the vast majority of programmers. Talk about grasping for straws.", "author": "Der_Einzige", "timestamp": "2026-02-07T03:47:38+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:51.733332+00:00", "processed": false}
{"id": "hn_story_46920069", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46920069", "title": "Show HN: LLM-use \u2013 Open-source tool to route and orchestrate multi-LLM tasks", "text": "I built llm\u2011use, an open\u2011source Python framework for orchestrating large language model workflows across local and cloud models with smart routing, cost tracking, session logs, optional web scraping, and optional MCP integration. It\u2019s designed for agent workflows (planner + workers + synthesis) that leverage multiple LLMs without manual switching or custom glue code.<p>Examples<p>Simple local usage:<p>ollama pull llama3.1:70b  \nollama pull llama3.1:8b<p>python3 cli.py exec \\\n  --orchestrator ollama:llama3.1:70b \\\n  --worker ollama:llama3.1:8b \\\n  --task &quot;Summarize 10 news articles&quot;<p>This runs a planner + worker flow fully locally.<p>Hybrid cloud + local usage:<p>export ANTHROPIC_API_KEY=&quot;sk-ant\u2011...&quot;  \nollama pull llama3.1:8b<p>python3 cli.py exec \\\n  --orchestrator anthropic:claude-3-7-sonnet-20250219 \\\n  --worker ollama:llama3.1:8b \\\n  --task &quot;Compare 5 products&quot;<p>export ANTHROPIC_API_KEY=&quot;sk-ant\u2011...&quot;  \nollama pull llama3.1:8b<p>python3 cli.py exec \\\n  --orchestrator anthropic:claude-3-7-sonnet-20250219 \\\n  --worker ollama:llama3.1:8b \\\n  --task &quot;Compare 5 products&quot;<p>Routes tasks between cloud provider models and a local worker.<p>TUI chat mode:<p>python3 cli.py chat \\\n  --orchestrator anthropic:claude-3 \\\n  --worker ollama:llama3.1:8b<p>Interactive CLI chat with live logs and cost breakdown.<p>Why it matters\n \u2022 Orchestrate multiple LLMs \u2014 OpenAI, Anthropic, Ollama&#x2F;llama.cpp \u2014 without writing custom routing logic.   \n \u2022 Smart routing and fallback \u2014 choose better models for each task and fall back heuristically or learned over time.   \n \u2022 Cost tracking &amp; session logs \u2014 see costs per run and preserve history locally.   \n \u2022 Optional scraping + caching \u2014 enrich tasks with real web data if needed.   \n \u2022 Optional MCP server integration \u2014 serve llm\u2011use workflows via PolyMCP.<p>llm\u2011use makes it easier to build robust, multi\u2011model LLM systems without being tied to a single API or manual orchestration.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;llm\u2011use&#x2F;llm\u2011use\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;llm\u2011use&#x2F;llm\u2011use</a>", "author": "justvugg", "timestamp": "2026-02-07T00:36:18+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-07T17:17:55.847818+00:00", "processed": false}
