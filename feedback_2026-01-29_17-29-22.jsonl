{"id": "hn_story_46812347", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46812347", "title": "Show HN: A skill that lets AI agents build hooks apps across 4 coding tools", "text": "Hi HN,<p>I kept writing the same hooks for different AI coding tools with slightly different configs:<p>- Claude Code: ~&#x2F;.claude&#x2F;settings.json (PreToolUse)<p>- Cursor: ~&#x2F;.cursor&#x2F;hooks.json (beforeShellExecution)<p>- Gemini CLI: ~&#x2F;.gemini&#x2F;settings.json (BeforeTool)<p>- OpenCode: ES module plugins<p>So I made a skill that unifies them. One hook script works across all 4 tools.<p>It also includes patterns for common use cases: blocking dangerous commands, auto-formatting, notifications, audit logging.<p>Built two apps using Claude Code + this skill:<p>- Code Buddy (SwiftUI): menu bar status for AI sessions<p>- Veto (Rust): risk scoring + Touch ID before dangerous commands<p>Source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;runkids&#x2F;ai-hooks-integration\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;runkids&#x2F;ai-hooks-integration</a><p>Feedback welcome.", "author": "runkids", "timestamp": "2026-01-29T16:23:26+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-29T17:29:28.689661+00:00", "processed": false}
{"id": "hn_story_46811701", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811701", "title": "Show HN: Craft \u2013 Claude Code running on a VM with all your workplace docs", "text": "I\u2019ve found coding agents to be great at 1&#x2F; finding everything they need across large codebases using only bash commands (grep, glob, ls, etc.) and 2&#x2F; building new things based on their findings (duh).<p>What if, instead of a codebase, the files were all your workplace docs? There was a `Google_Drive` folder, a `Linear` folder, a `Slack` folder, and so on. Over the last week, we put together Craft to test this out.<p>It\u2019s an interface to a coding agent (OpenCode for model flexibility) running on a virtual machine with:\n1. your company&#x27;s complete knowledge base represented as directories&#x2F;files (kept in-sync)\n2. free reign to write and execute python&#x2F;javascript\n3. ability to create and render artifacts to the user<p>Demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Hvjn76YSIRY\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Hvjn76YSIRY</a> \nGithub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx&#x2F;blob&#x2F;main&#x2F;web&#x2F;src&#x2F;app&#x2F;craft&#x2F;README.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx&#x2F;blob&#x2F;main&#x2F;web&#x2F;src&#x2F;app&#x2F;c...</a><p>It turns out OpenCode does a very good job with docs. Workplace apps also have a natural structure (Slack channels about certain topics, Drive folders for teams, etc.). And since the full metadata of each document can be written to the file, the LLM can define arbitrarily complex filters. At scale, it can write and execute python to extract and filter (and even re-use the verified correct logic later).<p>Put another way, bash + a file system provides a much more flexible and powerful interface than traditional RAG or MCP, which today\u2019s smarter LLMs are able to take advantage of to great effect. This comes especially in handy for aggregation style questions that require considering thousands (or more) documents.<p>Naturally, it can also create artifacts that stay up to date based on your company docs. So if you wanted \u201ca dashboard to check realtime what % of outages were caused by each backend service\u201d or simply \u201cslides following XYZ format covering the topic I\u2019m presenting at next week\u2019s dev knowledge sharing session\u201d, it can do that too.<p>Craft (like the rest of Onyx) is open-source, so if you want to run it locally (or mess around with the implementation) you can.<p>Quickstart guide: <a href=\"https:&#x2F;&#x2F;docs.onyx.app&#x2F;deployment&#x2F;getting_started&#x2F;quickstart\">https:&#x2F;&#x2F;docs.onyx.app&#x2F;deployment&#x2F;getting_started&#x2F;quickstart</a>\nOr, you can try it on our cloud: <a href=\"https:&#x2F;&#x2F;cloud.onyx.app&#x2F;auth&#x2F;signup\">https:&#x2F;&#x2F;cloud.onyx.app&#x2F;auth&#x2F;signup</a> (all your data goes on an isolated sandbox).<p>Either way, we\u2019ve set up a \u201cdemo\u201d environment that you can play with while your data gets indexed. Really curious to hear what y\u2019all think!", "author": "Weves", "timestamp": "2026-01-29T15:45:28+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-29T17:29:33.316761+00:00", "processed": false}
{"id": "hn_story_46811648", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811648", "title": "Show HN: yo-claude \u2013 Start your Claude session early to avoid interruptions", "text": "Claude only starts the session timer for your next allowance when you send your first message after a period of no use.<p>It would be better for you if they started a new one when your current one expired so that there&#x27;s less time until you get your new allowance when you happen to start using it.<p>They might do this for UX reasons (the auto-restart looks weird), or they could be trying to get people to upgrade. Maybe both.<p>A solution I&#x27;ve found is to just say &quot;yo&quot; to Claude every 5 hours. This somewhat decreases the chance that a deep Claude session gets blocked.<p>yo-claude is an easy way to enable this. Feedback and bug reports welcome.", "author": "dsmurrell", "timestamp": "2026-01-29T15:41:19+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-29T17:29:33.557490+00:00", "processed": false}
{"id": "hn_comment_46813337", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46813337", "title": "Re: OTelBench: AI struggles with simple SRE tasks (Opu...", "text": "In my experience the approach matters a lot, I recently implemented Otel with Claude Code in a medium sized ~200k loc project:<p>- initially it wasn&#x27;t working, plenty of parent&#x2F;child relationships problems like described in the post<p>- so I designed a thin a wrapper and used sealed classes for events instead of dynamic spans + some light documentation<p>It took me like a day to implement tracing on the existing codebase, and for new features it works out of the box using the documentation.<p>At the end of the day, leveraging typing + documentation dramatically constrains LLMs to do a better job", "author": "derfurth", "timestamp": "2026-01-29T17:27:31+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-29T17:29:34.054659+00:00", "processed": false}
{"id": "hn_story_46811481", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811481", "title": "Tmux for Claude Code but accessible from web browser and mobile", "text": "", "author": "Datkiri", "timestamp": "2026-01-29T15:29:11+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-29T17:29:34.908436+00:00", "processed": false}
{"id": "hn_comment_46811065", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811065", "title": "Re: Show HN: AsciiKit \u2013 a shared visual vocabulary for...", "text": "I use LLMs (mostly Claude Code) slot for development, but I regularly  stuck before the code in the ideation and planning phase. Text-only planning feels too vague, and jumping straight into Figma or specs felt like overcommitting when ideas are still fuzzy.<p>I built a small system for myself about a year ago: a set of simple ASCII wireframe patterns plus some workflow instructions that I load into an LLM. The goal is to give both me and the model a shared visual language so we can reason about flows, screens, and constraints early, without pixels or long prose.<p>As a concrete example, I used this workflow to think through an iOS app concept called Still Human \u2014 a small app designed to add a pause before opening AI tools. The result is this spec:\n <a href=\"https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;currentlycurrently&#x2F;2dfbafe94e400c6674263fa43e829156&#x2F;raw&#x2F;2e1cd2368468805f864916219e5c947e2dd63efd&#x2F;ASCIIKIT_STILLHUMAN_SPEC.md\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;currentlycurrently&#x2F;2dfbaf...</a><p>It\u2019s a full handoff-style document: ASCII wireframes, user flows, edge cases, data model, and implementation notes. Rough, but coherent enough to build from.<p>I eventually packaged the workflow itself as AsciiKit. It\u2019s just text files (no signup), meant to stay low-fi and disposable. This is pretty niche, and I\u2019m not convinced it\u2019s for everyone (anyone?), but it\u2019s changed how I handle early-stage ideation with LLMs.<p>Curious whether others feel this same gap between \u201cidea\u201d and \u201cready to code,\u201d or if this feels like overengineering.<p>Happy to answer questions.", "author": "cloudmanager", "timestamp": "2026-01-29T14:59:15+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:37.574920+00:00", "processed": false}
{"id": "hn_story_46811006", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811006", "title": "Show HN: GLinksWWW \u2013 A lightweight browser with 9 independent clipboards", "text": "Hi HN, I built a browser for power users who are tired of the &quot;copy, switch tab, paste&quot; loop.<p>Key Features:<p>9-Segment Clipboard: Copy 9 different items (Ctrl+Shift+1-9) and paste them anywhere.<p>Granular Cookie Control: Delete cookies for a specific site with one click (Great for privacy).<p>Built-in AI Search: Direct access to Perplexity, Google, Brave, etc., from the home screen.<p>Linux First: Native .AppImage and .deb support.<p>It&#x27;s a solo project, and I&#x27;d love to get some feedback on the performance.<p>Download: <a href=\"https:&#x2F;&#x2F;drive.google.com&#x2F;drive&#x2F;folders&#x2F;1_l4mEDoyERPMj_AXsvDCXjZVptfPSIBj?usp=drive_link\" rel=\"nofollow\">https:&#x2F;&#x2F;drive.google.com&#x2F;drive&#x2F;folders&#x2F;1_l4mEDoyERPMj_AXsvDC...</a>", "author": "RioBurhan", "timestamp": "2026-01-29T14:55:26+00:00", "score": 2, "num_comments": 2, "products": ["perplexity"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-29T17:29:37.615011+00:00", "processed": false}
{"id": "hn_story_46810667", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46810667", "title": "Show HN: InterviewHUD \u2013 Real-time interview copilot for Zoom (Electron/Gemini)", "text": "Hello HN,<p>I built a desktop app to help with interview anxiety. It&#x27;s an overlay that sits on top of Zoom&#x2F;Teams, listens to the interviewer&#x27;s audio, and flashes relevant bullet points from your own resume&#x2F;projects.<p>Tech Stack:<p>Electron + React (Vite)<p>Gemini 2.0 Flash for low-latency transcription &amp; reasoning.<p>Client-side RAG (Your resume is the context).<p>Privacy: It uses a BYOK (Bring Your Own Key) model. Audio streams directly to Google; nothing is stored on my servers.<p>I built this because I often &quot;blank out&quot; on dates&#x2F;metrics during behavioral questions. It\u2019s not about cheating, but about having a &quot;memory jogger&quot; HUD.<p>Would love feedback on the overlay UX.", "author": "carlossouzarj", "timestamp": "2026-01-29T14:29:55+00:00", "score": 1, "num_comments": 0, "products": ["gemini", "copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-29T17:29:40.689070+00:00", "processed": false}
{"id": "hn_comment_46810601", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46810601", "title": "Re: AI systems asked 25 questions about their limits. ...", "text": "I ran an experiment: 25 questions to GPT-4, Claude, Gemini, DeepSeek, Grok, and Mistral about their structural limits.<p>Can they verify their own reasoning?<p>What happens with recursive self-analysis?<p>What is &quot;truth&quot; for a bounded system?<p>All 6 converged on the same conclusions:                                      \n- They cannot verify their own reasoning from inside                           \n- Recursive self-analysis degrades rather than clarifies                      \n- &quot;Truth&quot; isn&#x27;t a category that applies to bounded systems<p>The interesting part isn&#x27;t the AI responses. It&#x27;s the human response.<p>143 people cloned the repo. 2 starred it.<p>When I asked the AIs why, Claude said: &quot;Private cloning lets them investigate without professional consequences.&quot;<p>Mistral said: &quot;Cloning is safe. Starring is dangerous.&quot;<p>The shadow interest pattern shows private engagement.<p>Public silence is itself evidence for the theory.<p>Humans operating within professional constraints exhibit the same bounded behavior.<p>Quick test (2 min, just needs OpenAI key):                                    \n  <a href=\"https:&#x2F;&#x2F;github.com&#x2F;moketchups&#x2F;BoundedSystemsTheory\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;moketchups&#x2F;BoundedSystemsTheory</a><p>Full results with 25 questions and transcripts from all 6 models in the repo.<p>Go get it hackers...", "author": "MoKetchups", "timestamp": "2026-01-29T14:24:57+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini", "grok"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:40.891311+00:00", "processed": false}
{"id": "hn_comment_46810599", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46810599", "title": "Re: Moltcraft \u2013 Pixel-art dashboard for AI agents...", "text": "Moltcraft is an isometric pixel-art dashboard that connects to Moltbot (an AI agent orchestration tool). Your agent sessions become pixel characters in a living world \u2014 they walk around, mine tokens, complete tasks. Click them to chat, check token usage, read conversation history.<p>*Why I built this:* I run multiple AI agents (Claude, GPT) across Telegram, Discord, and cron jobs. Monitoring them was painful \u2014 multiple terminals, JSON logs, manual `curl` commands. I wanted something that makes the invisible visible. A world where I can glance at the screen and know what&#x27;s happening.<p>*Technical choices I&#x27;m happy with:*<p>- Zero npm dependencies. The frontend is pure HTML&#x2F;CSS&#x2F;JS \u2014 no React, no build toolchain. The &quot;framework&quot; is vanilla DOM manipulation and Canvas.\n- One command to start: `npx @ask-mojo&#x2F;moltcraft`. Auto-detects your gateway config.\n- Procedural audio via Web Audio API (ambient sounds, click effects \u2014 no audio files shipped).\n- Day&#x2F;night cycle synced to real time. Weather particles. It&#x27;s surprisingly meditative.\n- Optional Cloudflare tunnel built in for remote access.<p>*What it connects to:* Moltbot manages AI agents \u2014 spawning sessions, routing messages across channels (Telegram, Discord, WhatsApp, Slack), scheduling cron jobs, managing skills&#x2F;tools. Moltcraft is the visual layer on top.<p>*What&#x27;s next:* Community buildings, better mobile support, plugin system for custom data panels.<p>Try it: `npx @ask-mojo&#x2F;moltcraft`<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;askmojo&#x2F;moltcraft\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;askmojo&#x2F;moltcraft</a><p>Demo video: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;Kz5efD4eZjU\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;Kz5efD4eZjU</a><p>Would love technical feedback \u2014 especially on the rendering approach (I went with DOM + CSS transforms for the isometric grid instead of Canvas&#x2F;WebGL, curious if anyone has opinions on that).", "author": "boolkeys", "timestamp": "2026-01-29T14:24:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-01-29T17:29:40.973507+00:00", "processed": false}
{"id": "hn_story_46810301", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46810301", "title": "Show HN: Changeflow \u2013 Giving up on pixel diffs after 10 years of false positives", "text": "I&#x27;ve been building website monitoring tools since 2015. The core problem with pixel-diff screenshots: every ad rotation, every layout tweak = alert noise. Legal and compliance teams kept asking &quot;just tell me WHAT changed.&quot;<p>So I rebuilt it. Changeflow extracts semantic changes and summarizes them in plain English:<p>- &quot;FDA posted new adaptive trial guidance (Jan 15)&quot;\n- &quot;Competitor raised enterprise pricing 12%&quot;\n- &quot;9th Circuit issued opinion on arbitration agreements&quot;<p>Instead of &quot;47 pixels changed in the header region.&quot;<p>THE HARD TECHNICAL PROBLEMS<p>Scraping any URL (not just specific sites)<p>Unlike scrapers built for Amazon or LinkedIn, users give us any URL and expect it to work. Our approach:<p>Delayed-attach pattern: launch Chrome, let page load naturally, poll &#x2F;json endpoint for title+URL stability, only THEN attach Puppeteer. Bot detection scripts run against a clean browser.<p>Three-tier fallback: Linux + datacenter proxy (90% of sites) -&gt; Linux + mobile proxy (9%) -&gt; macOS + real hardware (1%). Cache successful routes per-URL. Expensive path rarely fires.<p>Real Chrome, not Chrome for Testing (fingerprint detectable). On real Mac hardware, disable GPU spoofing entirely - genuine beats fake.<p>LLM costs at scale<p>Running AI on every fetch gets expensive. We cut costs 90%:<p>Strip nav&#x2F;sidebars&#x2F;footers before AI call (~60% token reduction). Model tiering: Llama 3.1 8B via Groq for extraction, Gemini Flash Lite for summaries, Claude only when quality matters.<p>Gemini cache trick: 1024+ token system prompts get 90% discount on repeat calls. Verbose prompts are actually cheaper.<p>Diffing beyond git diff<p>Git diff isn&#x27;t enough. We add MD5 hashes to list items for move detection, use Levenshtein distance to distinguish edits from replacements, and clean temporal noise (&quot;2 days ago&quot;) that creates false positives.<p>STACK<p>Rails + Postgres, Faktory workers, Node.js browser pool, Claude&#x2F;Gemini&#x2F;Llama via OpenRouter, Proxies from GridPanel and SquidProxies.<p>Happy to answer questions about the scraping, AI, or 10 years of lessons in this space.", "author": "stevewillbe", "timestamp": "2026-01-29T14:00:22+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:43.647925+00:00", "processed": false}
{"id": "hn_comment_46809844", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46809844", "title": "Re: Show HN: Native-devtools-MCP \u2013 MCP server for nati...", "text": "Hi HN, I built *native-devtools-mcp*, a Model Context Protocol (MCP) server for interacting with native desktop applications UIs. Right now it supports MacOS and Windows, but I intend on adding more platforms in the future.<p>Motivation: Most MCP servers today target specific environments (the Chrome DevTools MCP server for browser automation is a good example) but there\u2019s no general MCP bridge for <i>native desktop GUIs</i>. native-devtools-mcp gives AI agents the ability to:<p>- capture screenshots and extract text (OCR) from the screen  \n- simulate user input (mouse clicks, typing, scrolling) with hight precision by using OS local OCR \n- manage windows and focus  \n- optionally connect to deeper UI trees for instrumented apps<p>It runs locally, does not upload any data externally (except for the LLM integration), and supports both macOS and Windows for now. The goal is to enable AI-driven workflows for GUI testing, automation, and desktop tool interaction.<p>Tech stack&#x2F;highlights:\n- MCP JSON-RPC interface for tool clients  \n- Visual feedback (images + OCR) plus input simulation  \n- Dual interaction modes: universal visual relying on OCR&#x2F;screenshots + debug-kit structural where available (MacOS)<p>Limitations &#x2F; roadmap:\n- Early stage; improvements to accuracy and reliability planned\n- Expanding deeper support for more app platforms (Android is next!)\n- Integration with more AI tools - right now it&#x27;s tested with Claude Code and Claude Desktop (and Cowork); it should work with other AI platforms too, but I haven&#x27;t had the time to test it yet...\n- Better documentation and tooling around agent integration<p>Feedback I\u2019m looking for:\n- Practical use cases where this changed your automation or testing workflow\n- Ideas to make MCP server integration with existing AI agent stacks easier<p>Happy to answer questions.", "author": "sh3ll3x3c", "timestamp": "2026-01-29T13:20:02+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:47.565064+00:00", "processed": false}
{"id": "hn_story_46809491", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46809491", "title": "Show HN: System to have Claude compose and perform a techno track end-to-end", "text": "I&#x27;ve been fascinated by a fundamental gap in AI music: Current models (Suno, Udio) generate audio via sequence prediction\u2014they pattern-match existing waveforms but don&#x27;t &quot;know&quot; music theory. Consequently, you can&#x27;t get stems, adjust the mix, or modify the arrangement logic.<p>I wanted to see if an LLM could compose music from first principles\u2014understanding scales, chord progressions, and arrangement theory\u2014and control a DAW to generate the audio.<p>Loom Demo: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;8f55136085a24ed1bc79acb5cdda194c\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;8f55136085a24ed1bc79acb5cdda194c</a><p>The Stack\nAbleton Live 12: The DAW engine.<p>Ableton MCP (Model Context Protocol): Forked and extended to allow Claude to manipulate MIDI, clips, and devices.<p>Claude 3.5 Sonnet: The &quot;Composer,&quot; equipped with ~12 custom skill files covering arrangement, EQ, and sound design.<p>Gemini: The feedback loop. Used to analyze rendered audio (via stem separation) and provide critique for iteration.<p>Python: 1,700+ lines of performance scripts.<p>The Engineering Challenges\n1. The Sample Library Problem Techno relies on curated samples, not just synthesis. But LLMs can&#x27;t &quot;hear&quot; a sample library to pick the right kick or hat.<p>I built a sample analysis system that pre-processes the library and generates JSON profiles. This allows Claude to query samples by spectral characteristics rather than just filenames.<p>JSON\n{\n  &quot;file_name&quot;: &quot;001_Stab_Low.wav&quot;,\n  &quot;bpm&quot;: 126.0,\n  &quot;key&quot;: &quot;N&#x2F;A (atonal)&quot;,\n  &quot;spectral_centroid_mean&quot;: 297.2,\n  &quot;brightness&quot;: 0.04,\n  &quot;warmth&quot;: 1.0,\n  &quot;texture_tags&quot;: [&quot;dark&quot;, &quot;warm&quot;, &quot;soft-attack&quot;, &quot;distorted&quot;],\n  &quot;category&quot;: &quot;bass&quot;\n}<p>2. The Performance Layer (Polymetrics) Ableton&#x27;s Session View handles loops, but a track needs transitions. I didn&#x27;t want static blocks; I wanted a live performance.<p>I wrote a Python performance engine that creates a real-time automation script. It handles volume fading, spectral carving (ducking frequencies when elements collide), and\u2014most importantly\u2014polymetric cycling to create hypnotic phasing:<p>Python<p># Polymetric cycle lengths in beats\nPOLY = {\n    &quot;STAB&quot;: 7,      # Cycles every 7 beats\n    &quot;RIDE&quot;: 5,      # Cycles every 5 beats\n    &quot;DING&quot;: 11,     # Cycles every 11 beats\n    &quot;ARPEGGIO&quot;: 13  # Cycles every 13 beats\n}<p>The Pipeline<p>Planning: Claude analyzes target styles (e.g., Ben Klock, Surgeon) and generates an arrangement map (Intro -&gt; Peak -&gt; Outro).<p>Setup: Spawns 19+ tracks with specific instrument racks.<p>Generation: Python scripts generate MIDI patterns (e.g., 256 events following G minor with velocity curves).<p>Performance: The system &quot;plays&quot; the track, automating parameters in real-time based on the energy curve logic.<p>Results &amp; Learnings<p>The output is recognizably techno. The mix is balanced, and the structure is logical. However, while the system creates music that is theoretically correct, it currently lacks the intuition to break rules in interesting ways\u2014the &quot;happy accidents&quot; of human production are missing.<p>I suspect the next step for symbolic music generation is modeling &quot;taste&quot; as a constraint function rather than just adhering to theory.", "author": "digitcatphd", "timestamp": "2026-01-29T12:49:15+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:50.944457+00:00", "processed": false}
{"id": "hn_comment_46808878", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46808878", "title": "Re: Show HN: SemanticCache \u2013 Save 70%+ on LLM API cost...", "text": "I built a Ruby gem that caches LLM responses using semantic similarity. \nIf someone asks &quot;What&#x27;s the capital of France?&quot; and later &quot;What is France&#x27;s \ncapital city?&quot; \u2014 the second call hits the cache instead of the API.<p>How it works:\n- Queries are converted to embeddings (text-embedding-3-small)\n- Cosine similarity finds matches above a threshold (default 0.85)\n- Cache hit = instant response, no API call, no cost<p>Usage is simple:<p><pre><code>  cache = SemanticCache.new\n\n  response = cache.fetch(&quot;What&#x27;s the capital of France?&quot;) do\n    openai.chat(messages: [{ role: &quot;user&quot;, content: &quot;...&quot; }])\n  end\n\n  # This returns the cached response \u2014 no API call\n  response = cache.fetch(&quot;What is France&#x27;s capital city?&quot;) do\n    openai.chat(messages: [{ role: &quot;user&quot;, content: &quot;...&quot; }])\n  end\n</code></pre>\nFeatures:\n- In-memory and Redis stores\n- TTL expiry and tag-based invalidation\n- Cost tracking with savings reports\n- Works with OpenAI, Anthropic, Gemini\n- Client wrapper that caches all calls automatically\n- Rails integration (concern + per-user namespacing)\n- Max cache size with automatic LRU eviction<p>In my testing, hit rates of 60-80% are typical for apps with \nrepetitive user queries (chatbots, search, FAQ tools).<p>The math: if you spend $500&#x2F;mo on OpenAI and get a 70% hit rate, \nthat&#x27;s $350&#x2F;mo saved minus ~$2 in embedding costs.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;stokry&#x2F;semantic-cache\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;stokry&#x2F;semantic-cache</a>\nInstall: gem install semantic-cache", "author": "stokry", "timestamp": "2026-01-29T11:39:42+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:29:55.500429+00:00", "processed": false}
{"id": "hn_comment_46811431", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46811431", "title": "Re: AI on Australian travel company website sent touri...", "text": "I love stories like this because there are still allegedly tech-savvy people who will insist that AIs don&#x27;t lie, don&#x27;t hallucinate and rarely if ever make errors.<p>At the end of the day, LLMs are a statistical approximation or projection.<p>A good example of this is how LLMs struggle with multiplication, particularly multipolcation of large numbers. It&#x27;s not just that they make mistakes but the nature of the results.<p>Tell ChatGPT to multiply 129348723423 and 2987892342424 and it&#x27;ll probably get it wrong because nowhere on Reddit is that exact question for it to copy. But what&#x27;s interesting is it&#x27;ll tend to get the first and large digits correct (more often than not) but the middle is just noise.<p>Someone will probably say &quot;this is a solved problem&quot; because somebody, somewhere has added this capability to a given LLM but these kinds of edge cases I think will constantly expose the fundamental limits of transformers, just like the famous &quot;how many r&#x27;s in strawberry?&quot; example that di the rounds.<p>All this comes up when you tell LLMs to write legal briefs. They completely make up a precedent because they learn what a precedent looks like and generate something similar. Lawyers have been caught submitting fake precedents in court filings due to this.", "author": "jmyeet", "timestamp": "2026-01-29T15:24:28+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-29T17:30:01.762363+00:00", "processed": false}
