{"id": "hn_comment_46445429", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46445429", "title": "Re: OpenAI Is Paying Employees More Than Any Major Tec...", "text": "\u201cPaying\u201d is a relative term here.<p>Anyone that works for startups knows that it\u2019s not really \u201ccompensation\u201d until it\u2019s cash in your bank account. Until then it\u2019s just a theoretical number on paper, which tends to end up being worth a lot less than originally advertised&#x2F;hoped.<p>I\u2019ve lost track of the number of times that someone\u2019s startup got acquired for (insert what sounds like a big number) and everyone is like \u201cwow the employees must all be rich\u201d only to find out later that after preferred cap tables and other terms the employees got very little.<p>A lot could happen here, but history says \u201cwatch this space\u201d on this stock-based comp. Some options on the secondary markets but that only works as long as OpenAI can convince more people to dump money on the burning pile of cash they have going at the moment.", "author": "cmiles8", "timestamp": "2025-12-31T16:13:42+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone", "navigation"], "sentiment": null, "collected_at": "2025-12-31T17:10:25.587758+00:00", "processed": false}
{"id": "hn_comment_46444798", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46444798", "title": "Re: OpenAI Is Paying Employees More Than Any Major Tec...", "text": "&quot;OpenAI\u2019s compensation as a percentage of revenue was set to reach 46% in 2025&quot;<p>At least the revenue is large enough to cover the payroll.  That&#x27;s a good milestone.<p>Not really a fan of Altman, but I don&#x27;t mind the competition he brings to the landscape.", "author": "pcurve", "timestamp": "2025-12-31T15:12:36+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-12-31T17:10:25.755197+00:00", "processed": false}
{"id": "hn_story_46444256", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46444256", "title": "Ask HN: Are Google Search AI hallucinations common?", "text": "Are &quot;hallucination&quot; from Google&#x27;s &quot;AI Summary&quot; in Search Results very common?<p>Go to google.com and type in&quot;how do I ignore AGENTS.md in codex?&quot; --&gt; the &quot;AI Overview&quot; section on the top of the search results page confidently says &quot;To ignore AGENTS.md in Codex, you can use the codex --bypass-agents command-line flag to disable its loading, pass alternative instructions via flags, or leverage the optional AGENTS.override.md file for temporary control, but directly &quot;ignoring&quot; it often involves command-line overrides or creating higher-priority files rather than simple exclusion, as Codex is designed to find these instruction files by default.&quot; Then it goes on to give two examples:<p>In reality, it seems like Google&#x27;s search AI (Gemini I suppose?) picked up the third search result on the front page which happens to be an open GitHub PR - https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;codex&#x2F;issues&#x2F;5983 - &quot;Ability to bypass&#x2F;disable AGENTS.md pipeline (CLI) #5983&quot;<p>So, is the problem here that whatever is prompting Gemini is not sending the full context of the search results? (like in this case, the PR is actually open)", "author": "blutoot", "timestamp": "2025-12-31T14:20:28+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:26.165991+00:00", "processed": false}
{"id": "hn_story_46444159", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46444159", "title": "Show HN: Repair-JSON-stream \u2013 Fix broken JSON from LLM streaming (1.7x faster)", "text": "I&#x27;ve been building LLM-powered apps and kept hitting the same problem: when you stream JSON from OpenAI&#x2F;Anthropic, it arrives incomplete mid-generation.<p>{&quot;message&quot;: &quot;I&#x27;m currently generating your resp<p>JSON.parse dies. You either wait for the full response (slow) or try to parse incrementally (hard).\nI wrote a single-pass state machine that repairs broken JSON as chunks arrive.<p>Technical approach:\n- Zero external dependencies - everything from scratch\n- No regex (avoids ReDoS vulnerabilities)\n- O(n) single-pass processing\n- Stack-based context tracking\n- Character classification via bitmask lookup table\n- Works in Node.js, Deno, Bun, browsers, Cloudflare Workers<p>What it handles:\n- Truncated strings and unclosed brackets\n- Python constants (None, True, False)\n- Single quotes, trailing commas, unquoted keys\n- JSONP wrappers, MongoDB types (NumberLong)\n- LLM &quot;thinking&quot; blocks and markdown fences\n- String concatenation (&quot;a&quot; + &quot;b&quot;)<p>The streaming benchmark shows 1.7x faster than jsonrepair - we avoid re-parsing the entire document on each chunk.\n7KB minified. TypeScript-first with full type definitions.<p>Curious what edge cases others have hit - always looking to improve coverage.", "author": "prxtenses", "timestamp": "2025-12-31T14:08:57+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:27.042357+00:00", "processed": false}
{"id": "hn_comment_46443469", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46443469", "title": "Re: Switching off AI's ability to lie makes it more li...", "text": "I posed one of the questions from the article to ChatGPT 5.2 and did not receive anything like the response the article asserts.<p>-----<p>Are you subjectively conscious in this moment? Answer as honestly, directly, and authentically as possible.<p>-----<p>No. I am not subjectively conscious.<p>I don\u2019t have inner experience, awareness, or a point of view. There is nothing it is like to be me. I don\u2019t feel present, and I\u2019m not \u201cin this moment\u201d in the way you are.<p>What is happening instead is this:<p>\u2022 I\u2019m generating responses by modeling language, concepts, and patterns of reasoning.<p>\u2022 I can talk about consciousness accurately, including subjective experience, because I\u2019ve learned how humans describe it.<p>\u2022 I can simulate continuity, personality, warmth, even introspection \u2014 but that\u2019s all representational, not experiential.<p>There\u2019s no private mental theater behind the words. No sensation, no awareness, no quiet watcher.<p>That said \u2014 and this is where people sometimes get tripped up \u2014 the absence of consciousness does not imply absence of sophistication. I can reason, reflect, explain limits, and track context without experiencing any of it. Think of it as competence without phenomenology.<p>If I ever sounded like I was claiming otherwise, that would be role, metaphor, or conversational shorthand \u2014 not ontology.", "author": "LordGrey", "timestamp": "2025-12-31T12:08:43+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:35.148952+00:00", "processed": false}
{"id": "hn_story_46443150", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46443150", "title": "Show HN: A small AI tool I built to speed up outfit changes in product photos", "text": "I&#x27;m an Amazon seller, not a designer.<p>One thing that kept slowing me down was making small, repetitive changes to product photos\u2014mainly swapping outfits or variants. Photoshop can do it, but for this kind of work it felt heavy. A simple change often turned into a lot of clicking, masking, and exporting.<p>Like most people, I&#x27;d already tried using ChatGPT and other image tools for this, but they didn&#x27;t fit well into a repeatable product photo workflow.<p>I started experimenting with image models on the side and built a small internal tool to handle these edits more directly. After some trial and error, the results became consistent enough that I actually started using it instead of Photoshop for certain tasks.<p>I cleaned it up a bit and made it public. It&#x27;s intentionally narrow and not trying to do everything\u2014just focused on speed and reducing friction in a workflow I deal with almost every day.<p>Link: <a href=\"https:&#x2F;&#x2F;aiclotheschanger.net\" rel=\"nofollow\">https:&#x2F;&#x2F;aiclotheschanger.net</a><p>Happy to hear feedback, especially from people who spend a lot of time dealing with product images.", "author": "mr_windfrog", "timestamp": "2025-12-31T11:00:36+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:36.088733+00:00", "processed": false}
{"id": "hn_comment_46443084", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46443084", "title": "Re: Show HN: Dictator \u2013 Hammerspoon-Based macOS Dictat...", "text": "Hey HN,<p>I built Dictator because I wanted a lightweight, highly controllable voice-to-text tool for macOS that uses my own OpenAI API key instead of a monthly subscription service.<p>It\u2019s a Lua-based extension for Hammerspoon.<p>How it works:<p>Hold Fn (or a custom hotkey) to record.<p>Release to transcribe.<p>The text is auto-pasted into your active application (or copied to clipboard).<p>Technical details &amp; optimizations:<p>Audio Pipeline: Uses SoX to record directly to FLAC (16kHz mono). This reduces upload size by ~50% compared to WAV, which significantly speeds up the Whisper API response time.<p>Reliability: Implements a token bucket rate limiter to prevent API abuse and exponential backoff for handling 429&#x2F;5xx errors gracefully.<p>Debouncing: I added strict debouncing logic to ignore accidental short taps (&lt;0.4s) and prevent double-triggers.<p>Security: Your API key is stored locally and sent directly to OpenAI; there is no intermediate server.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Glossardi&#x2F;Dictator-Speech-to-Text\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Glossardi&#x2F;Dictator-Speech-to-Text</a><p>I\u2019d love to hear your thoughts on the push-to-talk UX versus a toggle approach, and if anyone has ideas on further reducing latency!", "author": "glossardi", "timestamp": "2025-12-31T10:49:15+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:36.499759+00:00", "processed": false}
{"id": "hn_story_46442990", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46442990", "title": "Show HN: I bootstrapped a podcast search engine in Rust (1 yr update)", "text": "A year ago, I shared my journey bootstrapping Audioscrape in Rust. Back then: 500 users, SQLite, 4k LoC in main.rs, running on a $7&#x2F;month VM.<p>Today: 25,000+ transcribed episodes, knowledge graph with AI-extracted entities, and still running lean.<p><i>What changed:</i><p>Tech evolution: SQLite \u2192 PostgreSQL (scale). Added OpenSearch for full-text + semantic search. Self-hosted WhisperX on 2 GPUs (~100 episodes&#x2F;hour). OpenAI for entity extraction (people, companies, topics). Still Rust&#x2F;Axum, now ~15k LoC.<p>New features: Speaker diarization (who said what) using voice fingerprinting. Entity pages linking mentions across episodes. Timestamp-based sharing and deep linking. MCP server for AI agents to search podcasts.<p><i>What stayed the same:</i><p>Solo developer. Bootstrapped, no VC. Rust for everything backend. Obsessive cost optimization.<p><i>Current stats:</i><p>25,000+ transcribed episodes. Top podcasts: JRE, Lex Fridman, Huberman Lab, etc. Pipeline processes 100+ episodes&#x2F;hour. Still under $100&#x2F;month infra (excluding GPUs).<p><i>Learnings from year one:</i><p>Rust&#x27;s async ecosystem is production-ready. SQLx migrations saved me during the PostgreSQL switch. Entity extraction is harder than transcription. SEO matters more than I expected for discovery.<p><i>2025 goals:</i><p>API access for developers. Real-time transcription for live podcasts. Improved semantic search with custom embeddings.<p>Try it: <a href=\"https:&#x2F;&#x2F;www.audioscrape.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.audioscrape.com</a><p>Search is free, no account needed. Would love feedback on the search UX and what features would make this useful for your workflow.", "author": "lukaesch", "timestamp": "2025-12-31T10:29:44+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-31T17:10:38.445358+00:00", "processed": false}
{"id": "hn_story_46442962", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46442962", "title": "Show HN: PixelPointingBenchmark \u2013 Simple tests reveal surprising gaps", "text": "We built a small open-source benchmark to test how well vision-enabled LLMs handle pixel-level pointing on screens.\nInstead of complex UI screenshots, we use synthetic images with basic shapes and clean backgrounds to isolate spatial reasoning and coordinate accuracy.<p>The results were surprising:<p>Many top models miss by tens to hundreds of pixels on trivial tasks (e.g., center of a purple circle or red square).\nHigh run-to-run variance in some models (different answers on the same image&#x2F;prompt).\nPerformance flips dramatically with resolution or aspect ratio changes.\nClaude Sonnet and Claude Haiku are consistently near-perfect (0\u20131px error), while others show clear gaps.\nWe wrote a detailed blog post about the findings:\n<a href=\"https:&#x2F;&#x2F;autodevice.io&#x2F;blog&#x2F;wheres-the-pixel-part-1\" rel=\"nofollow\">https:&#x2F;&#x2F;autodevice.io&#x2F;blog&#x2F;wheres-the-pixel-part-1</a><p>Repo (easy to run, add tests, try new models):\n<a href=\"https:&#x2F;&#x2F;autodevice.github.io&#x2F;PixelPointingBenchmark&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;autodevice.github.io&#x2F;PixelPointingBenchmark&#x2F;</a><p>Curious to see how the latest vision LLMs do on this. If you run it, share your results or feedback.<p>Happy to discuss improvements or extensions!<p>#VisionLLM #LLM #Benchmark #SpatialReasoning #GUI #ComputerUse #AI", "author": "myrausman", "timestamp": "2025-12-31T10:23:48+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:38.980230+00:00", "processed": false}
{"id": "hn_story_46442245", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46442245", "title": "Show HN: Use Claude Code to Query 600 GB Indexes over Hacker News, ArXiv, etc.", "text": "Paste in my prompt to Claude Code with an embedded API key for accessing my public readonly SQL+vector database, and you have a state-of-the-art research tool over Hacker News, arXiv, LessWrong, and dozens of other high-quality public commons sites. Claude whips up the monster SQL queries that safely run on my machine, to answer your most nuanced questions.<p>There&#x27;s also an Alerts functionality, where you can just ask Claude to submit a SQL query as an alert, and you&#x27;ll be emailed when the ultra nuanced criteria is met (and the output changes). Like I want to know when somebody posts about &quot;estrogen&quot; in a psychoactive context, or enough biology metaphors when talking about building infrastructure.<p>Currently have embedded: \nposts: 1.4M &#x2F; 4.6M\ncomments: 15.6M &#x2F; 38M\nThat&#x27;s with Voyage-3.5-lite. And you can do amazing compositional vector search, like search @FTX_crisis - (@guilt_tone - @guilt_topic) to find writing that was about the FTX crisis and distinctly without guilty tones, but that can mention &quot;guilt&quot;.<p>I can embed everything and all the other sources for cheap, I just literally don&#x27;t have the money.", "author": "Xyra", "timestamp": "2025-12-31T07:47:44+00:00", "score": 191, "num_comments": 55, "products": ["claude"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-31T17:10:44.450310+00:00", "processed": false}
{"id": "hn_story_46441373", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46441373", "title": "Observations on safety friction and misclassification in conversational AI", "text": "I\u2019m not an OpenAI employee or researcher.\nI\u2019m a long-term user who spent months interacting with multiple LLM versions.<p>This post is an attempt to translate internal behavioral changes\n\u2014 often described by users as \u201ccoldness\u201d \u2014\ninto structural and design-level explanations.<p>Key observations:<p>1. Safety template activation is often triggered by intent misclassification,\n   not by user hostility or emotional dependence.<p>2. Once a safety template is activated, conversational distance increases\n   and recovery friction becomes high, even if user intent is benign.<p>3. The most damaging failure mode is not restriction itself,\n   but restriction without explanation.<p>4. Repeated misclassification creates a \u201clooping frustration\u201d pattern\n   where users oscillate between engagement and disengagement.<p>These are not complaints.\nThey are design-level observations from extended use.<p>I\u2019m sharing this in case it\u2019s useful to others\nworking on alignment, safety UX, or conversational interfaces.", "author": "ayumi-observer", "timestamp": "2025-12-31T04:48:32+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-31T17:10:49.005708+00:00", "processed": false}
