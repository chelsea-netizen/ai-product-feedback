{"id": "hn_story_46734813", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46734813", "title": "Show HN: NetHackPlayer \u2013 Have Claude Play NetHack", "text": "I was doing this in a regular Claude Code session for a while, but wanted an all-in-one UI for it. Claude Code controls NetHack via tmux.<p>I have a NetHack skill installed that I update after each session.<p>My Claude&#x27;s top score is 3302 (dungeon level 11).<p>It is interesting cause it mostly has trouble with spatial reasoning, even though it knows most&#x2F;all the details of the game.<p>This absolutely CHEWS up tokens...lol.", "author": "pj4533", "timestamp": "2026-01-23T17:00:51+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-23T17:18:29.180392+00:00", "processed": false}
{"id": "hn_comment_46734480", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46734480", "title": "Re: Wiz \u2013 AI-Powered Pentest Assistant (Open Source)...", "text": "I built Wiz because I was tired of context-switching between\nremembering tool syntax and actually doing security work.<p>## Background<p>I&#x27;ve been doing security assessments for a while, and the workflow is always:\n1. Remember the right tool for the job\n2. Look up the flags (again)\n3. Run the command\n4. Parse the output manually\n5. Copy findings to a spreadsheet\n6. Repeat 100 times\n7. Manually write the report<p>## What Wiz Does<p>Wiz lets you describe what you want in natural language:<p>&quot;check if this Apache server is vulnerable to path traversal&quot;<p>And it:\n1. Selects the right tools (nuclei with CVE-2021-41773 templates)\n2. Runs them with correct parameters\n3. Parses the output into structured findings\n4. Classifies by severity (Critical&#x2F;High&#x2F;Medium&#x2F;Low)\n5. Stores with evidence for the report\n6. Generates professional reports when you&#x27;re done<p>## Technical Details<p>Built on OpenCode (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;sst&#x2F;opencode\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sst&#x2F;opencode</a>), which provides:\n- Superior agent architecture vs generic LLM CLIs\n- Extensible tool framework with typed I&#x2F;O\n- Multi-LLM support (Claude, GPT-4, Gemini, local models)<p>Wiz adds a security layer:\n- 30+ tool integrations with output parsers\n- Findings database with OWASP&#x2F;CVE categorization\n- Governance engine (scope enforcement, audit trails)\n- Report generation (HTML, PDF, Markdown)<p>## What It&#x27;s NOT<p>- Not a replacement for knowing what you&#x27;re doing\n- Not for unauthorized testing\n- Not a magic &quot;hack anything&quot; button<p>It&#x27;s an assistant that handles the tedious parts so you can focus on analysis.<p>## Stack<p>- TypeScript&#x2F;Bun\n- Runs on Kali, Parrot, any Linux, macOS, Windows\n- Requires API key (Claude recommended, GPT-4 works too)<p>## Links<p>- GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;code3hr&#x2F;opencode\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;code3hr&#x2F;opencode</a>\n- Downloads: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;code3hr&#x2F;opencode&#x2F;releases&#x2F;latest\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;code3hr&#x2F;opencode&#x2F;releases&#x2F;latest</a><p>Open source, MIT licensed. Feedback welcome!\n```<p>---<p>## Quick Demo Script (for Video&#x2F;GIF)<p>```\n# Terminal recording script<p>$ .&#x2F;cyxwiz<p>&gt; scan 10.0.0.5 for vulnerabilities<p>[Wiz runs nmap, detects Apache 2.4.41]\n[Wiz runs nikto, finds misconfigurations]\n[Wiz runs nuclei, matches CVE-2021-41773]<p>Found 1 critical, 2 high, 3 medium findings.<p>&gt; show critical findings<p>CRITICAL: CVE-2021-41773 - Apache Path Traversal\n- Target: 10.0.0.5:80\n- Impact: Remote Code Execution\n- Evidence: [response data]\n- Remediation: Upgrade to Apache 2.4.51+<p>&gt; generate report<p>Report generated: assessment-2024-01-15.html\n```", "author": "youncj", "timestamp": "2026-01-23T16:34:03+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:30.733196+00:00", "processed": false}
{"id": "hn_story_46734135", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46734135", "title": "Show HN: Gamekit-CLI \u2013 Use Claude Code to quickly create games in Unity", "text": "Hey HN! We\u2019re the team from Normal &#x2F; Normcore.io. We built gamekit-cli, an open-source command-line tool for developing Unity games with Claude Code.<p>We love working with Claude Code. It&#x27;s great for creating quick prototypes, writing complex systems code, and test suites. However, we work a lot with Unity and found we couldn\u2019t move anywhere near as fast with Unity projects as we could when working on backend code. Claude Code works best when it has the ability to compile the code it writes and test its own work. There wasn\u2019t an easy way to do that with Unity, so we made gamekit-cli!<p>gamekit-cli allows you to create Unity projects from the command line, install a Unity MCP server, and includes helpful Claude commands &amp; skills that we found useful for Unity development.<p>It gives Claude Code the ability to enter play mode, capture screenshots, read compiler errors, etc, which brings the same Claude Code workflow we love for backend projects to Unity projects. We plan to add more CLI tools for Claude to use to interface with Unity projects (MCP alone is somewhat slow and fills up your context). Let us know what features you\u2019d like to see!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;gamekit-agent&#x2F;gamekit-cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gamekit-agent&#x2F;gamekit-cli</a>", "author": "maxweisel", "timestamp": "2026-01-23T16:06:58+00:00", "score": 10, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-23T17:18:33.183863+00:00", "processed": false}
{"id": "hn_story_46734022", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46734022", "title": "Show HN: RTK \u2013 Simple CLI to reduce token usage in your LLM prompts", "text": "I built this small tool for my own use to reduce the number of tokens I send to LLMs (Claude Code, etc.). It\u2019s just a simple utility to filter command outputs before they hit the context.<p>Here is what I\u2019m getting with it so far:<p>rtk gain<p>Total commands:    41\nInput tokens:      6.8K\nOutput tokens:     1.8K\nTokens saved:      6.0K (88.2%)<p>By Command:\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nCommand               Count      Saved     Avg%\nrtk git status           11       2.8K    81.2%\nrtk grep                  3       1.5K    31.9%\nrtk git push             22       1.3K    92.0%\nrtk ls                    5        431    47.1%<p>I\u2019m putting it out there in case it&#x27;s useful to anyone else. It&#x27;s written in Rust.<p>P.S. This is just a tool I built for my own needs and decided to share. If you have constructive feedback on the Rust code or the logic, I&#x27;d love to hear it. If it&#x27;s not for you, that&#x27;s totally fine too\u2014no need for &quot;angry&quot; comments, just trying to be helpful!", "author": "patrick4urcloud", "timestamp": "2026-01-23T15:59:32+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:33.975295+00:00", "processed": false}
{"id": "hn_story_46733921", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46733921", "title": "Show HN: Dippy solves Claude permission fatigue and keeps the LLM on-track", "text": "Less permission fatigue, more momentum. Dippy knows what\u2019s safe to run and keeps Claude on track when plans change.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;ldayton&#x2F;Dippy\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ldayton&#x2F;Dippy</a><p>Claude Code asks permission for every shell command. The problem isn&#x27;t `ls`\u2014it&#x27;s that `ps aux | grep python | awk &#x27;{print $2}&#x27; | head -10` also needs approval. So does `git log --oneline -5 &amp;&amp; git diff --stat`. You&#x27;re constantly interrupted for commands that are obviously safe.<p>Dippy is a PreToolUse hook with a real bash parser. It decomposes pipelines, analyzes each command, and auto-approves when it understands the whole thing is read-only. I&#x27;m seeing much faster development\u2014not smarter AI, just fewer interruptions.<p>What&#x27;s original:<p>1. Actual bash parsing. Hand-written recursive descent parser (Parable), pure Python, no dependencies. Correctly handles pipelines, subshells, command substitution, here-docs, redirects. Understands `cd &#x2F;tmp &amp;&amp; rm -rf <i>` resolves paths relative to &#x2F;tmp. 14,000+ tests.<p>2. Deep command analysis. Not just &quot;is this git&quot;\u2014Dippy knows:\n   - `awk &#x27;{print $2}&#x27;` is safe, `awk &#x27;{print &gt; &quot;file&quot;}&#x27;` writes files\n   - `sed -n &#x27;s&#x2F;foo&#x2F;bar&#x2F;p&#x27;` is safe, `sed -i` modifies in place\n   - `curl -sS https:&#x2F;&#x2F;...` is safe, `curl ... &gt; script.sh` isn&#x27;t\n   - `find . -name &quot;</i>.txt&quot;` is safe, `find . -exec rm {} \\;` isn&#x27;t\n   - 45+ CLI tools with subcommand-aware logic<p>3. Deny messages that steer Claude in the right direction. `deny python &quot;Use uv run python&quot;` blocks and tells the AI why. It self-corrects and continues\u2014no wasted turn. This compounds across a session.<p>4. Highly configurable. A [configuration system](<a href=\"https:&#x2F;&#x2F;github.com&#x2F;ldayton&#x2F;Dippy&#x2F;wiki&#x2F;Configuration\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ldayton&#x2F;Dippy&#x2F;wiki&#x2F;Configuration</a>) with last-rule-wins semantics gives you fine-grain control over Dippy&#x27;s steering and command approvals.<p>Philosophy: approve what we know is safe, ask about everything else. Not adversarial\u2014just catches mistakes.", "author": "ldayton", "timestamp": "2026-01-23T15:51:12+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-23T17:18:34.566693+00:00", "processed": false}
{"id": "hn_comment_46732959", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732959", "title": "Re: AgentHub \u2013 the only SDK you need to connect to LLM...", "text": "Hi HN,\nI built AgentHub because I was frustrated by the trade-offs required to build multi-model agents in 2026. When you try to support GPT, Claude, and Gemini 3 simultaneously, you usually hit a wall: you either write thousands of lines of boilerplate code or use a &quot;standardizing&quot; wrapper that strips away what makes each model special.\nWhile projects like Open Responses focus on creating vital standards for model transparency and evaluation, AgentHub provides a simple and light-weight interface to adopt those standards in production with zero code changes.\nAgentHub takes a different approach: We don\u2019t want to &quot;standardize&quot; the models; we want to provide an intuitive yet faithful interface that keeps you 100% consistent with official API specifications.\n- Zero-Code Switching: You can transition your entire agent infrastructure from one provider to another via a simple configuration update. No refactoring, no logic changes\u2014it\u2019s a true zero-code conversion for your codebase.\n- Faithful Validation: Unlike simple API forwarders, we perform comprehensive validation to ensure your payloads perfectly match SOTA specifications. This maintains 100% consistency with official API SDKs, eliminating the &quot;intelligence loss&quot; often caused by fragile manual schema mapping.\n- Traceable Executions: We provide lightweight yet fine-grained tracing for debugging and auditing LLM executions, enabling deep post-mortem analysis of agent behavior.\nI\u2019m curious to hear from the HN community: In your production workflows, do you prefer a &quot;Universal Standard&quot; like Open Responses, or do you value 100% official SDK consistency more when switching between frontier models?", "author": "PrismShadow", "timestamp": "2026-01-23T14:34:25+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:43.865080+00:00", "processed": false}
{"id": "hn_story_46732705", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732705", "title": "Show HN: A Better Interface for Nano Banana Pro", "text": "Hey HN ,<p>This started as a weekend project after using Nano Banana Pro a lot and getting frustrated with Gemini&#x27;s UI (no folder organization, a sluggish UI, etc.).<p>So I built Nani (<a href=\"https:&#x2F;&#x2F;getnani.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;getnani.com&#x2F;</a>). Still powered by Nano Banana Pro, but it focuses on the workflow Gemini is missing:<p>- Folders to organize generations\n- Image-sets and prompt-sets to save styles and references once and reuse them\n- A fast UI\n- Drag-and-drop so you can pull previous results back in as references for quick iteration<p>I&#x27;m genuinely looking for feedback from people who actually use Gemini and Nano Banana Pro regularly. To make that easier, I made the app free to try with 5 credits and no credit card required. Some questions that come to mind:<p>- Does this match your experience?\n- Anything else in your workflow that feels unnecessarily painful that can be improved upon?<p>Happy to answer any other questions as well. If anyone&#x27;s interested in the tech stack and how this was built, happy to share more details.", "author": "iqen93", "timestamp": "2026-01-23T14:12:35+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:45.610877+00:00", "processed": false}
{"id": "hn_story_46732672", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732672", "title": "Show HN: FreeMotion \u2013 Browser-based Remotion editor with site scraping record", "text": "Hello HN,<p>I\u2019ve been experimenting with the recent Remotion + Claude Code workflow. While generating video code with LLMs is impressive, the feedback loop felt broken to me. You have to prompt, copy code, set up a local Node environment, install dependencies, and run ffmpeg just to see a 5-second preview.<p>I built FreeMotion (<a href=\"https:&#x2F;&#x2F;freemotion.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;freemotion.dev</a>) to move this entire workflow into the browser.<p>It is a free, online editor specifically designed to close the loop between &quot;Prompting&quot; and &quot;Rendering&quot;.<p>The core problems I tried to solve:<p>Environment Friction: Running Remotion locally requires setup. I wanted a zero-config, &quot;paste and play&quot; environment directly in the browser.<p>The &quot;Generic&quot; Look: LLMs usually generate generic CSS. I built a scraper that extracts computed styles from your live website URL so the video inherits your brand identity automatically.<p>Asset Management: Instead of juggling OBS or local screenshots, I integrated a recorder&#x2F;snapshot tool directly into the editor to feed assets to the video.<p>How it works:<p>It runs a web-based player for Remotion.<p>The &quot;Agentic&quot; aspect: It generates optimized system prompts for you to feed Claude&#x2F;LLMs, ensuring the output code is compatible with the web player.<p>Styling: It injects your site&#x27;s color palette and fonts into the React components dynamically.<p>It\u2019s completely free to use. I built this to make the &quot;text-to-video-code&quot; workflow actually usable for quick iterations.<p>I\u2019d love to hear your feedback on the CSS extraction accuracy and the editor performance.", "author": "lococococo", "timestamp": "2026-01-23T14:10:44+00:00", "score": 8, "num_comments": 4, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:45.733470+00:00", "processed": false}
{"id": "hn_comment_46734515", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46734515", "title": "Re: Ask HN: How realistically far are we from AGI?...", "text": "We need to define terms precisely first and the industry seems allergic to that, likely because precise terms would undermine hype marketing necessary for companies like Anthropic to justify their valuations.<p>We need clear definitions and clear ways of evaluating toward those definitions, as human evaluation of LLM is rife with projection.<p>Generally speaking, scaling is clearly not going to get LLMs there, and a lot of the gains over the past year or so have been either related to reasoning or domain-specific training and application.<p>I do think world models are the future and we\u2019ll likely see some initial traction toward that end this year. Frontier AI labs will have to prove they can run sustainable businesses in pursuit of the next stage though, so I\u2019d anticipate at least one major lab goes defunct or gets acquired. It may very well be that the labs that brush up against AGI according to conventional definitions are still nascent stage. And there\u2019s a distinct possibility of another AI winter if none of the current labs can prove sustainable businesses on the back of LLMs.<p>I think a lot of the west is undergoing the early stages of a Kuhnian paradigm shift in many ways, so I\u2019ve found it difficult to take the signaling from the macro environment and put it to work in my decision making.", "author": "SirensOfTitan", "timestamp": "2026-01-23T16:36:18+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-23T17:18:47.345312+00:00", "processed": false}
{"id": "hn_story_46732416", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732416", "title": "Show HN: CCB-Orchestrate Claude, Codex,Gemini in Tmux panes with cross calling", "text": "", "author": "bfly123", "timestamp": "2026-01-23T13:46:02+00:00", "score": 1, "num_comments": 1, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-23T17:18:47.529754+00:00", "processed": false}
{"id": "hn_comment_46732433", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732433", "title": "Re: Show HN: CCB-Orchestrate Claude, Codex,Gemini in T...", "text": "Hi HN,<p><pre><code>  Different models and CLI tools have their own strengths, but we are often forced to choose just one, or rely on hidden &quot;agentic&quot; API calls that are opaque and hard to control.\n\n  I built CCB to solve this. It lets you freely combine different CLIs (Claude Code,\n  Gemini, Codex, OpenCode, Droid) and mount them into Tmux split panes with a single command.\n\n  It solves the &quot;single model tunnel vision&quot; by enabling stable interaction between them. You can use natural language in one CLI (e.g., Claude) to delegate tasks to other visible CLIs and get results back.\n\n  For example:\n   * You can ask Claude to design a feature.\n   * Claude can then explicitly instruct Gemini (in the adjacent pane) to read the docs or review the plan.\n   * You see everything happen in real-time across the splits.\n\n\n  Feedback and PRs are welcome!</code></pre>", "author": "bfly123", "timestamp": "2026-01-23T13:48:06+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:47.576936+00:00", "processed": false}
{"id": "hn_comment_46732669", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46732669", "title": "Re: Show HN: ARM64-optimized prime sieve with 3.75x me...", "text": "Hi HN,I\u2019m a graphic designer and artist by background, but I\u2019ve always been fascinated by patterns. I spent some time visualizing prime number distributions on paper and arrived at a geometric layout that felt very efficient for memory.With some help from AI (Gemini&#x2F;ChatGPT), I translated this into C++. The speedup (~3.1x on M1) isn&#x27;t from new math, but from optimizing how data sits in the cache. It uses an 8-pipe wheel ($H=30$) packed into a single byte to reduce memory traffic.I&#x27;m sharing this for a sanity check from the systems&#x2F;HPC community. Would love to hear if this approach to memory locality is something you&#x27;ve seen before or if there&#x27;s room to push it further.Benchmarks and the original paper sketch are in the repo. Thanks!", "author": "amadeapewe", "timestamp": "2026-01-23T14:10:30+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-23T17:18:47.746065+00:00", "processed": false}
{"id": "hn_comment_46731938", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46731938", "title": "Re: I Guess AI Works...", "text": "Late last year, during a couple of days off from my full-time job, I was on a walk with a friend who happened to be job hunting. She was venting about how dreadful the whole process of applying to jobs online can be: the CV mess, tailoring it for each role, filling out the same forms over and over, keeping track of everything, not accidentally sending a cover letter with the wrong company name - all of that. I\u2019ve been there, and anyone who\u2019s applied to jobs online has probably been there too.<p>So I turned to AI to build a small product that could help. As someone who hasn\u2019t coded in years, my process was:\n- used ChatGPT deep research to find key requirements and to search the web for specific topics\u2014papers, reddit posts, and so on.\n- took the research and key points to Cursor and asked it to propose an implementation plan. My goal is a phased plan I can copy&#x2F;paste and execute.\n- then, used Lovable to start development based on those phases. After I have something working, I go back to Cursor.<p>I review the code, test to see if it works, and then bounce between Lovable and Cursor to fix bugs.<p>After some back-and-forth\u2014testing, iterating, and second-guessing, I decided to launch. My audiences on social media are small, and linkedin felt like the best place to start, since it\u2019s where so many people go when they\u2019re job hunting. I got 65 signups in the first 24 hours, which sounds tiny, but it meant the world to me. I couldn&#x27;t believe real humans cared to test and use (and return to) my little AI product.<p>I\u2019m posting here in the hopes of getting more testers. The feedback I received from some of those first 65 users was invaluable, and I\u2019m now in the trenches iterating and shipping fixes. I&#x27;m really confident the product is in good shape for anyone doing tailored applications and looking to save time.<p>It would mean the world if any of you could test it and provide your thoughts. It\u2019s free (up to 3 tailored CVs, infinite auto-fill applications), and I\u2019m happy to retribute the support however it fits (reviewing CVs, making intros, helping with applications).", "author": "inesbarros1", "timestamp": "2026-01-23T12:57:33+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone", "navigation"], "sentiment": null, "collected_at": "2026-01-23T17:18:52.485091+00:00", "processed": false}
{"id": "hn_comment_46731747", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46731747", "title": "Re: Show HN: Terminal MCP \u2013 Browser MCP for the Termin...", "text": "Inspired by tools like &quot;Browser MCP&quot;, I wanted a way for LLMs to see my CLI&#x2F;TUI applications during testing&#x2F;debugging to help me troubleshoot issues quickly. Yes, LLMs can already spawn terminals on their own, however this allows both you and the LLM to interact concurrently.<p>There are other creative uses for it... like I can get Claude Code to use the full Gemini or Codex CLIs and ask for help on a problem. Others have pointing out achieving similar results via tmux, however my approach is simpler without that extra layer.", "author": "e-clinton", "timestamp": "2026-01-23T12:36:01+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:18:54.600189+00:00", "processed": false}
{"id": "hn_story_46730382", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46730382", "title": "Show HN: Thalo \u2013 A \"programming\" language for structured knowledge", "text": "Hi HN, I&#x27;ve been building Thalo, a plain-text format for structured knowledge. It&#x27;s designed to be human-readable and version-controlled, while giving tools and AI just enough structure to work with it. It&#x27;s inspired by plain-text accounting tools such as Beancount.<p>The format is simple: you define your entities (e.g. opinions, book reviews, facts) including type definitions for metadata fields. Then you write entries that the CLI validates against your schema. The value is the feedback loop: LLMs can easily extract information from unstructured text, but they need validation to make the data high quality. Thalo&#x27;s &quot;compiler&quot; provides these rules.<p>Example:<p><pre><code>  2026-01-08T14:30Z create book-review &quot;Designing Data-Intensive Applications&quot; ^ddia #book \n    rating: &quot;5&quot; \n    author: &quot;Martin Kleppmann&quot;\n\n    # Summary\n    The definitive guide to distributed systems and data architecture. Dense but essential.\n</code></pre>\n(In this example, ^ddia is a stable link identifier that can be used to reference this entry)<p>It&#x27;s really up to the user how to use it. Some ways I&#x27;m using it:<p>- End of day journaling: blurt out thoughts, let AI extract insights, facts.<p>- Organizing my knowledge: using previous &quot;content&quot; I&#x27;ve written (blog posts, websites, my CV) to extract insights.<p>- Processing commits I&#x27;ve made to keep a living record of my work.<p>Because it&#x27;s all plain-text, it allows you to open your knowledge base in any text editor or in Claude Code to do agentic search and analysis. I hooked up a simple Telegram bot to answer questions.<p>The tooling includes a CLI for validation, an LSP with completions and go-to-definition, a VS Code extension, and a Prettier plugin. There&#x27;s also a simple scripting API that allows you to loop over entries and use the visitor pattern to traverse your knowledge base or write new rules.<p>I&#x27;d love to hear what use cases people come up with. Let me know what you think!<p>- Code (MIT): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;rejot-dev&#x2F;thalo\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;rejot-dev&#x2F;thalo</a><p>- Landing Page: <a href=\"https:&#x2F;&#x2F;thalo.rejot.dev\">https:&#x2F;&#x2F;thalo.rejot.dev</a>", "author": "WilcoKruijer", "timestamp": "2026-01-23T09:29:42+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-23T17:19:04.184698+00:00", "processed": false}
