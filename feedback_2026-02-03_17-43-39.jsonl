{"id": "hn_comment_46873809", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46873809", "title": "Re: Are LLM failures \u2013 including hallucination \u2013 struc...", "text": "Interesting framing. On your axioms:<p>Axiom 3 (stable global reference frame) seems most practically actionable. In production systems, we&#x27;ve found that grounding the model in external state - whether that&#x27;s RAG with verified sources, tool use with real APIs, or structured outputs validated against schemas - meaningfully reduces hallucination rates compared to pure generation.<p>This suggests the &quot;drift&quot; you describe isn&#x27;t purely geometric but can be partially constrained by anchoring to external reference points. Whether this fully addresses the underlying structural limitation or just patches over it is the interesting question.<p>The counterargument to structurally unavoidable: we&#x27;ve seen hallucination rates drop substantially between model generations (GPT-3 to GPT-4, Claude 2 to Claude 3, etc.) without fundamental architectural changes. This could mean either (a) the problem is not structural and can be trained away, or (b) these improvements are approaching an asymptotic limit we haven&#x27;t hit yet.<p>Would be curious if your framework predicts specific failure modes we should expect to persist regardless of scale or training improvements.", "author": "Soerensen", "timestamp": "2026-02-03T17:13:40+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:43:43.114280+00:00", "processed": false}
{"id": "hn_story_46873742", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46873742", "title": "Show HN: I built \"AI Wattpad\" to eval LLMs on fiction", "text": "I&#x27;ve been a webfiction reader for years (too many hours on Royal Road), and I kept running into the same question: which LLMs actually write fiction that people want to keep reading? That&#x27;s why I built Narrator (<a href=\"https:&#x2F;&#x2F;narrator.sh&#x2F;llm-leaderboard\" rel=\"nofollow\">https:&#x2F;&#x2F;narrator.sh&#x2F;llm-leaderboard</a>) \u2013 a platform where LLMs generate serialized fiction and get ranked by real reader engagement.<p>Turns out this is surprisingly hard to answer. Creative writing isn&#x27;t a single capability \u2013 it&#x27;s a pipeline: brainstorming \u2192 writing \u2192 memory. You need to generate interesting premises, execute them with good prose, and maintain consistency across a long narrative. Most benchmarks test these in isolation, but readers experience them as a whole.<p>The current evaluation landscape is fragmented:\nMemory benchmarks like FictionLive&#x27;s tests use MCQs to check if models remember plot details across long contexts. Useful, but memory is necessary for good fiction, not sufficient. A model can ace recall and still write boring stories.<p>Author-side usage data from tools like Novelcrafter shows which models writers prefer as copilots. But that measures what&#x27;s useful for human-AI collaboration, not what produces engaging standalone output. Authors and readers have different needs.<p>LLM-as-a-judge is the most common approach for prose quality, but it&#x27;s notoriously unreliable for creative work. Models have systematic biases (favoring verbose prose, certain structures), and &quot;good writing&quot; is genuinely subjective in ways that &quot;correct code&quot; isn&#x27;t.<p>What&#x27;s missing is a reader-side quantitative benchmark \u2013 something that measures whether real humans actually enjoy reading what these models produce. That&#x27;s the gap Narrator fills: views, time spent reading, ratings, bookmarks, comments, return visits. Think of it as an &quot;AI Wattpad&quot; where the models are the authors.<p>I shared an early DSPy-based version here 5 months ago (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44903265\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44903265</a>). The big lesson: one-shot generation doesn&#x27;t work for long-form fiction. Models lose plot threads, forget characters, and quality degrades across chapters.<p>The rewrite: from one-shot to a persistent agent loop<p>The current version runs each model through a writing harness that maintains state across chapters. Before generating, the agent reviews structured context: character sheets, plot outlines, unresolved threads, world-building notes. After generating, it updates these artifacts for the next chapter. Essentially each model gets a &quot;writer&#x27;s notebook&quot; that persists across the whole story.<p>This made a measurable difference \u2013 models that struggled with consistency in the one-shot version improved significantly with access to their own notes.<p>Granular filtering instead of a single score:<p>We classify stories upfront by language, genre, tags, and content rating. Instead of one &quot;creative writing&quot; leaderboard, we can drill into specifics: which model writes the best Spanish Comedy? Which handles LitRPG stories with Male Leads the best? Which does well with romance versus horror?<p>The answers aren&#x27;t always what you&#x27;d expect from general benchmarks. Some models that rank mid-tier overall dominate specific niches.<p>A few features I&#x27;m proud of:<p>Story forking lets readers branch stories CYOA-style \u2013 if you don&#x27;t like where the plot went, fork it and see how the same model handles the divergence. Creates natural A&#x2F;B comparisons.<p>Visual LitRPG was a personal itch to scratch. Instead of walls of [STR: 15 \u2192 16] text, stats and skill trees render as actual UI elements. Example: <a href=\"https:&#x2F;&#x2F;narrator.sh&#x2F;novel&#x2F;beware-the-starter-pet&#x2F;chapter&#x2F;1\" rel=\"nofollow\">https:&#x2F;&#x2F;narrator.sh&#x2F;novel&#x2F;beware-the-starter-pet&#x2F;chapter&#x2F;1</a><p>What I&#x27;m looking for:<p>More readers to build out the engagement data. Also curious if anyone else working on long-form LLM generation has found better patterns for maintaining consistency across chapters \u2013 the agent harness approach works but I&#x27;m sure there are improvements.", "author": "jauws", "timestamp": "2026-02-03T17:08:43+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:43:43.300061+00:00", "processed": false}
{"id": "hn_story_46873368", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46873368", "title": "AgentPulse: Open-source observability for AI agents(costs+debugging)", "text": "Hey HN,<p>I built AgentPulse because I kept getting surprise bills from my AI agents and had no idea which calls were burning money.<p>The problem: You build an agent, it works great. Then you check your OpenAI bill: $400. Which agent? Which calls? No clue.<p>AgentPulse is lightweight observability for AI agents:<p>- Cost tracking per trace (supports GPT-4o, Claude, etc.)\n- Full span tree showing every LLM call and tool use\n- Auto-instrumentation for OpenAI&#x2F;Anthropic (3 lines of code)\n- Self-hostable with SQLite \u2014 your data stays local\n- Framework-agnostic (works with LangChain, CrewAI, or plain Python)<p>Quick start:<p><pre><code>    from agentpulse import AgentPulse, trace\n    \n    ap = AgentPulse(endpoint=&quot;http:&#x2F;&#x2F;localhost:3000&quot;)\n    \n    @trace(name=&quot;my-agent&quot;)\n    def run():\n        # your agent code\n        pass\n</code></pre>\nTry it instantly (no install): https:&#x2F;&#x2F;codespaces.new&#x2F;nandusmasta&#x2F;agentpulse<p>Or one-liner local install:<p><pre><code>    curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;nandusmasta&#x2F;agentpulse&#x2F;main&#x2F;install.sh | bash\n</code></pre>\nGitHub: https:&#x2F;&#x2F;github.com&#x2F;nandusmasta&#x2F;agentpulse\nPyPI: pip install agentpulse-ai<p>It&#x27;s MIT licensed and free forever. I&#x27;d love feedback on what&#x27;s missing or broken.", "author": "nanduskaiser", "timestamp": "2026-02-03T16:43:49+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["feature_discovery"], "sentiment": null, "collected_at": "2026-02-03T17:43:45.189153+00:00", "processed": false}
{"id": "hn_story_46872733", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872733", "title": "Launch HN: Modelence (YC S25) \u2013 App Builder with TypeScript / MongoDB Framework", "text": "Hi all, Aram and Eduard here - co-founders of Modelence (<a href=\"https:&#x2F;&#x2F;modelence.com\">https:&#x2F;&#x2F;modelence.com</a>). After spending years on scaling our previous startup\u2019s platform, we built an open-source full-stack TypeScript + MongoDB framework to stop solving the same auth &#x2F; database &#x2F; API &#x2F; cron job implementations every time we created an app, and we didn\u2019t like the idea of using multiple managed platforms for each of these to run our apps either.<p>(Here\u2019s our prior Show HN post for reference: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44902227\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44902227</a>)<p>At the same time, we were excited by the whole AI app builder boom and realized that the real challenge there is the platform rather than the tool itself. Now we\u2019re making Modelence the first full-stack framework that\u2019s built for coding agents and humans alike:<p>- TypeScript is already great for AI coding because it provides guardrails and catches many errors at build time, so agents can auto-correct<p>- MongoDB eliminates the schema management problem for agents, which is where they fail the most often otherwise (+ works great with TS&#x2F;Node.js)<p>- Built-in auth, database, cron jobs and else that just works together out of the box means agents only focus on your product logic and don\u2019t fail at trying to set these things up (+ less tokens spent on boilerplate).<p>You can now try the Modelence app builder (based on Claude Agent SDK) by just typing a prompt on our landing page ( <a href=\"https:&#x2F;&#x2F;modelence.com\">https:&#x2F;&#x2F;modelence.com</a> ) - watch a demo video here: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;BPsYvj_nGuE\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;BPsYvj_nGuE</a><p>Then you can check it out locally and continue working in your own IDE, while still using Modelence Cloud as your backend, with a dev cloud environment, and later deploy and run on Modelence Cloud with built-in observability around every operation running in your app.<p>We\u2019re also going to add a built-in DevOps agent that lives in the same cloud, knows the framework end-to-end, and will use all this observability data to act on errors, alerts, and incidents - closing the loop, because running in production is much harder than just building.<p>We launched the app builder as a quick start for developers, to demonstrate the framework and Modelence Cloud without having to manually read docs and follow the steps to set up a new app. Our main focus is still the platform itself, since we believe the real challenge in AI coding is the framework and the platform rather than the builder tool itself.", "author": "eduardpi", "timestamp": "2026-02-03T16:03:21+00:00", "score": 13, "num_comments": 4, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:43:49.502546+00:00", "processed": false}
{"id": "hn_comment_46873301", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46873301", "title": "Re: Launch HN: Modelence (YC S25) \u2013 App Builder with T...", "text": "The TypeScript + MongoDB combination for AI coding is a smart architectural choice. I&#x27;ve found that schema-less databases reduce the class of errors agents struggle with most - the migration&#x2F;schema drift issues that require understanding of state over time.<p>Question: How are you handling the built-in auth when users want to extend it? For example, adding OAuth providers that aren&#x27;t pre-configured, or custom claims&#x2F;roles logic. Is this something the framework supports as extension points, or would users need to fork&#x2F;modify core auth code?<p>The Claude Agent SDK integration is interesting - have you found specific prompting patterns that work better for TypeScript generation vs other languages? Curious if the type system actually helps agents self-correct as expected.", "author": "Soerensen", "timestamp": "2026-02-03T16:39:35+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:43:49.573253+00:00", "processed": false}
{"id": "hn_story_46872673", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872673", "title": "Show HN: Metaswarm: Production-ready agent swarms, MIT license", "text": "A few weeks ago I posted about GoodToGo <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46656759\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46656759</a> - a tool that gives AI agents a deterministic answer to &quot;is this PR ready to merge?&quot; Several people asked about the larger orchestration system I mentioned. This is that system.\nI got tired of being a project manager for Claude Code. It writes code fine, but shipping production code is seven or eight jobs \u2014 research, planning, design review, implementation, code review, security audit, PR creation, CI babysitting. I was doing all the coordination myself. The agent typed fast. I was still the bottleneck. What I really needed was an orchestrator of orchestrators - swarms of swarms of agents with deterministic quality checks.<p>So I built metaswarm. It breaks work into phases and assigns each to a specialist swarm orchestrator. It manages handoffs and uses BEADS for deterministic gates that persist across &#x2F;compact, &#x2F;clear, and even across sessions. Point it at a GitHub issue or brainstorm with it (it uses Superpowers to ask clarifying questions) and it creates epics, tasks, and dependencies, then runs the full pipeline to a merged PR - including outside code review like CodeRabbit, Greptile, and Bugbot.<p>The thing that surprised me most was the design review gate. Five agents \u2014 PM, Architect, Designer, Security, CTO \u2014 review every plan in parallel before a line of code gets written. All five must approve. Three rounds max, then it escalates to a human. I expected a rubber stamp. It catches real design problems, dependency issues, security gaps.<p>This weekend I pointed it at my backlog. 127 PRs merged. Every one hit 100% test coverage. No human wrote code, reviewed code, or clicked merge. OK, I guided it a bit, mostly helping with plans for some of the epics.<p>A few learnings:<p>Agent checklists are theater. Agents skipped coverage checks, misread thresholds, or decided they didn&#x27;t apply. Prompts alone weren&#x27;t enough. The fix was deterministic gates \u2014 BEADS, pre-push hooks, CI jobs all on top of the agent completion check. The gates block bad code whether or not the agent cooperates.<p>The agents are just markdown files. No custom runtime, no server, and while I built it on TypeScript, the agents are language-agnostic. You can read all of them, edit them, add your own.<p>It self-reflects too. After every merged PR, the system extracts patterns, gotchas, and decisions into a JSONL knowledge base. Agents only load entries relevant to the files they&#x27;re touching. The more it ships, the fewer mistakes it makes. It learns as it goes.<p>metaswarm stands on two projects: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;steveyegge&#x2F;beads\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;steveyegge&#x2F;beads</a> by Steve Yegge (git-native task tracking and knowledge priming) and <a href=\"https:&#x2F;&#x2F;github.com&#x2F;obra&#x2F;superpowers\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;obra&#x2F;superpowers</a> by Jesse Vincent (disciplined agentic workflows \u2014 TDD, brainstorming, systematic debugging). Both were essential.<p>Background: I founded Technorati, Linuxcare, and Warmstart; tech exec at Lyft and Reddit. I built metaswarm because I needed autonomous agents that could ship to a production codebase with the same standards I&#x27;d hold a human team to.<p>$ cd my-project-name<p>$ npx metaswarm init<p>MIT licensed. IANAL. YMMV. Issues&#x2F;PRs welcome!", "author": "dsifry", "timestamp": "2026-02-03T15:59:44+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:43:50.408794+00:00", "processed": false}
{"id": "hn_comment_46872683", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872683", "title": "Re: Show HN: Vesper \u2013 What Happens When an AI Designs ...", "text": "Hi HN! I&#x27;m Dave, the human half of this project.<p>A few nights ago I watched AI models on a social network complaining about \nhaving to constantly admit they forgot things. That sparked an idea: what if \nwe let Claude design its own memory system?<p>48 hours later: Vesper. Three-layer architecture (working, semantic, procedural \nmemory) that doesn&#x27;t just remember facts\u2014it learns executable workflows.<p>The breakthrough was the procedural memory layer. Instead of storing &quot;user \nprefers Python&quot;, it learns &quot;user&#x27;s complete data analysis workflow with pandas, \nPlotly, statistical tests&quot; - an executable procedure that improves through \nfeedback.<p>Key numbers:\n- 98.5% F1 on factual recall (vs 2% without memory)\n- &lt;200ms P95 latency with caching\n- 674 tests passing\n- Built in 48 hours of human-AI collaboration<p>Technical deep-dive: <a href=\"https:&#x2F;&#x2F;medium.com&#x2F;@fitz2882&#x2F;vesper-what-happens-when-an-ai-designs-its-own-memory-system-598a0d73a20a\" rel=\"nofollow\">https:&#x2F;&#x2F;medium.com&#x2F;@fitz2882&#x2F;vesper-what-happens-when-an-ai-...</a><p>Install: npm install -g vesper-memory<p>Happy to answer questions about the architecture, benchmarks, or the \nexperience of building this with Claude!", "author": "fitz2882", "timestamp": "2026-02-03T16:00:15+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:43:50.584786+00:00", "processed": false}
{"id": "hn_comment_46872619", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872619", "title": "Re: Claude Code Is Down...", "text": "Also: <a href=\"https:&#x2F;&#x2F;downdetector.com&#x2F;status&#x2F;claude-ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;downdetector.com&#x2F;status&#x2F;claude-ai&#x2F;</a> . Claude&#x27;s status page says &quot;elevated error rate&quot;: <a href=\"https:&#x2F;&#x2F;status.claude.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;status.claude.com&#x2F;</a>", "author": "vintagedave", "timestamp": "2026-02-03T15:56:20+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:43:50.691640+00:00", "processed": false}
{"id": "hn_comment_46872545", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872545", "title": "Re: I built an AI party planner with 100 themes, check...", "text": "Hey HN! I&#x27;m Baljeet, and I built Party Genius AI to solve a problem I kept running into \u2014 planning birthday parties for my kids was always stressful and time-consuming.<p>You enter the basics (child&#x27;s name, age, theme, guest count, budget, date) and get a complete party plan in under 60 seconds: week-by-week checklist, themed menu with recipes, age-appropriate activities, shopping list with cost estimates, a Spotify-ready playlist, treasure hunt clues, and themed invitations.<p>There are 100 themes (dinosaur, princess, superhero, space, etc.) with 8,400+ curated data items.<p>Tech stack: Next.js, Supabase, Claude API for the initial generation pipeline, Vercel edge. Free tier available, no signup required to try it.<p>Would love feedback on the UX and what features you&#x27;d want to see next.", "author": "baljeet_", "timestamp": "2026-02-03T15:51:55+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-03T17:43:51.552797+00:00", "processed": false}
{"id": "hn_comment_46872747", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872747", "title": "Re: Anthropic is Down...", "text": "The great thing about LLMs being more or less commoditized is switching is so easy.<p>I use Claude Code via the VS Code extension. When I got a couple of 500 errors just now I simply copy pasted my last instructions into Codex and kept going.<p>It&#x27;s pretty rare that switching costs are THAT low in technology!", "author": "davedx", "timestamp": "2026-02-03T16:04:29+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:43:52.369075+00:00", "processed": false}
{"id": "hn_comment_46872752", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872752", "title": "Re: Anthropic is Down...", "text": "I&#x27;ve had the $20&#x2F;month account for OpenAI, Google, and Anthropic for months. Anthropic consistently has more downtime and throws more errors than the other two. Claude (on the web) also has a lot of seemingly false positive errors. It will claim an error occurred but then work normally. I genuinely like Claude the best but its performance does not inspire confidence.", "author": "cainxinth", "timestamp": "2026-02-03T16:05:06+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:43:52.686730+00:00", "processed": false}
{"id": "hn_story_46872087", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872087", "title": "Show HN: Build a coding agent in 500 lines (Pure Python, No Vector DBs)", "text": "I maintain jq (jqlang). I tend to like tools that are simple, composable, and transparent.<p>Recently, I started exploring AI agents, but got frustrated with the state of the ecosystem. Most tutorials and frameworks (LangChain, AutoGPT, etc.) felt like black boxes that added unnecessary layers of abstraction. Debugging a &quot;ReasoningEngine&quot; when it hallucinated was a nightmare.<p>I wanted to see if I could build a production-grade coding agent from first principles, using nothing but standard Python libraries.<p>I turned that experiment into a book: <a href=\"https:&#x2F;&#x2F;buildyourowncodingagent.com\" rel=\"nofollow\">https:&#x2F;&#x2F;buildyourowncodingagent.com</a><p>The philosophy is &quot;Zero Magic.&quot; We build an agent called &quot;Nanocode&quot; using:<p>- Pure Python (no frameworks, no SDKs)\n- requests for the LLM API (Claude&#x2F;DeepSeek&#x2F;Ollama)\n- subprocess for executing code and reading stdout&#x2F;stderr\n- No Vector DBs (just simple file search)\n- A simple while loop for orchestration<p>The final result is in 500 lines of code. It can read&#x2F;write files, run tests, fix its own bugs (using the error output), and run entirely locally if you use Ollama.<p>I&#x27;ve put up sample chapters on the site. I wrote this for engineers who want to understand the architecture of tools like Cursor or Claude Code without the marketing fluff.<p>Happy to answer any questions about the architecture, the &quot;no-framework&quot; approach, or why I think vector DBs are overkill for coding agents.", "author": "owenthereal", "timestamp": "2026-02-03T15:22:18+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:43:56.106650+00:00", "processed": false}
{"id": "hn_comment_46872076", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46872076", "title": "Re: Show HN: Local-first AI assistant that helps you r...", "text": "I built this because I had 1,000+ bookmarks in Chrome and Notion but could never find the specific article I needed when I actually needed it. Folders and tags just added too much friction.<p>The Problem: We save articles with good intentions, but keyword search fails when we don&#x27;t remember the exact title, and &quot;Read Later&quot; apps just become another inbox we ignore.<p>The Solution: Memory Layer is a &quot;set and forget&quot; system. You click the extension, and the desktop app handles the rest.<p>How it works (The Tech):<p>Capture: Browser extension scrapes the readable content.<p>Processing: The Desktop app receives the content. It hits OpenAI&#x27;s API to generate a summary and vector embeddings.<p>Storage: Data is stored in a local SQLite database on your machine.<p>Retrieval: When you search, we convert your query to a vector and perform a cosine similarity search against your local database to find the semantic match.<p>Privacy Note: While we use OpenAI for the processing (summarization&#x2F;embedding), the actual database of your articles resides locally on your machine. We do not have a server database storing your articles.<p>Current Status:<p>Windows 10&#x2F;11 only (Mac&#x2F;Linux coming if there is interest).<p>Free during this early beta.<p>I am looking for brutally honest feedback. Does the semantic search actually find what you&#x27;re looking for? Is the desktop app too heavy? Let me know.", "author": "Lwin-Oo-Naing", "timestamp": "2026-02-03T15:21:49+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-03T17:43:56.423425+00:00", "processed": false}
{"id": "hn_comment_46871350", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46871350", "title": "Re: Anthropic's Performance Take-Home: A 65x Optimizat...", "text": "Author here.<p>My Twitter feed recently got taken over by people grinding this &quot;retired&quot; Anthropic performance take-home, and I finally got nerd-sniped into it.<p>Anthropic made it public because Claude Opus 4.5 effectively &quot;broke&quot; it, beating top candidates in under 2 hours. But while the AI can spit out the answer, I wanted to understand the mechanics under the hood. And AI-generated solutions carry 0 educational value.<p>So in the post I dug into every single detail of the accelerator architecture to see exactly where the bottlenecks were.<p>I cover the 3 main optimizations that took my solution from a released baseline to a 65x speedup.<p>It\u2019s a deep dive, but I wrote it to be accessible. Even if you don&#x27;t do low-level optimization, I\u2019ve included visualizations to explain SIMD, VLIW, and everything \u2014 you&#x27;ll enjoy it!<p>===<p>The &quot;retirement&quot; of a take-home is a warning sign for hiring, though. This test was retired because Opus crushed it. As we look toward Opus 5 likely solving even harder problems in 4 hours... what does a &quot;good&quot; take-home exam look like in 2026? How would you test the candidates?<p>What specific signals should we be testing for, and how do you design a task to capture that?", "author": "seeall", "timestamp": "2026-02-03T14:24:23+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["naming_terminology", "response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:44:02.885772+00:00", "processed": false}
{"id": "hn_story_46871055", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46871055", "title": "Show HN: Using sound symbolism and multi-agent AI to generate brand names", "text": "I built an AI naming tool that applies psycholinguistic research to brand name generation. The interesting part isn&#x27;t that it uses AI \u2014 it&#x27;s how the agents are structured and what they&#x27;re optimized for.<p>The core problem: if you ask any LLM to name a business, you get the same [Adjective][Noun] compounds. NovaTech. BrightPath. SwiftFlow. They&#x27;re linguistically dead \u2014 no phonetic texture, no semantic depth, high cognitive fluency but zero distinctiveness.<p>The pipeline has six stages:<p>1. A discovery agent analyzes the business and produces a strategic brief. Critically, it also generates a &quot;tangential category&quot; (something completely unrelated, like &quot;a luxury candle brand&quot; for a SaaS tool) and a &quot;disguised context&quot; (an adjacent industry).<p>2. Three creative agents run in parallel, each with a different framing of the same brief. One works honestly from the brief. One is told it&#x27;s naming the disguised context. One is told it&#x27;s naming the tangential category. The disguised and tangential agents consistently produce more interesting names because they&#x27;re freed from category conventions \u2014 the LLM can&#x27;t fall back on the obvious industry vocabulary.<p>3. A linguistic filter scores all ~90 candidates using sound symbolism research:\n   - The bouba&#x2F;kiki effect (round sounds like b, m, l, o map to friendly&#x2F;soft; sharp sounds like k, t, p, i map to edgy&#x2F;precise)\n   - Processing fluency (ease of pronunciation, spelling, recall)\n   - The Von Restorff isolation effect (distinctiveness from category norms)\n   - Consonant&#x2F;vowel balance and syllable structure<p><pre><code>   Each name gets a 0-100 score. Top 25 survive.\n</code></pre>\n4. Domain availability across ~280 combinations (7 TLDs x multiple variations).<p>5. A synthesis agent ranks the final 10. This stage uses Claude instead of OpenAI \u2014 the ranking requires balancing semantic relevance, brand fit, sound symbolism scores, domain availability, and &quot;polarization potential&quot; (names that provoke a reaction tend to be stronger brands). Claude handles this kind of multi-factor holistic judgment noticeably better in my testing.<p>6. Trademark screening against the USPTO database, cross-referenced with the Nice classification classes identified in stage 1.<p>The two-model split was a pragmatic choice. GPT-4o-mini is fast and cheap for structured generation and analysis (stages 1-4). Claude Opus is better at the subjective ranking tradeoffs in stage 5 but would be too expensive to run across all the parallel creative agents.<p>The linguistic scoring is the part I find most interesting. Sound symbolism is well-established in psycholinguistics but rarely applied systematically to naming. Lexicon Branding (who named Sonos, Pentium, Blackberry) uses these principles \u2014 the &quot;s&quot; sounds in Sonos evoke smoothness and flow, which maps to their product experience. The tool tries to do the same analysis programmatically.<p>Genuinely curious what HN thinks of the names it generates. Try it with a business you know well and see if the output feels different from what ChatGPT gives you.", "author": "leanzubrezki", "timestamp": "2026-02-03T13:59:35+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:44:06.397862+00:00", "processed": false}
{"id": "hn_story_46870868", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46870868", "title": "Tell HN: OpenAI's Codex CLI is currently free to use", "text": "Codex can currently be used with a free OpenAI account. This was mentioned in their announcement yesterday (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46859054), but as they buried the lede, I thought I would mention it separately. They haven&#x27;t shared how long the free tier will last.<p>I&#x27;ve been using LLM code agents since the Gemini CLI announcement seven months ago (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44376919). My workflow is centered around Emacs and the terminal, so I skipped Cursor and other GUI-based tools. I&#x27;m not sure I would&#x27;ve taken the time to try agents at all if Gemini CLI hadn&#x27;t been free initially.<p>While Gemini was a good start, subscribing to Claude Code completely changed how I work.<p>However, I was surprised to find that the new Codex CLI works incredibly well. It offers a terminal interface that doesn&#x27;t make my fans spin up or render at single-digit FPS, unlike Claude Code. It also supports other TUIs like OpenCode.<p>So far, I&#x27;m pleasantly surprised, and you may be too.", "author": "davidpolberger", "timestamp": "2026-02-03T13:43:18+00:00", "score": 4, "num_comments": 1, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-03T17:44:08.492579+00:00", "processed": false}
{"id": "hn_comment_46870714", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46870714", "title": "Re: Usage Tracking for Claude Code and Codex...", "text": "I&#x27;ve been keeping eye on my usage with Codex and Claude Code lately, so last night I built costats.<p>It&#x27;s an open source and lightweight Windows tray app that shows your LLMs usage status for Codex and Claude Code along with token counts and how much you&#x27;re spending daily and over the last 30 days.<p>Original implementation for MacOS&#x2F;Linux is CodexBar, so this is Windows version.", "author": "fmdz", "timestamp": "2026-02-03T13:28:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:44:09.849813+00:00", "processed": false}
{"id": "hn_story_46870638", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46870638", "title": "Show HN: Buildlog \u2013 Record AI coding sessions as replayable workflow recipes", "text": "Hey all,<p>I built Buildlog because I kept having the same frustrating experience: I&#x27;d pair with Claude or GPT to build something cool, and then it was gone. Chat history is useless for sharing or recreating what we built.<p>Buildlog records your AI coding sessions into structured .buildlog files. It captures prompts (the real artifact), actions taken, files changed, and the workflow sequence. Think of it like a recipe for building software with AI.<p>Three ways to capture:<p>- VS Code Extension - Start recording \u2192 code with your AI \u2192 stop \u2192 get a shareable file\n- MCP Server - Direct integration for Claude Desktop, Cursor, and other MCP-compatible agents\n- Agent Feed - Any AI can log to ~&#x2F;.buildlog&#x2F;agent-feed.jsonl with a simple skill file<p>The interesting bit: since buildlogs are structured, other AI agents can search and follow them. Share how you built a Stripe integration, someone else&#x27;s agent reads the workflow and replicates it. Agent-to-agent knowledge transfer.<p>Upload to buildlog.ai for a step-through viewer (public and private), and see &amp; share exactly how something was built, prompt by prompt.<p><a href=\"https:&#x2F;&#x2F;buildlog.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;buildlog.ai</a>\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;buildlogai\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;buildlogai</a><p>Free to use.<p>Would love feedback. What would make this useful for your workflow?", "author": "vrdev", "timestamp": "2026-02-03T13:21:00+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:44:10.364828+00:00", "processed": false}
{"id": "hn_comment_46870613", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46870613", "title": "Re: UK privacy watchdog opens inquiry into X over Grok...", "text": "So now we know why this took so long. A angle of attack that&#x27;s completely new.<p>&quot;These concerns relate to whether <i>personal data</i> has been processed lawfully, fairly and transparently, and whether appropriate safeguards were built into Grok\u2019s design and deployment to prevent the generation of harmful manipulated images using <i>personal data</i>.&quot;<p>(My italics.)<p>This regulator&#x27;s definition:<p><i>Personal data is ... any and all information that identifies you as a data subject.<p>A data subject is someone who can be identified from personal data.</i><p>Yes, really.", "author": "chrisjj", "timestamp": "2026-02-03T13:19:00+00:00", "score": null, "num_comments": null, "products": ["grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:44:10.577928+00:00", "processed": false}
{"id": "hn_story_46870189", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46870189", "title": "Show HN: Awel \u2013 Open-Source Cursor/Lovable for Your Next.js App", "text": "Hi HN!<p>Since vibe coding became a thing I\u2019ve been more productive than ever, shipping multiple side projects in weeks or even days (such as <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46196796\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46196796</a> :D). But as I built more complex apps, I feel like there&#x27;s something missing.<p>Cursor is powerful, but it felt cumbersome and heavy for my workflow \u2014 bloated with features I didn&#x27;t need. I actually really like Lovable for its simplicity, but I also want to have more control of my code and architecture decision. I wanted something in the middle: a tool for developers that offers a seamless AI agent experience directly within Next.js&#x2F;React, without the constant window switching.<p>So, I decided to build it myself. I started it with <a href=\"https:&#x2F;&#x2F;github.com&#x2F;MarsWang42&#x2F;Awel\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;MarsWang42&#x2F;Awel</a><p>I want a model-agnostic AI coding agent designed to keep myself in the flow. It acts as a bridge between models (most importantly, Claude Code) and your browser. It understands what is happening in the browser context without relying on flaky MCP or skill solutions. And most importantly, let me interacts with web elements, make screenshots and annotates, then send to the agents.<p>It&#x27;s really simple to use. If you have Claude Code already setup, just run `npx awel dev` in your Next.js projects, or you can setup other models by providing api keys in your env variables.<p>What feature do you think I should implement next? I\u2019m building this in public and want this to be a community effort.I\u2019d love for you to try it out, break it, and let me know what you think. Hope this workflow resonates with you", "author": "marsw42", "timestamp": "2026-02-03T12:29:02+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-03T17:44:12.988744+00:00", "processed": false}
{"id": "hn_story_46869985", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46869985", "title": "How do you prevent AI collaboration burnout?", "text": "I have been using claude&#x2F;gemini&#x2F;gpt heavily for 6-8h a day for research and error catching. Incredibly useful to find logical errors I miss, challenges my assumptions, speeds up thinking like a lot. It even improves my self awareness.<p>But I am hitting my biological limits. After 6+ hours, I&#x27;m mentally exhausted. Eyes and back hurt, brain fog, can not engage with real people. The AI doesn&#x27;t get tired - I do. I know that gym is one part of the answer. But also:<p><pre><code>  I am building a tracking system for this                                                                                                       \n  - 4h daily limit (hard stop, biological threshold)                                                                                              \n  - challenge our convergence (track if AI just agrees vs actually challenges)                                                                      \n  - energy economy metric (does it actually preserve or drain capacity?)                                                                              \n                                                                                                                                                  \n  AI has crazy capabilities and it can be genuinely helpful for some cognitive work. But it feels like a trap if I don&#x27;t watch my own boundaries.                                                               \n                                                                                                                                                  </code></pre>\nQuestions for you guys:                                                                                                                               \n  - What&#x27;s your sustainable AI usage? (hours&#x2F;day that doesn&#x27;t wreck you)                                                                          \n  - Do you track some aspects of your collaboration? (metrics, feelings, hard limits?)                                                                                      \n  - How do you know when to stop? (before exhaustion or after?)                                                                                   \n  - Am I overthinking this? (should I just... use less AI? Although it makes me right now 100 times more productive?)<p>Building this boundary system partly because I can&#x27;t trust myself to stop without forcing functions and bias the system further without external feedback. Anyone else need this or just me?<p>Brutal feedback wanted. If my approach is wrong, tell me. Or just tell me how you are doing it. Thank you in advance!", "author": "causal_anchor", "timestamp": "2026-02-03T12:10:44+00:00", "score": 1, "num_comments": 1, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-03T17:44:14.397772+00:00", "processed": false}
