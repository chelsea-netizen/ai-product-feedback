{"id": "hn_story_46935631", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46935631", "title": "Show HN: I am building \"Jira\" for AI coding agents", "text": "Hello HN,<p>I have been building a Task Manager for AI coding agents like Claude Code. It has a concept called \u201cgates\u201d where an agent cannot close a task unless at least one gate is tied to the task, a gate could be as \u201cEnsure the project builds without error\u201d, \u201cmake sure unit tests pass\u201d or even \u201chave user do confirmation testing\u201d solving one of my paint points of Beads. My other pain point stems from how Beads tracks everything using git hooks, which is why I felt appropriate to build an alternative that works purely with SQLite.<p>Right now I have no releases pipeline, and I am working on the MCP aspect of the project. I also have it synching to GitHub, you can see all my local tasks on the GitHub issues open or closed.<p>Looking for any feedback good or bad, if this project interests you feel free to contribute &#x2F; suggest features. Feel free to ask me anything, though I may not answer everyone right away, but I will respond as soon as I can.<p>I wrote more about it here:<p><a href=\"https:&#x2F;&#x2F;giancarlostoro.com&#x2F;introducing-guardrails-a-new-coding-agent-task-companion\" rel=\"nofollow\">https:&#x2F;&#x2F;giancarlostoro.com&#x2F;introducing-guardrails-a-new-codi...</a>", "author": "giancarlostoro", "timestamp": "2026-02-08T16:16:43+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:35.497154+00:00", "processed": false}
{"id": "hn_comment_46935579", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46935579", "title": "Re: Show HN: MCP App Template designed for coding agen...", "text": "Hi, author of the repo speaking here!<p>When I tried building MCP Apps [1], the official repos (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-apps-sdk-examples\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-apps-sdk-examples</a>, <a href=\"https:&#x2F;&#x2F;github.com&#x2F;modelcontextprotocol&#x2F;ext-apps&#x2F;tree&#x2F;main&#x2F;examples\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;modelcontextprotocol&#x2F;ext-apps&#x2F;tree&#x2F;main&#x2F;e...</a>) were great starting points, but they&#x27;re designed for human developers. When I used them with Claude Code, I ended up in the usual loop: agent writes code \u2192 I manually test the app on ChatGPT \u2192 describe errors back \u2192 repeat. Plus, we didn&#x27;t know what the best practices are, and struggled to enforce them.<p>So I built an MCP App template designed for coding agents to work as autonomously as possible on an MCP app.<p>The key idea: orthogonal testing. 450+ tests parameterized across 12 widget modules that verify infrastructure (protocol compliance, best practices grade, browser rendering), not business logic. Modify widgets, change data, add features \u2014 the tests should still pass. Agents iterate freely and get feedback without a human in the loop.<p>Other features:\n- Hierarchical documentation that includes the MCP-App &amp; OpenAI Apps SDK official llms.txt files\n- Local chat simulator app that works even without API keys via Puter.js\n- Visual testing of every widget: pnpm run ui-test --tool show_carousel \u2192 screenshot at &#x2F;tmp&#x2F;ui-test&#x2F;screenshot.png\n- 12 working examples (QR codes to 3D solar system) gathered from the official repos mentioned above.<p>The repo includes an unedited ~15 min video of Claude Code building an app autonomously which worked directly within ChatGPT.<p>I&#x27;d love to hear how it goes if you try it. Or even better: ask for a feedback to your agent, and post it here!<p>[1] MCP Apps (<a href=\"https:&#x2F;&#x2F;modelcontextprotocol.io&#x2F;docs&#x2F;extensions&#x2F;apps\" rel=\"nofollow\">https:&#x2F;&#x2F;modelcontextprotocol.io&#x2F;docs&#x2F;extensions&#x2F;apps</a>) let you build interactive widgets that run inside Claude, ChatGPT, VS Code, and other AI hosts. In contrast to smartphone apps, the same code can deploy to all platforms.", "author": "sebderhy", "timestamp": "2026-02-08T16:13:31+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-08T17:17:35.849920+00:00", "processed": false}
{"id": "hn_story_46934582", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934582", "title": "Show HN: Sediment \u2013 Local semantic memory for AI agents (Rust, single binary)", "text": "I&#x27;ve been increasingly relying on AI coding assistants. I recently had my first child, and my coding hours look different now. I prompt between feedings, sketch out ideas while he naps, and pick up where I left off later. AI lets me\nstay productive in fragmented time. But every session starts from zero.<p>Claude doesn&#x27;t remember the product roadmap we outlined last week. It doesn&#x27;t know the design decisions we already made. It forgot the feature spec we iterated on across three sessions. I kept re-explaining the same things.<p>I looked at existing memory solutions but never got past the door. Mem0 wants Docker + Postgres + Qdrant. I just want memory, not infrastructure. mcp-memory-service has 12 tools, which is just complexity tax on every LLM call. And\nanything cloud-hosted means my codebase context leaves my machine. The setup cost was always too high and privacy never guaranteed, so I stuck with CLAUDE.md files. They work for a handful of preferences, but it&#x27;s a flat file injected\ninto context every time. No semantic search, no cross-project memory, no decay, no dedup. It doesn&#x27;t scale.<p>So I built Sediment. The entire API is 4 tools: store, recall, list, forget.<p>I deliberately kept it small. I tried adding tags, metadata, expiration dates. Every parameter I added made the LLM worse at using it. With just store content, it just works. The assistant stores things naturally when they seem worth\nremembering and recalls them when context would help.<p>It&#x27;s made a noticeable difference. My assistant remembers product ideas I brainstormed at 2am, the coding guidelines for each project, feature specs we refined over multiple sessions, and the roadmap priorities I set last month. It\nremembers across projects too.<p>I benchmarked it against 5 alternatives to make sure I wasn&#x27;t fooling myself. 1,000 memories, 200 queries. Sediment returns the correct top result 50% of the time (vs 47% for the next best). When I update a memory, it always returns the\nlatest version. Competitors get this right only 14% of the time. And it&#x27;s the only system that auto-deduplicates (99% consolidation rate).<p>Everything runs locally. Single Rust binary, no Docker, no cloud, no API keys.<p>A few things I expect pushback on:<p>&quot;4 tools is too few.&quot; I tested 8, 12, and more. Every parameter is a decision the LLM makes on every call. Tags alone create a combinatorial explosion. Semantic search handles categorization better because it doesn&#x27;t require consistent\nmanual labeling.<p>&quot;all-MiniLM-L6-v2 is outdated.&quot; I benchmarked 4 models including bge-base-en-v1.5 (768-dim) and e5-small-v2. MiniLM tied with bge-base on quality but runs 2x faster. The model matters less than you&#x27;d think when you layer memory decay,\ngraph expansion, and hybrid BM25 scoring on top.<p>&quot;Mem0 supports temporal reasoning too.&quot; Mem0&#x27;s graph variant handles conflicts via LLM-based resolution (ADD&#x2F;UPDATE&#x2F;DELETE) on each store, which requires an LLM call on every write. Their benchmarks use LOCOMO, a conversational memory\ndataset that tests a different use case than developer memory retrieval. The bigger issue is that there&#x27;s no vendor-neutral, open benchmark for comparing memory systems. Every project runs their own evaluation on their own dataset.\nThat&#x27;s why I open-sourced the full benchmark suite: same dataset, same queries, reproducible by anyone. I&#x27;d love to see other tools run it too.<p>Benchmark methodology: 1,000 developer memories across 6 categories, 200 ground-truth queries, 50 temporal update sequences, 50 dedup pairs.<p>Landing page: <a href=\"https:&#x2F;&#x2F;sediment.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;sediment.sh</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;rendro&#x2F;sediment\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;rendro&#x2F;sediment</a><p>Benchmark suite: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;rendro&#x2F;sediment-benchmark\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;rendro&#x2F;sediment-benchmark</a>", "author": "rendro", "timestamp": "2026-02-08T14:41:07+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:42.131059+00:00", "processed": false}
{"id": "hn_story_46934411", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934411", "title": "Show HN: I built an open-source Gmail productivity app that auto-labels emails", "text": "I was drowning in email. Not the usual &quot;too many emails&quot; problem , I had a system, I had labels, but I was manually dragging hundreds of emails into folders every single day.<p>Gmail filters work great if your emails follow predictable patterns. But my inbox doesn&#x27;t. Client emails, project updates, newsletters I actually want to read, invoices, meeting notes, they all come from different senders with different subject lines. Writing regex patterns for everything felt like a part-time job.<p>So, I built NeatMail.<p>Here&#x27;s how it actually works:\nYou define labels in plain English. Not regex, not complex filter rules \u2013 just describe what you want labeled.\nExample: &quot;Label all emails about invoices as &#x27;Finance&#x27;&quot;\nOr: &quot;Anything from clients asking for updates goes into &#x27;Client-Urgent&#x27;&quot;\nThe AI reads incoming emails and applies your custom labels directly in Gmail. That&#x27;s it. No learning period, no training data, no analyzing your email history. You tell it what you want, it does it.<p>The part that surprised me:\nI added an auto-draft feature almost as an afterthought. It reads emails that need replies and drafts responses in your tone (you can set the tone: professional, casual, friendly, etc.). I thought I&#x27;d never use it.\nI use it every day now. Even if I don&#x27;t send the draft as-is, having a starting point saves 5-10 minutes per response.<p>Why open source:\nBecause I&#x27;m handling your email. That felt too personal to keep closed. You can see exactly what it&#x27;s doing, modify it, host it yourself if you want. The code is straightforward \u2013 no black boxes.<p>Current limitations:\nGmail only (that&#x27;s what I use, so that&#x27;s what I built for)\nThe label suggestions can get overly specific sometimes\nDraft tone matching is decent but not perfect\nRate limits with Gmail API mean very high-volume users might hit delays<p>Tech stack:\nBuilt with Next.js, uses OpenAI&#x27;s API (you need your own key), integrates via Gmail API. Setup takes maybe 10 minutes if you&#x27;ve used OAuth before.\nI&#x27;ve been using it for 3 months. My inbox actually stays at zero now. Not because I&#x27;m more disciplined \u2013 because the boring part is automated.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Lakshay1509&#x2F;NeatMail\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Lakshay1509&#x2F;NeatMail</a>\nHappy to answer questions about how it works or why I made certain decisions. Also genuinely curious if anyone has suggestions for improving the label accuracy.", "author": "mafia15", "timestamp": "2026-02-08T14:20:19+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:43.213799+00:00", "processed": false}
{"id": "hn_comment_46935165", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46935165", "title": "Re: I am happier writing code by hand...", "text": "Even if Claude writes 100% code, I think there will be a bifurcation between people who are finicky about 10 lines of code. And those finicky about high level product experiences.<p>I think the 10 lines of code people worry their jobs now become obsolete. In cases where the code required googling how to do X with Y technology, that&#x27;s true. That&#x27;s just going to be trivially solvable. And it will cause us to not need as many developers.<p>In my experience though, the 10 lines of finicky code use case usually has specific attributes:<p>1. You don&#x27;t have well defined requirements. We&#x27;re discovering correctness as we go. We &#x27;code&#x27; to think how to solve the problem, adding &#x2F; removing &#x2F; changing tests as we go.<p>2. The constraints &#x2F; correctness of this code is extremely multifaceted. It simultaneously matters for it to be fast, correct, secure, easy to use, etc<p>3. We&#x27;re adapting a general solution (ie a login flow) to our specific company or domain. And the latter requires us to provide careful guidance to the LLM to get the right output<p>It may be Claude Code around these fewer bits of code, but in these cases its still important to have taste and care with code details itself.<p>We may weirdly be in a case where it&#x27;s possible to single-shot a slack clone, but taking time to change the 2 small features we care about is time consuming and requires thoughtfulness.", "author": "softwaredoug", "timestamp": "2026-02-08T15:34:29+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:44.674118+00:00", "processed": false}
{"id": "hn_story_46934254", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934254", "title": "Show HN: Verification-first workflow plugin for Claude Code", "text": "I built a set of open-source Claude Code plugins that add a structured define \u2192 execute \u2192 verify loop to agentic coding workflows.<p>*The problem*: Claude Code is capable, but on non-trivial tasks the default workflow is iterative \u2014 you prompt, review output, correct, re-prompt. Each cycle costs time and tokens, and the failure mode is accepting &quot;looks right&quot; code that breaks in edge cases you didn&#x27;t think to check.<p>*What this does*: You run two commands:<p>- `&#x2F;define` \u2014 Converts a task description into concrete acceptance criteria and invariants before any code is written. The agent explores the codebase, identifies constraints, and produces a manifest of what &quot;done&quot; means.\n- `&#x2F;do` \u2014 Executes against the manifest, tracking progress per criterion. Verification runs automatically at the end \u2014 each acceptance criterion is checked as a separate pass&#x2F;fail gate. If something fails, it fixes and re-verifies before declaring done.<p>That&#x27;s it. Define what you want, then execute. The verification loop is built in.<p>*How it differs from Plan mode*: Claude Code&#x27;s built-in Plan mode lets you review a plan before execution. But the plan is unstructured text \u2014 there&#x27;s no formal criteria, no verification after execution, and no way to know if the output actually matches what you planned. This adds structured acceptance criteria that get verified automatically, so &quot;done&quot; means &quot;all criteria passed,&quot; not &quot;the agent stopped.&quot;<p>*How it differs from manual prompting*: Writing good prompts helps. But prompts describe intent \u2014 they don&#x27;t verify outcomes. This separates the &quot;what do I want&quot; step from the &quot;did I get it&quot; step, with explicit checks for each.<p>Built with Claude Code&#x27;s plugin system (agents, skills, hooks). No external dependencies.", "author": "doodledood", "timestamp": "2026-02-08T14:01:37+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:45.939368+00:00", "processed": false}
{"id": "hn_comment_46934293", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934293", "title": "Re: Show HN: Team of agent researchers read things I d...", "text": "1. I would allow users to play around without entering their email.\n2. Why can&#x27;t I just ask ChatGPT to do deep research on a topic for me?\n3. What evals do you have to prove that the agents don&#x27;t hallucinate output that sounds good", "author": "rubenflamshep", "timestamp": "2026-02-08T14:05:43+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:49.142799+00:00", "processed": false}
{"id": "hn_story_46933515", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46933515", "title": "Show HN: Fine-tuned Qwen2.5-7B on 100 films for probabilistic story graphs", "text": "Hi HN, I&#x27;m a computer systems engineering student in Mexico who switched from film school. I built CineGraphs because my filmmaker friends and I kept hitting the same wall\u2014we&#x27;d have a vague idea for a film but no structured way to explore where it could go. Every AI writing tool we tried output generic, formulaic slop. I didn&#x27;t want to build another ChatGPT wrapper, so I went a different route.<p>The idea is simple: you input a rough concept, and the tool generates branching narrative paths visualized as a graph. You can sculpt those branches into a structured screenplay format and export to Fountain for use in professional screenwriting software.<p>Most AI writing tools are trained on generic internet text, which is why they output generic results. I wanted something that understood actual cinematic storytelling\u2014not plot summaries or Wikipedia synopses, but the actual structural DNA of films. So I spent a month curating 100 films I consider high-quality cinema. Not just popular films, but works with distinctive narrative structures: Godard&#x27;s jump cuts and essay-film digressions, Kurosawa&#x27;s parallel character arcs, Brakhage&#x27;s non-linear visual poetry, Tarkovsky&#x27;s slow-burn temporal structures. The selection was deliberately eclectic because I wanted the model to learn that &quot;story&quot; can mean many things.<p>Getting useful training data from films is harder than it sounds. I built a 1000+ line Python pipeline using Qwen3-VL to analyze each film with subtitles enabled. The pipeline extracts scene-level narrative beats, character relationships and how they evolve, thematic threads, and dialogue patterns. The tricky part was getting Qwen3-VL to understand cinematic structure rather than just summarizing plot. I had to iterate on the prompts extensively to get it to identify things like &quot;this scene functions as a mirror to the opening&quot; or &quot;this character&#x27;s arc inverts the protagonist&#x27;s.&quot; That took weeks and I&#x27;m still not fully satisfied with it, but it&#x27;s good enough to produce useful training data.<p>From those extractions I generated a 10K example dataset of prompt-to-branching-narrative pairs, then fine-tuned Qwen2.5-7B-Instruct with a LoRA optimized for probabilistic story branching. The LoRA handles the graph generation\u2014exploring possible narrative directions\u2014while the full 7B model generates the actual technical screenplay format when you export. I chose the 7B model because I wanted something that could run affordably at scale while still being capable enough for nuanced generation. The whole thing is served on a single 4090 GPU using vLLM. The frontend uses React Flow for the graph visualization. The key insight was that screenwriting is fundamentally about making choices\u2014what if the character goes left instead of right?\u2014but most writing tools force you into a linear document too early. The graph structure lets you explore multiple paths before committing, which matches how writers actually think in early development.<p>The biggest surprise was how much the film selection mattered. Early versions trained on more mainstream films produced much more formulaic outputs. Adding experimental and international cinema dramatically improved the variety and interestingness of the generations. The model seemed to learn that narrative structure is a design space, not a formula.<p>We&#x27;ve been using it ourselves to break through second-act problems\u2014when you know where you want to end up but can&#x27;t figure out how to get there. The branching format forces you to think in possibilities rather than committing too early.<p>You can try it at <a href=\"https:&#x2F;&#x2F;cinegraphs.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;cinegraphs.ai&#x2F;</a> \u2014 no signup required to test it out. You get a full project with up to 50 branches without registering, though you&#x27;ll need to create an account to save it. Registered users get 3 free projects. I&#x27;d love feedback on whether the generation quality feels meaningfully different from generic AI tools, and whether the graph interface adds value or just friction.", "author": "graphpilled", "timestamp": "2026-02-08T12:00:02+00:00", "score": 73, "num_comments": 20, "products": ["chatgpt"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:53.850663+00:00", "processed": false}
{"id": "hn_story_46933368", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46933368", "title": "Show HN: Tandem \u2013 An open-source, local-first AI workspace (Rust and React)", "text": "Hi HN,<p>I\u2019m the solo developer behind *Tandem*, a local-first, zero-trust AI workspace.<p>I built this because I was tired of &quot;renting my intelligence&quot; to cloud providers. I wanted a workspace that felt like a real tool, not just another chat wrapper\u2014one where my &quot;second brain&quot; actually lived on <i>my</i> machine, fully encrypted, and under my control.<p>While big tech is releasing closed, Mac-only tools (like the recently announced Anthropic Cowork), I believe the future of AI productivity should be open, transparent, and cross-platform.<p>*What makes Tandem different?*<p>*   *Local-First &quot;Brain&quot;:* It\u2019s not just an API client. It has a built-in vector database (`sqlite-vec`) and a long-term memory engine running locally in Rust.\n*   *Zero-Trust Security:* Everything is stored in an encrypted &quot;Vault&quot; on your drive (using Argon2&#x2F;AES-GCM). No telemetry, no data leaking to training sets.\n*   *Modular &quot;Packs&quot; System:* This is the coolest part\u2014you can &quot;install&quot; domain expertise. I built a system where Markdown&#x2F;YAML configs turn the app into a specialized tool (e.g., a Bio-informatics researcher, Legal analyst, or Screenwriter) with one click.\n*   *Full MCP Support:* It supports the Model Context Protocol out of the box. You can connect any local or remote MCP server to give the AI direct access to your internal tools and databases.<p>*The Tech Stack:*\n*   *Core:* Rust (Tauri v2)\n*   *Frontend:* React + Tailwind + Vite\n*   *Data:* SQLite + Vector Extensions<p>I\u2019ve been working on this solo and would love your feedback on the architecture, especially the &quot;Packs&quot; system.<p>*You can download the latest installers for Windows, macOS, and Linux here:*\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;frumu-ai&#x2F;tandem&#x2F;releases\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;frumu-ai&#x2F;tandem&#x2F;releases</a><p>*Repo:* <a href=\"https:&#x2F;&#x2F;github.com&#x2F;frumu-ai&#x2F;tandem\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;frumu-ai&#x2F;tandem</a>\n*Docs:* <a href=\"https:&#x2F;&#x2F;tandem.frumu.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;tandem.frumu.ai&#x2F;</a><p>Thanks for checking it out!", "author": "frumu", "timestamp": "2026-02-08T11:32:32+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-08T17:17:56.306074+00:00", "processed": false}
{"id": "hn_story_46933367", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46933367", "title": "Show HN: AI Perks \u2013 A curated list of free AI credits and deals for developers", "text": "Hi HN,<p>I built Get AI Perks to solve a problem I faced myself: keeping track of free credits, grants, and deals for AI tools is painful. Most &quot;perk&quot; lists are hidden behind expensive paywalls or buried in incubator intranets.<p>I wanted to make a clean, public dashboard where developers can easily find valid offers for tools like OpenAI, Anthropic, Cursor, Deepgram, and others.<p>Key Features:\n- Approval Index: I try to track how likely you are to actually get the perk (High&#x2F;Average&#x2F;Low approval rates).\n- Search &amp; Filters: Filter by category or provider (e.g., &quot;Free&quot;, &quot;OpenAI&quot;, &quot;Hosting&quot;).\n- Transparency: Detailed instructions on how to apply for each credit.<p>The site is free to browse. I use it myself to track new offers as they pop up.<p>Link: <a href=\"https:&#x2F;&#x2F;getaiperks.com\" rel=\"nofollow\">https:&#x2F;&#x2F;getaiperks.com</a><p>For AI Companies &amp; Incubators:\n- List your perk: If you run an AI tool and want to offer credits to developers (I also feature new perks in my newsletter), fill out this form: <a href=\"https:&#x2F;&#x2F;form.getaiperks.com&#x2F;listing\" rel=\"nofollow\">https:&#x2F;&#x2F;form.getaiperks.com&#x2F;listing</a><p>- White-label for Accelerators: If you manage an incubator or community and want a branded perks dashboard for your startups, I offer a white-label solution: <a href=\"https:&#x2F;&#x2F;form.getaiperks.com&#x2F;vc-whitelabel\" rel=\"nofollow\">https:&#x2F;&#x2F;form.getaiperks.com&#x2F;vc-whitelabel</a><p>Would love your feedback on the UX or any perks I&#x27;m missing!", "author": "artluko", "timestamp": "2026-02-08T11:32:30+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-08T17:17:56.349420+00:00", "processed": false}
{"id": "hn_comment_46933303", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46933303", "title": "Re: How do you use AI coding tools at scale without lo...", "text": "I\u2019ve been experimenting quite a bit with AI-assisted development recently (Copilot, Cursor, Claude, etc.), both in larger systems and in smaller side projects.<p>What keeps surprising me is not hallucinations or model output quality as such, but how easy it is to lose shared architectural context over time.<p>At first everything feels great. Things move fast. Demos work. Features pile up.<p>But after a while I notice that parts of the system were built differently than I would have designed them myself. not necessarily wrong, just inconsistent in ways that are hard to see early.<p>Nothing breaks right away.\nBut at some point I realize I wouldn\u2019t feel comfortable taking full responsibility \nfor the system anymore, especially under (long-term) production constraints..<p>What I\u2019m struggling with is this:\nHow do you keep architectural intent explicit when AI is writing a lot of the code?<p>For me it seems less like a prompt or a context window problem and more like a governance issue: Which decisions must stay stable? What must not change? Where is AI allowed to explore, and where should it be constrained?<p>I\u2019ve started experimenting with more explicit roles, workflows, and step-by-step development phases, but honestly I\u2019m not convinced yet this is the right balance.<p>I\u2019m curious how others handle this in practice:\nHow do you get real speed from AI tools without slowly drifting into a system you no longer fully understand or trust?", "author": "seekerXtruth", "timestamp": "2026-02-08T11:17:28+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:17:57.705773+00:00", "processed": false}
{"id": "hn_comment_46934611", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934611", "title": "Re: Slop Terrifies Me...", "text": "The terrifying part isn&#x27;t obsolescence. It&#x27;s mediocrity becoming the ceiling.<p>AI produces code that technically runs but lacks the thoughtfulness that makes software maintainable or elegant. The &quot;90% solution&quot; ships because economic pressure rewards speed over quality.<p>What haunts me: compilers don&#x27;t make design decisions. IDEs don&#x27;t choose architecture. AI does both, and most users accept those choices uncritically. We&#x27;re already seeing juniors who&#x27;ve never debugged without a copilot.<p>The author&#x27;s real question: what if most people genuinely don&#x27;t care about the last 10%? Not from laziness, but because &quot;good enough&quot; is cheaper and we&#x27;re all exhausted.<p>Dismissing this as &quot;just another moral panic&quot; feels too easy. The handcraft isn&#x27;t dying because AI is too good. It&#x27;s dying because mediocrity is profitable.", "author": "wundersam", "timestamp": "2026-02-08T14:44:04+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:18:00.210542+00:00", "processed": false}
{"id": "hn_comment_46934687", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46934687", "title": "Re: Matchlock \u2013 Secures AI agent workloads with a Linu...", "text": "We definitely need a vendor-independent tool like this. Have been reviewing the Claude setup and, despite initially being hopeful since it uses bubblewrap, it&#x27;s quite problematic:<p>* The definitions of security config in the documentation of settings.json are unclear. Since it&#x27;s not open source, you can&#x27;t check the ground truth.<p>* The built in constructs are insufficient to do fully whitelist based access control (It might be possible with a custom hook).<p>* Security related issues go unanswered in the repo, and are automatically closed.<p>Haven&#x27;t looked into copilot as much but didn&#x27;t look great either. Seems like the vendors don&#x27;t have the incentives to do this properly.<p>So I&#x27;m on the lookout for a better way, and matchlock seems like a contender.", "author": "ajb", "timestamp": "2026-02-08T14:52:37+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["content_clarity", "response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:18:05.285246+00:00", "processed": false}
{"id": "hn_comment_46933936", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46933936", "title": "Re: Matchlock \u2013 Secures AI agent workloads with a Linu...", "text": "containers are fine for basic isolation but the attack surface is way bigger than people think. you&#x27;re still trusting the container runtime, the kernel, and the whole syscall interface. if the agent can call arbitrary syscalls inside the container, you&#x27;re one kernel bug away from a breakout.<p>what I&#x27;m curious about with matchlock - does it use seccomp-bpf to restrict syscalls, or is it more like a minimal rootfs with carefully chosen binaries? because the landlock LSM stuff is cool but it&#x27;s mainly for filesystem access control. network access, process spawning, that&#x27;s where agents get dangerous.<p>also how do you handle the agent needing to install dependencies at runtime? like if claude decides it needs to pip install something mid-task. do you pre-populate the sandbox or allow package manager access?", "author": "the_harpia_io", "timestamp": "2026-02-08T13:16:14+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-08T17:18:05.545774+00:00", "processed": false}
{"id": "hn_story_46932153", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46932153", "title": "Show HN: A Prompting Framework for Non-Vibe-Coders", "text": "Hi, a little context for this simple project:<p>I only started this &quot;agentic development&quot; thing this year thanks to the Google AI Pro sale, therefore my most used agent is Antigravity - Gemini 3, which is smart but a loose cannon. So my attempt to &quot;tame&quot; this model turned into this. (Btw I have claude code and cursor)<p>It could be useful for people who:<p>- are used to conventional coding and want to try out agentic development<p>- don&#x27;t vibe-code or prefer staying in the loop<p>- using less polished harness or less rigorous models<p>It&#x27;s a skill defining a methodology to command LLMs. You reference the workflow files to make LLM plan, execute, review, red-team, etc. \u2014 each output a typed markdown document with a defined template and lifecycle.<p>Documents chain together (Plan \u2192 Execute \u2192 Audit), are just files in your repo, and double as persistent memory across sessions. Basically a lightweight project management protocol between you and the agent.<p>I am posting this simply because it&#x27;s proven useful for me; I wouldn&#x27;t say this is good or smart way to approach agentic development :)", "author": "3371", "timestamp": "2026-02-08T07:32:01+00:00", "score": 4, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:18:06.925071+00:00", "processed": false}
{"id": "hn_story_46931987", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46931987", "title": "Turn Claude Code/OpenClaw into Your Local Lovart \u2013 AI Design MCP Server", "text": "", "author": "jaujaujau", "timestamp": "2026-02-08T07:08:26+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-08T17:18:08.122021+00:00", "processed": false}
{"id": "hn_story_46931848", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46931848", "title": "Show HN: SAA \u2013 A minimal shell-as-chat agent using only Bash", "text": "I wrote this purely out of frustration. Claude Code recently started making my terminal lag, Codex keeps flickering, and the Gemini CLI just spams deprecation warnings. I wanted something dead simple.<p>SAA (Single Action Agent) is a Go binary that turns your shell into a chat interface. It has no fancy UI and gives the agent only one tool: bash.<p>I started this as a half-joke PoC, but I was surprised to find that even local LLMs (running GLM-4.7-Flash UDQ4) handle &quot;Bash is all you need&quot; remarkably well. It keeps sessions in a hidden directory and stays out of your way.<p>Is anyone else building minimal ecosystems around this &quot;shell-as-chat&quot; concept? I&#x27;d love to hear about interesting wrapper scripts or ideas.", "author": "mrvmochi", "timestamp": "2026-02-08T06:34:11+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-08T17:18:09.448667+00:00", "processed": false}
{"id": "hn_comment_46930880", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46930880", "title": "Re: Ask HN: The Coming Class War...", "text": "Is every forum just full of Reddit users complaining about le capitalism now?<p>It\u2019s never been easier to make your own software. You don\u2019t even need to know how to program. You don\u2019t even need to buy an operating system. You need like $200 for a shitty laptop. People doing good and interesting work aren&#x27;t reliant on these agents. People writing these posts aren\u2019t outputting good software \u2014 let alone any software anyone actually cares about. Where\u2019s the billion dollar game franchise written mostly by Claude? It doesn\u2019t exist.", "author": "zachYCB", "timestamp": "2026-02-08T02:51:12+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-08T17:18:19.361110+00:00", "processed": false}
