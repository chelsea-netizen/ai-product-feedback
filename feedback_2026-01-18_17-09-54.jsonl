{"id": "hn_story_46669267", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46669267", "title": "Show HN: Rails engine for building production-ready LLM agents", "text": "I built a Rails engine for building and managing LLM-powered agents. It wraps RubyLLM and adds the production infrastructure I kept rebuilding across projects:<p>- Execution tracking with cost&#x2F;token analytics\n- Reliability (retries, model fallbacks, circuit breakers)\n- Budget controls (daily&#x2F;monthly limits per agent or tenant)\n- Workflow orchestration (pipelines, parallel, routers)\n- Real-time monitoring dashboard<p>Example:<p><pre><code>    class SearchAgent &lt; ApplicationAgent\n        model &quot;gpt-4o&quot;\n    \n        reliability do\n            retries max: 3, backoff: :exponential\n            fallback_models &quot;gpt-4o-mini&quot;, &quot;claude-3-5-sonnet&quot;\n        end\n    \n        param :query, required: true\n    \n        def user_prompt\n            &quot;Extract search intent from: #{query}&quot;\n        end\n    end\n\n    result = SearchAgent.call(query: &quot;red shoes under $50&quot;)\n    result.content      # structured response\n    result.total_cost   # $0.00025\n</code></pre>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;adham90&#x2F;ruby_llm-agents\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;adham90&#x2F;ruby_llm-agents</a><p>I&#x27;ve been using it in production for a few months. Happy to answer questions.", "author": "adham900", "timestamp": "2026-01-18T16:41:18+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:09:56.345966+00:00", "processed": false}
{"id": "hn_story_46668939", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46668939", "title": "Seamless Claude Code Handoff: SSH from Your Phone with Tmux", "text": "", "author": "elliotbnvl", "timestamp": "2026-01-18T16:10:33+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:09:58.027420+00:00", "processed": false}
{"id": "hn_story_46668780", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46668780", "title": "Show HN: Open-source certificate from GitHub activity", "text": "I built this as a small side project to learn and experiment, and I ended up with this!<p>I used a subdomain from my personal portfolio, and everything else runs on free tiers.<p>The project uses Nuxt, SVG, Cloudflare Workers, D1 (SQL), KV, Terraform, and some agentic coding with OpenAI Codex and Claude Code.<p>What started as a joke among friends turned into a fun excuse to build something end to end, from zero to production, and to explore a few things \nI\u2019d never touched before.<p>I\u2019d really appreciate any feedback or suggestions.", "author": "brendonmatos", "timestamp": "2026-01-18T15:52:05+00:00", "score": 9, "num_comments": 2, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:09:58.757763+00:00", "processed": false}
{"id": "hn_story_46668008", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46668008", "title": "OpenAI appears to be moving toward ads in ChatGPT for logged-in U.S. users", "text": "Even if ads are limited at first, this raises questions about UX, privacy, and long-term direction.<p>1.What do you think:<p>2.Would ads change how you use ChatGPT?<p>Are ads inevitable for consumer AI?<p>3.What would an acceptable implementation look like?", "author": "SRMohitkr", "timestamp": "2026-01-18T14:23:40+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:02.456586+00:00", "processed": false}
{"id": "hn_story_46667685", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46667685", "title": "Show HN: Moshi \u2013 Talk to Claude Code from your phone (zero desktop install)", "text": "I built an iOS app to interact with coding agents from my phone.<p>Most remote solutions I&#x27;ve seen require installing a server or relay on your machine. Moshi is just an app \u2014 SSH&#x2F;Mosh into your Mac&#x2F;PC&#x2F;Sandbox and you&#x27;re done.<p>The use case isn&#x27;t really &quot;I need to get back to my computer.&quot; It&#x27;s more like:\n- I&#x27;m curious how the agent is doing on that refactor\n- I want Claude Code to research something for me (it knows my codebase, unlike a fresh chatbot)\n- I have an idea and want to tell the agent before I forget<p>I just type what I want \u2014 or speak it. Whisper transcribes locally, I hit send, done.<p>Whenever I open the app, it&#x27;s ready. Connection stays alive \u2014 no tmux attach every time. Uses Mosh protocol so sessions survive wifi switches, phone sleep, walking between rooms.<p>Technical bits:\n- Native iOS (React Native + Expo)\n- libmosh&#x2F;libssh2\n- Whisper.cpp for speech-to-text (runs locally, no cloud)\n- Face ID for key protection<p>No subscription, no server install, no cloud relay.<p>Testflight: <a href=\"https:&#x2F;&#x2F;testflight.apple.com&#x2F;join&#x2F;yApyT263\" rel=\"nofollow\">https:&#x2F;&#x2F;testflight.apple.com&#x2F;join&#x2F;yApyT263</a><p>I know there are similar solutions, but Moshi is the first I&#x27;ve seen that doesn&#x27;t require additional software on your Mac or rewire how data passes through (web relays, proxy servers, etc).<p>Happy to answer questions here or on Twitter: @odd_joel", "author": "rjyo", "timestamp": "2026-01-18T13:34:01+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:04.367799+00:00", "processed": false}
{"id": "hn_comment_46668535", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46668535", "title": "Re: Software engineers can no longer neglect their sof...", "text": "I thought this article was going to be about something else ...<p>It is really about prompting and writing specs - the &quot;soft&quot; (but really &quot;hard&quot;) skill of giving detailed specs to an LLM so it does what you want.<p>I think the more important, truly soft, skill in the age of AI is going to be communicating with humans and demonstrating your value in communicating both vertically up and down and horizontally within your team. LLMs are becoming quite capable at the &quot;autistic&quot; skill of coding, but they are still horrible communicators, and don&#x27;t communicate at all unless spoken to. This is where humans are currently, and maybe for a long time, irreplaceable - using our soft skills to interact with other humans and as always translate and refine fuzzy business requirements into the unforgiving language of the machine, whether that is carefully engineered LLM contexts, or machine code.<p>As far as communication goes, I have to say that Gemini 3.0, great as it is, is starting to grate on me with it&#x27;s sycophantic style and failure to just respond as requested rather than to blabber on about &quot;next steps&quot; that it is constantly trying to second guess from it&#x27;s history. You can tell it to focus and just answer the question, but that only lasts for one or two conversational turns.<p>One of Gemini&#x27;s most annoying traits is to cheerfully and authoritatively give design advice, then when questioned admit (or rather tell, as if it were it&#x27;s own insight) that this advice is catastrophically bad and will lead to a bad outcome, and without pause then tell you what you <i>really</i> should do, as if this is going to be any better.<p>&quot;You&#x27;re absolutely right! You&#x27;ve just realized the inevitable hard truth that all designers come to! If you do [what I just told you to do], program performance will be terrible! Here is how you avoid that ... (gives more advice pulled out of ass, without any analysis of consequences)&quot;<p>It&#x27;s getting old.", "author": "HarHarVeryFunny", "timestamp": "2026-01-18T15:24:22+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:05.356783+00:00", "processed": false}
{"id": "hn_story_46667317", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46667317", "title": "Show HN: Claude Threads \u2013 Collaborate on Claude Code via Slack/Mattermost", "text": "I wanted my team to start using Claude Code but didn&#x27;t want to set everyone up. Started piping output to Mattermost (and later Slack) so people could watch.<p>Ended up building more: multiple sessions in parallel (each in a thread, hence the name), approve messages from other users with emojis, approve file writes, attach images&#x2F;files, worktrees per thread.<p>It runs on your machine.<p>I built most of it using itself. Teammates watching live caught stuff I missed.<p><a href=\"https:&#x2F;&#x2F;claude-threads.run\" rel=\"nofollow\">https:&#x2F;&#x2F;claude-threads.run</a>\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;anneschuth&#x2F;claude-threads\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;anneschuth&#x2F;claude-threads</a>", "author": "aschuth", "timestamp": "2026-01-18T12:32:20+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:06.884195+00:00", "processed": false}
{"id": "hn_comment_46667406", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46667406", "title": "Re: Agent Psychosis: Are We Going Insane?...", "text": "<p><pre><code>        All I know is that when I watch someone at 3am, running their tenth parallel agent session, telling me they\u2019ve never been more productive\n</code></pre>\n... okay, I&#x27;ll bite. What is actually being made here?<p>These people are so productive, running 10 checkouts of a repo with Claude or whoever... Code must be flying out. I&#x27;m sure github is seeing a rise in lines pushed faster than ever.<p>I am not seeing an explosion of products worthy of any cents out of this, though, at least nowhere near what is being evangelised by the &quot;trust me bro, we&#x27;re productivity gods now&quot;.<p>Where is the output of all these tokens going, when you wake up the next morning?<p>I&#x27;ve used AI quite a lot. Enough to know that an inference state machine is an inference state machine.<p>I want to see it, I want to believe! Show me the goods! Stop telling everyone how productive you are and show the finished work.<p>At least the post seems to be rightfully conclusive that people are going to go _insane_.<p>Vibecoding slop every night, waking up the next morning, starting again, and again. Without any meaning or end; I suspect these people will quit and move on to something else. I&#x27;ve been programming, probably averagely, for over 25 years -- because I like computers -- not because I like being a productivity junkie, shooting on dopamine.<p>Make it count.", "author": "keyle", "timestamp": "2026-01-18T12:46:48+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["naming_terminology", "response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:10.936275+00:00", "processed": false}
{"id": "hn_story_46666723", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666723", "title": "Show HN: Apex Agent \u2013 Connect the Browser to AI via MCP", "text": "Hey HN,<p>I\u2019m a developer and 3D artist, and I wanted my AI (specifically Cursor and Claude Desktop) to have &quot;hands and eyes&quot; in my actual browser while I work.<p>I tried the official Chrome DevTools MCP, but it felt overkill for my workflow. It requires setting up remote debugging ports and is heavily geared toward performance profiling and deep-dive engineering. I just wanted something &quot;generalized&quot;\u2014like ChatGPT Atlas or Comet\u2014but for my own dev environment.<p>So, I built Apex Agent.<p>It\u2019s a lightweight Chrome extension + a tiny Node.js bridge that lets any MCP-compatible AI control your browser session.<p>Why I built this vs. using the official MCP:\nHuman-Centric Tools: While the official tool is for debugging, Apex is built for interaction. It has 69+ tools for clicking, typing, scrolling, and taking full-page screenshots.\nNo Remote Debugging Mess: You don\u2019t need to restart Chrome with special flags or mess with debugging ports. Just connect the extension and go.\nControl Your Active Session: It doesn&#x27;t spawn a separate &quot;headless&quot; instance. It works with the tabs you already have open, which is way more useful for vibe coding or UI testing.\nDev Workflow Ready: I optimized this specifically to work with Cursor. Now I can tell Cursor to &quot;Go to my local dev site, find the submit button, and tell me if the console shows any errors&quot; without leaving my editor.<p>I\u2019m looking for feedback from the community\u2014what tools are missing for your daily AI workflows?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;RTBRuhan&#x2F;ApexAgent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;RTBRuhan&#x2F;ApexAgent</a><p>Chrome Web Store: <a href=\"https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;apex-agent&#x2F;pmpkkbjdkmcjcekkokcgakngkbmgehcp\" rel=\"nofollow\">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;apex-agent&#x2F;pmpkkbjd...</a>", "author": "rtbruhan00", "timestamp": "2026-01-18T10:54:26+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-18T17:10:11.383406+00:00", "processed": false}
{"id": "hn_comment_46666485", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666485", "title": "Re: QWED AI \u2013 Open-source deterministic verification l...", "text": "I built QWED \u2013 a verification layer that sits between your LLM and production.\nThe idea: Don&#x27;t fix hallucinations, verify them. If AI output can&#x27;t be mathematically proven, it doesn&#x27;t ship.\n11 specialized engines:\n- Math (SymPy) \u2013 verify calculations\n- Logic (Z3 SMT) \u2013 formal proofs\n- SQL (SQLGlot) \u2013 detect injection&#x2F;dangerous queries\n- Code (AST) \u2013 security analysis + taint tracking\n- Facts (KB) \u2013 entity verification without LLM\nWorks with ANY LLM \u2013 OpenAI, Claude, Gemini, or local models via Ollama ($0).\nModel-agnostic: Your LLM choice, our verification.\nHappy to answer questions about deterministic AI verification!", "author": "rahuldass", "timestamp": "2026-01-18T10:12:58+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:13.767213+00:00", "processed": false}
{"id": "hn_story_46666240", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666240", "title": "Show HN: iTerm2 MCP Server \u2013 Let Claude see and control your terminal panes", "text": "Hello,<p>I built an MCP server that connects Claude (Desktop or Claude Code) to iTerm2. It lets the AI read what&#x27;s in your other terminal tabs and send commands to them.<p><pre><code>  What it does:\n  - List all open panes with their working directories and running processes\n  - Read the screen buffer from any pane\n  - Send commands or keystrokes (Ctrl+C, Ctrl+D, etc.) to any pane\n  - Split panes programmatically\n\n  Why I made this:\n  When using Claude Code for development, I often have servers, logs, or test runners in other terminal tabs. Previously, I had to copy-paste output to give Claude context. Now I can just say &quot;What&#x27;s the error in tab 3?&quot; or &quot;Run the tests in the pane next to you.&quot;\n\n  It uses iTerm2&#x27;s Python API via WebSocket. For Claude Code:\n  claude mcp add --scope user iterm2 -- npx github:sumchattering&#x2F;iterm2-mcp-server\n\n  GitHub: https:&#x2F;&#x2F;github.com&#x2F;sumchattering&#x2F;iterm2-mcp-server\n</code></pre>\nHope you find it useful!", "author": "sumeruchat", "timestamp": "2026-01-18T09:27:54+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:15.498577+00:00", "processed": false}
{"id": "hn_story_46666087", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666087", "title": "Show HN: Design Rails \u2013 Complete brand package for AI coding agents", "text": "Hey HN, we&#x27;re building Design Rails.<p>It&#x27;s a chat-based brand builder. You describe your project, iterate with an AI designer, and walk away with a logo, color palette, typography, and style guide - all formatted as specs you can drop into your project for Claude Code, Cursor or whatever you&#x27;re coding with.<p>Free tier gets you a full logo (PNG) and basic palette. Paid tier ($49 one-time) - everything you need for your next project - full coding-agent ready specs, SVG logos, icon variants, etc.<p>Built with Next.js, Vercel AI SDK, and Inngest for the async generation jobs.<p>Would love to hear your feedback - what&#x27;s missing, what would make this more useful for your workflow?", "author": "amitbar", "timestamp": "2026-01-18T08:59:01+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:16.405982+00:00", "processed": false}
{"id": "hn_story_46665639", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46665639", "title": "Best approach for generating SVG graphics with LLMs?", "text": "I&#x27;m working on a project that needs to dynamically generate simple icons and diagrams. I&#x27;ve tried GPT-4 and Claude - they can output SVG code but the results are hit or miss, especially for anything beyond basic shapes.<p>Has anyone found a reliable workflow for this? I&#x27;m wondering if there are specialized models, better prompting techniques, or if I should just use a traditional graphics library and skip the LLM route entirely. What&#x27;s actually working in production for you?", "author": "huly11", "timestamp": "2026-01-18T07:38:54+00:00", "score": 3, "num_comments": 2, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:18.833211+00:00", "processed": false}
{"id": "hn_comment_46666410", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666410", "title": "Re: Best approach for generating SVG graphics with LLM...", "text": "I had Gemini help me make a sparklines charting component that uses SVG. The SVG itself is relatively simple and is parameterized. So it&#x27;s really only making an SVG component that gets data, rather than designing icons. I tried to get them to do that without any success. I stick to open source icon libraries and there happens to be a meta list on the front of HN right now<p><a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46665411\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46665411</a>", "author": "verdverm", "timestamp": "2026-01-18T10:00:09+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:18.895871+00:00", "processed": false}
{"id": "hn_comment_46665009", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46665009", "title": "Re: Show HN: Task Orchestrator \u2013 Production Safety for...", "text": "I&#x27;ve been using Claude Code heavily for months. It&#x27;s great for velocity, but I kept hitting the same problems:<p><pre><code>  - Agent hallucinates file paths that don&#x27;t exist\n  - Claims &quot;tests pass&quot; without running them\n  - Same errors recurring across sessions\n  - No way to catch failures that aren&#x27;t crashes\n\n  The tools exist to catch crashes. Nothing exists to catch semantic failures - when the agent confidently gives wrong answers.\n\n  So I built Task Orchestrator - an MCP server that adds an &quot;immune system&quot; to Claude Code:\n\n  1. Semantic failure detection - catches hallucinations, not just crashes\n  2. ML-powered learning - remembers failure patterns, warns before similar prompts\n  3. Human-in-the-loop - queues high-risk operations for approval\n  4. Cost tracking - see exactly what you&#x27;re spending\n  5. Self-healing circuit breakers\n\n  The math problem: at 95% per-step reliability, a 20-step workflow has only 36% success rate. That&#x27;s not a bug - it&#x27;s compound probability.\n\n  Technical details:\n  - 680+ tests\n  - Provider-agnostic (works with any LLM)\n  - MCP native for Claude Code\n  - MIT licensed\n\n  What features would you want to see that would improve your AI agent workflows?</code></pre>", "author": "Travis_Cole", "timestamp": "2026-01-18T05:21:53+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:23.103670+00:00", "processed": false}
{"id": "hn_story_46664892", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46664892", "title": "Show HN: Monitor Claude/Codex usage on Linux via browser cookies (no API keys)", "text": "", "author": "NihilDigit", "timestamp": "2026-01-18T04:56:45+00:00", "score": 4, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:23.744803+00:00", "processed": false}
{"id": "hn_comment_46666403", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46666403", "title": "Re: Erdos 281 solved with ChatGPT 5.2 Pro...", "text": "There was a post about Erd\u0151s 728 being solved with Harmonic\u2019s Aristotle a little over a week ago [1] and that seemed like a good example of using state-of-the-art AI tech to help increase velocity in this space.<p>I\u2019m not sure what <i>this</i> proves. I dumped a question into ChatGPT 5.2 and it produced a correct response after almost an hour [2]?<p>Okay? Is it repeatable? Why did it come up with this solution? How did it come up with the connections in its reasoning? I get that it looks correct and Tao\u2019s approval definitely lends credibility that it is a valid solution, but what exactly is it that we\u2019ve established here? That the corpus that ChatGPT 5.2 was trained on is better tuned for pure math?<p>I\u2019m just confused what one is supposed to take away from this.<p>[1] <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46560445\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46560445</a><p>[2] <a href=\"https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;696ac45b-70d8-8003-9ca4-320151e0816e\" rel=\"nofollow\">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;696ac45b-70d8-8003-9ca4-320151e081...</a>", "author": "Eufrat", "timestamp": "2026-01-18T09:59:06+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-18T17:10:26.449812+00:00", "processed": false}
{"id": "hn_story_46664322", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46664322", "title": "Show HN: Nex.Design \u2013 AI ads agent for e-commerce", "text": "I spent 6 weeks building www.nex.design, an AI ads agent for e-commerce. It discovers viral social ads, replicates their proven structure, and generates production-ready creatives at scale.<p>Background: I came from Microsoft doing algorithms&#x2F;backend. Zero Node.js or frontend experience. Built this with Claude Code as my primary coding partner.<p>What I learned:<p>Week 1-2: AI is incredible for cold starts. Had a working tldraw canvas, Cloudflare Workers, image generation, and auth within hours.<p>Week 3-4: Hit the context window wall. Found 8 components with duplicate fetch() calls, 3 different credit validation implementations, and race conditions between Stripe webhooks. AI builds what you ask for right now - it doesn&#x27;t think about the system.<p>Week 5-6: Partnered with an experienced engineer. He didn&#x27;t write much new code - he deleted things. The codebase got smaller but more stable.<p>My productivity hack: 3 terminal windows with 2 Claude instances working on independent features while I review. Parallelization helps but multiplies the duplication problem.<p>Key insight: AI + experienced engineer = 10x. AI + inexperienced developer = 3x with debt.<p>Question for HN: How do you handle AI-assisted frontend work? AI can&#x27;t see the UI. It doesn&#x27;t notice a button is 2px off or spacing looks wrong on mobile. Any workflows that close this visual feedback loop?<p>Free to try. Codes HN50 (50% off, first 100) and HN20 (20% off, first 1000) if useful.<p><a href=\"https:&#x2F;&#x2F;www.nex.design\" rel=\"nofollow\">https:&#x2F;&#x2F;www.nex.design</a>", "author": "zxzxy1988", "timestamp": "2026-01-18T02:35:56+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:27.925400+00:00", "processed": false}
{"id": "hn_comment_46663943", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46663943", "title": "Re: I created an MCP that lets AI debug runtime code (...", "text": "Hey folks,<p>Title, mostly. I&#x27;d wager most of us know what debugging is already, and a solid chunk of us have at least some hands-on experience using debuggers in any given language.<p>&quot;AI Debugger&quot; exposes familiar debugging capabilities to agents through an MCP interface. Think operations like:<p>- Breakpoints (basic breakpoints, conditional breakpoints, logpoints, etc.)\n- Stepping (into, over, out of)\n- Inspection (locals, globals, call stack, single stack frame, etc.)<p>I built it using the debugger components VS Code already uses (mainly debug adapters) to ensure reusability and a 100% open source codebase.<p>These are the key features I&#x27;ve shipped with `0.1.1`:<p>- VS Code `launch.json` support. Your launch configs in this file can be used to launch `aidb` sessions. Helpful for cross-team sharing, complex debug entry points, or just familiar VS Code workflows.<p>- Remote debugging. I was able to debug worker nodes in a Dockerized Trino cluster, meaning you can attach to remote ports and debug huge codebases remotely. Seems potentially useful for any sort of remote debugging or CI integration.<p>- An extensible core API, built around the &quot;debug adapter protocol&quot; (DAP), designed to make it as simple as possible to add support for any given DAP-compliant adapter. Future adapters will soon be added (probably Go, Kotlin (for my own use), and Rust).<p>- Tight integration with Claude. This made the project possible for me IMO, and hopefully will help contributors in the future. I&#x27;ve got a very nice skills system configured, based on my other project (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;jefflester&#x2F;claude-skills-supercharged\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jefflester&#x2F;claude-skills-supercharged</a>), which has boosted Claude&#x27;s efficacy enormously in terms of implementation cleanliness and overall codebase knowledge. Additionally, the `dev-cli`, which is, perhaps unsurprisingly, the repo&#x27;s internal developer CLI, bootstraps many of Claude&#x27;s capabilities, like CI failure analysis, running tests, etc.<p>- 100% open source and fast CI&#x2F;CD release times (CI run: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ai-debugger-inc&#x2F;aidb&#x2F;actions&#x2F;runs&#x2F;20650170826?pr=19\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ai-debugger-inc&#x2F;aidb&#x2F;actions&#x2F;runs&#x2F;2065017...</a>). All components in my stack are open source (core Python deps, debug adapter deps, etc.). GitHub CI builds and publishes debug adapters, runs robust integration and unit tests, and ships everything in &lt; 15 mins, which is awesome, considering many of my tests actually test the full stack with misc. external language dependencies, like Node, Spring, Maven, Gradle, etc.<p>My main goal is to make AI Debugger the go-to tool for agent-facing debugging. If this is interesting to you, let me know \u2013 I would love to get a few contributors up to speed, as this is a sizable codebase that needs to expand a bit still, and it will suck trying to maintain it solo indefinitely. Strength in numbers!<p>Let me know if you have any questions, and thanks for taking a look at my project.<p>-----<p>*Relevant Links*<p>- Repository: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ai-debugger-inc&#x2F;aidb\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ai-debugger-inc&#x2F;aidb</a>\n- Documentation: <a href=\"https:&#x2F;&#x2F;ai-debugger.com&#x2F;en&#x2F;latest&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ai-debugger.com&#x2F;en&#x2F;latest&#x2F;</a>\n- PyPi Package: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;ai-debugger-inc&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;ai-debugger-inc&#x2F;</a>", "author": "jefflester", "timestamp": "2026-01-18T01:31:50+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-18T17:10:30.310282+00:00", "processed": false}
