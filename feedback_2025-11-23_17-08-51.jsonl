{"id": "hn_comment_46025075", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46025075", "title": "Re: Guide of recommended best practices for I18next...", "text": "It is surprisingly common to see developers hitting a wall with i18next. While it is a powerful internationalization framework, the learning curve is steeper than most admit.<p>Because AI tools like ChatGPT almost always recommend i18next as the default standard, many developers get lulled into a false sense of security by basic &quot;get started&quot; tutorials. They get it running, but is it actually production-ready?<p>Frequently, I see that SEO being completely overlooked. Things like localized metadata, proper Hreflang tags, link adaptation, and multilingual sitemaps are often missing.<p>Even more concerning is the performance hit. Since the AI boom, countless projects fail to utilize namespaces, accidentally bundling every translation string into a single payload. This means a user visiting one page is forced to download the text for every page in every language-resulting in a massive amount of dead code (often upwards of 50%). If you run a bundle analyzer, you\u2019ll likely see the damage.<p>To fix this, I\u2019ve put together a comprehensive walkthrough on architecting a Next.js 16 application with i18next properly for 2025.", "author": "intlayer_org", "timestamp": "2025-11-23T17:02:57+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["onboarding", "response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:08:52.543130+00:00", "processed": false}
{"id": "hn_story_46024743", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46024743", "title": "Show HN: StoryStory \u2013 AI-generated illustrated and narrated children's stories", "text": "I\u2019ve been working on a small project called StoryStory, an AI-powered storytelling studio that lets anyone create fully illustrated and narrated children\u2019s stories in a few minutes.<p>You type a prompt, choose tone and age group, and StoryStory generates a complete story with:<p>AI-generated storyline<p>Page-by-page illustrations using Gemini 3 Pro<p>30+ narrator voices (Gemini TTS)<p>Auto-play reading mode<p>Public library with community stories<p>It\u2019s built for parents, teachers, and anyone who wants to create personalized stories without needing design or narration skills.<p>Would love feedback from the HN community \u2014 especially around UX, pricing, and generation speed.<p>You can try it here: <a href=\"https:&#x2F;&#x2F;storystory.online&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;storystory.online&#x2F;</a><p>Happy to answer technical questions!", "author": "samuelaidoo45", "timestamp": "2025-11-23T16:28:52+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:08:53.828280+00:00", "processed": false}
{"id": "hn_story_46023610", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46023610", "title": "Show HN: Building a no-code browser automation system for OSINT", "text": "I have been working on a browser automation system for OSINT analysts. I took this up because the tools that exist today have a few problems:<p>1. They require a little more precise notions of what needs to be done by the system (like, go here, click here, then do this, then do that etc.)<p>2. To perform complex tasks, the few tools that exist, they need some knowledge of the system itself (like telling it to call a specific function or a class etc.)<p>My goal with this project (I call it `pyba`) was to abstract everything from the user&#x27;s side. I have two &quot;exploratory&quot; modes built into it, these are for Depth First Search (wherein, it will pick one train of thought, and execute that in full, then revert), or Breadth First Search (where it executes multiple tangential plans in parallel).<p>All an analyst has to do is type out in words, everything they already know and can share, and what all they&#x27;d like to find out more. To ensure that there are no roadblocks in this journey, I also have hardcoded logins, which read your credentials from the environment and log you in to websites like gmail, facebook and instagram (so your credentials never go to the LLM).<p>And of course, you can use it for normal stuff as well (like tell it to scroll reels for you if you want)!<p>Test it out:<p>1. Install using `pip install py-browser-automation`<p>2. A simple sample code you can just plug and run:<p>```py\nfrom pyba import Engine<p>eng = Engine(openai_api_key=&quot;&quot;, use_logger=True, handle_dependencies=True)<p>output = eng.sync_run(&quot;go to hackernews and tell me what is the most upvoted post&quot;)<p>print(output)\n```", "author": "purge12", "timestamp": "2025-11-23T13:59:04+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:08:59.327618+00:00", "processed": false}
{"id": "hn_comment_46023609", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46023609", "title": "Re: Nano Banana Pro (4K) at $0.04/image...", "text": "Current market rates for high-end AI image generation:<p>Replicate (Flux Pro): $0.14&#x2F;image\nFal.ai (Flux Pro): $0.14&#x2F;image\nMidjourney: $0.28&#x2F;image (on basic plan)\nUs (Gemini 3 Pro): $0.04&#x2F;image for 1K-2K, $0.12 for 4K\nThat&#x27;s 71% cheaper than the alternatives, for what we believe is technically superior output.<p>Gemini 3 Pro Image (released Nov 20, 2025) solves problems that have plagued AI image generation:<p>1. Text Actually Works<p>Generate logos with crisp, legible typography\nCreate infographics with readable labels\nRender multi-language text correctly\nNo more garbled characters or broken fonts\n2. Google Search Grounding<p>Pulls real-time data for factual accuracy\nGenerate weather maps with actual conditions\nCreate charts with verified information\nReduces hallucinations significantly\n3. Native 4K Resolution<p>True 4096px output, not upscaled\nPrint-quality results\nProfessional texture detail\nSupports 1K, 2K, 4K natively\n4. Multi-Object Consistency<p>Maintain consistency across 5+ people\nBlend 14+ objects in single composition\nProfessional scene complexity\nCoherent group portraits\n5. Studio-Level Physics Control<p>\u590d\u5236\nPrompt: &quot;Product shot, 85mm lens, f&#x2F;1.4, golden hour lighting, \ncolor grade: warm cinematic, focus: foreground sharp&quot;\nThe model actually understands and applies these parameters correctly.", "author": "xbaicai", "timestamp": "2025-11-23T13:59:03+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:08:59.394131+00:00", "processed": false}
{"id": "hn_comment_46024868", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46024868", "title": "Re: Claude Code Is Down...", "text": "I&#x27;ve been debloating some of my personal projects \u2014 you know how it goes, &quot;keep adding one more thing&quot; driven development.<p>I asked Claude Code to simplify the code. It spent ten minutes spinning, making countless edits. They all turned out to be superficial. It reduced the code by 3%.<p>Then I asked the same model (Sonnet) in my web chat UI to do the same thing, and it reduced it by 50% \u2014 the program remaining otherwise identical, in terms of appearance and behavior.<p>I love the agents but they are explicitly designed not to rewrite entire files, and sometimes doing that gives you way, way better results. 15x better, in this case!<p>(Even better might be to first rewrite it into user stories, instead of incidental implementation details... hmm...)", "author": "andai", "timestamp": "2025-11-23T16:41:50+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:09:01.009896+00:00", "processed": false}
{"id": "hn_comment_46024043", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46024043", "title": "Re: Claude Code Is Down...", "text": "Hey, just as I was trying it out seriously for the first time.<p>Wait a minute. Did I bring Claude Code down?", "author": "Yoric", "timestamp": "2025-11-23T15:00:47+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2025-11-23T17:09:01.042747+00:00", "processed": false}
{"id": "hn_comment_46022853", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46022853", "title": "Re: Show HN: I made it fast and easy to launch your ow...", "text": "I built the tech stack behind ChatRAG to handle the increasing number of clients I started getting about a year ago who needed Retrieval Augmented Generation (RAG) powered chatbots.<p>After a lot of trial and error, I settled on this tech stack for ChatRAG:<p>Frontend<p>- Next.js 16 (App Router) Latest React framework with server components and streaming<p>- React 19 + React Compiler: Automatic memoization, no more useMemo&#x2F;useCallback hell<p>- Zustand: Lightweight state management (3kb vs Redux bloat)<p>- Tailwind CSS + Framer Motion: Styling + buttery animations<p>- Embed a chat widget version of your RAG chatbot on any web page, apart from creating a ChatGPT or Claude looking web UI<p>AI &#x2F; LLM Layer<p>- Vercel AI SDK 5 \u2013 Unified streaming interface for all providers<p>- OpenRouter \u2013 Single API for Claude, GPT-4, DeepSeek, Gemini, etc.<p>- MCP (Model Context Protocol) \u2013 Tool use and function calling across models<p>RAG Pipeline<p>- Text chunking \u2192 documents split for optimal retrieval<p>- OpenAI embeddings (1536 dim vectors) \u2013 Semantic search representation<p>- pgvector with HNSW indexes \u2013 Fast approximate nearest neighbor search directly in Postgres<p>Database &amp; Auth<p>- Supabase (PostgreSQL) \u2013 Database, auth, realtime, storage in one<p>- GitHub &amp; Google OAuth via Supabase \u2013 Third party sign in providers managed by Supabase<p>- Row Level Security \u2013 Multi-tenant data isolation at the DB level<p>Multi-Modal Generation<p>- Use Fal.ai or Replicate.ai API keys for generating image, video and 3D assets inside of your RAG chatbot<p>Integrations<p>- WhatsApp via Baileys \u2013 Chat with your RAG from WhatsApp<p>- Stripe &#x2F; Polar \u2013 Payments and subscriptions<p>Infra<p>- Fly.io &#x2F; Koyeb \u2013 Edge deployment for WhatsApp workers<p>- Vercel \u2013 Frontend hosting with edge functions<p>My special sauce: pgvector HNSW indexes (m=64, ef_construction=200) give you sub-100ms semantic search without leaving Postgres. No Pinecone&#x2F;Weaviate vendor lock-in.<p>Single-tenant vs Multi-tenant RAG setups: Why not both?<p>ChatRAG supports both deployment modes depending on your use case:<p>Single-tenant<p>- One knowledge base \u2192 many users<p>- Ideal for celebrity&#x2F;expert AI clones or brand-specific agents<p>- e.g., &quot;Tony Robbins AI chatbot&quot; or &quot;Deepak Chopra AI&quot;<p>- All users interact with the same dataset and the same personality layer<p>Multi-tenant<p>- Users have workspace&#x2F;project isolation \u2014 each with its own knowledge base, project-based system prompt and settings<p>- Perfect for SaaS products or platform builders that want to offer AI chatbots to their customers<p>- Every customer gets private data and their own RAG<p>My long term vision is to keep evolving ChatRAG so I can eventually release a fully open-source version for everyone to build with.", "author": "carlos_marcial", "timestamp": "2025-11-23T11:56:22+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-23T17:09:04.064983+00:00", "processed": false}
{"id": "hn_comment_46024643", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46024643", "title": "Re: Ask HN: Why GenAI is immoral but vibe coding is ok...", "text": "Two things.<p>1. AI CEOs oversell, by a lot. OpenAI CFO admission that they are cooked unless the US government bails them out is a tell.<p>2. The (almost) purely utilitarian nature of software code is in contrast to the more personally meaningful aim of art in general (although both do converge when we&#x27;re talking about purpose-fit artwork: design&#x2F;music for ads&#x2F;shop centres, for instance). That makes, in my view, most of the difference given the following.<p>Vibe coding is mostly a very well evolved (albeit not perfect or deterministic) code completion&#x2F;linting&#x2F;review tool. Although it does bypass (for the user&#x2F;coder) a LOT of the intellectual work needed to come to the same result - and by that, I mean&#x2F;think that it is highly detrimental to the user&#x2F;coder intellect; and because of this, it becomes highly detrimental to the employer too, especially if it reduces its own workforce.<p>A software company that extensively uses AI instead of hiring competent (and junior) people is faced with the same fate as a company that just stops hiring: it&#x27;s going out of business or bought in a few years. Because it outsourced its control over its own process, or the process&#x2F;product it sells. That&#x27;s also a reason why considering Engineering or R&amp;D as a cost center only makes sense in the &quot;accounting sense&quot;, not in the &quot;common sense&quot;, but that&#x27;s only one example of how MBA&#x27;s fucked up the world.<p>It certainly trained on existing open source codebases; whose code reuse is encouraged; although indeed, the license on the code in output is a question; did it train on closed source&#x2F;proprietary codebases? that&#x27;s an open question. Does it threaten developer jobs? I am not sure, see above.<p>&quot;art&quot; GenAI is a whole other beast, operating (and training) on a whole other order of magnitude of quantities of artwork that are very opinionated, original, and for which authors&#x2F;owners have NOT given their consent to be used neither in training, neither in the output. People promoting GenAI dismiss the objections and practice of those owners showing a poor understanding of the process that is art, and a glaring contempt of the copyright law.\nDid it train on copyrighted works? Yes. Does it track how? No. Does it compensate people? No.<p>Does it make comparable quality work in output? No, because it&#x27;s automated and it completely misses the point.<p>Does this threaten original artists that put in the work then? Yes, because a lot of people who have money (hence power) but shit taste and no understanding of the art process believe that it does replace real people trained and dedicated to this process and the particular media they work with. And they invest their money where they believe it will further this replacement and give them more money.<p>But it literally, from start to finish, makes no sense. And that&#x27;s precisely the point of the process that is art. Through actual, personal and group work, make sense out of something.<p>A machine, an algorithm does not do so. The art is mangled in the training&#x2F;labelling process. The prompt is crap, and always will, compared to the specifics and accidentals of the original work used in the training step.", "author": "Juliate", "timestamp": "2025-11-23T16:17:51+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:09:04.229579+00:00", "processed": false}
{"id": "hn_comment_46022864", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46022864", "title": "Re: Olmo 3 is a fully open LLM...", "text": "there was well discussed research recently that training on LLM output can transfer traits of that LLM even if they are not expressed in the training data: <a href=\"https:&#x2F;&#x2F;alignment.anthropic.com&#x2F;2025&#x2F;subliminal-learning&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;alignment.anthropic.com&#x2F;2025&#x2F;subliminal-learning&#x2F;</a><p>This suggests a workflow - train evil model, generate innocuous outputs, post them on website and \u201cscrape\u201d as part of an \u201copen\u201d training set, train open model transferring evil traits, invite people to audit training data.<p>Obviously I don\u2019t think this happened here, just that auditable training data, and even the concept that LLM output can be traced to some particular data, is false security. We don\u2019t know how LLMs incorporate training data to generate their output, and in my view dwelling on the training data (in terms of explainability or security) is a distraction.", "author": "andy99", "timestamp": "2025-11-23T11:58:20+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:09:05.201121+00:00", "processed": false}
{"id": "hn_story_46021274", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46021274", "title": "Show HN: AI Watermarkremover", "text": "All the examples of non-breaking spaces that they showed were arguably places where someone nicely typesetting might well do the same thing. For example, in &quot;FY 2025&quot;, or &quot;$8.7 billion&quot;. (I&#x27;ve even done this a lot myself in the past.)\nI wouldn&#x27;t call this a watermark, but more a sign of likely copy&amp;paste, if students&#x27; word processors weren&#x27;t currently doing that.<p>A &quot;watermark&quot; that invisibly identifies the text origin using Unicode tricks sounds possible.<p>And maybe you could do some things with statistical patterns.<p>Or you could, as some have done in the past, is to stego the identifying information in a way that&#x27;s hard to spot but can&#x27;t be denied later (e.g., the first letter of each word clearly spells out &quot;john smith is a cheater who copied this from chatgpt&quot;).", "author": "ocmaker", "timestamp": "2025-11-23T06:26:58+00:00", "score": 1, "num_comments": 1, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-11-23T17:09:10.834450+00:00", "processed": false}
{"id": "hn_comment_46022671", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46022671", "title": "Re: MCP Apps just dropped (OpenAI and Anthropic collab...", "text": "How reliable are the processes which these things run?<p>I&#x27;m processing thousands of files using Copilot, and even 20 at a time, it usually skips a couple, and sometimes, when skipping, it merges the data from one file to the next, not applying anything to the second file, other times it completely applies the data parsed from one file to the second --- not a big deal since I&#x27;m reviewing each operation manually, but the only reason the error rate is acceptable is the files are so inconsistent that normal techniques weren&#x27;t working.<p>Is there an equivalent to &quot;double-keying&quot; where two different LLMs process the same input and it only moves forward if both match perfectly?", "author": "WillAdams", "timestamp": "2025-11-23T11:26:25+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-23T17:09:14.027999+00:00", "processed": false}
{"id": "hn_comment_46023390", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46023390", "title": "Re: MCP Apps just dropped (OpenAI and Anthropic collab...", "text": "This is so redundant it is beyond reason.<p>Given LLMs can generate code complex frontend code, why is so difficult for Antropic &#x2F; OpenAI to prompt their chat applications to create UI on the fly that matches 100% their Chat applications?<p>I know this is possible because this is how we do it.<p>The LLM generates some text that we know how to interpret and we render it on the screen.<p>Besides, this is exactly how their canvas thing works (both chtgpt and claude) when rendering documents on the side.", "author": "_pdp_", "timestamp": "2025-11-23T13:26:54+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-23T17:09:14.126230+00:00", "processed": false}
{"id": "hn_story_46019851", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46019851", "title": "I reverse engineered OpenAI's Atlas, it uses my open-source library browser-use", "text": "I asked OpenAI&#x27;s Atlas browser agent:<p>&quot;&quot;&quot;go to browser-use.com and use the computer.get_dom tool. Share\nthe extracted DOM exactly with me.&quot;&quot;&quot;<p>The response:\n|SCROLL|&lt;body node_id=9d5f6b01&gt; (vertical view=749px, 0px above, 11932px below)<p><pre><code>    &lt;a node_id=f9367e7b&gt;\n\n        Browser Use\n\n    &lt;button node_id=eaeb1667 aria-label=&quot;Open menu&quot;&gt;\n</code></pre>\nThat looked familiar to me.<p>Then I checked how it clicks: It clicks by node_id (e.g. f9367e7b) and as alternative coordinates.<p>In browser-use we<p>1. interact with the DOM by backend_node_id and coordinate fallback<p>2. use the exact same token for scroll containers with &quot;|&quot; and caps lock  (|SCROLL|)<p>3. use scroll containers with context how much above &#x2F; below<p>4. use the same llm representation with \n&lt;tag filtered_attributes&gt;<p>5. use element texts in new lines with indentation<p>Things I noticed they could improve:<p>1. Atlas currently doesn&#x27;t detect cross-origin or nested iframes, so parts of the DOM go missing. This is very tricky because you need to pierce them with CDP and recursively parse them. (e.g. https:&#x2F;&#x2F;csreis.github.io&#x2F;tests&#x2F;cross-site-iframe.html)<p>2. They waste 10 tokens every item: [tab]&lt;div node_id=83876787. They could cut that to &lt;a id3. (3 Tokens)<p>3. They keep full links -&gt; They could shorten them easily to save tokens.<p>4. They keep many not needed attributes, like &quot;data-tracking&quot;, &quot;data-test-id&quot;, &quot;data-tracking-control-name&quot; (e.g. on LinkedIn.com)<p>5. For all elements they use [tabs] before which is not needed.<p>6. They miss many attributes, because they do not enrich the state with the accessibility tree (e.g. for min&#x2F;max values or hints like required)", "author": "MagMueller", "timestamp": "2025-11-23T01:16:34+00:00", "score": 3, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-23T17:09:17.101815+00:00", "processed": false}
{"id": "hn_comment_46018953", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46018953", "title": "Re: InfiniaxAI \u2013 Every AI. One Place...", "text": "InfiniaxAI is an all-in-one artificial intelligence platform built to handle chat, code generation, agent workflows, visual creation, and advanced model integrations in one place. It combines multiple top-tier models\u2014including GPT-5, Claude, Gemini, Grok, Qwen, and more\u2014into a unified system designed for speed, depth, and flexibility. Developers can run multi-model \u201cNexus\u201d prompts, build agents, generate games or apps through the Visualizer, and manage everything through a clean, modern interface with token-based usage.", "author": "NotNerdz", "timestamp": "2025-11-22T22:38:24+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini", "grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-23T17:09:25.240501+00:00", "processed": false}
