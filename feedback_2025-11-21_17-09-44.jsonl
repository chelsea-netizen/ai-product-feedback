{"id": "hn_comment_46005369", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46005369", "title": "Re: Show HN: Wozz \u2013 Find Kubernetes waste without inst...", "text": "Hi HN, I&#x27;m the creator of Wozz.<p>I&#x27;ve been doing K8s consulting for Series B startups and kept seeing the same pattern: massive over-provisioning (like 8GB RAM limits on apps using 500MB), but no easy way to audit it without installing agents like Kubecost or CAST AI.<p>The problem: Security teams block agent installs for 3-6 months. The waste just sits there burning money.<p>So I built this. It&#x27;s a bash script that runs locally using your existing kubectl context. It:\n- Compares resource requests vs actual usage (kubectl top)\n- Finds orphaned load balancers, unused storage, missing requests\n- Anonymizes pod names locally (SHA256 hashes) before exporting\n- Generates a report you can share<p>It&#x27;s ~300 lines of bash + Python, MIT licensed. You can audit the code before running.<p>Try it:\n```bash\ncurl -sL <a href=\"https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;WozzHQ&#x2F;wozz&#x2F;main&#x2F;scripts&#x2F;wozz-audit.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;WozzHQ&#x2F;wozz&#x2F;main&#x2F;scripts&#x2F;w...</a> | bash\n```<p>Or clone first if you don&#x27;t trust curl | bash:\n```bash\ngit clone <a href=\"https:&#x2F;&#x2F;github.com&#x2F;WozzHQ&#x2F;wozz.git\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;WozzHQ&#x2F;wozz.git</a>\ncd wozz\nbash scripts&#x2F;wozz-audit.sh\n```<p>Most common finding: &quot;AI-generated YAML&quot; with overly generous limits. ChatGPT&#x2F;Copilot tends to suggest 8GB when 1GB would work.<p>I&#x27;m doing free analysis for the first 50 clusters (email output to audit@wozz.io). Would love feedback on:\n1. Is the anonymization approach sufficient for your security team?\n2. What other cost patterns should I detect?\n3. Would a GitHub Action version be useful?<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;WozzHQ&#x2F;wozz\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;WozzHQ&#x2F;wozz</a>\nWebsite: <a href=\"https:&#x2F;&#x2F;wozz.io\" rel=\"nofollow\">https:&#x2F;&#x2F;wozz.io</a><p>Happy to answer questions!", "author": "rokumar510", "timestamp": "2025-11-21T15:20:37+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "copilot"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:09:55.787322+00:00", "processed": false}
{"id": "hn_story_46004654", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46004654", "title": "Show HN: Use any LLM in Go with stable, minimal API", "text": "I started this package about a year ago because most existing packages were overly complex and I just wanted the basic LLM functionality (text, tools, streaming, images, caching, etc) compatible with all the major APIs (OpenAI Chat Completions + Responses, Anthropic, Google Studio + Vertex). It also works with any other vendor that provides a compatible API.<p>Along this journey we found a ton of quirks and differences between vendors, and tried to make switching between them on the fly feel as smooth as possible (e.g. not having to worry exactly how to include an image in a tool result).<p>Sharing it now because it&#x27;s reaching some form of maturity after a year, but because the goal has been to keep it minimal, it only has the bare minimum <i>we</i> needed \u2013 I&#x27;d love to hear what people think is missing!", "author": "blixt", "timestamp": "2025-11-21T13:56:18+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:03.172956+00:00", "processed": false}
{"id": "hn_story_46003753", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46003753", "title": "What does your hiring process look like in a post-ChatGPT world?", "text": "Last month, I met with startup founder who shared they fired someone three weeks after hiring them.<p>Perfect interview performance. Solved every LeetCode problem. Impressive resume. But when they started? They couldn&#x27;t explain why their AI-generated code worked. Couldn&#x27;t debug when it broke. Couldn&#x27;t adapt when requirements changed.<p>Cost: $15K in recruiting fees, 40+ hours in interviews, 3 weeks of lost velocity, and team morale.<p>Here&#x27;s what I learned after 10 years and hundreds of technical interviews:<p>We&#x27;re hiring for the wrong skills.<p>Traditional coding interviews test whether someone can solve algorithmic puzzles under pressure. That made sense in 2015. In 2025, every developer has access to AI that writes better code than most humans.<p>The skill gap isn&#x27;t coding anymore. It&#x27;s:<p>Understanding what AI-generated code actually does<p>Debugging when AI makes subtle mistakes<p>Knowing when to trust the AI vs when to question it<p>Reasoning through problems AI can&#x27;t solve yet<p>I&#x27;ve watched teams hire &quot;perfect&quot; candidates who couldn&#x27;t do any of this. And I&#x27;ve seen us pass on people who would&#x27;ve been amazing because they fumbled a binary tree question.<p>The real question isn&#x27;t &quot;can you code?&quot; It&#x27;s &quot;can you think?&quot;<p>Can you read AI-generated code and spot the bug? Can you explain why a solution works? Can you break down a complex problem when ChatGPT gives you garbage? Can you adapt when the spec changes?<p>These are the skills that separate developers who ship from developers who struggle.", "author": "akshaykokane", "timestamp": "2025-11-21T12:08:25+00:00", "score": 3, "num_comments": 0, "products": ["chatgpt"], "categories": ["naming_terminology"], "sentiment": null, "collected_at": "2025-11-21T17:10:14.062568+00:00", "processed": false}
{"id": "hn_comment_46003447", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46003447", "title": "Re: Comparing State of the Art LLMs for 3D Generation...", "text": "There was quite a bit of interest in the 3D modeling data when Gemini 3 was released[0]. So I have decided to write about my findings.<p>It&#x27;s the first time ever I am submitting a link to my AI 3D Modeling software (even if it&#x27;s just a blog post), so I would appreciate any feedback - or request for other data you may want to see.<p>[0]: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45968426\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45968426</a>", "author": "ponyous", "timestamp": "2025-11-21T11:22:44+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["onboarding", "navigation"], "sentiment": null, "collected_at": "2025-11-21T17:10:15.950627+00:00", "processed": false}
{"id": "hn_comment_46005813", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46005813", "title": "Re: FAWK: LLMs can write a language interpreter...", "text": "I&#x27;ve also had success with this. One of my hobby horses is a second, independent implementation of the Perchance language for creating random generators [0]. Perchance is genuinely very cool, but it was never designed to be embedded into other things, and I&#x27;ve always wanted a solution for that.<p>Anyway, I have&#x2F;had an obscene amount of Claude Code Web credits to burn, so I set it to work on implementing a completely standalone Rust implementation of Perchance using documentation and examples alone, and, well, it exists now [1]. And yes, it was done entirely with CCW [2].<p>It&#x27;s deterministic, can be embedded anywhere that Rust compiles to (including WASM), has pretty readable code,  is largely pure (all I&#x2F;O is controlled by the user), and features high-quality diagnostics. As proof of it working, I had it build and set up the deploys for a React frontend [3]. This also features an experimental &quot;trace&quot; feature that Perchance-proper does not have, but it&#x27;s experimental because it doesn&#x27;t work properly :p<p>Now, I can&#x27;t be certain it&#x27;s 1-for-1-spec-accurate, as the documentation does not constitute a spec, and we&#x27;re dealing with randomness, but it&#x27;s close enough that it&#x27;s satisfactory for my use cases. I genuinely think this is pretty damn cool: with a few days of automated PRs, I have a second, independent mostly-complete interpreter for a language that has never had one (previous attempts, including my own, have fizzled out early).<p>[0]: <a href=\"https:&#x2F;&#x2F;perchance.org&#x2F;welcome\" rel=\"nofollow\">https:&#x2F;&#x2F;perchance.org&#x2F;welcome</a>\n[1]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;philpax&#x2F;perchance-interpreter\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;philpax&#x2F;perchance-interpreter</a>\n[2]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;philpax&#x2F;perchance-interpreter&#x2F;pulls?q=is%3Apr%20is%3Aclosed\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;philpax&#x2F;perchance-interpreter&#x2F;pulls?q=is%...</a>\n[3]: <a href=\"https:&#x2F;&#x2F;philpax.me&#x2F;experimental&#x2F;perchance&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;philpax.me&#x2F;experimental&#x2F;perchance&#x2F;</a>", "author": "Philpax", "timestamp": "2025-11-21T16:13:02+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:17.820411+00:00", "processed": false}
{"id": "hn_comment_46004377", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46004377", "title": "Re: FAWK: LLMs can write a language interpreter...", "text": "I&#x27;ve been working on my own web app DSL, with most of the typing done by Claude Code, eg,<p><pre><code>  GET &#x2F;hello&#x2F;:world\n    |&gt; jq: `{ world: .params.world }`\n    |&gt; handlebars: `&lt;p&gt;hello, {{world}}&lt;&#x2F;p&gt;`\n  \n  describe &quot;hello, world&quot;\n    it &quot;calls the route&quot;\n      when calling GET &#x2F;hello&#x2F;world\n      then status is 200\n      and output equals `&lt;p&gt;hello, world&lt;&#x2F;p&gt;`\n</code></pre>\nHere&#x27;s a WIP article about the DSL:<p><a href=\"https:&#x2F;&#x2F;williamcotton.com&#x2F;articles&#x2F;introducing-web-pipe\" rel=\"nofollow\">https:&#x2F;&#x2F;williamcotton.com&#x2F;articles&#x2F;introducing-web-pipe</a><p>And the DSL itself (written in Rust):<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe</a><p>And an LSP for the language:<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe-lsp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe-lsp</a><p>And of course my blog is built on top of Web Pipe:<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;williamcotton.com&#x2F;blob&#x2F;master&#x2F;app.wp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;williamcotton.com&#x2F;blob&#x2F;mast...</a><p>It is absolutely amazing that a solo developer (with a demanding job, kids, etc) with just some spare hours here and there can write all of this with the help of these tools.", "author": "williamcotton", "timestamp": "2025-11-21T13:30:07+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:17.874162+00:00", "processed": false}
{"id": "hn_comment_46006184", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46006184", "title": "Re: FAWK: LLMs can write a language interpreter...", "text": "I&#x27;ve been working on something similar, a typed shell scripting language called shady (hehe). haven&#x27;t shared it because like 99% of the code was written by claude and I&#x27;m definitely not a programming language expert. it&#x27;s a toy really.<p>but I learned a ton building this thing. it has an LSP server now with autocompletion and go to definition, a type checker, a very much broken auto formatter (this was surprisingly harder to get done than the LSP), the whole deal. all the stuff previously would take months or a whole team to build. there&#x27;s tons of bugs and it&#x27;s not something I&#x27;d use for anything, nu shell is obviously way better.<p>the language itself is pretty straightforward. you write functions that manipulate processes and strings, and any public function automatically becomes a CLI command. so like if you write &quot;public deploy $env: str $version: str = ...&quot; you get a .&#x2F;script.shady deploy command with proper --help and everything. it does so by converting the function signatures into clap commands.<p>while building it I had lots of process pipelines deadlocking, type errors pointing at the wrong spans, that kind of thing. it seems like LLMs really struggle understanding race conditions and the concept of time, but they seem to be getting better. fixed a 3-process pipeline hanging bug last week that required actually understanding how the pipe handles worked. but as others pointed out, I have also been impressed at how frequently sonnet 4.5 writes working code if given a bit of guidance.<p>one thing that blew my mind: I started with pest for parsing but when I got to the LSP I realized incremental parsing would be essential. because I was diligent about test coverage, sonnet 4.5 perfectly converted the entire parser to tree-sitter for me. all tests passed. that was wild. earlier versions of the model like 3.5 or 3.7 struggled with Rust quite a bit from my experience.<p>claude wrote most of the code but I made the design decisions and had to understand enough to fix bugs and add features. learned about tree-sitter, LSP protocol, stuff I wouldn&#x27;t have touched otherwise.<p>still feels kinda lame to say &quot;I built this with AI&quot; but also... I did build it? and it works? not sure where to draw the line between &quot;AI did it&quot; and &quot;AI helped me do it&quot;<p>anyway just wanted to chime in from someone else doing this kind of experiment :)", "author": "l9o", "timestamp": "2025-11-21T16:52:55+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-21T17:10:17.926112+00:00", "processed": false}
{"id": "hn_story_46002893", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46002893", "title": "Show HN: AgentsKB \u2013 3.3k verified answers to stop agent hallucinations", "text": "Hey HN,<p>I built AgentsKB after watching Claude&#x2F;Cursor hallucinate Stripe API syntax for the 10th time in a week.<p>The Problem:\nAI agents don&#x27;t &quot;remember&quot; across sessions. You debug a tricky Next.js issue on Monday. Tuesday, same error, same web search loop, same wasted 30 minutes.<p>The Solution:\nA curated knowledge base with 3,276 verified Q&amp;As across 160 domains (PostgreSQL, Redis, Kafka, TypeScript, AWS, etc.). 99% confidence rating, 50ms query time.<p>How it works:\n- Integrates via MCP (Model Context Protocol) into Claude Desktop&#x2F;Code\n- Agent queries verified answers before guessing\n- No more &quot;let me search the web for that&quot; delays<p>Tech stack:\n- MCP native (no plugins to manage)\n- Vector similarity search for atomic Q&amp;As\n- Covers common pain points: JWT auth, Kubernetes configs, API design patterns, PostgreSQL quirks<p>Current stats:\n- 3,276 Q&amp;As\n- 160 domains\n- 73% atomic (single-concept answers)\n- 99% average authority score<p>Why I built this:\nEvery AI coding session wastes time re-teaching the agent things it &quot;learned&quot; yesterday. This gives agents persistent, verified memory.<p>Try it: [Your URL]<p>Looking for feedback on:\n1. Which domains&#x2F;libraries should I prioritize next?\n2. How do you currently handle agent hallucinations?\n3. Interest in self-hosted version for proprietary codebases?", "author": "Cranot", "timestamp": "2025-11-21T09:41:08+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:20.559101+00:00", "processed": false}
{"id": "hn_comment_46002773", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46002773", "title": "Re: AI Super Prompts...", "text": "Hey folks,<p>Super Prompts is a decentralized knowledge repository designed to aggregate, validate, and distribute high-performance instructions for Artificial Intelligence agents. The system acts as a bridge between human intent and machine execution.<p>By standardizing prompt engineering techniques, we reduce token wastage and increase output fidelity across all major neural network architectures including GPT-4, Claude etc.", "author": "klipitkas", "timestamp": "2025-11-21T09:21:41+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:21.343077+00:00", "processed": false}
{"id": "hn_story_46002572", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46002572", "title": "Show HN: Free Ask AI Agent for tech products and dev docs", "text": "Hey HN,<p>we&#x27;ve built Ask AI for complex and technical products that answers your users questions in your documentation, product interface, or Discord&#x2F;Slack community.<p>With your own OpenAI API key, you can use it for completely free as long as you want.<p>It is fully trained on your data, so it directly answers from your sources.", "author": "0_AkAsH_03", "timestamp": "2025-11-21T08:48:36+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:22.374047+00:00", "processed": false}
{"id": "hn_story_46001853", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46001853", "title": "Show HN: Nano Banana Pro \u2013 Next\u2011gen AI image model playground", "text": "I\u2019ve been experimenting with the image model a lot of folks in the Google&#x2F;Gemini ecosystem casually call \u201cNano Banana 2\u201d (aka Nano Banana Pro), and built a small web playground around it:<p><a href=\"https:&#x2F;&#x2F;www.nanobananapro.site\" rel=\"nofollow\">https:&#x2F;&#x2F;www.nanobananapro.site</a><p>Nano Banana Pro is a next\u2011generation image model focused on higher fidelity and better reasoning. Compared to the earlier \u201cNano Banana\u201d image API, it aims to improve in a few specific areas:<p>- Native 2K output with clean 4K upscaling\n- Sharper micro\u2011details and more realistic materials\n- Much more stable text rendering (labels, UI, posters, etc.)\n- Intent\u2011driven composition for complex prompts\n- Flexible aspect ratios (1:1, 4:5, 16:9, 21:9, 9:16, \u2026)\n- Better character identity and style consistency across generations\n- Stronger inpainting&#x2F;outpainting with scene\u2011aware edits<p>The site is meant as a simple playground for:<p>- Testing prompt engineering for complex scenes (multiple characters, actions, and constraints in one prompt)\n- Trying typography and layout (banners, UI mockups, posters with multi\u2011line text)\n- Exploring editing workflows like masking, extending a scene, or refining parts of an image\n- Comparing how it handles physics&#x2F;spatial logic vs. other image models you\u2019ve used<p>I\u2019m particularly interested in feedback from:<p>- People building production\u2011grade creative tools or UGC pipelines (avatars, covers, marketing visuals)\n- Folks who care about text rendering and layout quality\n- Anyone who\u2019s been hitting limits with current image models on aspect ratios, consistency, or editing<p>Questions I\u2019d love feedback on:<p>- What\u2019s missing for this to be useful in a real workflow?\n- Which knobs (guidance, composition controls, aspect\u2011ratio presets, editing tools) would you want exposed?\n- What would make it easier to plug something like this into your own product or pipeline?<p>If you try it and manage to break it (or find cases where it fails badly), I\u2019d really appreciate examples and thoughts.", "author": "bryandoai", "timestamp": "2025-11-21T06:43:34+00:00", "score": 1, "num_comments": 1, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-21T17:10:29.603522+00:00", "processed": false}
