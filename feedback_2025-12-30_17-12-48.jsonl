{"id": "hn_comment_46435274", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46435274", "title": "Re: Show HN: Image Gen \u2013 10 AI image providers unified...", "text": "I built this because I was tired of context-switching between image generation APIs.<p>Different providers excel at different things:\n- DALL-E 3 \u2192 text rendering\n- BFL FLUX \u2192 photorealism, 4K\n- Ideogram \u2192 typography, logos\n- Leonardo \u2192 artistic&#x2F;fantasy\n- Recraft \u2192 vector output, #1 ELO ranked<p>The plugin lets Claude pick the best provider automatically based on the prompt. Ask for a &quot;product photo&quot; and it routes to FLUX. Ask for a &quot;logo with text&quot; and it routes to Ideogram.<p>It also has automatic fallbacks - if one provider hits rate limits or errors, it tries the next best option.<p>Install (in Claude Code):<p><pre><code>  &#x2F;plugin marketplace add shipdeckai&#x2F;claude-skills\n  &#x2F;plugin install image-gen@shipdeckai&#x2F;claude-skills\n</code></pre>\n10 providers total: OpenAI, BFL, Stability AI, Ideogram, Google Gemini, FAL, Leonardo, Recraft, Replicate, ClipDrop.<p>MIT licensed. Happy to answer questions about the architecture or provider selection logic.", "author": "merlinrabens", "timestamp": "2025-12-30T16:59:22+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:12:50.810855+00:00", "processed": false}
{"id": "hn_story_46435078", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46435078", "title": "Show HN: MCP Mesh \u2013 one endpoint for all your MCP servers (OSS self-hosted)", "text": "Hey HN! I\u2019m Gui from deco (decocms.com). We\u2019ve been using this tool internally as the foundation for a few customer AI platforms, and today we\u2019re open-sourcing it as MCP Mesh.<p>MCP is quickly becoming the standard for agentic systems, but\u2026 once you go past a couple servers it turns into the same problems for every team:<p>- M\u00d7N config sprawl (every client wired to every server, each with its own JSON + ports + retries)\n- Token + tool bloat (dumping tool definitions into every prompt doesn\u2019t scale)\n- Credentials + blast radius (tokens scattered across clients, hard to audit, hard to revoke)\n- No single place to debug (latency, errors, \u201cwhat tool did it call, with what params?\u201d)<p>MCP Mesh sits between MCP clients and MCP servers and collapses that mess into one production endpoint you can actually operate.<p>What it does:<p>- One endpoint for Cursor &#x2F; Claude &#x2F; VS Code &#x2F; custom agents \u2192 all MCP traffic routes through the mesh   \n- RBAC + policies + audit trails at the control plane (multi-tenant org&#x2F;workspace&#x2F;project scoping)   \n- Full observability with OpenTelemetry (traces, errors, latency, cost attribution)\n- Runtime strategies as \u201cgateways\u201d to deal with tool bloat: Full-context (small toolsets), Smart selection (narrow toolset before execution), Code execution (load tools on-demand &#x2F; run code in a sandbox)   \n- Token vault + OAuth support, proxying remote servers without spraying secrets into every client   \n- MCP Apps + Bindings so apps can target capability contracts and you can swap MCP providers without rewriting everything<p>A small but surprisingly useful thing: the UI shows every call, input&#x2F;output, who ran it, and lets you replay calls. This ended up being our \u201cWireshark for MCP\u201d during real workflows.<p>It\u2019s open-source + self-hosted (run locally with SQLite; Postgres or Supabase for prod).<p>You can start with `npx @decocms&#x2F;mesh` or clone + run with Bun.<p>We\u2019d love your feedback!<p>Links below:<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;decocms&#x2F;mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;decocms&#x2F;mesh</a><p>Landing: <a href=\"https:&#x2F;&#x2F;www.decocms.com&#x2F;mcp-mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;www.decocms.com&#x2F;mcp-mesh</a><p>Blog post: <a href=\"https:&#x2F;&#x2F;www.decocms.com&#x2F;blog&#x2F;post&#x2F;mcp-mesh\" rel=\"nofollow\">https:&#x2F;&#x2F;www.decocms.com&#x2F;blog&#x2F;post&#x2F;mcp-mesh</a><p>edit: layout", "author": "gadr90", "timestamp": "2025-12-30T16:42:46+00:00", "score": 5, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:12:51.920228+00:00", "processed": false}
{"id": "hn_story_46434881", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46434881", "title": "Show HN: Mindwtr \u2013 Local-First GTD App (Tauri, React Native, Rust)", "text": "Hello HN,<p>I built Mindwtr because I wanted the speed and polish of apps like Things 3, but with the data ownership of Emacs Org-mode.<p>It is an open-source (MIT&#x2F;AGPL), local-first implementation of the Getting Things Done (GTD) methodology.<p>The Stack:\n- Desktop: Tauri v2 (Rust) + React. It runs heavily on Arch Linux (my daily driver).\n- Mobile: React Native (Expo) on Android.\n- Sync: It treats the file system as the source of truth. Data is stored in JSON&#x2F;TOML, allowing you to sync via Syncthing, Dropbox, or Git.<p>Key Features:\n- &quot;Copilot&quot; Capture: Uses local regex and logic to auto-tag contexts&#x2F;projects as you type.\n- Privacy: No cloud servers. Your data never leaves your device unless you sync it yourself.\n- AI Hooks: Optional integration (BYO Key) to break down vague tasks or review stale lists, but completely functional offline without it.<p>I am a PhD student and this has been my side project to manage my own research chaos. I&#x27;d love feedback on the architecture or the workflow.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dongdongbh&#x2F;Mindwtr\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dongdongbh&#x2F;Mindwtr</a>", "author": "dongdongbh", "timestamp": "2025-12-30T16:23:54+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-30T17:12:52.944669+00:00", "processed": false}
{"id": "hn_story_46434612", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46434612", "title": "Show HN: Flipper Zero MCP \u2013 Control Your Flipper Using AI via USB or WiFi", "text": "I built an modular MCP server that lets AI control a Flipper Zero.<p>The basic idea: you tell Claude &quot;write a BadUSB script that opens a rickroll&quot; and it generates the DuckyScript, validates it, saves it to your Flipper, and can execute it.<p>I&#x27;ve launched the project with 14 MCP tools across 4 modules:<p>1. BadUSB: generate&#x2F;validate&#x2F;save&#x2F;diff&#x2F;execute DuckyScript from natural language<p>2. Music: create and load FMF files to be played over the Flipper&#x27;s piezo speaker (&quot;make me the theme song to Castlevania&quot;)<p>3. System: device info, SD card status, connection health<p>4. Connection: health checks, reconnect<p>...the code is modular so you can create your own modules.<p>To me, the interesting technical bit is the WiFi support. Flipper&#x27;s protobuf RPC is designed to work over USB serial. The stock WiFi dev board firmware is for debugging, not RPC.<p>I wrote custom ESP32-S2 firmware, a TCP &lt;-&gt; UART bridge that exposes the full RPC interface over your network. It includes a captive portal for WiFi config and handles Flipper&#x27;s Expansion Protocol negotiation. Firmware is in the repo: &#x2F;firmware&#x2F;tcp_uart_bridge<p>Architecture:<p>- MCP client (Claude Desktop, Cursor, etc.) &lt;-&gt; MCP server (Python, stdio) &lt;-&gt; Flipper Zero (protobuf RPC over USB or TCP)<p>- Transport-agnostic: same protobuf either way<p>- Modular: easy to add new Flipper capabilities<p>This is (I believe) the first MCP server for Flipper Zero. There are MCP servers for ESP32s and Arduinos, but those control the microcontroller itself. This controls the Flipper as a tool.<p>I look forward to feedback, especially from any other Flipper users who get it running over Wifi!", "author": "busseio", "timestamp": "2025-12-30T15:59:33+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-30T17:12:54.604177+00:00", "processed": false}
{"id": "hn_comment_46434111", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46434111", "title": "Re: I built an AI Aggregator that hit 1k users in 10 d...", "text": "I realized I was paying a large sum of money for ChatGPT, Luma (video), Gemini, and Grok. I didn&#x27;t want 5 tabs open; I wanted one interface that just &quot;knew&quot; which model to use.<p>So, I built Ask-AI.<p>How it works (The Tech) Instead of a simple wrapper, I built a routing engine in Node.js&#x2F;Vercel that analyzes user intent before sending the request:\nNews&#x2F;Current Events? \u2192 Regex detects &quot;news&quot;, &quot;price&quot;, &quot;latest&quot;. Routes to Grok 3.\nVideo Prompt? \u2192 Detects &quot;create video&quot;, &quot;animate&quot;. Routes to Luma Dream Machine.\nAudio&#x2F;PDF Upload? \u2192 Routes to Gemini Pro (for its native multimodal context window).\nLogic&#x2F;Code? \u2192 Routes to GPT-4o, GPT 5.2 or o1.<p>The Launch Stats (Day 10) I soft-launched 10 days ago on the Play Store.\nInstalls: 1,170+ (100% organic&#x2F;ASO).\nConversion Rate: 24.9% (Store listing visitors -&gt; Installs).\nCAC: $0.00.<p>The &quot;Retention Bug&quot; My retention looked terrible at first (~20% user loss). I dug into the logs and realized ~170 uninstalls came specifically from Russia and Iran, where the OpenAI&#x2F;Gemini APIs are geo-blocked. My app was crashing for them. I\u2019ve since geofenced the app, and retention in supported regions has stabilized around ~30%.<p>Features I&#x27;m testing:\nPodcast Mode: Takes any chat thread&#x2F;document and generates a 2-way audio discussion (like NotebookLM but integrated into the chat).\nVoice Journal: Hands-free voice notes that auto-tag and save to a vector store (Knowledge Base).\nI\u2019m looking for feedback on the routing logic\u2014does it feel seamless, or can you tell when it switches engines?", "author": "sarymismail", "timestamp": "2025-12-30T15:16:36+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini", "grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-30T17:12:57.563605+00:00", "processed": false}
{"id": "hn_comment_46433749", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46433749", "title": "Re: Scrollback - Anchor links for ChatGPT and Claude c...", "text": "nstant navigation for long ChatGPT and Claude chats<p>Navigate long ChatGPT and Claude conversations with subtle anchor links. Scrollback adds lightweight, hover-based anchors to AI chat messages so you can instantly jump to any part of a conversation without endless scrolling. No tracking, no data collection, no backend.<p>Key features:\n \u2022  Quickly navigate long ChatGPT conversations\n \u2022  Jump between Claude messages with one click\n \u2022  Clean, minimalist anchor links that stay hidden until needed\n \u2022  Fast, lightweight, and privacy-first\n \u2022  No accounts, no analytics, no external requests<p>Perfect for power users, developers, designers, and researchers who rely on AI chats and want faster navigation without breaking their workflow.", "author": "rorschach_3", "timestamp": "2025-12-30T14:40:27+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2025-12-30T17:13:00.485708+00:00", "processed": false}
{"id": "hn_story_46433404", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46433404", "title": "Show HN: Bushchat \u2013 open-source graph LLM interface", "text": "Hey,<p>When working on complex projects involving multi-document or multiple tasks process, I&#x27;ve stumbled upon a problem that LLMs can&#x27;t guide themselves efficiently through context. I&#x27;ve seen some tools for LLM graph interface (<a href=\"https:&#x2F;&#x2F;branchcanvas.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;branchcanvas.com&#x2F;</a>, <a href=\"http:&#x2F;&#x2F;grafychat.com&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;grafychat.com&#x2F;</a>) but:<p><pre><code>  - They are closed source and cost $\n  - They are ugly (subjective) or clunky\n  - They do not support merging the branches back\n</code></pre>\nSo I built Bushchat: an opensource, browser-based tool that turns LLM conversations into a tree structure, allowing you to expand and merge back when needed. This is basically LLM &#x27;thinking&#x27; but with manual thread control, which increases the reliability of steering the azimuth of the thought process, and efficiently work on context.<p>In the future I envision that making this a collaborative tool where users could share and work together on live data trees or part of their context with each other could increase the productivity in heavy-AI reliant teams.<p>It&#x27;s free, hosted on gh-pages and you can access it <a href=\"https:&#x2F;&#x2F;bushchat.xyz&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;bushchat.xyz&#x2F;</a> or run it yourself <a href=\"https:&#x2F;&#x2F;github.com&#x2F;srakai&#x2F;bushchat\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;srakai&#x2F;bushchat</a><p>Everything is DOM based, there is no server, but you need your API key or local LLAMA with OpenAI compatible API. Also disclaimer: There is posthog analytics, which is used to collect solely usage metrics (gh-pages does not facilitate that). Messages, API keys, responses, chat names are out of scope (<a href=\"https:&#x2F;&#x2F;bushchat.xyz&#x2F;privacy\" rel=\"nofollow\">https:&#x2F;&#x2F;bushchat.xyz&#x2F;privacy</a> ).<p>Happy to hear your thoughts!", "author": "Xx_crazy420_xX", "timestamp": "2025-12-30T14:02:21+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:13:04.125718+00:00", "processed": false}
{"id": "hn_story_46433138", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46433138", "title": "Show HN: Terminalot \u2013 A local-first, open-core SSH terminal with AI copilot", "text": "Hi HN,<p>I built Terminalot, a local-first SSH terminal that runs entirely on your own infrastructure (Docker) and connects to real Linux servers.<p>The goal was to make an AI-assisted terminal that infra people can actually trust:\n- every command is shown and requires explicit approval\n- no hidden execution\n- no mandatory cloud backend\n- all security-critical logic is open and auditable<p>It\u2019s open-core. The free version is fully functional; paid licensing only unlocks higher limits (e.g. saved connections). You can inspect or modify everything.<p>Quick start:\ndocker run -p 3001:3001 linkeliai&#x2F;terminalot:latest-beta<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;linkeli-labs&#x2F;terminalot\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;linkeli-labs&#x2F;terminalot</a><p>This is the first public beta. I\u2019d really appreciate feedback, especially around security assumptions, UX, and deployment expectations.", "author": "linkeli", "timestamp": "2025-12-30T13:29:01+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-30T17:13:06.380843+00:00", "processed": false}
{"id": "hn_story_46432979", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46432979", "title": "Show HN: Spraff \u2013 Voice and text AI chat, self-hostable, no data retention", "text": "Hi HN! I built a simple, self-hostable AI chat app that focuses on voice input and privacy.<p>Why I made this: I want to talk to AI (voice or text) without my conversations being logged, used for training etc.<p>Requires an OpenRouter account. No subscription: pay-as-you-go with most conversations costing a fraction of a cent (a couple of cents for requests with search enabled)<p>Privacy:<p>- Uses OpenRouter to route to Gemini 3 Flash on Google Vertex with Zero Data Retention (ZDR).<p>- Prompts and responses aren&#x27;t stored or logged at any layer.<p>- OpenRouter keeps only metadata like timestamps and token counts.<p>How it works:<p>- Single HTML file \u2013 download and self-host, or use the hosted version <a href=\"https:&#x2F;&#x2F;martinpllu.github.io&#x2F;spraff\" rel=\"nofollow\">https:&#x2F;&#x2F;martinpllu.github.io&#x2F;spraff</a><p>- Log in to OpenRouter via OAuth (API key kept in browser local storage until logout)<p>- Audio recorded in browser, sent directly to Gemini for processing (no separate transcription step)<p>- Text-to-speech via your device&#x27;s local voices<p>Technical notes:<p>- Gemini 3 Flash is currently the only model that supports both audio input and ZDR<p>- Provider is pinned to Google Vertex with zdr: true in the API request<p>- No build step, no dependencies \u2013 just one HTML file<p>- Current status: beta, tested on MacOS, Android and iOS. Should work but issues&#x2F;feedback welcome.<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;martinpllu&#x2F;spraff\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;martinpllu&#x2F;spraff</a>", "author": "pllu", "timestamp": "2025-12-30T13:08:17+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:13:09.251937+00:00", "processed": false}
{"id": "hn_comment_46432156", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46432156", "title": "Re: I partnered with a 1.5M influencer to build then \"...", "text": "Hi HN,<p>I\u2019m the technical half of a two-person team. I partnered with an English teacher (1.5M followers) to build a voice-first language learning app.<p>The goal was to solve the &quot;Intermediate Plateau&quot;. Most apps (like Duolingo) are great for vocabulary, but they gamify the process so much that users become addicted to &quot;streaks&quot; rather than actually speaking.<p>*The Experiment (Dev + Creator):*\nWe have $0 marketing budget. I handle the product&#x2F;engineering, he handles the distribution. We are betting that &quot;Product + Audience&quot; is enough to compete with VC-backed giants.<p>Stack:<p>- Mobile: React Native (Expo). We needed to ship iOS and Android fast with a single codebase.\n- Voice: 11Labs. We cloned the partner&#x27;s voice. The main engineering challenge is minimizing latency to make the conversation feel natural (we are currently optimizing the stream buffer).\n- Logic: OpenAI (Custom system prompts for roleplay scenarios like &quot;Job Interview&quot; or &quot;Customs Officer&quot;).\n- Backend: Supabase.<p>We launched few days ago after getting rejected 10 times in 14 days.\nWe were stuck in a loop with Design Guidelines for the Paywall. Imo they were not checking the updates as I was not submitting a new build (it was handled by RevenueCat), I had to textually explain that for them to approve the app.<p>I\u2019m happy to answer questions about the React Native &lt;-&gt; 11Labs integration, the latency challenges, or the partnership structure.<p>PS: If you want to try it, this link gives 50% off the first month: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;redeem?ctx=offercodes&amp;id=6755333340&amp;code=EARLYBIRD\">https:&#x2F;&#x2F;apps.apple.com&#x2F;redeem?ctx=offercodes&amp;id=6755333340&amp;c...</a>", "author": "0xreskue", "timestamp": "2025-12-30T11:24:04+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:13:15.758542+00:00", "processed": false}
{"id": "hn_story_46431727", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46431727", "title": "Show HN: Cover letter maker with Ollama/local LLMs (Open source)", "text": "I made an open source web app that generates cover letters using local AI models (Ollama, LM Studio, vLLM, Openrouter, etc) so your CV and job application data never leaves your browser.\nNo placeholders. No typing. Letters are ready to copy and paste. 100% local and private depending on the LLM of your choice. Multi-language support (so you can add more languages).<p>It connects to any OpenAI-compatible local LLM endpoint. I use it with Ollama + llama3.2, but it works with any server.<p>The generated letters unique since they are based on your unique experience and skills from your resume. They will also be written as if directly responding to that job posting, so all letters are unique.<p>I honestly don&#x27;t feel bad about using or making this becuase while actively applying for jobs, I see that a high percentage of recruiters now use AI to generate job descriptions and also during the interview process.<p>I was tired of wasting time with writing and personalising letters while applying for jobs. All other tools I tried weren&#x27;t as quick as I wanted because I still needed to modify the letters to replace placeholders.<p>I also didn&#x27;t find any tool that let&#x27;s me use my local LLM for free, and I didn&#x27;t want to pay for ChatGPT&#x2F;Claude API calls for every job application.<p>The output quality is good, and it can bypass some AI detectors.<p>It&#x27;s open source too and free to use. You can self-host it or run it locally in development mode.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;stanleyume&#x2F;coverlettermaker\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;stanleyume&#x2F;coverlettermaker</a><p>Cheers :)", "author": "stanyy", "timestamp": "2025-12-30T10:31:09+00:00", "score": 1, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:13:17.888197+00:00", "processed": false}
{"id": "hn_comment_46431622", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46431622", "title": "Re: Show HN: LLMRouter \u2013 Stop using GPT-4/o1 for every...", "text": "OP here. I&#x27;m a CS PhD student at UIUC working on User Modeling and Applied ML.<p>We built LLMRouter because we noticed a gap in the current LLM stack: everyone knows we shouldn&#x27;t route every query to GPT-4&#x2F;o1 (it&#x27;s slow and expensive), but building a reliable router that handles context, reasoning, and user history is surprisingly hard.<p>Most existing solutions are either simple regex&#x2F;keyword matching or closed-source APIs. We wanted to build a standard, open-source library that unifies the SOTA.<p>What LLMRouter actually does: It provides a unified interface to 16+ routing strategies, ranging from lightweight ML to heavy reasoning agents:<p>Single-Round: Classification-based (KNN, SVM, BERT) and Embedding-based methods.<p>Multi-Round &amp; Agentic: Routers that &quot;think&quot; before assigning models (CoT reasoning) or break down tasks step-by-step.<p>Personalized Routing: This is a key focus of our research. The router learns from user interaction history to fit individual preferences (e.g., some users prefer concise answers from faster models, others need detailed reasoning).<p>The Pipeline: We didn&#x27;t just ship the model weights. The library includes:<p>Data Generation: A pipeline to generate synthetic routing data for your specific domain.<p>Benchmarks: 11 datasets to evaluate router performance.<p>Deployment: A CLI and Gradio UI to visualize routing decisions in real-time.<p>In our experiments, we typically see 30\u201350% cost reduction while maintaining response quality by correctly identifying easy vs. hard queries.<p>The code is open source (MIT&#x2F;Apache): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ulab-uiuc&#x2F;LLMRouter\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ulab-uiuc&#x2F;LLMRouter</a><p>Happy to answer any questions about the implementation details or the specific RL&#x2F;Ranking algorithms we used!", "author": "tao2024", "timestamp": "2025-12-30T10:18:50+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-30T17:13:19.090400+00:00", "processed": false}
{"id": "hn_comment_46430195", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46430195", "title": "Re: Show HN: DevBox \u2013 An execution contract to end AI ...", "text": "The current state of AI engineering is fragmented.<p>Every &quot;agentic&quot; IDE or CLI tool has its own proprietary way of being &quot;instructed&quot;: Cursor has .cursorrules, Claude Code has custom hooks, Copilot has instruction files. As developers, we are now forced to re-implement our repository&#x27;s &quot;rules of engagement&quot; for every new tool we adopt; or even worse, our codebase becomes cluttered with all these tool-specific &quot;instructions&quot;.<p>The real problem isn&#x27;t that agents are &quot;bad&quot; at following instructions; it&#x27;s that we lack a standard interface to communicate what a repository is and how it can be safely operated.<p>I built devBox to move the source of truth out of tool-specific config files and into a single deterministic execution contract that lives in the &quot;.box&#x2F;&quot; directory in each repo.<p>The Concept: One contract, any agent.<p>Why this matters: This approach allows for a &quot;Write Once, Run Anywhere&quot; workflow for AI agents. Whether you are using Cursor, Windsurf, or a custom LLM script, they should be able to interact with your repo through the same deterministic interface and under the same security guardrails.<p>I&#x27;m curious to hear from others: Are you also feeling the &quot;instruction bloat&quot; of maintaining 5 different .rules files for 5 different tools? How are you centralizing your repo&#x27;s operational logic?", "author": "danieljhkim", "timestamp": "2025-12-30T06:29:44+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-30T17:13:30.074661+00:00", "processed": false}
