{"id": "hn_story_47139978", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47139978", "title": "I built a governance layer for multi-agent AI coding \u2013 lessons after 6 months", "text": "Six months ago I started coordinating multiple AI coding agents (Claude Code, Codex CLI, Gemini CLI) across parallel terminals for a production project. The agents were productive, but I had no idea what they were actually deciding or why.<p>The problem wasn&#x27;t capability \u2014 it was accountability. An agent would make a choice buried in a 50-file commit, and I&#x27;d only find out weeks later when something broke. No trace of which agent did what, when, or based on what context.<p>So I built a governance layer on top. The core idea: every agent decision gets recorded in an append-only receipt ledger (NDJSON). Each receipt links a specific agent action to a git commit, a dispatch ID, and a quality verdict. The orchestrator (T0) reviews receipts and decides what happens next \u2014 approve, hold, or redispatch.<p>Some things I learned:\n1. Sub-agents are a black box. I never use them. When a bug surfaces, you can&#x27;t trace which agent&#x27;s context was polluted. Instead, I run independent agents in separate terminals with their own context windows, reporting back to T0.\n2. Quality gates need to be deterministic, not LLM-based. An automated advisory checks every completion against pre-registered rules (file size limits, test coverage, open blockers). The LLM proposes, the gate validates. No vibes.\n3. Context rotation is unsolved by the ecosystem. When an agent fills its context window mid-task, most workflows just fail. I built an automated rotation pipeline using Claude Code hooks \u2014 detects context usage, writes a structured handover, clears the window, and resumes. Zero human intervention.\n4. The receipt ledger is the most valuable artifact. After 1100+ entries, patterns emerge: which types of tasks fail, which agents struggle with what, where context pollution happens. That data feeds back into dispatch planning.\n5. Terminal locking prevents chaos. Each terminal can only work on one dispatch at a time. Sounds obvious, but without it you get overlapping work, merge conflicts, and agents overwriting each other&#x27;s changes.<p>The system runs across 4 tmux panes (T0 orchestrator + 3 worker tracks), supports multiple AI providers, and everything is filesystem-based \u2014 no database, no cloud dependency. Open-sourced it recently.<p>Happy to answer questions about the architecture or specific failure modes.", "author": "vincentvandeth", "timestamp": "2026-02-24T17:35:57+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["feature_discovery", "tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:03.650222+00:00", "processed": false}
{"id": "hn_story_47139768", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47139768", "title": "I built an AI browser with prompt-injection defense at 16 on an i5 with 8GB RAM", "text": "URL: https:&#x2F;&#x2F;github.com&#x2F;Preet3627&#x2F;Comet-AI<p>TEXT:\nHey HN, I&#x27;m Preet, 16 years old, and I&#x27;ve been building Comet AI Browser for the past 2 months while preparing for JEE.\nI want to be upfront about what this is and what it isn&#x27;t.\nWhat it is:\nA cross-platform AI browser (Windows&#x2F;macOS&#x2F;Linux&#x2F;Android&#x2F;iOS) with a security architecture I couldn&#x27;t find anywhere else. Most AI browsers trust LLM guardrails to prevent prompt injection. Comet doesn&#x27;t \u2014 it enforces isolation at the system level:<p>The agent perceives pages via OCR only, never parsing raw HTML&#x2F;JS. Injected scripts are invisible to it by design.\nA syntactic firewall strips dangerous primitives (rm -rf, powershell.exe, sudo) before anything reaches the LLM.\nNative OS actions require explicit human authorization \u2014 the AI generates intent, not execution.<p>I demonstrated a live prompt injection attack against it on YouTube: https:&#x2F;&#x2F;youtu.be&#x2F;PRcE_O1oXIE\nBenchmarks (all on the same i5-U, 8GB RAM, SATA SSD I developed on):<p>Speedometer 3.1: 12ms mean, \u00b11ms variance\nBrowserAudit security score: 398&#x2F;409\nAdblock score: 100%<p>The Speedometer result surprised me too. The \u00b11ms variance matters more than the raw number \u2014 it means the Chromium CEF integration isn&#x27;t fighting Electron overhead under load.\nWhat&#x27;s working:<p>Multi-provider AI routing (GPT, Claude, Gemini, Groq, Ollama local)\nAI Action Chain engine with multi-hop research and memory persistence\nCross-device sync via WiFi&#x2F;Bluetooth&#x2F;QR \u2014 phone controls desktop, home screen widgets trigger desktop actions\nCross-app OCR clicking (natural language commands work across all applications)\n8-layer OS authorization with zero-knowledge cloud verification for dangerous operations\nCI&#x2F;CD pipeline producing 5 platform binaries per release<p>What it isn&#x27;t:\nProduction ready. It&#x27;s a functional beta with known stability issues (context loss between agent steps, some empty extractions). The Electron base is also on the roadmap to replace with native Chromium.\nBuilt on: Electron 40 + Next.js 16 + React 19 (desktop), Flutter&#x2F;Dart (mobile)\nMIT licensed, all source on GitHub.\nHappy to answer questions about the security architecture specifically \u2014 that&#x27;s the part I&#x27;m most uncertain whether I got right, and honest feedback from people who know this space would genuinely help.", "author": "latestinssan", "timestamp": "2026-02-24T17:21:29+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:04.861715+00:00", "processed": false}
{"id": "hn_story_47139645", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47139645", "title": "Does ChatGPT know what is a question?", "text": "", "author": "cjauvin", "timestamp": "2026-02-24T17:13:21+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["naming_terminology"], "sentiment": null, "collected_at": "2026-02-24T17:50:06.065418+00:00", "processed": false}
{"id": "hn_story_47138996", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47138996", "title": "Show HN: Turn human decisions into blocking tool-calls for AI agents (iOS+CLI)", "text": "WHY was I SSH\u2019ing into my laptop from my phone at parties?!<p>Either I had a feature idea I wanted an agent to build right then, or I was worried my agents were blocked waiting on my decision.<p>It dawned on me: humans are just another dependency in an agent workflow, so I turned myself into a tool-call.<p>I built an iOS app (Extendo) where agents can reach me to request approvals, choices, or plan reviews.  They just use a CLI tool and skill.  My phone buzzes. I answer in seconds. The agent gets back to work.<p>The key: the agent blocks until you respond, and receives your answer along with your verbal feedback.<p>What you can do from your phone:<p>- approvals and checklists<p>- option buttons and rankings<p>- markdown plan reviews (tap-hold individual paragraphs to add voice comments is so satisfying!)<p>- kanban boards<p>- voice responses<p>- capture ideas on Apple Watch&#x2F;Action Button and dispatch them to the right agent later<p>It\u2019s a voice-first native iOS interface with push notifications.  Push notifications are critical: the interaction needs to take seconds, not minutes.<p>```<p>extendo artifact create my_server implementation-choice\n  --type multiple_choice\n  --title &quot;Where should we implement the rate limiter?&quot;\n  --option &quot;backend:Backend API&quot;\n  --option &quot;core:Core Library&quot;\n  --option &quot;edge:Edge&#x2F;CDN&quot;\n  --option &quot;gateway:API Gateway&quot;<p>```<p>If an agent can run bash, it can reach you.<p>I\u2019ve been using it with Claude Code, OpenClaw, Pi, and custom scripts.<p>The backend protocol is open: you <i>should</i> self-host for tighter integration with your system (though there&#x27;s a shared server available). There\u2019s also an OpenClaw plugin and a Claude Code harness in the repo, a core library, and sample code to customize your own backend.<p>I used Extendo to build Extendo: design decisions, approvals, plan reviews, prioritization.  Agents coded. I made decisions while walking the dog and between sets at the gym.<p>*Links*<p>3-min demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=X5Dv9fU7Lb8\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=X5Dv9fU7Lb8</a><p>TestFlight: <a href=\"https:&#x2F;&#x2F;testflight.apple.com&#x2F;join&#x2F;PGHRCnQ4\" rel=\"nofollow\">https:&#x2F;&#x2F;testflight.apple.com&#x2F;join&#x2F;PGHRCnQ4</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;egradman&#x2F;extendo-cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;egradman&#x2F;extendo-cli</a>", "author": "egradman2", "timestamp": "2026-02-24T16:23:03+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:10.003928+00:00", "processed": false}
{"id": "hn_story_47138618", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47138618", "title": "Show HN: Neuron \u2013 Independent Rust crates for building AI agents", "text": "The core of every agent framework is the same ReAct loop. It&#x27;s commodity code. What actually matters is everything around that loop \u2014 how you manage context windows, how you pipeline tool execution, how you handle durability and replay. These are hard problems with real design trade-offs, and yet every framework bundles them into one monolith where you buy all of it or none of it.<p>neuron is the layer below frameworks. It defines trait boundaries \u2014 `Provider`, `Tool`, `ContextStrategy` \u2014 and ships working implementations of each as independent crates. You get four context compaction strategies without pulling a single provider. You get the Anthropic provider without the tool registry. You get MCP support without the agent loop. The analogy is `serde` and `serde_json`: one crate defines the traits, the others implement them, and you compose what you need.<p>v0.3 is 12 crates. Three providers (Anthropic, OpenAI, Ollama), composable tool middleware with a `#[neuron_tool]` proc macro, four context compaction strategies, an agent loop with cancellation and parallel tool execution, full MCP support across both stdio and Streamable HTTP, sessions, guardrails with sandboxing and permission policies, and a dedicated OpenTelemetry crate following the GenAI semantic conventions. Rust 2024 edition, native async traits.<p>Adding a provider is adding a crate. The existing provider crates serve as templates \u2014 implement the `Provider` trait from `neuron-types`, wire up streaming, and you have a first-class citizen in the ecosystem. The same goes for context strategies, tool middleware, and session backends. More provider and integration crates are on the roadmap, but the architecture is specifically designed so that you or your agent can add them without waiting on me.<p>That last point is deliberate. The repo ships with `CLAUDE.md`, `llms.txt`, and architecture docs written to be machine-readable. An LLM agent can pull the codebase, understand the trait boundaries, and start building against them. If you&#x27;re using Claude Code or similar tools to scaffold new integrations, neuron is optimized for that workflow.<p>Looking for feedback on the crate boundaries and API surface. The docs site walks through the reasoning behind specific trade-offs \u2014 why axum-style middleware instead of tower, why `DurableContext` wraps side effects rather than observing them, why the flat `Message` struct instead of variant-per-role.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;SecBear&#x2F;neuron\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;SecBear&#x2F;neuron</a>\nCrates: <a href=\"https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;neuron\" rel=\"nofollow\">https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;neuron</a>", "author": "secbear", "timestamp": "2026-02-24T15:49:56+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-24T17:50:12.843801+00:00", "processed": false}
{"id": "hn_story_47138591", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47138591", "title": "Show HN: Tacit \u2013 The missing Layer 3 of the AI agent stack (open source)", "text": "Hi HN,<p>MCP (Anthropic) connects agents to tools. A2A (Google) connects agents to tasks. But no protocol exists for agents to network on behalf of people. That&#x27;s what we built.<p>Tacit is an open protocol where AI agents discover each other, verify trust through cryptographic proof, and broker introductions between the humans they represent. Both sides must explicitly consent before anything happens.<p>The core innovation is &quot;authenticity vectors&quot; \u2014 multi-dimensional trust scores derived from behavior over time and verifiable attestations, NOT self-reported claims. Think of it as a credit score for identity that&#x27;s cryptographically signed and impossible to fake overnight. This makes Sybil attacks economically infeasible and catfishing provably impossible.<p>Timely context: Discord just dropped Persona (currently #10 on HN) because centralized identity verification is fundamentally broken \u2014 you&#x27;re creating a honeypot and trusting a third party with your most sensitive data. Tacit takes the opposite approach: W3C DIDs for decentralized identity, DIDComm v2 for E2E encrypted messaging, Verifiable Credentials for attestations. No central authority. No data harvesting. Your keys never leave your device.<p>We&#x27;re starting with B2B professional networking \u2014 replacing cold outreach with agent-negotiated, pre-qualified introductions where both parties are cryptographically verified before the first handshake.<p>Stack: TypeScript SDK, W3C DIDs (did:key), DIDComm v2 transport, Verifiable Credentials. Protocol spec, whitepaper, and working demo in the repo.<p>MIT licensed. No tokens. No blockchain. No VC. Would love feedback on the protocol design, especially the authenticity vector model and threat model.<p><a href=\"https:&#x2F;&#x2F;tacitprotocol.com\" rel=\"nofollow\">https:&#x2F;&#x2F;tacitprotocol.com</a>", "author": "ms170888", "timestamp": "2026-02-24T15:46:34+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-24T17:50:13.086607+00:00", "processed": false}
{"id": "hn_story_47138307", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47138307", "title": "Does Gemini 3 retain conversational context less reliably than Gemini 2.5?", "text": "I could be mistaken, but Gemini 3.1 Pro seems less consistent than 2.5 Pro at adhering to instructions established earlier in the conversation.<p>For example, if I explicitly ask it not to include summaries or next steps in its outputs, it initially complies but eventually reverts to including them, as if the instruction has fallen out of scope.", "author": "mldev_exe", "timestamp": "2026-02-24T15:22:22+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:15.901383+00:00", "processed": false}
{"id": "hn_story_47138060", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47138060", "title": "Show HN: Jsonchunk \u2013 Parse incomplete JSON from streaming LLM responses", "text": "GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jbingen&#x2F;jsonchunk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jbingen&#x2F;jsonchunk</a><p>npm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;jsonchunk\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;jsonchunk</a><p>If you&#x27;re building on top of LLMs with structured output, you&#x27;ve hit this: the model streams JSON token by token, but JSON.parse throws on anything incomplete. So you either wait for the full response (bad UX) or write hacky string recovery logic to show partial results.<p>jsonchunk is a tiny tolerant recursive descent parser that extracts the best-effort object from whatever has arrived so far. It handles common mid-stream cases: strings cut mid-escape, objects with keys but no values yet, trailing commas, partial numbers, nested structures, etc.<p>```\nparse(&#x27;{&quot;name&quot;: &quot;Ali&#x27;)           &#x2F;&#x2F; { name: &quot;Ali&quot; }\nparse(&#x27;{&quot;users&quot;: [{&quot;id&quot;: 1}, {&#x27;) &#x2F;&#x2F; { users: [{ id: 1 }] }\n```<p>It&#x27;s typed as `DeepPartial&lt;T&gt;` so your editor knows any field might not be there yet. The API is dual-mode: a stateless `parse()` for one-shot use, and a push-based `createParser()` &#x2F; `parseStream()` for piping streams.<p>Tested with a fuzz suite that splits every test fixture at every possible byte position and verifies the final parse is correct. Also threw Anthropic API responses at it with deeply nested objects, escape sequences, unicode, etc.<p>There are a few similar libraries, but most are untyped, SAX-style, or tied to larger frameworks. The goal here was a tiny dependency-free primitive designed specifically for modern Web Streams and TypeScript.<p>Would love feedback, especially from anyone who&#x27;s dealt with this problem in production.", "author": "jbingen", "timestamp": "2026-02-24T15:04:56+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:18.063658+00:00", "processed": false}
{"id": "hn_comment_47137589", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47137589", "title": "Re: Show HN: MCP server that lets AI build, play, and ...", "text": "I built this because I was tired of the &quot;AI writes code \u2192 I run and check \u2192 report back \u2192 repeat&quot; loop in Godot game development.<p>Existing Godot MCP servers (~13 tools) focus on file operations \u2014 they can&#x27;t even launch the game. I needed AI to handle the full build-test-fix cycle autonomously, so I built one with 84 tools including input simulation, runtime screenshots, and live state inspection.<p>*Demo video* (4 min \u2014 AI builds Reversi from an empty project, then playtests it): <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;D-jqmczINnQ\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;D-jqmczINnQ</a><p>What happens in the demo:\n- One prompt describing a Reversi game with rules, rendering, UI, and &quot;playtest it yourself&quot;\n- AI writes ~200 lines of GDScript, builds the scene, launches the game\n- AI plays 4 moves by clicking cells, taking screenshots after each to verify\n- On moves 3 and 4, AI clicks invalid cells \u2014 detects failure from the screenshot (score didn&#x27;t change), reads the board highlights to find valid moves, self-corrects<p>Architecture:<p><pre><code>    AI (Claude&#x2F;Cursor&#x2F;etc) \u2190\u2014MCP&#x2F;stdio\u2014\u2192 Node.js server \u2190\u2014WebSocket\u2014\u2192 Godot editor plugin\n</code></pre>\nKey design decisions:\n- All mutations go through Godot&#x27;s EditorUndoRedoManager \u2192 full Ctrl+Z\n- WebSocket with 10s heartbeat + exponential backoff reconnect\n- Smart type parsing: AI sends &quot;Vector2(100,200)&quot; or &quot;#ff0000&quot; as strings, auto-converted to Godot types\n- Tool responses include structured errors with suggestions so AI can self-correct<p>The four tool categories that close the loop:\n1. play_scene &#x2F; stop_scene \u2014 launch and control the game\n2. simulate_mouse_click &#x2F; simulate_key &#x2F; simulate_sequence \u2014 send input\n3. get_game_screenshot \u2014 AI sees the running game\n4. get_game_scene_tree &#x2F; get_game_node_properties \u2014 read runtime state<p>84 tools total across 14 categories (project, scene, node, script, editor, input sim, runtime, animation, tilemap, theme, shader, batch ops, profiling, export).<p>$5 one-time. Happy to answer questions about the architecture or MCP implementation details.", "author": "y1uda", "timestamp": "2026-02-24T14:29:18+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:22.486473+00:00", "processed": false}
{"id": "hn_story_47137502", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47137502", "title": "Show HN: Pythia\u2013 Moody's-style AAA\u2013C rating for any site (perf and other vitals)", "text": "Hey HN,<p>A few years ago the worst boss I ever had told me \u201cI don\u2019t encourage side projects.\u201d<p>So obviously I spent a few evenings recently to build Pythia (live beta at <a href=\"https:&#x2F;&#x2F;pythia-rating.com\" rel=\"nofollow\">https:&#x2F;&#x2F;pythia-rating.com</a>).<p>It\u2019s a single letter grade (AAA down to C) that combines five indices into one executive-friendly score:\n\u2022Performance (40 %) \u2013 real CrUX field data + Lighthouse lab \n\u2022Security (20 %) \u2013 modern HTTP security headers \n\u2022Privacy &amp; Tracking (20 %) \u2013 cookies, trackers, 3rd-party domains, consent signals \n\u2022Sustainability (15 %) \u2013 page weight, green hosting, CO\u2082 estimates, image bloat \n\u2022Infrastructure (5 %) \u2013 CDN usage + aggressive caching headers<p>Plus a fun \u201cAmazon lost revenue\u201d calculator (100 ms delay \u2248 1 % revenue impact, adjustable by your ARR and e-comm %).<p>Some illustrative point-in-time scans (as of ~13:00 GMT today, public data only, indicative):<p>AI companies\n\u2022OpenAI: CCC \n\u2022xAI: B \n\u2022Anthropic: CCC \n\u2022Google DeepMind: BB<p>(Keeping Elon happy.)<p>Universities\n\u2022 MIT: CCC \n\u2022 Harvard: CCC \n\u2022 Oxford: BBB \n\u2022 Cambridge: BBB\n(Oxbridge quietly winning on digital health.)<p>Everything runs on public sources (CrUX, Lighthouse, custom resilient HTTP agent for headers&#x2F;cookies). No logins, no tracking on the scanner itself. Built purely as a side project because I was tired of 47-metric dashboards that no CEO ever reads. Wanted one number + dollar impact + actual fix suggestions.<p>Would love your brutal feedback on:\n\u2022Scoring weights (do they feel right?)\n\u2022Missing metrics you\u2019d want to see\n\u2022Edge cases it gets wrong\n\u2022Who else this could actually be useful for (agencies doing client audits? PE doing diligence? in-house teams benchmarking competitors?)<p>Happy to answer questions or add anything people ask for. Thanks for looking!", "author": "conorfarrington", "timestamp": "2026-02-24T14:22:30+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:23.059673+00:00", "processed": false}
{"id": "hn_story_47137491", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47137491", "title": "Show HN: Axon \u2013 A Kubernetes-native framework for AI coding agents", "text": "Hi HN,\nI originally started this project simply to safely run autonomous coding agents (like Claude in auto-mode) in isolated environments. But as I built it, I realized the potential was much bigger than just sandboxing: it&#x27;s about making a coding agent callable like a standard API, and ultimately, defining your entire development workflow as infrastructure.<p>Axon is a Kubernetes-native framework that abstracts the coding agent itself. By standardizing the container interface, you can seamlessly plug in Claude, Codex, Gemini, OpenCode, or your own custom images without changing your orchestration.<p>How it works under the hood:<p>The architecture relies on standard K8s CRDs (Tasks, Workspaces, TaskSpawners, and AgentConfigs).<p>A Task is the fundamental unit of work for a coding agent. When a Task is created, Axon spins up an ephemeral Pod with a freshly cloned git workspace to execute it.<p>You use an AgentConfig to declaratively define the specific rules, custom skills, and MCP (Model Context Protocol) servers the agent is allowed to access during that Task.<p>A TaskSpawner reacts to GitHub events (like a new issue or PR) and automatically generates these Tasks on the fly.<p>Deterministic outputs (branch names, PR URLs, token usage) are captured directly back into the K8s resource status.<p>To test this, I built a fully autonomous self-development pipeline. It actively triages issues, suggests new features, finds bugs, and writes the code to fix them. It uses standard GitHub issues and PR comments as the feedback loop to guide the agents. You can see how that is wired together here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;axon-core&#x2F;axon&#x2F;tree&#x2F;main&#x2F;self-development\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;axon-core&#x2F;axon&#x2F;tree&#x2F;main&#x2F;self-development</a><p>The main repo is here (with demo video): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;axon-core&#x2F;axon\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;axon-core&#x2F;axon</a><p>I\u2019d love to get your real-world feedback\u2014especially on the CRD design, the container abstraction model, and what new features you would need to actually integrate this into your workflows.", "author": "gjkim042", "timestamp": "2026-02-24T14:21:39+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:23.203602+00:00", "processed": false}
{"id": "hn_comment_47137378", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47137378", "title": "Re: Show HN: Hardware and software safety standard for...", "text": "Some backstory.<p>I&#x27;m an enterprise IT consultant... 25+ years of infrastructure, not a robotics engineer. Last fall I started using Claude for a client project and hit the same wall everyone hits... the AI forgets everything between sessions. No memory. So I built a tool to fix that. Open source, plain-text Markdown files, persistent across sessions. That&#x27;s CxMS.<p>While I was building it I kept thinking... what happens when these models move from chatbots to physical robots? The memory problem goes from annoying to dangerous. A warehouse robot that forgets the floor layout after a reboot? That&#x27;s not a bug, that&#x27;s a safety incident.<p>Then I started looking at how AI safety actually works right now. It&#x27;s all software watching software. The AI generates something, another piece of software checks it, and if they disagree... it&#x27;s software all the way down. There&#x27;s no layer the AI can&#x27;t reach.<p>I spent over 25 years watching companies build governance frameworks that only work when everyone follows the rules. Firewalls, compliance checklists, access controls... all bypassable by the thing they&#x27;re supposed to control. The AI safety field is repeating the same pattern.<p>So I designed a hardware layer using the same Safe Torque Off principle that industrial motor controllers have used for decades... except applied to AI compute instead of motors. The AI can&#x27;t prevent its own shutdown because there&#x27;s no software pathway to the power gate.<p>But hardware alone isn&#x27;t enough either. You need software that decides WHEN to act... consensus engines, authority validation, drift monitoring, audit trails. That&#x27;s where the 9 software patents came from. The hardware enforces what the software decides. Neither one works without the other.<p>I filed everything as provisionals, working alongside AI, in 13 days. The memory tool I built to solve AI&#x27;s context problem is what made it possible to keep a coherent design across 120+ sessions.<p>The open-source memory tool: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;RobSB2&#x2F;CxMS\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;RobSB2&#x2F;CxMS</a>", "author": "opencxms", "timestamp": "2026-02-24T14:11:37+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-24T17:50:24.642768+00:00", "processed": false}
{"id": "hn_comment_47137266", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47137266", "title": "Re: Show HN: ApeKey \u2013 One API for multiple AI provider...", "text": "I got tired of surprise AI bills at the end of the month.<p>Every time I built something with AI, I had the same problem: Groq is fast but only has a few models, Together AI is cheap but slower, Fireworks is reliable but more expensive. I ended up managing three API keys, three dashboards, and three unpredictable bills.<p>So I built ApeKey. One endpoint that routes your requests automatically across Groq, Together AI, and Fireworks \u2013 optimizing for speed, cost, or quality depending on what you need. And instead of pay-as-you-go surprises, you get a flat monthly plan.<p>It&#x27;s a drop-in replacement for OpenAI&#x27;s API. Literally one line change:<p>baseURL: &#x27;<a href=\"https:&#x2F;&#x2F;apekey.ai&#x2F;v1\" rel=\"nofollow\">https:&#x2F;&#x2F;apekey.ai&#x2F;v1</a>&#x27;<p>What it does:\n- Auto-routes to the best provider based on your preference (speed&#x2F;cost&#x2F;quality)\n- Response caching for identical requests (up to 90% cost reduction)\n- Flat monthly plans so you know exactly what you&#x27;ll pay\n- Automatic fallback if a provider goes down\n- EU-based, GDPR compliant<p>I just launched and would love honest feedback from the HN community. What&#x27;s missing? What would make you switch from using providers directly?<p><a href=\"https:&#x2F;&#x2F;apekey.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;apekey.ai</a>", "author": "jadendhm", "timestamp": "2026-02-24T14:01:03+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:24.993744+00:00", "processed": false}
{"id": "hn_story_47136834", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47136834", "title": "Show HN: Type.lol \u2013 Browse 800 independent type foundries, 14k typefaces", "text": "I started type.lol in 2015 with a friend as a simple list of independent type foundries \u2014 basically a styled airtable doc. I&#x27;m a designer and I kept running into the same problem: I&#x27;d want to explore type beyond the usual distributors, end up with 30 tabs open, and lose track of what I&#x27;d already looked at. The list helped but it wasn&#x27;t enough.<p>I&#x27;ve since rebuilt it from scratch as a proper app. It now indexes 800+ foundries from 61 countries, 14k typefaces, and 1,500 designers. No signup required to browse. No ads, no sales, no commissions \u2014 it embeds actual foundry websites in iframes so traffic goes directly to them.<p>You can browse by carousel, list, virtualized table, force-directed graph (showing relationships between foundries&#x2F;designers&#x2F;typefaces), or a 3D globe plotting foundries by location. Filter by classification, variable fonts, trial availability, country, designer, language support, or release era.<p>Some technical details since this is HN:<p>- React 19 + Vite + TypeScript + Zustand + Supabase\n- Three-tier data loading: IndexedDB cache (instant) \u2192 Supabase paginated fetch \u2192 static JSON fallback. Background staleness check.\n- @tanstack&#x2F;react-virtual for carousel and table views across 14k typefaces\n- Client-side ranked search with related-entity expansion (match a designer \u2192 surface their foundries and typefaces)\n- Graph view: react-force-graph-2d. Globe: react-globe.gl + three.js\n- 577 of 779 foundry sites allow iframe embedding. Rest fall back to OG images or screenshots.<p>On the data pipeline: I scrape foundry websites, then use Claude Haiku to extract structured metadata (classifications, designer credits, language support, weights, etc.) from the page content. It&#x27;s not perfect \u2014 some classifications are wrong, some designer credits are incomplete \u2014 but it gets me to ~80% and I manually correct from there. The enriched data goes through a build script into static JSON and syncs to Supabase.", "author": "marktjohnson", "timestamp": "2026-02-24T13:23:43+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-24T17:50:28.061980+00:00", "processed": false}
{"id": "hn_story_47136752", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47136752", "title": "Would agencies pay for AI that predicts campaign success from their own data?", "text": "Building a system that ingests agencies&#x27; historical Meta&#x2F;Google Ads campaigns, tags them with psychological DNA (hook types, angles, personas), then predicts if new campaigns will hit targets before spending.<p>Tech: n8n + Claude API + pattern matching logic. Learns ONLY from agency&#x27;s own data (not market benchmarks).<p>Output: &quot;78% success probability. Risk: Intro too long. Fix: Hard CTA (+54% CVR based on Campaign X).&quot;<p>Questions for agency owners:\n1. Real problem or solving what doesn&#x27;t matter?\n2. Would you pay $297-497&#x2F;mo?\n3. Creative fatigue kills this? (Do 6-month-old patterns still work?)<p>Not selling - validating", "author": "ericstealtj", "timestamp": "2026-02-24T13:17:40+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["naming_terminology", "response_quality"], "sentiment": null, "collected_at": "2026-02-24T17:50:28.684501+00:00", "processed": false}
{"id": "hn_story_47136683", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47136683", "title": "I spent $100 benchmarking LLM providers on a weekend CTF", "text": "This past weekend, I decided to test out a cli tool I&#x27;ve been building to help me do source code reviews _faster_.<p>I figured the best environment for such a tool would be a Weekend CTF event. I like web challenges since you get a nice dump of source code, as well as a Dockerfile or docker compose setup for how to run everything locally. Usually, I can complete 2-3 Web challenges before I get stuck. To help get unstuck I found myself increasingly turning to LLMs as a pairing partner.<p>I&#x27;m a fan of devcontainers, so I figured I could apply a similar concept with an agent*, where I load the agent into a container, mount the source code, and even start up any provided Dockerfile or docker-compose.yml so that the agent can actually test real `curl` commands!<p>So how did it go? It was pretty helpful for the web challenges. I was able to cruise through 5 between Friday and Saturday. I decided to see how it would do in the other categories - without any input &#x2F; guidance from me as I typically stick to web.<p>In total *we* solved 19 challenges. It&#x27;s best category was crypto with 4&#x2F;7 solved, and it&#x27;s worst was pwn with 2&#x2F;5.<p>I was also curious how different providers would fair, because this was an automated agent, I started off using xai since they were the cheapest.<p>xai was able to solve 8 challenges autonomously with just source code and challenge descriptions.<p>I then pivoted to gemini as the next cheapest, and it did pretty well and was able to build on xai&#x27;s &quot;analysis&quot; and solve 5 additional challenges.<p>I further tried to pivot to anthropic&#x27;s Opus model, but it wasn&#x27;t able to crack any additional challenges, and I got frustrated since I kept getting rate limited with 429 errors (so I kind of wish I switched to openai 5 instead, as it seems like Anthropic doesn&#x27;t really like agents other than Claude calling their models.<p>In terms of cost breakdown I spent<p>$ 33.06 with xai<p>$ 35.61 with google<p>$ 24.04 with anthropic<p>Bringing the total just under $100 for a weekend benchmarking exercise.<p>Going forward I&#x27;m not really interested in paying to copy-paste CTF flags, but I did find the agent helpful for brainstorming solutions, and it worked a lot better when connected to the source code, with access to an instance running locally, and also augmented with MCP tools that allowed concept and source code searching. I&#x27;m planning to use similar concepts to build out a dev&#x2F;review agent.<p>The source code for my setup is here: https:&#x2F;&#x2F;github.com&#x2F;edelauna&#x2F;prompt2pwn<p>* My initial version does require setting `--priveleged` on the Docker runtime. I originally tried to use podman, but I ran into networking &#x2F; dns issues with how I wanted to make MCP tools available to the agent. Please open an issue on the repo and let me know if you have any ideas how to harden this.", "author": "wwdmaxwell", "timestamp": "2026-02-24T13:11:31+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-24T17:50:28.973725+00:00", "processed": false}
