{"id": "hn_story_46991817", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991817", "title": "Zero State Architecture deep dive", "text": "Ab\u00ebONE&#x27;s Zero State Architecture: How We Eliminated Drift and Recursive Loops<p>Most LLMs accumulate context drift over long conversations. Ab\u00ebONE doesn&#x27;t. Here&#x27;s how:<p>*THE PROBLEM WITH STATEFUL AI:*<p>Traditional conversational AI maintains state across turns. This creates:\n1. Context window pollution (irrelevant early context affects late responses)\n2. Coherence drift (model &quot;forgets&quot; constraints it accepted earlier)\n3. Recursive loops (model enters infinite reasoning spirals)\n4. Accumulated hallucination risk (errors compound)<p>*ZERO STATE ARCHITECTURE:*<p>Ab\u00ebONE computes state fresh on every execution:<p>Input \u2192 State Reconstruction \u2192 Context Retrieval \u2192 Fresh Inference \u2192 Validation \u2192 Output<p>Key innovations:<p>*1. Declarative State Reconstruction*\nInstead of carrying forward conversation state, Ab\u00ebONE reconstructs relevant state from:\n- User profile embeddings (persistent, user-controlled)\n- Retrieved context (semantic search over conversation history)\n- Explicit constraints (re-validated each turn)<p>*2. Invariant Enforcement*\nEvery response is validated against declared invariants before output:\n- Consistency with previous commitments\n- Factual grounding checks\n- Constraint satisfaction verification\nResult: 98.7% validation accuracy<p>*3. Intelligent Exit Conditions*\nRecursive reasoning is bounded by:\n- Depth limits with graceful degradation\n- Progress detection (if not converging, exit)\n- Loop signature detection (pattern matching on reasoning traces)\nResult: 0 recursive loop incidents per 10K queries<p>*4. Context Window Management*\nInstead of cramming everything into context, we use:\n- Tiered relevance scoring\n- Just-in-time context injection\n- Explicit &quot;forget&quot; signals for stale context<p>*BENCHMARKS vs COMPETITORS:*<p>| Metric | Ab\u00ebONE | GPT-5.2 | Claude Opus 4 | Gemini 3 |\n|--------|--------|---------|---------------|----------|\n| Validation Accuracy | 98.7% | 91.2% | 93.4% | 89.8% |\n| Drift (100+ turns) | 0% | 12% | 8% | 15% |\n| Recursive Loops&#x2F;10K | 0 | 47 | 23 | 89 |\n| Energy Efficiency | +60% | baseline | +15% | -10% |<p>*TRADEOFFS:*\n- Higher per-turn compute (state reconstruction isn&#x27;t free)\n- Requires robust retrieval infrastructure\n- Cold start on new users until profile builds<p>Worth it? Our retention data says yes: 94% 30-day retention vs industry average of 23%.<p>Technical paper draft available. Feedback welcome.<p>hello@bravetto.com | www.bravetto.com", "author": "buttersmoothAI", "timestamp": "2026-02-12T17:27:05+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["onboarding", "response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:49:58.232002+00:00", "processed": false}
{"id": "hn_comment_46991930", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991930", "title": "Re: Show HN: Myrlin \u2013 Open-Source Workspace Manager fo...", "text": "I run 8-12 Claude Code sessions at a time and was drowning in terminal windows. No way to see what&#x27;s running, no cost tracking, if my terminal crashes I lose track of everything, no shift enter, the &#x2F;resume system is a little tedious because of no named sessions, overall layout headache if you have multiple codes open, no persistence if your pc restarts (i.e. had to reopen EVERYTHING again).<p>Got fed up and built something for it. Myrlin scans ~&#x2F;.claude&#x2F;projects&#x2F;, finds all your sessions, and you organize them into workspaces. You can drag sessions into a 4-pane terminal grid (real node-pty, not fake terminals), see costs, search through session history, keep notes per workspace. Runs in the browser, everything stays local.<p>Node.js + Express, vanilla JS, xterm.js for terminals, SSE for live updates. No build step. Went with Node because node-pty works on Windows without needing WSL or tmux.<p>You can try it without touching your real sessions:<p><pre><code>    git clone https:&#x2F;&#x2F;github.com&#x2F;therealarthur&#x2F;myrlin-workbook.git\n    \n    cd myrlin-workbook &amp;&amp; npm install &amp;&amp; npm run gui:demo\n</code></pre>\nAGPL-3.0. The whole thing was built in Claude Code sessions managed by Myrlin itself which was kind of fun. Would love to hear what&#x27;s missing or broken.", "author": "therealarthur", "timestamp": "2026-02-12T17:32:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-12T17:49:58.331293+00:00", "processed": false}
{"id": "hn_story_46991656", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991656", "title": "Show HN: I lost $200 from an agent loop, so I built per-tool AI budget controls", "text": "I left an agent running before bed. It got stuck in a loop. By morning it had burned through $200 in LLM calls.<p>That was the breaking point, but the real problem had been building for a while. I use tools like OpenClaw and Cursor daily, each hitting various AI providers. But I had no idea what each tool was actually costing me. One shared key across everything, no per-tool visibility, no way to cap spend.<p>So I built AI Spend into Lava. The idea is simple. Create isolated API keys, each with their own:<p>- Spend limit (daily&#x2F;weekly&#x2F;monthly&#x2F;total)\n- Model restriction (lock to a specific model or allow any)\n- Real-time usage tracking\n- Instant revoke<p>It works as a transparent proxy. Your tools point to a single OpenAI-compatible endpoint. Lava validates the key, checks the spend limit and model restrictions, then forwards the request to the right provider. Spend is tracked per key per cycle. When a key hits its limit, requests are rejected until the cycle resets. Under the hood it translates requests across 38+ providers (OpenAI, Anthropic, Google, Mistral, DeepSeek, etc.), so anything that works with the OpenAI API works with this. No SDK changes.<p>Would love to hear how others are handling AI cost control, especially if you&#x27;re running agents in production.", "author": "mej2020", "timestamp": "2026-02-12T17:17:55+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["feature_discovery"], "sentiment": null, "collected_at": "2026-02-12T17:49:59.073130+00:00", "processed": false}
{"id": "hn_story_46991591", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991591", "title": "Launch HN: Omnara (YC S25) \u2013 Run Claude Code and Codex from Anywhere", "text": "Hey y\u2019all, Kartik, Ishaan, and Christian from Omnara (<a href=\"https:&#x2F;&#x2F;www.omnara.com&#x2F;\">https:&#x2F;&#x2F;www.omnara.com&#x2F;</a>) here. We\u2019re building a web and mobile agentic IDE for Claude Code and Codex that lets you run and interact with coding agents from anywhere. Omnara lets you run Claude Code and Codex sessions on your own machine, and exposes those sessions through a web and mobile interface so you can stay involved even when you\u2019re away from your desk. Think of it like Claude Code Desktop or Conductor, except you can continue your sessions on your phone.<p>Here\u2019s a demo of the web and mobile apps - <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;R8Wmy4FLbhQ\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;R8Wmy4FLbhQ</a><p>We started using Claude Code early last year and quickly ran into a pattern: agents could work for long stretches on their own, but progress would stall whenever they needed follow-up input. If that happened while we were away from our desks, everything just paused. We looked at remote agent solutions like Codex Web and Devin, which were the main options at the time, but they ran in remote VMs, and we wanted our coding agent to run in our own environment. Our first attempt at solving this was a lightweight wrapper that streamed messages from the Claude Code CLI to a mobile app, but that approach ended up being fragile and hard to maintain.<p>As the Claude Agent SDK matured, it gave us enough control to rewrite Omnara from scratch and run the agent loop directly. We chose to build a GUI across web and mobile instead of a TUI or CLI, because we think GUIs are generally more ergonomic for working with agents and code, especially on mobile. We still preserve the main strength of CLIs and TUIs: running anywhere, including on headless machines.<p>Omnara keeps that property by running a small headless daemon on the user\u2019s machine (or a remote VM) that hosts the agent loop. The daemon maintains an authenticated, outbound WebSocket connection to our server, which relays messages between the agent running on the user\u2019s machine and any connected web or mobile clients. Because the daemon only makes outbound connections, there\u2019s no need for exposed ports, SSH access, or tunneling on the user\u2019s machine.<p>In our first version of Omnara, users liked that agent sessions ran in their own environment, but they still depended on the machine staying online. Some users ran Omnara on a remote machine that stayed up, which worked well for them, though most still did most of their work on laptops. In the current version, Omnara can continue an agent session in a hosted remote sandbox when your local machine goes offline.<p>The conversation state of an agent is already persisted on our server, and you can optionally enable cloud syncing for the working code. When syncing is enabled, Omnara creates git commits at each turn in the conversation and pushes them to our server, so execution can resume from the same state regardless of whether it continues locally or in the cloud. If you continue working in a remote sandbox, you can later pull any changes back into your local environment when you return to your machine. Environment parity in the sandbox isn\u2019t perfect yet, but in practice, missing dependencies are usually easy to resolve by asking the agent to install them.<p>Another thing we learned from using the initial version of Omnara is that mobile is fine for quick interactions, but not great for extended back-and-forth. Users asked for a hands-free way to keep agents moving while walking, driving, or doing something else, which led us to add a voice agent. Coming from more traditional software engineering backgrounds, we honestly thought coding by talking to a voice agent would be gimmicky and added it mostly as a fallback.<p>What surprised us is how useful the voice agent ended up being in practice. When working with coding agents, being redundant and overly explicit usually helps, and people naturally give more detail when speaking than when typing. Going back and forth with the agent as the conversation unfolds tends to produce a much more solid plan than trying to one-shot it with a prompt (this could technically also be done over text, but talking and iterating over voice feels easier and more natural). It\u2019s also just fun. Talking through an idea with an agent while out on a walk is a lot more enjoyable than staring at a terminal screen.<p>To try it out, open your terminal and download Omnara with<p><pre><code>  curl -fsSL https:&#x2F;&#x2F;omnara.com&#x2F;install&#x2F;install.sh | bash\n</code></pre>\nthen run omnara inside any git repository. This starts a headless Claude Code or Codex session in that repo, which immediately appears in the Omnara web and mobile apps. From there, you can continue that session or start new ones remotely (with or without worktrees) and switch between the web and mobile clients without interrupting the agent.<p>Omnara is free for 10 agent sessions per month, then $20&#x2F;month for unlimited sessions. When agents run in your own environment, you can use your existing Claude or Codex subscription, so there\u2019s no need to pay us for additional tokens. If you use Claude Code or Codex, we\u2019d love to hear your feedback on Omnara!", "author": "kmansm27", "timestamp": "2026-02-12T17:14:28+00:00", "score": 17, "num_comments": 15, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-12T17:49:59.170796+00:00", "processed": false}
{"id": "hn_comment_46991658", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991658", "title": "Re: Launch HN: Omnara (YC S25) \u2013 Run Claude Code and C...", "text": "I have been hungry to do more work from my cell phone. It&#x27;s ridiculous to be <i>forced</i> to sit in front of a computer to work with AI.<p>My current solution is to have claude (--dangerously-skip-permissions) listen for messages in my slack DMs to myself and take action in response to those messages.<p>I would happily switch to something better.<p>Why is Omnara better?", "author": "zomglings", "timestamp": "2026-02-12T17:18:02+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:49:59.391703+00:00", "processed": false}
{"id": "hn_story_46991520", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46991520", "title": "Show HN: TinyFish Web Agent (82% on hard tasks vs. Operator's 43%)", "text": "Enterprises need ~90% accuracy to deploy web agents. Until now, no agent has come close on real-world tasks. TinyFish is the first production-ready web agent. Here&#x27;s the evidence.<p>Results of hard task scores on Online-Mind2Web (300 tasks, 136 live websites, human-correlated judge):<p>- TinyFish: 81.9%\n- OpenAI Operator: 43.2%\n- Claude Computer Use: 32.4%\n- Browser Use: 8.1%<p>Why not WebVoyager like everyone else?<p>Because it&#x27;s broken. Easy tasks, Google Search shortcuts, and a judge that agrees with humans only 62% of the time. Browser Use self-reported 89% on WebVoyager \u2014 then scored 8.1% on hard tasks here.<p>We evaluated TinyFish against Online-Mind2Web instead \u2014 300 real tasks, 136 live websites, three difficulty levels, and a judge that agrees with humans 85% of the time. No shortcuts. No easy mode.<p>The cookbook repo is open source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;tinyfish-io&#x2F;tinyfish-cookbook\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tinyfish-io&#x2F;tinyfish-cookbook</a><p>You can see all failure task runs form here: <a href=\"https:&#x2F;&#x2F;tinyurl.com&#x2F;tinyfish-mind2web\" rel=\"nofollow\">https:&#x2F;&#x2F;tinyurl.com&#x2F;tinyfish-mind2web</a><p>Happy to answer questions about the architecture, the benchmark methodology, or why we think WebVoyager scores are misleading.", "author": "gargi_tinyfish", "timestamp": "2026-02-12T17:11:16+00:00", "score": 12, "num_comments": 9, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:49:59.776453+00:00", "processed": false}
{"id": "hn_story_46990733", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46990733", "title": "Show HN: 20+ Claude Code agents coordinating on real work (open source)", "text": "Single-agent LLMs suck at long-running complex tasks.<p>We\u2019ve open-sourced a multi-agent orchestrator that we\u2019ve been using to handle long-running LLM tasks. We found that single LLM agents tend to stall, loop, or generate non-compiling code, so we built a harness for agents to coordinate over shared context while work is in progress.<p>How it works:\n1. Orchestrator agent that manages task decomposition\n2. Sub-agents for parallel work\n3. Subscriptions to task state and progress\n4. Real-time sharing of intermediate discoveries between agents<p>We tested this on a Putnam-level math problem, but the pattern generalizes to things like refactors, app builds, and long research.\nIt\u2019s packaged as a Claude Code skill and designed to be small, readable, and modifiable.<p>Use it, break it, tell me about what workloads we should try and run next!", "author": "austinbaggio", "timestamp": "2026-02-12T16:23:37+00:00", "score": 15, "num_comments": 19, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-12T17:50:04.346761+00:00", "processed": false}
{"id": "hn_story_46990146", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46990146", "title": "Show HN: Tako AI \u2013 Agent for Okta With Natural language (zero hallucination)", "text": "Hi HN,<p>Every week I watched Okta admins burn hours answering ad-hoc questions from security teams: &quot;Who has access to Salesforce?&quot;, &quot;Find all contractors with GitHub access who haven&#x27;t used MFA in 30 days.&quot; The answers always involved the same painful loop: dig through a slow web console, chain API calls, correlate CSVs, write throwaway Python scripts. Repeat next week.<p>I spent 12 months building Tako AI to fix this. You ask a question in plain English, it returns verified data.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;fctr-id&#x2F;okta-ai-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;fctr-id&#x2F;okta-ai-agent</a><p>THE ONE RULE: Zero hallucinations.<p>In identity and access management, a wrong answer is worse than no answer. If an AI tells your CISO a contractor doesn&#x27;t have admin access when they actually do, that&#x27;s a security incident. Tako never &quot;predicts&quot; an answer. It writes the code to find the answer, executes it, and returns the raw result. Ask the same question twice, you get the same data.<p>THE HARDEST PROBLEM: Scaling to 107+ API endpoints<p>Most AI agents break down past 10-20 tools. They hallucinate parameters, call wrong endpoints, invent fields that don&#x27;t exist. We went through five architecture rewrites over 12 months.<p>Each iteration: new LLM drops (GPT-4, Claude 3.5), we rebuild the agent, hit context limits, watch it snowball into gibberish. The breakthrough wasn&#x27;t bigger context windows \u2014 it was precise context engineering. Instead of cramming 107 endpoint definitions into a prompt, the agent dynamically discovers the right spec for the task at hand. It reads a custom JSON API documentation file for the specific endpoint it needs, constructs validated requests, executes them. No hardcoded tools per endpoint. We&#x27;re adding full CRUD operations next.<p>HOW IT WORKS:<p>Multi-agent architecture based on ReAct (Reasoning + Acting). Each agent has a narrow job:<p>\u2022 Router: analyzes your question, decides local cache vs live API\n\u2022 SQL Agent: queries local SQLite cache for bulk data (10k users in milliseconds vs minutes via API)\n\u2022 API Agent: handles live Okta calls\n\u2022 Synthesis Agent: merges everything into final verified report<p>The API Agent has a self-healing loop that surprised us. When generated code fails \u2014 wrong parameter name, rate limit hit, API schema changed \u2014 it traps the stack trace, feeds the error back to the LLM with context, and rewrites the code. We&#x27;ve seen it recover from Okta API changes we didn&#x27;t even know happened yet.<p>PRIVACY &amp; SECURITY:<p>Runs 100% locally in Docker. You bring your own LLM keys (OpenAI, Anthropic, Gemini, or Ollama for fully offline). Your employee PII never leaves your machine.<p>READ-ONLY by design. All generated Python and API code runs in a sandboxed environment. Every execution is automatically verified against security patterns before running \u2014 code is logged and available for audit, but you don&#x27;t manually approve each query.<p>WHAT&#x27;S NEXT:<p>We see this as a platform, not just an Okta tool. The pattern (local cache + live ReAct agent + self-healing code execution) generalizes to any SaaS API. Google Workspace, Slack, Workday \u2014 same architecture, different spec files. Working on write operations with human-in-the-loop approval next.<p>What would you want AI agents to actually do for you in 2026? Where do you see this tech going beyond chatbots?<p>\u2014Dan", "author": "danFctr", "timestamp": "2026-02-12T15:38:38+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:07.795530+00:00", "processed": false}
{"id": "hn_comment_46989454", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46989454", "title": "Re: I benchmarked 4 coding agents on an NP-hard proble...", "text": "I gave an unpublished fiber network optimization problem to Claude Code, Codex, Gemini CLI, and Mistral. The score is total fiber length (lower is better). A good human solution in 30 minutes: ~40,000. My best after days of C++: 34,123. Given one hour, Claude Code hit 34,061 \u2014 beating me by 62 points. A 7-word prompt hint improved every agent by 18-30%. About 15% of all trials produced completely invalid outputs.", "author": "couAUIA", "timestamp": "2026-02-12T14:44:20+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:12.710585+00:00", "processed": false}
{"id": "hn_story_46989026", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46989026", "title": "Show HN: Scan your codebase for off-brand copy (open source CLI)", "text": "hey,<p>built a cli that scans your codebase for off-brand product copy. think eslint but for your brand voice.<p>`npx brandlint`<p>it extracts user-facing strings (jsx text, error messages, placeholders, i18n), checks them against a voice template (professional, casual, technical), and reports issues with file and line number.<p>works with anthropic or openai keys. nothing leaves your machine except the score summary if you choose to share it :)<p>supports ts&#x2F;tsx, vue, svelte, html, json, yaml, markdown, php, python, and more.<p>would love feedback. what brand voice rules do you usually enforce in your products, if any?", "author": "tonychx", "timestamp": "2026-02-12T14:09:26+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2026-02-12T17:50:18.593824+00:00", "processed": false}
{"id": "hn_story_46988924", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988924", "title": "Show HN: MCP server for generating images directly in Claude Code", "text": "I built an MCP server that handles the full image lifecycle from within Claude Code: generate, preview variations, select, upload to cloud storage, get a CDN URL.<p>The motivation was simple \u2014 every blog post needs images, and the workflow of open-separate-tool \u2192 generate \u2192 download \u2192 upload \u2192 copy-URL is tedious. This collapses it into one conversation.<p>What&#x27;s implemented:<p>- Providers: Google Gemini (free tier), Fal.ai (Flux models)\n- Storage: Cloudflare R2 (free egress), local\n- Cost tracking: SQLite-backed, monthly budgets\n- Interactive setup wizard\n- In-session configuration (switch providers without restart)\n- 264 unit tests, CI on Node 18&#x2F;20&#x2F;22<p>What&#x27;s on the roadmap: Together.ai, Replicate, HuggingFace providers. Backblaze B2 storage.<p>TypeScript, ~2,100 lines of production code, 37 kB package. MIT licensed.<p>Happy to answer questions about MCP server architecture or the design decisions.", "author": "maheshcr", "timestamp": "2026-02-12T14:00:16+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:19.396735+00:00", "processed": false}
{"id": "hn_comment_46988843", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988843", "title": "Re: AI-BOM \u2013 scan your codebase for AI agents, models ...", "text": "Hey HN, we built ai-bom because we kept finding undocumented AI stuff in production. Devs ship LLM calls, agent frameworks, MCP servers without anyone reviewing it - shadow IT but for AI.<p>We also built an n8n community node (npm install n8n-nodes-trusera) that lets you scan all your n8n workflows for AI components directly inside n8n. As far as we know this is the first tool that does this - n8n is huge for AI automation but completely invisible to security tools.<p>Existing SBOM tools (Trivy, Syft, Grype) don&#x27;t catch any of this. They scan packages and deps but miss things like a LangChain agent calling GPT-4 with a hardcoded API key, or an n8n workflow running 12 AI nodes nobody knew about.<p>We wrote 13 scanners that detect LLM providers, agent frameworks (LangChain, CrewAI, AutoGen), model files, MCP configs, n8n AI nodes, hardcoded credentials, Docker AI containers, and more. Outputs CycloneDX SBOM and SARIF for GitHub Code Scanning.<p><pre><code>    pipx install ai-bom\n    ai-bom scan .\n</code></pre>\nTakes about 45 seconds on a typical repo.<p>Part of the motivation was EU AI Act Article 53 (Aug 2025) requiring orgs to keep an AI component inventory. But the real use case is security teams just trying to figure out what AI is running in their infra.<p>Curious to hear:\n- What AI patterns are we missing?\n- How do you track AI usage in your org today?\n- Anyone dealing with EU AI Act compliance yet?", "author": "trusera", "timestamp": "2026-02-12T13:53:03+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:20.069502+00:00", "processed": false}
{"id": "hn_comment_46988806", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988806", "title": "Re: PixMind...", "text": "Pixmind is an all-in-one AI visual creation platform designed for creators, marketers, designers, and businesses who want to turn ideas into high-quality images and videos\u2014fast. By integrating multiple state-of-the-art AI models into a single, intuitive workspace, Pixmind removes technical barriers and empowers anyone to create professional-grade visual content with ease.\nFor image generation, Pixmind supports a wide range of leading AI models such as Nano Banana, Midjourney, Stable Diffusion, Imagen, and GPT-4o. Users can generate images from text prompts or reference images, choose from diverse visual styles\u2014including photorealistic, illustration, anime, oil painting, watercolor, and pixel art\u2014and maintain visual consistency across outputs. Advanced image-to-prompt capabilities also help users reverse-engineer visuals into usable prompts, improving creative control and efficiency.\nPixmind\u2019s video generation features are equally powerful. With support for text-to-video and image-to-video workflows powered by models like Veo 3.1 and Seedance, users can transform static ideas or images into dynamic video content in minutes. Built-in viral AI video effects\u2014such as AI Kiss and AI Hug\u2014make it easy to create engaging, social-media-ready content for marketing campaigns, storytelling, product showcases, and short-form videos.\nBeyond generation, Pixmind offers practical AI tools such as image compression and workflow-oriented design, ensuring a smooth experience from creation to export. Whether you are an individual creator exploring new ideas, a marketer producing content at scale, or a business building brand visuals, Pixmind gives you the freedom to create without limits.\nNo constraints. Just create. Pixmind turns imagination into visuals.", "author": "bscbia", "timestamp": "2026-02-12T13:50:18+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:20.228019+00:00", "processed": false}
{"id": "hn_story_46988432", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988432", "title": "Camera based true random number generator Beta", "text": "I\u2019m an electromechanical engineer who usually tinkers with RPis and Arduinos more than software, but a few weeks ago I went down the rabbit hole of randomness. I read about Cloudflare\u2019s lava lamp wall and thought: if they\u2019re ultimately using cameras, why not use the image sensor noise directly?<p>Modern CMOS sensors produce a lot of grainy, unstable pixels\u2014even when pointed at a static scene. You can film the same white wall at 30 fps and never get an identical frame. That felt like a decent physical entropy source, so I built a TRNG around it and called it Aegis Optikon(.com).<p>The pipeline right now looks like this:<p><pre><code>    Capture frames from a camera (client devices)\n\n    Extract \u201cnoisy\u201d pixel data\n\n    Whiten and compress it\n\n    Send entropy packets to the server\n\n    Mix multiple streams together\n\n    Extract with BLAKE3\n\n    Attach timestamps and hashes per packet for basic verifiability\n</code></pre>\nI\u2019m not a seasoned backend&#x2F;security engineer\u2014I leaned heavily on AI tools (Copilot&#x2F;DeepSeek) to get the code into shape, then iterated until it worked end\u2011to\u2011end. It\u2019s running on a Contabo VPS, with a simple HTML&#x2F;session\u2011based frontend and username+email login.<p>What I\u2019d really like from HN:<p><pre><code>    Feedback on the entropy model (image sensor noise as a source)\n\n    Thoughts on the extraction&#x2F;mixing pipeline\n\n    How to think about capacity: how much entropy can I safely serve, and how does this scale?\n\n    Security concerns with the current architecture (e.g., inlined HTML&#x2F;CSS&#x2F;JS, API design, threat model)\n\n    Any obvious \u201cdon\u2019t do this\u201d mistakes I\u2019m making\n</code></pre>\nRight now only the free tier is active: 8&#x2F;16&#x2F;32&#x2F;64\u2011byte requests, up to 1 MB&#x2F;month per user. Paid tiers are placeholders until I\u2019m confident in the design and implementation.<p>I\u2019d really appreciate brutally honest feedback\u2014especially from people who\u2019ve worked on RNGs, cryptography, or high\u2011assurance systems. If you see something fundamentally flawed, I\u2019d rather hear it now.", "author": "Coppernickske", "timestamp": "2026-02-12T13:13:02+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-12T17:50:22.575236+00:00", "processed": false}
{"id": "hn_story_46988224", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988224", "title": "Show HN: LLM-DAG-UI \u2013 A branching conversation interface for Claude", "text": "I built a proof-of-concept UI that displays LLM conversations as a directed acyclic graph instead of a linear chat.<p>Try it: <a href=\"https:&#x2F;&#x2F;llm-dag-ui.vercel.app\" rel=\"nofollow\">https:&#x2F;&#x2F;llm-dag-ui.vercel.app</a> (screenshot in repo)<p>The idea: conversations with LLMs often hit dead ends or go in directions you want to backtrack from. What if you could branch off from any message and explore a different path, while keeping the original intact?<p>How it works:<p>- Drag from any message node to create a new branch.<p>- Each branch only has context of its direct ancestors \u2013 it doesn&#x27;t know about sibling branches or other parts of the tree.<p>- Delete a node and all its children disappear with it.<p>Useful when you want to try three different approaches to a problem from the same starting point, or test how Claude responds to different phrasings.\nThis is a concept demo, not a polished product.<p>It uses BYOK (bring your own Anthropic API key), stored only in your browser&#x27;s localStorage. The Express proxy just controls which Claude model is used; your key passes through but is never logged or stored. Nothing persists between sessions.<p>I think this is closer to how LLM conversations should work. The linear chat paradigm made sense for messaging, but exploration is rarely linear.<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dgrims3&#x2F;LLM-DAG-UI\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dgrims3&#x2F;LLM-DAG-UI</a><p>Would love feedback on the interaction model.", "author": "tenahu", "timestamp": "2026-02-12T12:55:11+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-12T17:50:24.017641+00:00", "processed": false}
{"id": "hn_story_46988195", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46988195", "title": "Show HN: NoSpamPro \u2013 AI Spam Blocker for Android (Privacy-First)", "text": "Hi HN,<p>I built NoSpamPro because I was tired of &quot;spam blockers&quot; that required uploading my entire contact list or call logs to their servers just to work. Most current solutions are essentially data-harvesting tools disguised as security apps.<p>NoSpamPro is an Android SMS&#x2F;Call blocker designed with a privacy-first, local-only philosophy. It uses a hybrid 8-layer filtering system to handle threats without compromising your data.<p>How it works (The Engineering Side):<p>95% of the filtering happens on-device. The app follows a decision-tree logic to minimize battery impact and maximize privacy:<p>Local Heuristics: We use Room DB for instant lookups against known malicious prefixes, B-Codes (Business Sender IDs like B043), and user-defined Regex patterns.<p>B-Code Registry: A specialized layer that verifies official business codes to detect &quot;spoofing&quot; attempts common in banking fraud.<p>The AI Layer (Optional): This is where it gets interesting. If the local layers are inconclusive (e.g., a &quot;Likely Spam&quot; score), the app can use Gemini AI for contextual analysis.<p>Privacy Protocol: Before any text leaves the device, it is anonymized. We only ask the model: &quot;Is this intent-based spam?&quot;.<p>Zero-Log: We implemented a protocol where analysis results are returned and the source data is immediately vaporized. No logs, no archives.<p>Technical Stack:<p>- Language: 100% Kotlin.\n- UI: Jetpack Compose (Material 3).\n- Storage: Room Persistence Library.\n- Async: Kotlin Coroutines &amp; Flow.<p>Why use this instead of the system default? While Google\u2019s default filter is decent, it often misses localized scams (like country-specific betting spam) and has limited customization. NoSpamPro gives you &quot;Advanced Protection&quot; toggles like:<p>Burst Protection: Detecting &quot;SMS Bomb&quot; attacks and silencing them.<p>De-shortening URLs: Analyzing the final destination of bit.ly&#x2F;t.co links within the app&#x27;s &quot;Ghost Browser.&quot;<p>International Guard: Blocking specific high-risk area codes while whitelisting others.<p>The app is currently available for Android. I&#x27;m looking for feedback specifically on the filtering logic and any edge cases in call screening you might have encountered.<p>Google Play: <a href=\"https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.byauth.nospampro&amp;pli=1\">https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.byauth.nos...</a><p>I&#x27;ll be around to answer any technical questions about the implementation or the privacy model!", "author": "huseyinsari", "timestamp": "2026-02-12T12:52:22+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-12T17:50:24.210235+00:00", "processed": false}
