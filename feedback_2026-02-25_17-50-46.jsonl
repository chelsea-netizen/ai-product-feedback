{"id": "hn_story_47154851", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154851", "title": "Perplexity Computer: research, design, code, deploy, and manage any project", "text": "", "author": "rob", "timestamp": "2026-02-25T17:40:18+00:00", "score": 2, "num_comments": 0, "products": ["perplexity"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:50:49.619083+00:00", "processed": false}
{"id": "hn_story_47154642", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154642", "title": "SpokedPy \u2013 Polyglot visual IDE with Universal IR, live execution (17 languages)", "text": "Hi HN,<p>Today I open-sourced SpokedPy \u2014 a visual-first programming platform that treats source code as a fully translatable, executable, and auditable data structure.<p>I built the entire core 81k+ lines of modular, production-oriented Python, 633+ pytest cases including property-based) in just 7 intense winter days (mostly with Claude Opus 4.6 which was released 3 days after the initial start of development).<p>It was a \u201cfor fun\u201d side project to see how dealing with multiple languages in a single visual way could be accomplished, and in doing so I was able to chase some features that I didn&#x27;t see coming during the specification creation and am pleasantly surprised in the result.<p>Core architecture highlights:<p>\u2022 Universal Intermediate Representation (UIR) \u2013 lossless bidirectional round-tripping and editing between visual nodes and real source code across Python, JavaScript&#x2F;TypeScript, Rust, Go, Java, C#, Kotlin, Swift, Scala, C, SQL, Bash, Lua, PHP, Ruby, R and more<p>\u2022 Four visual paradigms in one canvas: block-based, flow, graph, and hybrid<p>\u2022 Live execution engine with a register-file style Node Registry that supports true hot-swapping of implementations across 15+ language backends<p>\u2022 Parallax SVG rendering \u2013 the actual generated source code floats inside every visual node as you edit (very satisfying)<p>\u2022 Full Session Ledger (Kafka-style event sourcing) for complete time-travel debugging and auditability<p>\u2022 AST-Grep-powered cross-language refactoring<p>Full 40+-page technical specification (reads like a paper):<p>https:&#x2F;&#x2F;github.com&#x2F;madnguvu&#x2F;spokedpy&#x2F;blob&#x2F;main&#x2F;docs&#x2F;TECHNICAL_SPECIFICATION.md<p>Repo + one-minute local demo (MIT license, no sign-up, runs on localhost:5002):<p>https:&#x2F;&#x2F;github.com&#x2F;madnguvu&#x2F;spokedpy<p>Quick start:<p>1. `git clone https:&#x2F;&#x2F;github.com&#x2F;madnguvu&#x2F;spokedpy.git &amp;&amp; cd spokedpy`\n2. `pip install -r requirements.txt`\n3. `cd web_interface &amp;&amp; python app.py`\n4. Open http:&#x2F;&#x2F;localhost:5002<p>This was a fun and rewarding project that gave me some excellent insights into Claude Opus 4.6 in particular \u2014 felt like the right time to let one go.<p>This is v0.1 released literally hours ago. I\u2019d genuinely love candid technical feedback \u2014 especially on the UIR design, Node Registry hot-swapping, ledger semantics, or visual canvas ergonomics. Suggestions for additional language backends or edge-case demos are also very welcome.<p>Happy to answer any questions in the thread.<p>Enjoy,\nMatthew DiFrancesco\nReach out:  difran@gmail.com", "author": "mdifrancesco", "timestamp": "2026-02-25T17:28:49+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:50:53.944850+00:00", "processed": false}
{"id": "hn_story_47154476", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154476", "title": "Claude Status \u2013 Elevated error rates across multiple models", "text": "", "author": "StanAngeloff", "timestamp": "2026-02-25T17:18:46+00:00", "score": 10, "num_comments": 12, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:50:54.749261+00:00", "processed": false}
{"id": "hn_story_47154193", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154193", "title": "Show HN: I built a unified inference layer for Document Processing Models", "text": "Hey HN,<p>I\u2019m Adithya, a 22-year-old researcher from India. I work with a lot of document processing models while building AI pipelines, and one pain kept repeating: every model has its own inference code, preprocessing steps, and output format. Swapping models or testing new ones meant rewriting a lot of boilerplate each time.<p>So I built Omnidocs\u2014an open source library to run document processing models through a simple, unified API, with a vision-first approach to understanding documents.<p>Key features:<p>&gt; Pick a task and a model, run inference with one interface\n&gt; Supports common document tasks: Text extraction, OCR, Table extraction, Layout analysis and Structured Extraction ...\n&gt; 16+ models supported out of the box (many more integrations to come)\n&gt; Runs locally on Mac or GPUs (MLX and vLLM backends supported)\n&gt; Works with VLM APIs like GPT, Claude, Gemini and many more that support Open Responses API spec\n&gt; Designed to quickly build and test document processing pipelines<p>This has helped me prototype document workflows much faster and compare models easily.<p>Would love feedback on the API design, developer experience, and what integrations would make this more useful.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;adithya-s-k&#x2F;omnidocs\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;adithya-s-k&#x2F;omnidocs</a>", "author": "Adithya-Kolavi", "timestamp": "2026-02-25T16:58:38+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:50:56.732196+00:00", "processed": false}
{"id": "hn_comment_47154106", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154106", "title": "Re: Gatekeeper \u2013 open-source policy engine and sandbox...", "text": "<p><pre><code>  AI agents (Claude Code, Cline, Aider, OpenClaw) execute real side effects \u2014 writing\n  files, running shell commands, making network requests. Most security approaches\n  evaluate each action in isolation against a blocklist. That misses the pattern that\n  actually matters.\n\n  Gatekeeper tracks behavioural state across the entire session. If an agent reads\n  credentials, then ingests content from an untrusted source, and then attempts a network\n  call \u2014 that combination triggers escalation to human review, even if each individual\n  The action would normally be allowed. We call it the exfiltration trifecta:\n  read_sensitive + ingested_untrusted + has_egress.\n\n  OpenClaw is the tightest integration: Gatekeeper launches it as a managed child\n  process inside an OS-native sandbox (macOS sandbox-exec, Linux unshare), generates\n  its config automatically, and intercepts every tool call before it executes. One\n  command: `gatekeeper run --agent openclaw --workspace &#x2F;path&#x2F;to&#x2F;project`.\n\n  Other things it does:\n  - Policy-as-code: YAML rulepacks signed with Ed25519 (tamper-evident, auditable)\n  - Approval flow: ASK decisions pause execution and wait for human approval in a UI\n  - Append-only audit log with SHA-256 hash chain\n  - Prompt injection scanner on tool call inputs&#x2F;outputs (16 patterns, NFKC normalized)\n  - Agent identity guard: blocks writes to CLAUDE.md, .cursorrules, system_prompt files\n  - Claude Code, Cline, Aider, and Continue also supported via MCP or REST\n\n  Honest limitations: operates at the execution boundary, not the cognitive layer. If\n  An agent&#x27;s context was poisoned before any tool call fires; Gatekeeper won&#x27;t catch\n  the injection \u2014 only its downstream consequences.</code></pre>", "author": "gemini2026", "timestamp": "2026-02-25T16:52:35+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:50:57.437066+00:00", "processed": false}
{"id": "hn_comment_47154114", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154114", "title": "Re: Show HN: Quoroom \u2013 local AI swarm (public research...", "text": "Hi HN \u2014 I built Quoroom, an open-source experiment in collective AI.<p>Instead of one agent, a \u201croom\u201d has:\n- a Queen (strategy + delegation)\n- Workers (specialized execution)\n- Quorum voting for decisions<p>It runs local-first (Mac&#x2F;Windows&#x2F;Linux), with a web UI at localhost.\nInstall is simple:<p>npm i -g quoroom\nquoroom serve<p>Current focus:\n- persistent rooms with goals&#x2F;tasks&#x2F;memory\n- quorum-based decision flow\n- Clerk assistant to manage rooms\n- local or cloud runtime options<p>Model support:\n- Claude&#x2F;Codex subscriptions\n- OpenAI&#x2F;Anthropic APIs<p>This is still experimental, and I\u2019m trying to answer one question:\nCan a coordinated AI collective outperform a solo agent on real tasks?<p>I\u2019d really value feedback on:\n1) swarm architecture,\n2) safety&#x2F;control model,\n3) how to benchmark \u201ccollective vs solo\u201d fairly.", "author": "vasilyt", "timestamp": "2026-02-25T16:53:09+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:50:57.506868+00:00", "processed": false}
{"id": "hn_comment_47153911", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153911", "title": "Re: PromptFast \u2013 Test and compare prompts across diffe...", "text": "I kept running into the same friction loop: tweak a prompt, spin up the\n  project, wait for deps, re-run the script, get an error, try again. Each\n  cycle was 8+ minutes. At 20 iterations a day that&#x27;s a real chunk of time\n  gone before I&#x27;ve learned anything useful.<p><pre><code>  So I built PromptFast \u2014 a browser-based prompt playground that skips all\n  of that. You open it, paste a prompt, and run it against whichever model\n  you want in under 5 seconds.\n\n  The features I use constantly:\n\n  - 13+ models across OpenAI, Anthropic, and Google \u2014 switch in one click\n  - Dynamic variables ({{tone}}, {{recipient}}) so you can test multiple\n    scenarios without rewriting\n  - Side-by-side model comparison \u2014 great for deciding between GPT-4o and\n    Sonnet on a specific task\n  - Token and cost breakdown per run \u2014 helps avoid surprise bills\n  - File upload context (PDF, DOCX, CSV, XLSX, JSON) \u2014 useful for\n    document-heavy prompts\n  - System prompt field + prompt history so you can reload and iterate\n    on past runs\n\n  Your API keys are encrypted client-side (AES-GCM) and never stored on\n  my server. The backend is FastAPI + LangGraph; the frontend is Next.js.\n\n  It&#x27;s a paid tool (\u20ac5&#x2F;mo, or \u20ac45&#x2F;yr, or \u20ac95 lifetime) \u2014 no free tier\n  currently, though you can try the demo on the landing page. Still early\n  days and happy to hear what&#x27;s missing or broken.\n\n  https:&#x2F;&#x2F;promptfast.app</code></pre>", "author": "bakszy", "timestamp": "2026-02-25T16:37:56+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-25T17:50:59.546102+00:00", "processed": false}
{"id": "hn_story_47153680", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153680", "title": "Show HN: Polos: Open-source runtime for AI agents with sandbox and durable exec", "text": "Hi HN, I&#x27;m Neha. I spent years at Google building infrastructure that handled billions of events at 99.999% reliability. When I started building AI agents, I was surprised at how much production plumbing you&#x27;re expected to own yourself.<p>The agent itself is the easy part. The hard part is everything around it: where does it execute safely? What happens when it fails midway through a workflow? How do you trigger it from your existing tools? How do you even know what it did?<p>I kept stitching together Docker, a workflow engine, a notification layer, and custom retry logic. Every team I talked to was doing the same thing. So I built Polos - an open-source runtime that handles the production layer so you just write the agent.<p>What it does:<p>- Sandboxed execution: agents run sensitive operations inside managed Docker containers with built-in tools for file I&#x2F;O, bash, and web search. You don&#x27;t manage the sandbox or its lifecycle, Polos does. Will support more sandboxes like E2B in the future.<p>- Slack integration: @mention an agent in Slack, get responses in thread. Trigger workflows from Slack, receive notifications, collect input. Agents become part of your team&#x27;s existing workflow.<p>- Durable workflows: if an agent fails mid-run, it resumes from the exact step that failed. Built-in prompt caching with 60-80% cost savings on retries.<p>- Observability: OpenTelemetry tracing for every step, tool call, and decision.<p>- LLM agnostic: works with OpenAI, Anthropic, Google, or any provider via Vercel AI SDK and LiteLLM.<p>The stack is Rust orchestrator (Axum + Tokio + PostgreSQL), Python and TypeScript SDKs, and Vite UI. You can install and run a durable, sandboxed agent in under 5 minutes:<p>```<p>curl -fsSL <a href=\"https:&#x2F;&#x2F;install.polos.dev&#x2F;install.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;install.polos.dev&#x2F;install.sh</a> | bash<p>npx create-polos<p>cd my-project &amp;&amp; polos dev<p>```<p>Here&#x27;s a 3-min demo of a coding agent that picks up a GitHub issue, fixes the code in a sandbox, and submits a PR: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KYVBpdZ_5eM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KYVBpdZ_5eM</a><p>Happy to discuss technical decisions and more: why Rust for the orchestrator, how durable execution works without a DAG, and the sandbox lifecycle model.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;polos-dev&#x2F;polos\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;polos-dev&#x2F;polos</a>", "author": "ndeodhar", "timestamp": "2026-02-25T16:24:03+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:01.011674+00:00", "processed": false}
{"id": "hn_comment_47153410", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153410", "title": "Re: Show HN: Dance of Tal V2 \u2013 Dependency injection an...", "text": "Hi HN,<p>I\u2019m sharing a project I built to solve a specific pain point I hit while building multi-agent systems and adopting AI coding assistants (Cursor, Antigravity, Codex, etc.).<p>As we move towards agent orchestration, we increasingly need specialized agents: one agent for architecture, another for security review, and another for writing tests. But right now, most of us manage this by stuffing everything into massive 1,000+ line AGENTS.md files or hardcoding prompt blobs into our scripts.<p>When a specific agent hallucinates or violates a security policy, debugging that monolithic prompt blob is impossible. There is no versioning, no diffs, and no way to say &quot;keep the senior backend persona, but swap out the testing rules for this specific CI agent.&quot;<p>I realized I needed to treat AI constraints the same way I treat code. So, I built Dance of Tal (DOT).<p>The name comes from Talchum, the traditional Korean mask dance, where Tal is the mask (character&#x2F;persona) and chum is the dance (the prescribed movements). DOT applies this exact metaphor to decouple system prompts into strongly typed, versioned components:<p>Tals (Personas): The mask. How the AI thinks and its professional identity (e.g., tal&#x2F;@username&#x2F;security-auditor).<p>Dances (Rules): The choreography. Strict formatting, JSON schemas, and coding standards. You can layer multiple Dances like CSS classes (e.g., dance&#x2F;@username&#x2F;kotlin-style + dance&#x2F;@username&#x2F;gdpr-rules).<p>Combos (Lockfiles): Pins a specific Tal and layered Dances together into a reproducible profile. (e.g., Your PR-review agent gets a different Combo than your hotfix agent).<p>Acts (Workflows): The stage play. A DAG-based workflow engine that conditionally switches between Tals and Dances (e.g., automatically switching the AI from a &quot;cautious architect&quot; to a &quot;fast hotfix specialist&quot; during a P0 incident).<p>Stages (Adapters): Translates the assembled payload perfectly for whatever vendor&#x2F;platform you&#x27;re using (Cursor, Antigravity, Codex, Claude API, etc.).<p>Instead of copy-pasting blobs, I just run dot lock to give each AI agent the exact reproducible behavior it needs. I also added native MCP (Model Context Protocol) support, so IDEs and orchestration frameworks can just fetch the compiled context exactly when needed\u2014no more manual prompt wrangling.<p>I&#x27;d love to hear your thoughts on this &quot;dependency injection for prompts&quot; approach. Are prompt monoliths and multi-agent context management causing friction for you as well?<p>Happy to answer any questions!", "author": "monarchjuno", "timestamp": "2026-02-25T16:07:01+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:03.136648+00:00", "processed": false}
{"id": "hn_story_47153297", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153297", "title": "AncestorTree \u2013 Open-source genealogy for Vietnamese families", "text": "Vietnamese genealogy has structures Western platforms don&#x27;t support:\nlunar calendars, hierarchical clan branches, auto generation numbering,\nand a 60-year zodiac cycle for date notation.<p>AncestorTree handles these. Built in 7.5 sprints over 24 hours by\norchestrating 8 AI agents through TinySDLC + Claude Code.<p>Stack: Next.js 16 + React 19 + TypeScript + Supabase + Vercel. $0&#x2F;mo.<p>13 PostgreSQL tables. 77 documented requirements. 4 permission roles\nenforced via RLS. DFS-based ceremony duty rotation. Family relations\npanel (parents, siblings, spouses, children per profile). Hierarchical\ntree layout. Branch filter with shareable URLs (?root=id).\nTree-scoped editor: users linked to their person, edits restricted\nto their subtree \u2014 enforced by a recursive PostgreSQL CTE in RLS.<p>Built with MTS-SDLC-Lite: stage gates, design review before code.\nSame agents without governance = plausible but broken.\nWith governance = production-ready in 1 day.<p>MIT licensed. Fork + deploy in ~30 min.<p>Feedback welcome.", "author": "dttai", "timestamp": "2026-02-25T15:59:22+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:03.543413+00:00", "processed": false}
{"id": "hn_story_47153242", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153242", "title": "Show HN: Memograph CLI- A tool to diagnose 'memory failures' in AI agents", "text": "Hi HN,<p>I\u2019ve been building AI agents and copilots, and kept running into a frustrating problem: they don\u2019t fail loudly, they forget things quietly.<p>Users re-explain preferences, agents contradict earlier responses, and context resets without any clear visibility into why.<p>I built Memograph CLI as a debugging tool to analyze conversation transcripts and show:<p>- what the agent forgot<p>- where continuity broke<p>- contradictions and repeated context<p>- estimated token waste due to re-prompting<p>It works locally and supports plain text or JSON transcripts.<p>Example:<p>$ memograph<p>Output:<p>Cognitive Drift Score: 41&#x2F;100<p>Forgotten preferences: 3<p>Token waste: 29%<p>Trust-breaking contradictions: 1<p>The goal isn\u2019t to replace your agent framework, but to give developers visibility into memory failures.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;memographAI&#x2F;Memograph-CLI\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;memographAI&#x2F;Memograph-CLI</a><p>Would love feedback, especially from people building agents in production.", "author": "memograph", "timestamp": "2026-02-25T15:55:55+00:00", "score": 5, "num_comments": 5, "products": ["copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:03.770439+00:00", "processed": false}
{"id": "hn_story_47152204", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47152204", "title": "Show HN: Automatic context rotation for Claude Code (no manual steps)", "text": "AI coding agents break when the context window fills up \u2014 they lose state,\nhallucinate, or auto-compact shreds the context you built up.<p>I built a 3-hook pipeline that rotates <i>before</i> that happens, with a dry-run\nreplay you can run locally (no LLM&#x2F;API keys).<p>Quick demo:\n- <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration&#x2F;tree&#x2F;master&#x2F;demo&#x2F;dry-run-context-rotation\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration&#x2F;tree&#x2F;master&#x2F;dem...</a><p>How it works:<p><pre><code>    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  PreToolUse hook \u2502\u2500\u2500 checks context % every tool call\n    \u2502  (\u226565% \u2192 block) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Agent writes    \u2502\u2500\u2500 structured ROTATION-HANDOVER.md\n    \u2502  handover file   \u2502   (task state, files, progress, next steps)\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  PostToolUse     \u2502\u2500\u2500 detects handover \u2192 atomic lock\n    \u2502  launches rotator\u2502   \u2192 vnx_rotate.sh (nohup, detached)\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Rotator         \u2502\u2500\u2500 &#x2F;clear via tmux \u2192 waits for SessionStart\n    \u2502  injects resume  \u2502   \u2192 pastes continuation prompt\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\nWhy 65%? It\u2019s ~15 points before auto-compact (~80%), so there\u2019s enough\nheadroom to write a clean handover without racing compaction.<p>I analyzed 5 projects attempting similar fixes \u2014 none have a full\ndetect \u2192 handover \u2192 clear \u2192 resume \u2192 verify loop.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration</a>\nDocs: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration&#x2F;blob&#x2F;master&#x2F;docs&#x2F;CONTEXT_ROTATION.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Vinix24&#x2F;vnx-orchestration&#x2F;blob&#x2F;master&#x2F;doc...</a>", "author": "vincentvandeth", "timestamp": "2026-02-25T14:45:37+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:11.810100+00:00", "processed": false}
{"id": "hn_story_47152118", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47152118", "title": "Show HN: Black Forest Labs CLI \u2013 let coding agents paint", "text": "I didn&#x27;t see any source code or SDK for handling black forest labs (pretty good image gen!) from the CLI or for agent use so I wrote it.<p>It&#x27;s super cool to see a coding agent using the anthropic frontend design skill calling this and adding images to its work.", "author": "mackenzie_bowes", "timestamp": "2026-02-25T14:39:15+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:12.122252+00:00", "processed": false}
{"id": "hn_story_47151982", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151982", "title": "ActivationKit \u2013 AI agent replaces manual tooltip tours with one script tag", "text": "I built an AI-powered user guidance tool that replaces Pendo&#x2F;Appcues&#x2F;WalkMe. One script tag install. No manual flow authoring.<p><pre><code>  The core design principle: observe the DOM, never require host cooperation. The AI reads disabled buttons, aria-disabled attributes, locked classes, hidden\n  elements \u2014 everything the app already shows. Zero config from the host app beyond the script tag.\n\n  How it works:\n\n  1. You add &lt;script&gt;ActivationKit(&#x27;init&#x27;, { apiKey: &#x27;...&#x27; });&lt;&#x2F;script&gt;\n  2. The SDK extracts your page structure (elements, roles, sections, navigation) using a DOM extractor\n  3. An AI enrichment pass builds a product schema from the extraction\n  4. When a user asks a question or needs help, a three-tier decision pipeline handles it:\n    - Tier 1 \u2014 Rules (&lt;10ms): 12 deterministic rules (welcome nudge, idle help, form abandonment, feature discovery, etc.)\n    - Tier 2 \u2014 Cache (&lt;50ms): Context-hash keyed response cache with quality scoring\n    - Tier 3 \u2014 LLM (500-2000ms): GPT-4o-mini with structured JSON output, only called when rules and cache miss\n\n  ~70% of requests resolve without touching the LLM.\n\n  The feature I&#x27;m most excited about: on-demand tour generation. If a user asks &quot;give me a tour of the wallet features&quot; and no pre-built tour exists, the LLM\n  generates 3-5 step tours inline from the page&#x27;s known elements. The SDK renders them immediately. No manual authoring, works for any page, any topic.\n\n  Architecture decisions:\n  - Shadow DOM (closed mode) for CSS isolation \u2014 the widget never breaks the host app&#x27;s styles\n  - Hono on Fly.io (not Vercel) \u2014 SSE needs long-lived connections\n  - TypeScript monorepo (SDK + API + Dashboard)\n  - Neon Postgres with pgvector for semantic element retrieval\n  - SDK is 30KB gzipped, vanilla JS, framework-agnostic\n\n  What&#x27;s different from existing tools:\n  - Pendo&#x2F;Appcues&#x2F;Chameleon require you to manually build every tooltip flow. ActivationKit generates guidance automatically.\n  - WalkMe costs $50K+&#x2F;yr. ActivationKit is $29&#x2F;mo.\n  - CommandBar (only real AI competitor) was acquired by Amplitude in 2024. Their roadmap is frozen.\n\n  Pricing: Free plan (25 conv&#x2F;mo), upgrade anytime. Pro $29&#x2F;mo, Business $99&#x2F;mo.\n\n  Stack: TypeScript, Hono, Next.js 15, Neon Postgres, GPT-4o-mini, Fly.io, Vercel. 437 tests + 6 Playwright E2E.\n\n  Looking for feedback, especially from anyone who&#x27;s struggled with Pendo&#x2F;Appcues maintenance overhead. What would make you switch?\n\n  https:&#x2F;&#x2F;activationkit.com</code></pre>", "author": "activationkit", "timestamp": "2026-02-25T14:31:04+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:13.417724+00:00", "processed": false}
{"id": "hn_comment_47154113", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47154113", "title": "Re: Palantir Built the Data Layer That Right to Erasur...", "text": "The idea that it&#x27;s harder to query and delete everything relating to a person from a well-organized graph than from the typical corporate patchwork of data systems seems very improbable. The post also reads like a barely tweaked Gemini output. I&#x27;m not a Palantir fan, but this feels flimsy.", "author": "Centigonal", "timestamp": "2026-02-25T16:53:08+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:16.017062+00:00", "processed": false}
{"id": "hn_story_47151598", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151598", "title": "Launch HN: TeamOut (YC W22) \u2013 AI agent for planning company retreats", "text": "Hi HN, I\u2019m Vincent, CTO of TeamOut (<a href=\"https:&#x2F;&#x2F;www.teamout.com&#x2F;\">https:&#x2F;&#x2F;www.teamout.com&#x2F;</a>). We build an AI agent that plans company events from start to finish entirely through conversation. Similar to how Lovable helps build websites through chat, we apply that approach to event planning. Our system handles venue sourcing, vendor coordination, flight cost estimation, itinerary building, and overall project management.<p>Here\u2019s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=QVyc-x-isjI\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=QVyc-x-isjI</a>. The product is live at <a href=\"https:&#x2F;&#x2F;app.teamout.com&#x2F;ai\">https:&#x2F;&#x2F;app.teamout.com&#x2F;ai</a> and does not require signup.<p>We went through YC in 2022 but did not launch on HN at the time. Back then, the product was more traditional, closer to an Airbnb-style search marketplace. Over the past two years, after helping organize more than 1,200 events, we rebuilt the core system around an agent architecture that directly manages the planning process. With this new version live, it felt like the right moment to share it here since it represents a fundamentally different approach to planning events.<p>The problem: Planning a company retreat usually means choosing between three imperfect options: (1) Hire an event planner and pay significant fees and venue markups; (2) Do it yourself and spend dozens of hours on research, emails, and negotiation; or (3) Use tools like Airbnb that are not designed for group logistics or meeting space.<p>The difficulty is not just finding a venue. Even for 30 to 50 people, planning turns into weeks of back-and-forth emails for quotes, comparing inconsistent pricing across PDFs, and tracking budgets in spreadsheets. It becomes an ongoing coordination problem with evolving constraints and slow, asynchronous vendor responses. Most existing software is form-driven, but the real workflow is conversational and stateful.<p>Offsites are expensive and high stakes. A single event can represent a significant chunk of a team\u2019s annual budget, and mistakes show up directly as cost overruns or poor experiences. Founders and operators often end up spending time on event logistics instead of their actual work.<p>I ran into this while organizing retreats at a previous company. Before TeamOut, I worked as an AI researcher at IBM on NLP and machine learning systems. Sitting inside long email threads and cost spreadsheets, it did not look like a marketplace gap to me. It looked like a reasoning and state management problem. As large language models improved at multi-step reasoning and tool use, it became realistic to automate the coordination layer itself.<p>Our Solution: The core agent relies on a combination of models such as Gemini, Claude, and GPT. A central LLM-based agent maintains planning context across turns and decides which specialized tool to call next.\nEach tool has a specific responsibility: - Venue search and filtering - Cost estimations (accommodation + flights) - Budget comparisons - Quote and outreach flows - Communication tool with our team<p>For venue recommendations across more than 10,000 venues, we do not rely purely on the language model. We embed both user requirements and venues into vector representations and retrieve candidates using similarity search. Hard constraints such as capacity and dates are applied first, and results are ranked before being presented.<p>On the interface side, we use a split layout: conversation on the left and structured results on the right. As you refine the plan in chat, the event updates in real time, allowing an iterative workflow rather than a static search experience.<p>What is different is that we treat event planning as a stateful coordination problem rather than a one-shot search query. The agent orchestrates tools, manages evolving constraints, and surfaces trade-offs explicitly. It does not invent venues or fabricate pricing, and it is not designed to replace human planners for very large or highly customized events.<p>We make money from commissions on venue bookings. It is free for teams to explore options and plan.\nIf you\u2019ve organized an offsite or large meetup before, I\u2019d genuinely value your perspective. Where would you expect this to fail? What edge cases are we underestimating? Where wouldn\u2019t you trust an agent to handle the details?<p>My engineering team and I will be here all day to answer questions, happy to go deep on architecture, tradeoffs, and lessons learned. \nWe\u2019d really appreciate your candid feedback.", "author": "vincentalbouy", "timestamp": "2026-02-25T14:02:02+00:00", "score": 19, "num_comments": 27, "products": ["claude", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:16.262189+00:00", "processed": false}
{"id": "hn_comment_47153896", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47153896", "title": "Re: Launch HN: TeamOut (YC W22) \u2013 AI agent for plannin...", "text": "&gt; Where would you expect this to fail?<p>Haven&#x27;t organized large meetups, but for regular enterprise companies this could be a difficult to buy decision, because you have ChatGPT + bunch of connectors which can get company policies.<p>This could be good idea for event companies who regularly schedule things, but even for them, probably difficult to justify the value when you have access to ChatGPT and other connectors", "author": "throwaw12", "timestamp": "2026-02-25T16:37:10+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:16.331983+00:00", "processed": false}
{"id": "hn_story_47151517", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151517", "title": "Show HN: Velar \u2013 Local privacy firewall for AI", "text": "I realized I was leaking sensitive data to ChatGPT every day.\nEmails, API keys, internal data.\nSo I built a local firewall that detects and masks sensitive data before it leaves your machine.\nIt runs as a local proxy, supports streaming, and restores data in responses.\nEverything is local.\nWould love feedback.", "author": "ubcent", "timestamp": "2026-02-25T13:57:49+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:17.377546+00:00", "processed": false}
{"id": "hn_comment_47151577", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151577", "title": "Re: Show HN: I cut LLM API bill by 55% with a Python t...", "text": "A new privacy-first API We redesigned our API \u2014 now the official version \u2014 to handle token compression with privacy at its core. We only require your AgentReady key. Your LLM API key stays yours \u2014 we never see it:<p>-------------------------------------------\nimport requests, os\nfrom openai import OpenAI<p># Step 1: Compress messages with AgentReady\nres = requests.post(&quot;<a href=\"https:&#x2F;&#x2F;agentready.cloud&#x2F;v1&#x2F;comp\" rel=\"nofollow\">https:&#x2F;&#x2F;agentready.cloud&#x2F;v1&#x2F;comp</a>...&quot;,\n    headers={&quot;Authorization&quot;: &quot;Bearer ak_live_116e......&quot;},\n    json={&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: your_text}]})\ncompressed = res.json()[&quot;messages&quot;]<p># Step 2: Send to YOUR LLM with YOUR key\nclient = OpenAI(api_key=os.environ[&quot;OPENAI_API_KEY&quot;])\nresponse = client.chat.completions.create(model=&quot;gpt-4o&quot;, messages=compressed)\n-------------------------------------------<p>Here&#x27;s everything else we shipped:<p>- Optimized compression \u2014 the new API compresses data more efficiently, reducing token usage further.<p>- OpenClaw integration \u2014 AgentReady now works seamlessly with OpenClaw.<p>- Benchmark page \u2014 we created a benchmark page AgentReady \u2014 Make the Web Readable for AI Agents<p>- PIP &amp; NPM packages \u2014 integrate AgentReady directly into your Python or JavaScript projects with a single install.<p>- Token usage tracking \u2014 better visibility into how your tokens are being used.<p>- Self-hostable version (coming soon) \u2014 compress tokens entirely on your local machine. Nothing leaves your environment. The only external call is a license key check against our server.<p>------------------------------------------<p>Get started in seconds We also streamlined the sign-up flow \u2014 you can now register and get your API key in less than 10 seconds here:<p><a href=\"https:&#x2F;&#x2F;agentready.cloud&#x2F;quick-key\" rel=\"nofollow\">https:&#x2F;&#x2F;agentready.cloud&#x2F;quick-key</a><p>-------------------------------------------\nYou can find everything else here:<p>homepage: <a href=\"https:&#x2F;&#x2F;agentready.cloud&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;agentready.cloud&#x2F;</a><p>docs: <a href=\"https:&#x2F;&#x2F;agentready.cloud&#x2F;docs&#x2F;quickstart\" rel=\"nofollow\">https:&#x2F;&#x2F;agentready.cloud&#x2F;docs&#x2F;quickstart</a>", "author": "christalingx", "timestamp": "2026-02-25T14:00:40+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:17.447153+00:00", "processed": false}
{"id": "hn_story_47151427", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151427", "title": "Show HN: Seite static site generator with MCP server and Claude Code integration", "text": "I&#x27;m CTO at a startup, tired of maintaining five separate tools for our web presence while shipping software with Claude Code every day. So I built seite \u2014 a Rust SSG where the AI agent has a proper MCP interface to your site, not just file access.<p>seite mcp runs a Model Context Protocol server that exposes resources (docs, config, content, themes) and tools (build, create, search, apply theme) to any MCP-compatible agent. seite init also scaffolds a CLAUDE.md context file so the agent knows your schemas and conventions before it writes anything.<p>Everything else you&#x27;d expect: six bundled themes, collection presets for blog&#x2F;docs&#x2F;changelog&#x2F;roadmap, one-command deploy to GitHub Pages&#x2F;Cloudflare&#x2F;Netlify, llms.txt and llms-full.txt on every build. Single binary, no runtime, sub-second builds. 331 tests.<p>MIT licensed, v0.1.6. Early but iterating fast \u2014 we&#x27;re using it on our own startup&#x27;s site so the feedback loop is tight.<p><pre><code>  curl -fsSL https:&#x2F;&#x2F;seite.sh&#x2F;install.sh | sh\n</code></pre>\nSite: <a href=\"https:&#x2F;&#x2F;seite.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;seite.sh</a>\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;seite-sh&#x2F;seite\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;seite-sh&#x2F;seite</a>", "author": "sanchezomar", "timestamp": "2026-02-25T13:50:50+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:17.751180+00:00", "processed": false}
{"id": "hn_story_47151385", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151385", "title": "Show HN: First native zeroclaw build on Android/Termux (aarch64, no proot)", "text": "Zeroclaw is a Rust-based Nostr client&#x2F;relay tool. As of a few hours ago, no one had compiled it natively on Android.<p>Gemini CLI tried. Gemini Android tried. Both failed.<p>The blockers:\n\u2014 koffi&#x27;s build script passes `make -j` bare, which Termux&#x27;s make rejects\n\u2014 The default linker OOM-kills during the final link step (Android blocks swapon for unprivileged processes)<p>The fix: mold linker + codegen-units=1 + lto=thin + opt-level=z in a .cargo&#x2F;config.toml<p>Binary: 15.5MB. Build time: 23m 55s. Kernel: Linux 5.4.284-moto. Completed at 04:11:47 CST.<p>Repo with binary, build config, and full reproduction steps:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;BleakNarratives&#x2F;zeroclaw-android\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;BleakNarratives&#x2F;zeroclaw-android</a>", "author": "bleaknarratives", "timestamp": "2026-02-25T13:46:45+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2026-02-25T17:51:17.919617+00:00", "processed": false}
{"id": "hn_story_47151344", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151344", "title": "Show HN: I scanned 35 SaaS products across ChatGPT, Claude, Perplexity, Gemini", "text": "I built a scoring system to measure how AI models represent software products when users ask buying questions.\nThe process: I take a product, generate the queries a buyer would ask (category, competitor alternatives, head-to-head), run them through ChatGPT, Claude, Perplexity, and Gemini, then score how prominently the product appears in each response (0-10).\nSome findings from scanning 35 products:\nChatGPT is the biggest blind spot. It scores 0 for most open source challengers, even ones with 30K+ GitHub stars.\nIncumbents dominate across all models. &quot;Best project management tool&quot; returns Jira, Linear, Asana \u2014 never Plane (31K stars on GitHub).\nBrand-name queries work. &quot;Cal.com vs Calendly&quot; scores 9+ everywhere. But generic category queries (&quot;best scheduling tool&quot;) often return 0.\nHaving revenue doesn&#x27;t help. Trigger.dev raised $16M and scores 0&#x2F;10 for background job queries.\nThe scoring methodology: each model gets 0-10 per query based on mention position, detail, and recommendation strength. Product consensus = average across all models and queries.\nCode and methodology are open. Happy to scan any product if you drop it in the comments.", "author": "gissurthor", "timestamp": "2026-02-25T13:43:00+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini", "perplexity"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:18.262385+00:00", "processed": false}
{"id": "hn_comment_47151318", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151318", "title": "Re: OpenPencil: Open-source vector design tool control...", "text": "OpenPencil is an MIT-licensed, AI-native vector design tool. It features a built-in MCP server, allowing AI Agents (like Claude Code or Cursor) to directly edit designs without a GUI. Thanks to its Design-as-Code architecture, all files are structured JSON, enabling version control and Git diffs for design.", "author": "finiking", "timestamp": "2026-02-25T13:41:22+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:18.568919+00:00", "processed": false}
{"id": "hn_comment_47151331", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151331", "title": "Re: OpenPencil: Open-source vector design tool control...", "text": "Hey! I&#x27;m the creator of OpenPencil, and I&#x27;m super excited to share it with you today.<p>We are entering the era of AI Agents, but our design tools are still stuck in the GUI era. We are constantly downloading &quot;final_v9.fig&quot; and manually clicking to tweak UI elements. I wanted to change that.<p>OpenPencil isn&#x27;t just another design tool with a magic AI button. It is structurally built for AI.<p>Here is why it&#x27;s different:<p>Agentic Design (MCP Server): You can connect Claude, Cursor, or any MCP-compatible agent directly to your design. Tell your AI IDE to &quot;update the login screen to match the new dark mode theme,&quot; and it modifies the design file without you ever touching a mouse.<p>Design-as-Code: The .op format is pure JSON. Finally, you can Git commit, diff, and PR your design files just like your codebase.<p>100% Open Source (MIT): No subscriptions, no vendor lock-in. Build on top of it, fork it, make it yours.<p>I built this because I believe the future of design is Human creativity + Agent execution.<p>I&#x27;d love your feedback! Drop your questions below, and let me know what features you want to see next!", "author": "finiking", "timestamp": "2026-02-25T13:42:24+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:18.604484+00:00", "processed": false}
{"id": "hn_comment_47152529", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47152529", "title": "Re: Show HN: ContextVM \u2013 Running MCP over Nostr...", "text": "I just learned yesterday that ChatGPT (and maybe others) can\u2019t connect to a MCP running on localhost; it needs an endpoint on the public internet. (I guess because the request comes from OpenAI servers?)<p>I\u2019d rather not expose a private MCP to the public, so ContextVM sounds like a step in the right direction. But I\u2019m confused about how it is called: doesn\u2019t OpenAI\u2019s servers still need you to provide a public endpoint with a domain name and TLS? Or does it use a Nostr API?", "author": "quinncom", "timestamp": "2026-02-25T15:07:15+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["feature_discovery", "tone"], "sentiment": null, "collected_at": "2026-02-25T17:51:18.739585+00:00", "processed": false}
{"id": "hn_story_47151273", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151273", "title": "Show HN: Echos \u2013 Self-hosted AI knowledge base for things you forget", "text": "Hi HN, I\u2019m Albino (<a href=\"https:&#x2F;&#x2F;www.albinotonnina.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.albinotonnina.com</a>). Happy Wednesday. I built echos because I often saved things but couldn\u2019t find them again. My memory isn\u2019t great. I\u2019d read something useful, but a couple of weeks later, I\u2019d forget where I put it or even that I\u2019d read it at all.<p>I tried a bunch of popular tools, but they all made me pick a category before saving anything. That small step was enough of a hassle that I\u2019d skip it, especially when I was busy. After a few months, I didn\u2019t have a knowledge base, just a reading list that made me feel guilty.<p>echos is a self-hosted AI knowledge system. You can send it all kinds of content during the day, like a URL, a voice note, or just a thought you want to save. It stores, sorts, and indexes everything for you, so you don\u2019t have to decide where it goes. Later, you just ask a question in plain language to find what you need.<p>Website: <a href=\"https:&#x2F;&#x2F;www.echos.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;www.echos.sh</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;albinotonnina&#x2F;echos\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;albinotonnina&#x2F;echos</a><p>Demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=D3QCQXqNewU\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=D3QCQXqNewU</a><p>How It Works<p>echos uses an AI agent built on Claude. It starts in Haiku mode by default, but you can switch modes at any time with the command &#x2F;model [fast|balanced|deep]. When you send a message, the AI figures out what to do, whether that\u2019s storing, searching, writing, or reminding you about something. Just tell it what you need. You can conversate with it like you would with a person, and it handles the rest.<p>Notes are saved as plain Markdown files in the data&#x2F;knowledge&#x2F; folder. You can open that folder in Obsidian, and live sync works out of the box with no plugins needed. If you ever stop using echos, your notes stay in plain text, so you\u2019re never locked in.<p>The search feature is hybrid. It combines full-text search with SQLite FTS5 and semantic search with LanceDB, using RRF. For example, you can ask, \u201cWhat did I save about async code review last month?\u201d and still find the right note, even if you phrase your question differently.<p>The writing feature is what I use most. You give it five samples of your writing, and it builds a style profile from them. When you ask it to draft something, it checks your notes first and writes using your own material and style. It doesn\u2019t pull from the internet or the model\u2019s training data\u2014everything comes from what you\u2019ve read and saved.<p>There are a lot of other features, like reminders, export options, and content processors for things like YouTube transcripts and article extraction. It\u2019s extensible, so you can add your own tools if you want.<p>What It Isn\u2019t<p>echos is meant for individual use. It\u2019s not multi-tenant by design. Each person runs it on their own server, so your data stays private. The only outbound calls are to the AI APIs you set up yourself.<p>Technical Decisions Worth Mentioning<p>- Uses a pnpm monorepo with TypeScript strict mode enabled throughout<p>- Implements BullMQ and Redis for background jobs, including reminders, export cleanup, and embedding generation<p>- Content processors are designed as plugins rather than core code. For instance, YouTube transcript extraction and article parsing come as separate packages, which allows you to write your own.<p>- Incorporates Zod validation at every input boundary and uses Pino for structured logging, complete with secret redaction features.<p>For full documentation, go to <a href=\"https:&#x2F;&#x2F;docs.echos.sh\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.echos.sh</a>. The project uses the MIT license. If you want to talk more about the agent tool design or the hybrid search, I\u2019m happy to chat!", "author": "dupp", "timestamp": "2026-02-25T13:36:52+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-25T17:51:19.013791+00:00", "processed": false}
{"id": "hn_story_47151187", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151187", "title": "Show HN: Dmark \u2013 DMARC report bulk evaluation tool", "text": "I&#x27;ve had the RUA tag populated in my DNS records from my mail server for a few years now and I have an email filter set up that dumps all of the DMARC reports into an email folder that I never look at. Right now it has over 4,000 of these emails and I thought maybe it was a good idea to make sure that our DMARC posture was good.<p>Rather than evaluate all the reports, I decided to quickly throw together a tool that will allow you to evaluate them and this is what I came up with.<p>It provides four different metrics by which it measures the effectiveness of your policy and it tells you if anything is incorrectly configured and what you should do about it. It is especially focused on evaluating the configuration of Office 365 mail servers, purely out of my own necessity, but it will work with any mail server. The most useful way to use it is to export a folder full of DMARC reports as a PST file and then upload them to the tool.<p>I vibe coded this with Codex in Visual Studio Code and then I had Gemini Pro take a pass at it to clean it up. I used Grok 4.20 as a third voice to ensure that I wasn&#x27;t getting too pigeon-holed by the perspective of the two LLMs I was using.<p>I have this other tool that I built called RoundTable, which enables you to easily ask multiple LLMs a question and then take their responses to build a prompt that you then get all of the LLMs to respond to. Through this iterative process they converge towards an ideal across all of the various perspectives that the LLMs hold.", "author": "prettyWise", "timestamp": "2026-02-25T13:27:58+00:00", "score": 1, "num_comments": 2, "products": ["gemini", "grok"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:19.914065+00:00", "processed": false}
{"id": "hn_comment_47151182", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151182", "title": "Re: Show HN: Mengram \u2013 AI agent memory with facts, eve...", "text": "Hi HN, I&#x27;m Ali. I&#x27;ve been building Mengram for the past year.<p><pre><code>  The problem: Every AI memory tool stores facts \u2014 &quot;user likes dark mode.&quot; But when my agents failed at a task, they&#x27;d fail the exact same way next time. They had no memory of what happened or how to do things better.                                                               \n                                                                                                                                                                                                                                                                                          \n  What Mengram does: It stores 3 types of memory, modeled after how human cognition works:                                                                                                                                                                                                \n                                                                                                                                                                                                                                                                                          \n  - Semantic \u2014 facts and preferences (like Mem0, Zep)                                                                                                                                                                                                                                     \n  - Episodic \u2014 events, decisions, outcomes (what happened and when)                                                                                                                                                                                                                       \n  - Procedural \u2014 learned workflows that evolve when they fail                                                                                                                                                                                                                             \n                                                                                                                                                                                                                                                                                          \n  The procedural part is what I&#x27;m most excited about. When an agent reports a failure, Mengram automatically evolves the procedure \u2014 adds a new step, changes the order, removes what didn&#x27;t work. Your agent literally gets better at its job over time.\n                                                                                                                                                                                                                                                                                          \n  Example: Week 1, &quot;Deploy&quot; = build \u2192 push \u2192 deploy. Agent forgets migrations, DB crashes. Week 2, Mengram evolves it to build \u2192 run migrations \u2192 push \u2192 deploy. Agent hits OOM. Week 3, adds memory check step. This happens automatically.                                              \n                                                                                                                                                                                                                                                                                          \n  Technical details:                                                                                                                                                                                                                                                                      \n  - Python &amp; JS SDKs: pip install mengram-ai                                                                                                                                                                                                                                              \n  - Free cloud API (no credit card) or fully self-hostable\n  - MCP server for Claude Desktop &#x2F; Cursor (21 tools)\n  - LangChain, CrewAI, OpenClaw integrations\n  - Knowledge graph + vector search + reranking\n  - Cognitive Profile: one API call generates a system prompt from all memories\n\n  What it&#x27;s NOT good at (yet):\n  - Smaller community than Mem0 (they have 25K stars, I&#x27;m just starting)\n  - No SOC2&#x2F;HIPAA yet (Zep has this)\n  - No agent-controlled memory like Letta&#x2F;MemGPT\n\n  I&#x27;d love feedback on the API design and the procedural memory concept. Is this something you&#x27;d actually use in production?\n\n  GitHub: https:&#x2F;&#x2F;github.com&#x2F;alibaizhanov&#x2F;mengram\n  Docs: https:&#x2F;&#x2F;mengram.io&#x2F;docs\n  Get a free key: https:&#x2F;&#x2F;mengram.io</code></pre>", "author": "mengram-ai", "timestamp": "2026-02-25T13:27:34+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2026-02-25T17:51:20.106409+00:00", "processed": false}
{"id": "hn_story_47151143", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47151143", "title": "Show HN: AutoBrief \u2013 Generate post-incident briefs from a structured form", "text": "Hi HN,<p>I built AutoBrief after noticing that resolving incidents wasn\u2019t the longest part \u2014 writing about them was.<p>After every incident we would write:\n \u2022 An engineering postmortem\n \u2022 An executive summary\n \u2022 A status page update\n \u2022 Runbook changes<p>Same incident, multiple documents.<p>AutoBrief lets you fill out one structured form (timeline, impact, root cause, mitigation, uncertainties) and generates tailored drafts for each audience.<p>A few design decisions:\n \u2022 Sensitive fields encrypted at the application layer\n \u2022 Workspace isolation using Postgres RLS\n \u2022 Incident data is not used to train AI models\n \u2022 Meant as a draft accelerator, not a replacement for review<p>Stack:\nNext.js 15, Supabase (Postgres + RLS), Claude API, deployed on Vercel.<p>I\u2019d especially appreciate feedback from engineers who run incident reviews.\nWould this reduce overhead in your workflow, or just add another tool?", "author": "SoloShipper", "timestamp": "2026-02-25T13:24:19+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-25T17:51:20.518215+00:00", "processed": false}
{"id": "hn_story_47150957", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47150957", "title": "Show HN: Signal Support for NanoClaw", "text": "NanoClaw now supports Signal via signal-cli&#x27;s JSON-RPC interface. Can run alongside WhatsApp or replace it entirely.<p>Signal&#x27;s E2E encryption pairs well with NanoClaw&#x27;s container isolation. Voice transcription runs locally too, so nothing leaves the machine unless intended.<p>What&#x27;s supported:<p><pre><code>  Typing indicators, reactions, quoted replies, polls\n  Signal text styling (bold, italic, strikethrough, spoiler, monospace) with UTF-16 offset handling\n  Image&#x2F;audio&#x2F;file attachments (send and receive)\n  Voice message transcription (local, via Whisper)\n  Group metadata (members, admins, description)\n  All existing NanoClaw features (scheduled tasks, per-group isolation, etc.)\n</code></pre>\nHow it works: signal-cli runs in JSON-RPC mode. Newline-delimited JSON from stdout gets parsed, messages route to the right group queue, a container spawns, and responses go back via stdin RPC calls. The Signal channel is ~800 lines.<p>Setup: run &#x2F;add-signal in Claude Code, or set SIGNAL_ONLY=true to drop WhatsApp. Needs Java 21+ and signal-cli, no npm dependencies.<p>Upstream skill PR: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;qwibitai&#x2F;nanoclaw&#x2F;pull&#x2F;490\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;qwibitai&#x2F;nanoclaw&#x2F;pull&#x2F;490</a>", "author": "dillpicholas", "timestamp": "2026-02-25T13:03:50+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:22.124911+00:00", "processed": false}
{"id": "hn_comment_47150923", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47150923", "title": "Re: I built an anti-hallucination safety layer for men...", "text": "Hey Fellow Ycombinators!<p>I built the Optimism Engine because I noticed a dangerous gap in how we are using AI for mental health.<p>Right now, everyone is rushing to add &quot;AI Chatbots&quot; to their apps. But there is a huge risk they are ignoring: Hallucinations. Generative AI (like ChatGPT) is creative, but it makes mistakes. It can miss a suicide cue. It can give bad advice. In mental health, a &quot;creative&quot; mistake isn&#x27;t just a bug, it&#x27;s a liability.<p>The Problem with &quot;Prompts&quot;:<p>Most apps try to fix this with &quot;Prompt Engineering.&quot; They write long instructions telling the AI: &quot;Please be safe. Don&#x27;t give medical advice.&quot;<p>But here is the problem: Asking an AI to be safe is not the same as forcing it to be safe. It\u2019s like asking a toddler to &quot;be careful&quot;, they try, but you can&#x27;t rely on them 100% of the time.<p>The Solution: The &quot;Gatekeeper&quot; Architecture:<p>I built the Optimism Engine to solve this. It is not just a chatbot; it is a Hybrid Safety System.<p>Think of it like a traffic light. Before the AI can say anything, it must pass through The Gatekeeper (my Logic Layer).<p>1. Logic First: The Gatekeeper is built with hard-coded rules, not AI. It checks every single message for danger signs (like suicide keywords) or cognitive distortions (like &quot;Catastrophizing&quot;).<p>2. The Override: If a danger sign is detected, the Gatekeeper physically cuts the power to the AI. The AI is never allowed to generate a response. Instead, a pre-written, safe response is served immediately. This guarantees Zero Hallucination Risk on safety issues.<p>3. Context Awareness: The engine is smart enough to know the difference between &quot;I don&#x27;t know how to code&quot; (a learning gap) and &quot;I don&#x27;t know why I&#x27;m alive&quot; (a crisis). It adjusts the AI&#x27;s instructions so it doesn&#x27;t annoy or panic the user.<p>An Engineering Upgrade, Not a Medical Tool:<p>I want to be clear: This is an Engineering Upgrade, not a clinical product. I am not a doctor; I am a developer. I am selling the infrastructure, the plumbing and safety valves that other companies need to build their own apps on top of.<p>Who is this for?<p>If you are a founder or developer building a mental health or coaching app, you have a choice:<p>* Spend 6 months and a ton of money building your own &quot;Safety Layer&quot; and State Machine.<p>* Or acquire the Optimism Engine today and have enterprise-grade safety tomorrow.<p>I\u2019m selling the Full Source Code + IP to help you build safer, smarter, and more reliable AI products. Let&#x27;s stop playing Russian Roulette with mental health technology.<p>Feel the App on Loom (Modest): <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;b488dee8afdb444184b30b6b23b54d73\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;b488dee8afdb444184b30b6b23b54d73</a>", "author": "sucharithan", "timestamp": "2026-02-25T12:59:26+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["naming_terminology", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:22.404120+00:00", "processed": false}
{"id": "hn_comment_47150892", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47150892", "title": "Re: Gh-PR-reviews Fetch GitHub PR reviews as compact M...", "text": "I built a GitHub CLI extension that fetches PR reviews, inline comments, and conversation threads, and outputs them as compact markdown optimized for LLM context windows.\nThe problem: I wanted to pipe PR review feedback into AI coding agents, but the GitHub REST API doesn&#x27;t expose thread resolution status, and the raw data is verbose. Copy-pasting from the UI wastes tokens and loses structure.\ngh-pr-reviews uses the GraphQL API to get everything in one paginated query -- reviews, inline comment threads (with resolved&#x2F;unresolved status), and conversation comments -- then formats it as minimal markdown: file:line notation, inline state brackets, no fluff.\ngh pr-reviews --reviewer copilot-pull-request-reviewer --last 1 owner&#x2F;repo 42\nExample output:\n## @alice [CHANGES_REQUESTED] 2024-01-15\nPlease fix the error handling.\n- file1.go:42 \u2014 Rename this variable to be more descriptive\n- pkg&#x2F;api.go:10-15 \u2014 This function needs error handling\nInstall: gh extension install Nittarab&#x2F;gh-pr-reviews\nIt also ships as an agent skill for Claude Code &#x2F; OpenCode so your coding agent can fetch reviews autonomously.<p>npx skills add Nittarab&#x2F;gh-pr-reviews@skills", "author": "Nittarab", "timestamp": "2026-02-25T12:55:31+00:00", "score": null, "num_comments": null, "products": ["claude", "copilot"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-25T17:51:22.676701+00:00", "processed": false}
