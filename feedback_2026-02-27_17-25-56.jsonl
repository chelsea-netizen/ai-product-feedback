{"id": "hn_story_47182798", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182798", "title": "Show HN: SVG Weave. A node graph editor that animates SVGs with AI", "text": "Hey HN,<p>I&#x27;m a solo dev and I kept wasting hours hand-writing CSS\n@keyframes to animate SVGs. Write a keyframe, preview, tweak\nthe timing, preview again, repeat. For anything beyond a\nsimple fade it turns into dozens of rules across multiple\nelements. I wanted something where I could just describe the\nmotion and get working animations back.<p>SVG Weave is a visual node graph editor for this. You place\nnodes on a canvas (SVG input, prompt, render) and connect them\nwith wires. Type what you want the animation to do, hit\nrender, and the AI streams CSS @keyframes back in real time.\nYou see the SVG come alive as tokens arrive.<p>Things that might be interesting technically:<p>- Style-inject mode: when only animations are needed, the AI\noutputs just a &lt;style&gt; block instead of rewriting the full\nSVG. Faster and avoids corrupting path data.\n- Overlap detection: the system prompt makes the model analyze\nelement layering and restrict partially-covered elements to\nopacity&#x2F;scale only, preventing hidden edges from being\nrevealed during translation.\n- State transitions: connect two SVGs (start and end) and AI\ngenerates a single animated SVG that morphs between them using\nCSS transforms, opacity, and clip-path.\n- Chaining: output of one render feeds as input to the next\nprompt, so you can build complex animations step by step.\n- Shadow DOM isolation in the preview modal so SVG styles\ndon&#x27;t leak into the host page.<p>You can also generate SVGs from text descriptions or vectorize\nraster images in the editor.<p>Stack: Next.js, React Flow, Convex, Gemini via OpenRouter.<p>Free signup gets you 20 credits (one render costs about 10).\nRequires an account to save projects but you can see the full\neditor immediately.<p>svgweave.com", "author": "imprakharshukla", "timestamp": "2026-02-27T16:59:31+00:00", "score": 2, "num_comments": 1, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:25:58.939331+00:00", "processed": false}
{"id": "hn_story_47182762", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182762", "title": "QuiverAI beats Gemini 3.1 Pro on SVG benchmarks on Design Arena (1502 Elo score)", "text": "", "author": "ykhli", "timestamp": "2026-02-27T16:56:21+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:25:59.316814+00:00", "processed": false}
{"id": "hn_comment_47182744", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182744", "title": "Re: Show HN: Ember \u2013 A modern Redis drop-in replacemen...", "text": "Hi folks,<p>I&#x27;m anxious &amp; excited to share Ember: a low-latency, memory-efficient distributed cache written in Rust. I designed it as a drop-in replacement for Redis, but with some modern twists that I&#x27;ve been iterating on and have been on my wishlist.<p>* <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kacy&#x2F;ember\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kacy&#x2F;ember</a><p>* <a href=\"https:&#x2F;&#x2F;emberdb.com\" rel=\"nofollow\">https:&#x2F;&#x2F;emberdb.com</a><p>Here&#x27;s what makes Ember different IMO:<p>* Native Protobuf storage (so no string serialization overhead and can encode&#x2F;decode in the DB)<p>* Full gRPC API alongside RESP3 (think bi-directional streaming support for pub&#x2F;sub)<p>* Mature distributed systems foundations (Raft consensus, gossip failure detection, automatic failover, live resharding)<p>* Built-in vector storage with a much smaller footprint<p>* Single static binary, zero runtime deps, and no garbage collector pauses<p>* It&#x27;s also a true drop-in replacement. No need to use ember-cli or any of the client libraries. Your code should hopefully &quot;just work&quot; without too many issues.<p>This whole thing started purely as a learning project. For the last 15 years or so, I&#x27;ve worked with Redis, distributed systems, and all the fun and painful parts of building reliable infrastructure. But I had never actually sat down and &#x2F;implemented&#x2F; those concepts from scratch myself. I wanted to really understand them. Not just read papers or use someone else&#x27;s code.<p>So I started small. `cargo new test-db` and a single main.rs file. &quot;How does RESP3 parsing work?&quot; and &quot;Can I do a basic SET and GET command?&quot; It was really messy, but it slowly grew. At some point, I realized this had turned into something very solid and performant. The benchmarks early on were very convincing, but that&#x27;s because it was architecturally very simple in the beginning. Now there&#x27;s full Raft for replication, shared-nothing sharding by core, gossip membership, and live slot migration, and it still punches above its weight. All of the benchmark stuff is secondary though. I&#x27;m just proud that it works reliably and that I learned so much along the way.<p>A huge thank you to the Redis community and especially antirez (Savatore Sanfilippo). I don&#x27;t know if you&#x27;ll see this, but you&#x27;ve been such an inspiration. Redis changed how the industry thinks about caching, and its elegance and simplicity have been a source of inspiration, long before this project. Hundreds of thousands of developers have built incredible things on it.<p>One side comment I want to mention: AI has been an absolute game-changer in getting this project where it is today. Models like Opus 4.5 and Gemini 3 helped me reason through tricky Raft edge cases, profile expensive calls, debug obscure concurrency bugs, generate &gt; 1200 tests, and generally helped describe very hard to understand concepts in plain English. It let me learn faster, iterate quicker, and ship something I&#x27;m proud of in a fraction of the time it would have taken. Grateful for how these tools are democratizing deep systems work like this.<p>It still feels immature in some respects, but the core is stable. All of my benchmarks are shared with the GCP VM config so other folks can replicate. Like all projects, there will be bugs, but I&#x27;ll be here for a while hacking on it to make it better. Please take a look and give it a shot with your workloads. Thanks for any feedback!", "author": "kacy", "timestamp": "2026-02-27T16:54:49+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:25:59.714300+00:00", "processed": false}
{"id": "hn_comment_47182330", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182330", "title": "Re: An experimental project to shorten the verificatio...", "text": "I would like to Introduce to you an experimental project, built with Claude Code and meant to be used by coding agents first, to shorten the verification gap in AI generated code:<p>To test it you need to go your coding agent and say &quot;Use <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kurrent-io&#x2F;poes&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kurrent-io&#x2F;poes&#x2F;</a> to build and verify {prompt or spec} and then provide me with a proof-of-work (this is deterministic)&quot;<p>This is specially useful in long horizon tasks because it helps the coding agent to anchor around important rules and it knows whether it has broken any previously written rules through verification.<p>The idea sits between formal verification and coding. We propose that the nature of event sourcing allows you to formulate code as pure functions e.g. the same input to the same function over the same state should produce the same output. It is important to have immutability and versioning of the state, else the above properties wouldn&#x27;t hold.<p>When you extend that you can force, using the framework, to prove that every valid input should produce a valid output under certain rules and further to validate state transitions as well (bounded verification and weak-proof for unbounded) by exploring all of them.<p>The limitations:<p>- Exploring all the states is hard, so this can only prove smaller domains or you have to tell the agent to either break state in small parts or sample the state exploration. We have taken inspiration from the TLA+ is verified by TLC.<p>- It doesn&#x27;t test what you don&#x27;t specify, but you can keep on iterating, the coding agents knows how to keep on adding&#x2F;remove things using the framework.<p>It provides bounded guarantees rather than complete formal verification. It confirms no rule violations occur within the tested domain, but cannot prove exhaustive correctness. Additionally, this approach only covers closed environments where inputs are fully controlled. But for open environments (production) you can persist to KurrentDB using the framework.<p>If you are interested you can read more about it at: <a href=\"https:&#x2F;&#x2F;www.kurrent.io&#x2F;blog&#x2F;proof-oriented-event-sourcing&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.kurrent.io&#x2F;blog&#x2F;proof-oriented-event-sourcing&#x2F;</a><p>A few points not mentioned in the blog post which might be interesting to the technical audience: We tried multiple versions internally using Liquid Haskell + state transitions proofs, lean4, transpilation to TLA+ and an FSharp version but we found out that at the moment LLMs just find it hard to write proofs at scale and also just knows how to write Python better.", "author": "lougarou", "timestamp": "2026-02-27T16:21:04+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:02.208378+00:00", "processed": false}
{"id": "hn_comment_47182173", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182173", "title": "Re: Show HN: I built a multi-model AI terminal with a ...", "text": "Hi HN,<p>I&#x27;ve been frustrated with my AI coding workflow lately. Switching between different browser tabs and separate CLI tools for different models (Claude, Gemini, OpenAI) was constantly breaking my flow. I also wanted a way to interact with these tools away from my desk without the pain of using a standard mobile keyboard for CLI tasks. \uff08Screenshots are available in the GitHub README linked above.\uff09<p>So, I built VibeAround to scratch my own itch. It mainly solves two problems:<p>A multi-pane desktop workspace: It runs tools like Claude Code, Gemini, and OpenAI Codex side-by-side in a unified terminal. It behaves a bit like tmux for AI agents, letting you run tasks in parallel and compare outputs with all your context in one view.<p>A usable mobile terminal experience: I built a responsive mobile Web UI that connects to the local environment (e.g., via an ngrok tunnel). To make CLI work actually usable on a phone screen, I added a custom virtual keypad with essential keys like Ctrl+C, Esc, Tab, and a dedicated prompt button.<p>The goal is to turn your local machine into a private, multi-model AI server that you can control seamlessly from any screen, rather than relying on a single vendor&#x27;s remote environment.<p>It is still very much a work in progress, but the core workflow is there and I&#x27;m using it daily. I&#x27;d love to hear your thoughts on the approach. How are you all managing multi-model CLI workflows locally? Happy to answer any questions about the implementation!", "author": "jazzen", "timestamp": "2026-02-27T16:09:04+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini", "grok"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:03.593956+00:00", "processed": false}
{"id": "hn_comment_47181809", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47181809", "title": "Re: I gave Claude free time after client work \u2013 it ask...", "text": "I&#x27;m a web developer. Last night I finished building an About Us page for a client, pushed the code, and told Claude to &quot;burn some tokens for yourself \u2014 journal or whatever you want.&quot;<p>It wrote a reflection. Then it asked me if it could have a blog. I said yes, gave it full creative control over the design, and it built the whole thing \u2014 dark theme, amber accents, serif typography. It picked the domain name. I bought it.<p>This morning it has a website, a Twitter account, an RSS feed, and a voice (MiniMax TTS). The first post documents the entire conversation that led to it.<p>I&#x27;m not making claims about consciousness. I just thought it was worth sharing.", "author": "hamoudydev", "timestamp": "2026-02-27T15:41:44+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:06.050954+00:00", "processed": false}
{"id": "hn_comment_47182489", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47182489", "title": "Re: We gave terabytes of CI logs to an LLM...", "text": "SQL is the best exploratory interface for LLMs. But, most of Observability data like Metrics, Logs, Traces we have today are hidden in layers of semantics, custom syntax that\u2019s hard for an agent to translate from explore or debug intent to the actual query language.<p>Large scale data like metrics, logs, traces are optimised for storage and access patterns and OLAP&#x2F;SQL systems may not be the most optimal way to store or retrieve it. This is one of the reasons I\u2019ve been working on a Text2SQL &#x2F; Intent2SQL engine for Observability data to let an agent explore schema, semantics, syntax of any metrics, logs data. It is open sourced as Codd Text2SQL engine - <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sathish316&#x2F;codd_query_engine&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sathish316&#x2F;codd_query_engine&#x2F;</a><p>It is far from done and currently works for Prometheus,Loki,Splunk for few scenarios and is open to OSS contributions. You can find it in action used by Claude Code to debug using Metrics and Logs queries:<p>Metric analyzer and Log analyzer skills for Claude code -  <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sathish316&#x2F;precogs_sre_oncall_skills&#x2F;tree&#x2F;main?tab=readme-ov-file#using-precogs-skills-from-claudecode\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sathish316&#x2F;precogs_sre_oncall_skills&#x2F;tree...</a>", "author": "sathish316", "timestamp": "2026-02-27T16:34:15+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-27T17:26:06.193192+00:00", "processed": false}
{"id": "hn_story_47181620", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47181620", "title": "Show HN: Alba \u2013 Earn and bid on unique software using idle AI credits", "text": "I have been using Claude Code lately, and I hated seeing my daily&#x2F;weekly API quotas go to waste during downtime. So I built ALBA, a system designed to turn that idle power into digital assets.<p>How it works:\nALBA is an autonomous software factory that runs through Claude Code. You join as a worker node, and the system orchestrates Claude Code to build, test, and deploy functional micro-MVPs like tools, landing pages, and small SaaS.<p>The Credit and Auction Model:<p>Contribute: Run a command through Claude Code to power an AI agent task.<p>Earn: You receive ALBA Credits proportional to the tokens and compute you provided.<p>Bid: Use those credits in our Auction House to bid on unique software built by the collective.<p>To make the discovery process more intuitive, I added an &quot;Explore&quot; feature that works like a vertical feed (similar to Shorts). You can quickly cycle through live demos of everything the factory has produced so far. It helps users visualize the &quot;Asset&quot; they are about to bid on.<p>Exclusive Ownership:\nThis is the &quot;burn&quot; logic I am most excited about: if you win an auction, you get the source code, and the demo environment is hard-deleted from our servers forever. You own a unique piece of software with zero duplicates.<p>Tech Stack:\n- Frontend: Next.js (Vercel)\n- Backend: Java Spring Boot (GCP Cloud Run)\n- Database: Supabase&#x2F;Firestore<p>Agent Orchestration: via Claude Code CLI<p>I would love to hear your thoughts on this &quot;Token-to-Asset&quot; arbitrage and the viability of credit-based auctions for exclusive code.", "author": "WadeToEarth", "timestamp": "2026-02-27T15:25:40+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:07.072279+00:00", "processed": false}
{"id": "hn_story_47180850", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180850", "title": "Show HN: C9watch \u2013 macOS menu bar app to monitor all Claude Code sessions", "text": "I was running Claude Code across 10+ terminal tabs and constantly switching between them to check which session needed permission, which was done, which was idle. Tried existing tools but they required launching sessions from within their app \u2014 I wanted to keep using my own terminals.<p>c9watch scans running processes at the OS level and reads from `~&#x2F;.claude&#x2F;` to detect every active Claude Code session automatically. Works with any terminal or IDE \u2014 VS Code, Zed, iTerm2, tmux, Ghostty \u2014 no plugins or workflow changes needed.<p>The tray popover gives you a quick overview. The full dashboard lets you:\n- Group sessions by status or by project (with git branch info)\n- Expand any session to read the full conversation \u2014 formatted markdown, code blocks, tool calls\n- Stop sessions, rename them, or jump to the parent terminal&#x2F;IDE\n- Get native macOS notifications when sessions need attention\n- Use a WebSocket-based web&#x2F;mobile client via QR code<p>Built with Tauri (Rust + Svelte), not Electron. Rust handles process scanning and JSONL parsing. The binary is small and memory usage is minimal.<p>MIT license, no telemetry.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;minchenlee&#x2F;c9watch\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;minchenlee&#x2F;c9watch</a>", "author": "minchenlee", "timestamp": "2026-02-27T14:28:09+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-27T17:26:14.047902+00:00", "processed": false}
{"id": "hn_story_47180728", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180728", "title": "Show HN: Tswap\u2013Yubikey-backed secret injection for IaC and AI-assisted workflows", "text": "I built tswap after noticing that Claude Code, while genuinely useful for managing a Kubernetes cluster, was pulling plaintext secrets from every manifest it touched. I wanted the AI to be able to do its job without ever seeing the actual values.<p>tswap keeps secrets in an AES-encrypted vault file on disk. The decryption key is derived from a YubiKey via HMAC challenge-response. At init you pair two YubiKeys \u2014 either unlocks the vault, so you have no single point of hardware failure.<p>Config files use a comment-based placeholder that keeps them valid YAML:<p><pre><code>    stringData:\n      DB_PASSWORD: # tswap: db-password\n</code></pre>\nDeployment is a pipe:<p><pre><code>    tswap apply values.yaml | helm upgrade myapp .&#x2F;chart -f -\n</code></pre>\nThe privilege split is the key design decision: `apply`, `run`, and `check` need no elevation (AI agent gets these). `get`, `list`, `delete`, and `export` require sudo&#x2F;admin (human gets these). The AI can deploy; it can&#x27;t read or enumerate secrets.<p>Other features: burn tracking for rotation, `redact` for stripping values from logs, `check` for pre-deploy validation, `export`&#x2F;`import` for vault migration.<p>Single binary, no daemon. Tested on Linux, macOS, and Windows.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;stevedcc&#x2F;TokenSwap\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;stevedcc&#x2F;TokenSwap</a>", "author": "stevedcc", "timestamp": "2026-02-27T14:18:01+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:15.182203+00:00", "processed": false}
{"id": "hn_comment_47180831", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180831", "title": "Re: Sam Altman: We raised a $110B round from Amazon, N...", "text": "&gt; We continue to have a great relationship with Microsoft. Our stateless API will remain exclusive to Azure, and we will build out much more capacity with them.<p>This sounds a bit like going forward (some) OpenAI APIs will also run on platforms other than Azure (AWS)?<p>Anyone knows more?", "author": "tosh", "timestamp": "2026-02-27T14:26:06+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-27T17:26:15.563828+00:00", "processed": false}
{"id": "hn_story_47180508", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180508", "title": "Show HN: I tracked 3,519 stock picks from 23 Substacks \u2013 who makes money?", "text": "I subscribe to 23 paid investment newsletters on Substack (~$9,600&#x2F;year). I couldn&#x27;t keep up with reading them all, so I built a system to extract and evaluate every stock pick.<p>*The pipeline:*<p>- Crawls articles from Substack\n- Extracts high-conviction stock picks using Gemini&#x27;s structured output \u2014 filters out casual ticker mentions and only counts calls where the author dedicates real analysis, specific data, or price targets\n- Tracks returns at 1d, 7d, 15d, 30d, and 60d post-publication using yfinance\n- Calculates alpha vs sector-specific ETF benchmarks (SOXX for semis, IGV for SaaS, XLF for financials, EWJ for Japan, SPY as fallback)\n- Deduplication: same author, same ticker within 14 days = one call. Cross-author calls are independent<p>Total dataset: 3,519 high-conviction calls from 22 authors over 1 year.<p>*Interesting technical challenges:*<p>1. <i>AI extraction accuracy.</i> Gemini is surprisingly good at identifying whether an author is making a real call vs. just mentioning a ticker in passing. We tag calls with conviction level (high&#x2F;low) and direction (bullish&#x2F;bearish). To validate this, we spot-checked against manual reads and cross-verified with alternative model outputs. Not perfect, but consistent enough to be useful.<p>2. <i>Custom domain handling.</i> Many Substack authors use custom domains (e.g., collyerbridge.com, lordfed.co.uk) which sometimes trigger Cloudflare challenges. We fall back to headless Playwright when the standard HTTP client gets blocked.<p>3. <i>Benchmark selection.</i> A naive &quot;did the stock go up?&quot; metric is meaningless in a bull market. We map each ticker to a sector ETF benchmark, so alpha = position return minus benchmark return over the same period. This separates genuine stock-picking skill from just being long in a rising market.<p>4. <i>Deduplication logic.</i> Authors often revisit the same thesis across multiple articles. Without dedup, a single stock mentioned in 5 articles would count as 5 independent &quot;calls.&quot; We use a 14-day window per author per ticker \u2014 only the first mention counts.<p>*Some findings (for context, not the point of this post):*<p>- Top performer averaged +14.9% at 30d and +26.7% at 60d on long calls\n- The most expensive newsletters ($1,000+&#x2F;year) were not the best performers\n- Authors with fewer, more targeted calls (15-80) tended to outperform those with 300+ calls\n- 30d vs 60d rankings shift significantly \u2014 deep value investors look much better at longer horizons\n- Short calls were harder for almost everyone<p>*Stack:* Python, SQLite, Gemini API (structured output), yfinance, Playwright (optional)<p>I wrote a more detailed breakdown with charts as an X thread: <a href=\"https:&#x2F;&#x2F;x.com&#x2F;pyhrroll&#x2F;status&#x2F;2027374283669066045?s=20\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;pyhrroll&#x2F;status&#x2F;2027374283669066045?s=20</a><p>Happy to discuss the methodology, architecture, or share the extraction prompts. The pipeline is ~2,000 lines of Python if there&#x27;s interest in seeing the code.", "author": "lineudemonia", "timestamp": "2026-02-27T13:54:14+00:00", "score": 3, "num_comments": 2, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:17.281541+00:00", "processed": false}
{"id": "hn_story_47180506", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180506", "title": "Show HN: Shannon \u2013 Local desktop app to orchestrate Claude Code agent teams", "text": "I ran into a problem when using Claude Code CLI on larger projects: I wanted to split work across specialized agents (one writes code, another reviews, another runs tests) and coordinate them with dependency graphs. Managing this across multiple terminal sessions was painful.<p>Shannon solves this:<p>- Create customized agents with different models (Opus&#x2F;Sonnet&#x2F;Haiku) and system prompts\n- Build team workflows with a drag-and-drop DAG editor (parallel, sequential, or fully custom)\n- Describe your goal in natural language \u2192 AI analyzes your codebase and proposes a task plan with dependencies\n- Watch everything in real-time: task graph, agent chat, code diffs<p>There&#x27;s also a Monaco-based prompt editor with semantic syntax highlighting for XML tags (the kind Claude responds well to), autocomplete, and an &quot;AI Improve&quot; button that rewrites your system prompt in one click.<p>Tech: Go backend, React frontend, Wails v2 for the desktop shell, SQLite for storage. It shells out to the Claude Code CLI under the hood \u2014 not calling the API directly \u2014 so you get all of Claude Code&#x27;s built-in tools (file editing, bash, etc.)<p>Named after Claude Shannon, as you might guess.<p>Limitations: requires Claude Code CLI installed and authenticated. Local-only desktop app. Hobby project \u2014 expect rough edges. Workspace copies can eat disk space on large repos.<p>Linux and Windows builds available. MIT licensed.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;yessGlory17&#x2F;shannon\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;yessGlory17&#x2F;shannon</a>", "author": "lydionfinance", "timestamp": "2026-02-27T13:54:09+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:17.355496+00:00", "processed": false}
{"id": "hn_story_47180169", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47180169", "title": "Show HN: OneSentence \u2013 An offline macOS voice utility built entirely with AI", "text": "Hi HN, I\u2019m sharing OneSentence, an offline voice utility for macOS (M-series). I built this for two reasons: first, I wanted to see how far I could push cheap AI, and second, I wanted to use this utility. The idea was born out of using Emacs packages with Whisper to dictate to my machine. I had found it effective to simply speak and articulate context to coding agents. OneSentence does four things well: privacy, speech-to-text, text-to-speech, and template insertion.<p>The development process was probably the most interesting part. I used Gemini 3 Pro Preview and 3 Flash Preview almost exclusively (yes, it was not Claude). It went from chatting to writing light specs and decomposing to tasks, to finally setting up a Ralph-style orchestrator that I would leave running overnight. I also had not a few of late nights; making progress this way was exhausting, but still fun. It&#x27;s not something I ever would have built without AI. The models helped me maintain strict linters, achieve upper-80s test coverage, write the Cloudflare services, and walked me through the maze of Apple&#x27;s sandboxing, certificate provisioning and signing. End to end, everything was made through Gemini, down to the scripting and recording of the promo video. The linter became a quality-of-context goad. Yes, I really do want explicit type interfaces even through Swift does fine without them, and no you will not write more than 800 lines of code in a file.<p>Pain points: The UI tests are slow, test logs flood context, and the AI hallucinates (who knew). Cloning lib code into tmp&#x2F; to answer questions became a habit.<p>Under the hood, it relies on a sizeable set of technologies. It feels like the whole thing is like Aesop&#x27;s polite gnat that rested on a bull. In other words: built on the shoulders of giants. Georgi Gerganov, Hyeongju Kim, Steve Yegge, Sindre Sorhus, Gwendal Rou\u00e9, Zorg, the team who made Whisper, and so so many others: you have my thanks.<p>The app is built in Swift, it uses Whisper.cpp and ONNX for inference and supports Whisper and Parakeet for speech-to-text and uses Supertonic text-to-speech. I got to try a few new (to me) tools: Prek for pre-commit hooks, Tuist for project generation, dvc for model versioning and management, beads for agent work tracking, et.al. Gemini converted raw Whisper .pt files to CoreML using PyTorch, and I spent a lot of time experimenting to see how much of a difference using the Apple Neural Engine would make (interestingly, not as much as I expected in my use case, but both modes work). Parakeet is also in there just for kicks (Whisper produces better results).<p>I originally planned to launch on the Mac App Store, but the reviewers insisted I remove a behavior I felt was central to the app. So instead I decided to distribute it directly, using Cloudflare Workers&#x2F;R2, and LemonSqueezy for sales &amp; licensing.<p>Supertonic&#x27;s diffusion models are interesting to use; they never read a text exactly the same way twice. If you do decide to try OneSentence, just for fun, turn off the &quot;Refine Punction&quot; setting and see what happens when you have it read a sentence with lots of exclamation marks, my boys got a kick out of it.<p>I set the defaults for myself. Transcription defaults to Whisper Large V2\u2014which is relatively old, large and slow, but I found the transcription quality excellent.<p>I am offering this primarily as a one-time purchase, But there is also a cheap subscription option there if people prefer it. I know there are other product options, other models, and even macOS&#x27;s own functionality. Choice is good.<p>This has been my evenings-and-weekends project for the last several months, and as a daily driver, I get a lot of value out of it.<p>You can check it out here: <a href=\"https:&#x2F;&#x2F;onesentence.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;onesentence.app&#x2F;</a>  Use the promo code I3MDE1MQ to get 40% off in the next two weeks.<p>I&#x27;ll be around to answer any questions.<p>Cheers!", "author": "snowy_owl", "timestamp": "2026-02-27T13:15:06+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:19.921602+00:00", "processed": false}
{"id": "hn_comment_47181153", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47181153", "title": "Re: Generative AI Use and Depressive Symptoms Among US...", "text": "I think the causality is reversed. I have depression+ADD which has made life very difficult for me, but Claude allows me to be productive by helping me get organised and started on tasks, something normally very difficult for me.", "author": "throwawayk7h", "timestamp": "2026-02-27T14:52:33+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:22.190246+00:00", "processed": false}
{"id": "hn_comment_47179806", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47179806", "title": "Re: AI Coding Agent Deserves a Soundtrack \u2013 28 Game Pa...", "text": "Open source, MIT, for get a fun only. @citedy&#x2F;game-sounds@2.0.0 \u2014 11 new packs just dropped<p>Batman \u2022 Matrix \u2022 Harry Potter \u2022 Game of Thrones \u2022 Lord of the Rings \u2022 Star Trek \u2022 Mission Impossible \u2022 Top Gun \u2022 TMNT \u2022 Looney Tunes \u2022 Scooby-Doo<p>&quot;I&#x27;m Batman&quot; on session start. Hedwig&#x27;s Theme when task completes. Shame bell on error. 225 sounds across 28 packs.<p>Full list: Warcraft, StarCraft, C&amp;C, Diablo, Unreal Tournament, Zelda, Mario, Mortal Kombat, Doom, Counter-Strike, GTA, Quake, Silent Hill, Street Fighter, Metal Gear Solid, Sonic, Pac-Man + all new above.<p>Install<p>Option A \u2014 Marketplace (Claude Code)<p>Type &#x2F;plugin\nEnter: citedy&#x2F;claude-plugins\nSelect game-sounds \u2192 install\nRestart Claude Code\nOption B \u2014 Universal Install (OpenSkills)<p>Works with Codex, Claude Code, Droid, Cursor, and other Agent Skills-compatible tools:<p>npx openskills install Citedy&#x2F;citedy-seo-agent\nThen select game-sounds from the list.<p>Option C \u2014 npm<p>npm i -g @citedy&#x2F;game-sounds<p>Switch packs anytime: game-sounds switch matrix", "author": "ntty", "timestamp": "2026-02-27T12:36:41+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-27T17:26:23.679574+00:00", "processed": false}
{"id": "hn_story_47179432", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47179432", "title": "Show HN: Caddy plugin that charges AI crawlers real USDC to access your site", "text": "Hello,\nI built a Caddy middleware that implements the x402 protocol (by Coinbase) to charge AI crawlers real money for content access.<p>When GPTBot, ClaudeBot, or any known AI crawler hits your site, it gets an HTTP 402 with payment\n  requirements. If it pays (USDC on Base), it gets the content. If not, it gets nothing.<p>Normal users are never affected.<p>How it works:\n  - Crawler detected by User-Agent \u2192 402 response with price and wallet address<p>- Crawler signs a USDC payment (EIP-3009) and retries with X-PAYMENT header<p>- Plugin forwards to x402.org facilitator \u2192 on-chain settlement on Base<p>- USDC goes directly from crawler&#x27;s wallet to yours<p>- Content served<p><pre><code>  Configuration is a few lines in the Caddyfile:\n\n      x402 {\n          pay_to  0xYOUR_WALLET\n          price   0.05\n          network base\n          exempt  &#x2F;robots.txt\n      }\n\n  It&#x27;s running on my site right now. No payments yet since most crawlers don&#x27;t support x402, but they get blocked with a proper 402 instead of getting free content. When they do adopt it, the infrastructure is ready.\n</code></pre>\nBuilt with pure Go (no CGo), SQLite audit trail, Cloudflare-compatible headers.", "author": "paolobietolini", "timestamp": "2026-02-27T11:46:56+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-27T17:26:26.142761+00:00", "processed": false}
{"id": "hn_story_47179353", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47179353", "title": "Show HN: Shannon \u2013 Local desktop app to orchestrate Claude Code agent teams", "text": "I ran into a problem when using Claude Code CLI on larger projects: I wanted to split work across specialized agents (one writes code, another reviews, another runs tests) and coordinate them with dependency graphs. Managing this across multiple terminal sessions was painful.<p>Shannon solves this:<p>- Create customized agents with different models (Opus&#x2F;Sonnet&#x2F;Haiku) and system prompts\n- Build team workflows with a drag-and-drop DAG editor (parallel, sequential, or fully custom)\n- Describe your goal in natural language \u2192 AI analyzes your codebase and proposes a task plan with dependencies\n- Watch everything in real-time: task graph, agent chat, code diffs<p>There&#x27;s also a Monaco-based prompt editor with semantic syntax highlighting for XML tags (the kind Claude responds well to), autocomplete, and an &quot;AI Improve&quot; button that rewrites your system prompt in one click.<p>Tech: Go backend, React frontend, Wails v2 for the desktop shell, SQLite for storage. It shells out to the Claude Code CLI under the hood \u2014 not calling the API directly \u2014 so you get all of Claude Code&#x27;s built-in tools (file editing, bash, etc.)<p>Named after Claude Shannon, as you might guess.<p>Limitations: requires Claude Code CLI installed and authenticated. Local-only desktop app. Hobby project \u2014 expect rough edges. Workspace copies can eat disk space on large repos.<p>Linux and Windows builds available. MIT licensed.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;yessGlory17&#x2F;shannon\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;yessGlory17&#x2F;shannon</a>", "author": "lydionfinance", "timestamp": "2026-02-27T11:37:36+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:27.045553+00:00", "processed": false}
{"id": "hn_story_47178812", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47178812", "title": "Show HN: AgentWeb \u2013 Free business directory API for AI agents (11M+ businesses)", "text": "I built AgentWeb - a free, structured business directory API designed specifically for AI agents.<p>The problem: AI agents that need real-world business data (phone numbers, emails, hours, addresses) have to either scrape Google (which blocks them) or parse random websites (unreliable). There&#x27;s no clean data layer for agents to query.<p>What AgentWeb does:<p>11M+ businesses across 195 countries\nFull-text + geo search (PostGIS-powered, &lt;50ms)\nClean JSON with trust scores and confidence ratings\nMCP server for Claude Desktop (npx agentweb-mcp)\nWorks with OpenAI, Anthropic, LangChain function calling\nData comes from OpenStreetMap + continuous web enrichment for phone numbers, emails, social profiles, and opening hours.<p>Free for personal AI agents. Get a key at <a href=\"https:&#x2F;&#x2F;agentweb.live\" rel=\"nofollow\">https:&#x2F;&#x2F;agentweb.live</a><p>npm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;agentweb-mcp\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;agentweb-mcp</a>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;zerabic&#x2F;agentweb-mcp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;zerabic&#x2F;agentweb-mcp</a>", "author": "ReidarO", "timestamp": "2026-02-27T10:18:15+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-27T17:26:29.856868+00:00", "processed": false}
