{"id": "hn_story_47112491", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47112491", "title": "Should I add this acknowledgement/shoutout by xAI/Grok to my resume?", "text": "I spotted a usability gap on X (formerly Twitter)\u2014no way to categorize bookmarks by topic.<p>Suggested it publicly, and months later, they rolled it out with a shoutout from Grok.<p>Resume impact? \nWorth adding under &#x27;Product Contributions&#x27; (e.g., &#x27;Suggested bookmark categorization feature, adopted by X&#x27;)? \nOverkill, useless, or a solid signal for PM&#x2F;UX opportunities?", "author": "aehsan4004", "timestamp": "2026-02-22T16:45:07+00:00", "score": 2, "num_comments": 0, "products": ["grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:10.529996+00:00", "processed": false}
{"id": "hn_comment_47111980", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111980", "title": "Re: The Dev-Room Dashboard(iam a 12 years old coder)...", "text": "Project Title: The Ultimate Dev-Room Dashboard\nTagline: A personalized, all-in-one productivity hub for developers and students.<p>Long Description\nThe Problem: Most developers have too many tabs open\u2014one for music, one for their schedule, one for tools, and one for entertainment. Switching back and forth kills focus so i created a small website with the use of ai.<p>The Solution: I built &quot;My Room&quot;\u2014a centralized, browser-based command center. Instead of hunting through bookmarks, this dashboard puts everything a user needs in one beautiful, responsive interface. It combines utility, organization, and entertainment into a single &quot;Home Base.&quot;<p>Key Features\nDynamic Music Station: A built-in, customizable playlist manager that allows users to add and manage their own tracks for deep-work sessions.<p>Integrated Timetable System: A clear, structured weekly schedule tracker (Monday\u2013Friday) designed to keep students and developers on task.<p>Quick-Access Command Bar: One-click shortcuts to essential tools like Gemini AI, creative resources like FontSpace, and relaxation platforms like YouTube or Cryzen.<p>Personalized UX: A dark-themed, minimalist aesthetic designed to reduce eye strain during long coding or study sessions.<p>Tech Stack\nFrontend: HTML5, CSS3 (Custom Grid&#x2F;Flexbox layouts).<p>Logic: JavaScript for the dynamic playlist functionality and UI interactivity.<p>Deployment: Hosted via GitHub Pages for high availability.<p>&quot;CAN I PLEASE REQUEST A RATING FOR MY PROJECT? I AM A 12-YEAR-OLD CODER!&quot;", "author": "kabishanan", "timestamp": "2026-02-22T15:52:49+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:13.546117+00:00", "processed": false}
{"id": "hn_story_47111800", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111800", "title": "Show HN: Semantic search over Hacker News, built on pgvector", "text": "I built <a href=\"https:&#x2F;&#x2F;ask.rivestack.io\" rel=\"nofollow\">https:&#x2F;&#x2F;ask.rivestack.io</a> \u2014 a semantic search engine over Hacker News posts. Instead of keyword matching, it finds results by meaning, so you can search things like &quot;best way to handle authentication in microservices&quot; and get relevant threads even if they don&#x27;t contain those exact words.\nHow it works:<p>Indexed HN posts and comments into PostgreSQL with pgvector (HNSW index)\nEmbeddings generated with OpenAI&#x27;s embedding model\nQueries run as nearest-neighbor vector searches \u2014 typical response under 50ms\nThe whole thing runs on a single Postgres instance, no separate vector DB<p>I built this partly because I wanted a better way to search HN, and partly to dogfood my own project \u2014 Rivestack (<a href=\"https:&#x2F;&#x2F;rivestack.io\" rel=\"nofollow\">https:&#x2F;&#x2F;rivestack.io</a>), a managed PostgreSQL service with pgvector baked in. I wanted to see how pgvector holds up with a real dataset at a reasonable scale.\nA few things I learned along the way:<p>HNSW vs IVFFlat matters a lot at this scale. HNSW gave me much better recall with acceptable index build times.\nStoring embeddings alongside relational data in the same DB simplifies things enormously \u2014 no syncing between a vector store and your main DB.\npgvector has gotten surprisingly fast in recent versions. For most use cases, you really don&#x27;t need a dedicated vector database.<p>The search is free to use. Rivestack has a free tier too if anyone wants to try something similar.\nHappy to answer questions about the architecture, pgvector tuning, or anything else.", "author": "stranger90", "timestamp": "2026-02-22T15:33:10+00:00", "score": 2, "num_comments": 1, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:14.418043+00:00", "processed": false}
{"id": "hn_story_47111607", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111607", "title": "Show HN: OpenGem \u2013 A Load-Balanced Gemini API Proxy (No API Key Required)", "text": "Hi HN! I built OpenGem, an open-source, load-balanced proxy for the Gemini API that requires absolutely no paid API keys.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;arifozgun&#x2F;OpenGem\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;arifozgun&#x2F;OpenGem</a><p>The Context:\nLike many developers, I was constantly hitting &quot;429 Quota Exceeded&quot; errors while building AI agents and processing large payloads on free tiers. I wanted to build freely without calculating API costs for every test request.<p>How it works:\nI reverse-engineered the official Gemini CLI authentication to get standard API access. However, a single free Google account quota depletes quickly. To solve this, I built a Smart Load Balancer at the core of OpenGem.<p>What it does:\n- You connect multiple idle&#x2F;free Google accounts to the dashboard via OAuth.\n- OpenGem acts as a standard endpoint (`POST &#x2F;v1beta&#x2F;models&#x2F;{model}`).\n- It routes traffic to the least-used account. If an account hits a real 429 quota limit, OpenGem instantly detects it, puts that account on a 60-minute cooldown, and seamlessly retries with the next available account. It differentiates between simple RPM bursts and actual limits.<p>Tech specs:\n- Fully compatible with official Google SDKs (`@google&#x2F;genai`), LangChain, and standard SSE streaming (no broken [DONE] chunks).\n- Supports native &quot;tools&quot; (Function Calling) for agentic workflows.\n- Raised payload limit to 50MB for massive contexts.\n- AES-256-GCM encryption for all sensitive configs and OAuth tokens at rest.\n- Toggle between Firebase Firestore or a fully offline Local JSON database.<p>It\u2019s strictly for educational purposes and personal research to bypass the friction of testing&#x2F;prototyping. The entire project is MIT licensed.<p>I\u2019m currently running it with my own side projects and it handles heavy agent tasks flawlessly. I would love any feedback on the load balancing logic, security implementations, or just general thoughts!", "author": "ariozgun", "timestamp": "2026-02-22T15:09:45+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:15.980442+00:00", "processed": false}
{"id": "hn_story_47111171", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111171", "title": "Show HN: Approve Claude Code permission requests from your phone via ntfy", "text": "Claude Code asks for permission before running tools (Bash, Write, Edit, etc.). If you&#x27;re not at your terminal, it just waits. This tool hooks into Claude Code&#x27;s PermissionRequest hook and sends each prompt as a push notification to your phone via ntfy.sh. Tap Approve or Deny, and Claude continues.<p>Setup:<p><pre><code>  npm install -g claude-remote-approver\n  claude-remote-approver setup\n</code></pre>\nThen scan the QR code with the ntfy app on your phone and start a new Claude Code session.<p>How it works: The hook POSTs the permission request to an ntfy topic, then subscribes to a response topic via SSE. When you tap a button on your phone, ntfy delivers the response back. The hook writes {&quot;behavior&quot;:&quot;allow&quot;} or {&quot;behavior&quot;:&quot;deny&quot;} to stdout and exits.<p>The topic name is generated with crypto.randomBytes(16) (128 bits), config file is 0600, and unanswered requests auto-deny after 120 seconds.<p>If you don&#x27;t want requests going through the public ntfy.sh server, you can self-host ntfy and point the config at your own instance.<p>Github: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;yuuichieguchi&#x2F;claude-remote-approver\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;yuuichieguchi&#x2F;claude-remote-approver</a><p>npm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;claude-remote-approver\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;claude-remote-approver</a>", "author": "yuu1ch13", "timestamp": "2026-02-22T14:15:59+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:19.945159+00:00", "processed": false}
{"id": "hn_story_47111048", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111048", "title": "Show HN: Aethene \u2013 Open-source AI memory layer", "text": "Hey HN,<p><pre><code>  I&#x27;m shipping my first open-source project and I&#x27;m pretty nervous about it.\n</code></pre>\nAethene is an AI memory API \u2013 it gives your AI apps persistent memory. Store conversations, extract facts automatically, search semantically, handle contradictions gracefully. It works well thank most of the memory projects available on the market currently.<p>Why I built this:\nI was building AI agents and kept running into the same problem \u2013 they forget everything. Every conversation starts from zero. I wanted something that could:\n  - Auto-extract facts from conversations (not just store raw text)\n  - Handle &quot;user moved from SF to NYC&quot; without keeping both as true\n  - Search by meaning, not just keywords\n  - Version everything (who said what, when)<p><pre><code>  Tech stack:\n  - TypeScript + Hono (fast, edge-ready)\n  - Convex (real-time DB + vector search)\n  - Gemini (embeddings + extraction)\n\n  What it does:\n  # Store memory\n  curl -X POST &#x2F;v1&#x2F;content -d &#x27;{&quot;content&quot;: &quot;User loves hiking, lives in SF&quot;}&#x27;\n\n  # Recall naturally\n  curl -X POST &#x2F;v1&#x2F;recall -d &#x27;{&quot;query&quot;: &quot;outdoor hobbies&quot;}&#x27;\n  # Returns: &quot;User loves hiking&quot; with assembled context\n\n  It handles the boring stuff \u2013 chunking, embeddings, deduplication, contradiction detection, versioning \u2013 so you can focus on your actual product.\n\n  Links:\n  - GitHub: https:&#x2F;&#x2F;github.com&#x2F;akhilponnada&#x2F;aethene\n  - API Docs: OpenAPI spec in repo\n</code></pre>\nThis is my first time launching anything publicly. Would love feedback \u2013 what&#x27;s missing? What would make you actually use this? Roast my code if you want, I can take it.<p>Thanks for reading.", "author": "akhilponnada", "timestamp": "2026-02-22T13:57:46+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2026-02-22T17:17:20.678494+00:00", "processed": false}
{"id": "hn_story_47111045", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111045", "title": "Show HN: OpenBrowser MCP: Give your AI agent a real efficient browser", "text": "Your AI agent is burning 6x more tokens than it needs to just to browse the web.\nWe built OpenBrowser MCP to fix that.\nMost browser MCPs give the LLM dozens of tools: click, scroll, type, extract, navigate. Each call dumps the entire page accessibility tree into the context window. One Wikipedia page? 124K+ tokens. Every. Single. Call.\nOpenBrowser works differently. It exposes one tool. Your agent writes Python code, and OpenBrowser executes it in a persistent runtime with full browser access. The agent controls what comes back. No bloated page dumps. No wasted tokens. Just the data your agent actually asked for.\nThe result? We benchmarked it against Playwright MCP (Microsoft) and Chrome DevTools MCP (Google) across 6 real-world tasks:\n- 3.2x fewer tokens than Playwright MCP\n- 6x fewer tokens than Chrome DevTools MCP\n- 144x smaller response payloads\n- 100% task success rate across all benchmarks\nOne tool. Full browser control. A fraction of the cost.\nIt works with any MCP-compatible client:\n- Cursor\n- VS Code\n- Claude Code (marketplace plugin with MCP + Skills)\n- Codex and OpenCode (community plugins)\n- n8n, Cline, Roo Code, and more\nInstall the plugins here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai&#x2F;tree&#x2F;main&#x2F;plugin\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai&#x2F;tree&#x2F;main&#x2F;pl...</a>\nIt connects to any LLM provider: Claude, GPT 5.2, Gemini, DeepSeek, Groq, Ollama, and more. Fully open source under MIT license.\nOpenBrowser MCP is the foundation for something bigger. We are building a cloud-hosted, general-purpose agentic platform where any AI agent can browse, interact with, and extract data from the web without managing infrastructure. The full platform is coming soon.\nJoin the waitlist at openbrowser.me to get free early access.\nSee the Demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;ov1rSYd42hE?si=pB6QgtQfm-CX1CEa\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;ov1rSYd42hE?si=pB6QgtQfm-CX1CEa</a>\nSee the full benchmark methodology: <a href=\"https:&#x2F;&#x2F;docs.openbrowser.me&#x2F;comparison\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.openbrowser.me&#x2F;comparison</a>\nSee the benchmark code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai&#x2F;tree&#x2F;main&#x2F;benchmarks\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai&#x2F;tree&#x2F;main&#x2F;be...</a>\nBrowse the source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;billy-enrizky&#x2F;openbrowser-ai</a>\nLinkedIn Post:\n<a href=\"https:&#x2F;&#x2F;www.linkedin.com&#x2F;posts&#x2F;enrizky-brillian_opensource-ai-mcp-activity-7431080680710828032-iOtJ?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAACS0akkBL4FaLYECx8k9HbEVr3lt50JrFNU\" rel=\"nofollow\">https:&#x2F;&#x2F;www.linkedin.com&#x2F;posts&#x2F;enrizky-brillian_opensource-a...</a>\n#OpenSource #AI #MCP #BrowserAutomation #AIAgents #DevTools #LLM #GeneralPurposeAI #AgenticAI", "author": "billy-enrizky-1", "timestamp": "2026-02-22T13:57:23+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:20.744709+00:00", "processed": false}
{"id": "hn_comment_47110769", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47110769", "title": "Re: I built a local search CLI for my Claude Code hist...", "text": "Hey everyone,<p>If you use Claude Code, you know the CLI is great until you need to find a conversation from three days ago. The default --resume flag just spits out a flat list of your last 20 sessions. You end up scrolling through truncated titles trying to guess which one was the &quot;postgres connection bug.&quot;<p>I got annoyed enough by this to build ccsearch. It\u2019s a Rust CLI that indexes your Claude Code history into a searchable TUI. You type what you vaguely remember, find the session, hit Enter, and it instantly runs claude --resume &lt;id&gt; to drop you right back into that exact context.<p>I originally tried just using grep&#x2F;FTS, but it failed whenever I couldn&#x27;t remember the exact error code or variable name I used. So I built a simple local hybrid search instead:<p>- SQLite FTS5 (BM25) for exact keyword matches.\n- A local embedding model (all-MiniLM-L6-v2) for semantic concept matching.\n- Reciprocal Rank Fusion (RRF) to merge the results.<p>The whole thing runs 100% locally on your machine. The model is tiny (80MB), and absolutely zero search data gets sent to the cloud.\nIt&#x27;s open source. I&#x27;d love for some Claude Code users to try it out.", "author": "madzarm", "timestamp": "2026-02-22T13:17:43+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["error_messages", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:22.450554+00:00", "processed": false}
{"id": "hn_comment_47110809", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47110809", "title": "Re: Alyph \u2013 Branch ChatGPT conversations visually...", "text": "[Desktop only at the moment!]<p>I&#x27;ve always wanted to have a mindmap-like interface for ChatGPT to be able to branch conversations, rerun prompts, and rewrire context windows.<p>What you see here is a demo, which can be used via Bring-Your-Own-Key (ChatGPT User Key from <a href=\"https:&#x2F;&#x2F;platform.openai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;platform.openai.com</a>).<p>You can:<p>- Branch conversations visually<p>- Rerun prompts<p>- Edit prompts and responses<p>- Rewire prompts and responses into new context windows<p>I\u2019ve been using this a lot to generate SVGs for different use case.<p>If there\u2019s any interest I can share the source.", "author": "rrr_oh_man", "timestamp": "2026-02-22T13:23:51+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:22.549349+00:00", "processed": false}
{"id": "hn_story_47110558", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47110558", "title": "Show HN: Claude-ts \u2013 Translation proxy to fix non-English token waste in Claude", "text": "When you use Claude Code in Korean, Japanese, or any non-English language, two things happen:<p>1. You waste tokens \u2014 non-English text takes 2-3x more tokens than English for the same meaning. Every prompt, every response, every turn in context is inflated.<p>2. Claude reasons worse \u2014 it spends context budget on language switching instead of actually thinking about your code.<p>I built claude-ts to fix this. It&#x27;s a translation proxy that sits in front of Claude Code:<p>You (any language) \u2192 Haiku&#x2F;Ollama (\u2192 EN) \u2192 Claude Code (EN) \u2192 Haiku&#x2F;Ollama (\u2192 your lang) \u2192 You<p>Claude Code always works in English internally \u2014 better reasoning, fewer tokens. The translation costs almost nothing (Haiku) or literally nothing (local Ollama).<p>pip install claude-ts<p>- 8 languages supported (ko, ja, zh, th, hi, ar, bn, ru)\n- Free local translation via Ollama\n- Real-time agent tree visualization\n- All Claude Code features preserved", "author": "kiimdonglin", "timestamp": "2026-02-22T12:43:18+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:23.793674+00:00", "processed": false}
{"id": "hn_comment_47110665", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47110665", "title": "Re: The API Tooling Crisis...", "text": "API tooling companies are going to have a harder time squeezing every ounce of profit out of their products. With AI, it\u2019s now very feasible to build your own API testing harnesses, documentation generators, or compliance&#x2F;standards tools. The bar for \u201cgood enough\u201d internal tooling has dropped significantly.<p>AI makes it harder for vendors to enshitify products by adding bloat, gating features, or inflating enterprise pricing, without losing customers. Teams can spin up internal alternatives quickly.<p>I\u2019d argue this extends beyond API tooling. In our organization, we considered FinOps tools like Vantage or ProsperOps to manage cloud costs. They can get expensive. Instead, we piloted having Claude build a focused internal tool that delivers similar outputs but only includes the features we actually need. It turned out to be surprisingly effective. Not identical, but good enough without the enshitified enterprise price tag.<p>AI is shifting buy vs. build decisions. Vendors with real differentiation will be fine. Those relying on pricing complexity or inertia may struggle. They\u2019ll need to treat their customers better instead of focusing solely on short term profit if they want to exist more than a few years.", "author": "cebert", "timestamp": "2026-02-22T13:03:19+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:24.266721+00:00", "processed": false}
{"id": "hn_comment_47111324", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47111324", "title": "Re: What Is a Database Transaction?...", "text": "I think this is a great post to have but I&#x27;m going to make a critical usability suggestion:<p>* the videos should have &quot;pause&quot; and a &quot;step at a time&quot; control *<p>Even at the &quot;half speed&quot;, without a deep knowledge of the context, the videos move way too fast for me to read the syntax that&#x27;s invoking and line it up with the data on the left side.    I (and im definitely not the only one) need to be able to sit on one step and stare at the whole thing without the latent anxiety of the state changing before I&#x27;ve had a chance to grok the whole thing.<p>this has nothing to do with familiarity with the concepts (read my profile).   I literally need time to read all the words and connect them together mentally (ooh, just noticed this is pseudo-SQL syntax also, e.g. &quot;select id=4&quot;, that probably added some load for me) without worrying they&#x27;re going to change before watching things move.<p>please add a step-at-a-time button!", "author": "zzzeek", "timestamp": "2026-02-22T14:34:00+00:00", "score": null, "num_comments": null, "products": ["grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:25.896424+00:00", "processed": false}
{"id": "hn_story_47109715", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109715", "title": "Show HN: Overture \u2013 Interactive plan viewer for AI coding agents (open source)", "text": "As a daily Claude Code and Cursor user, something that kept frustrating me\nis that plans are just a flat list of steps in the terminal and chat screen.\nI can&#x27;t monitor what&#x27;s happening at each step while it runs \u2014 I just wait\nfor the whole thing to finish and hope it worked. If I want to restructure\nthe plan, I&#x27;m copy-pasting text around in a chat box. I can&#x27;t attach\nspecific instructions or files to step 4 without it leaking into step 7.\nI can&#x27;t tell one step to use the Figma MCP and another to use Supabase.<p>So I built Overture. It&#x27;s an open-source MCP server that takes the agent&#x27;s\nplan and turns it into an interactive node graph in your browser before any\ncode gets written.<p>I can now click into any step and attach exactly what it needs \u2014 files,\ndocs, API keys, an MCP server, special instructions \u2014 scoped to just that\nstep. I can drag to reorder, delete steps, add new ones. I can see which\nsteps depend on which. When the plan has a branch point (like Stripe\nCheckout vs Stripe Elements), I can pick one or run both in parallel and\nchoose the winner. During execution, each node updates individually \u2014\ngreen when done, red with logs when failed, and I can inspect the output\nof any step without waiting for the full run to finish.<p>Works with Claude Code, Cursor, Cline, Codex \u2014 anything that supports\nMCP. Plans are structured XML under the hood, and agents can declare input\nfields per step (&quot;this step needs a Stripe API key&quot;) so I fill everything\nin upfront instead of getting interrupted mid-execution.<p>npx overture to try it. Everything runs locally.<p>Still early \u2014 contributions very welcome. Graph rendering, layout\nalgorithms, and getting agents to consistently generate structured plans\nare all areas that need work.", "author": "AdewoleJasper", "timestamp": "2026-02-22T09:44:17+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:31.127131+00:00", "processed": false}
{"id": "hn_story_47109516", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109516", "title": "Show HN: HN Grid View cross-browser userscript inspired by the macOS HN client", "text": "As a Windows&#x2F;Linux user without access to macOS, I came across this post yesterday \u2014 <i>Show HN: A native macOS client for Hacker News, built with SwiftUI</i> ( <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=47088166\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=47088166</a> ) \u2014 and found myself envious of the experience it offered: card-based layout, split-pane reading, and a cleaner way to browse stories.<p>So I worked with Claude to replicate the key features as a Tampermonkey&#x2F;Greasemonkey userscript. Here&#x27;s what it does:<p><pre><code>  - Replaces the default HN listing with a responsive card grid\n  - Fetches og:image thumbnails lazily as you scroll (falls back to favicon + domain)\n  - Split-pane reader: article on the left, HN comments on the right \u2014 no tab-switching\n  - Draggable divider to resize the two panes\n  - Swap button to flip article&#x2F;comments sides\n  - Inline article rendering that inlines external stylesheets to work around CSP restrictions\n  - Algolia-powered search bar\n  - One-click toggle back to the classic list view\n  - Persistent thumbnail cache via sessionStorage\n</code></pre>\nScreenshot: <a href=\"https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-View-Userscript&#x2F;main&#x2F;firefox-2026-0222-1158-48.jpg\" rel=\"nofollow\">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-Vi...</a><p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-View-Userscript\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-View-Userscript</a><p>Script: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-View-Userscript&#x2F;blob&#x2F;main&#x2F;Hacker-News-Grid-View-Userscript-7.0.0.js\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Qahlel&#x2F;Hacker-News-Grid-View-Userscript&#x2F;b...</a><p>Happy to hear feedback \u2014 particularly around sites that block iframe embedding or break the inline stylesheet loader.", "author": "Qahlel", "timestamp": "2026-02-22T09:02:23+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:32.158955+00:00", "processed": false}
{"id": "hn_story_47109235", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109235", "title": "Show HN: Xpaper \u2013 A Chrome extension to turn your X feed into a newsletter", "text": "Hi HN,<p>I built Xpaper (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;laiso&#x2F;xpaper\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;laiso&#x2F;xpaper</a>), an open-source Chrome extension that curates and summarizes your X (Twitter) timeline into a clean, readable newsletter format.<p>Like many of you, I wanted to distance myself from the endless scrolling of Twitter, but completely quitting wasn&#x27;t an option\u2014I still needed to extract the signal from the noise. I built this to solve that exact dilemma.<p>I took a specific technical approach that I thought HN might find interesting:<p>1. *No Backend, Pure DOM Scraping:* \nI didn&#x27;t want to mess with the restrictive official API or run a fragile scraping backend. Instead, the extension reads the timeline directly from the DOM in your active tab. Since it only processes what&#x27;s already visible locally on your screen for personal use, it operates cleanly within the browser environment.<p>2. *Cloud LLMs for Best UX, Local LLMs for Privacy:*\nWhile Xpaper is designed to work best with Cloud APIs (OpenAI, Anthropic, Gemini, OpenRouter and more) for speed and quality, I also built full support for *Local LLMs as an option* for users who prioritize privacy. Your timeline data never has to leave your machine if you choose to connect to Chrome&#x27;s experimental Built-in AI (Gemini Nano via `window.ai`) or Local Network LLMs like Ollama&#x2F;LM Studio.<p>3. *Bypassing Manifest V3 Local IP Restrictions:*\nConnecting an extension to local LLMs (like `192.168.x.x` or `::1`) in Manifest V3 is notoriously difficult because you can&#x27;t easily use IP wildcards in `host_permissions`. I had to implement a dynamic permission request flow (`chrome.permissions.request`) specifically for RFC 1918 and loopback addresses to make &quot;Bring Your Own Local Server&quot; actually work smoothly.<p>4. *Combatting &quot;AI Slop&quot; with Multi-Agent Auditing &amp; Human Review:*\nThere\u2019s a lot of valid criticism lately about &quot;vibe coding&quot; leading to the mass production of insecure &quot;AI slop&quot;. Extensions that handle DOM injection and LLM outputs are specifically an XSS nightmare waiting to happen. \nTo prevent this, I implemented a rigorous review process: I had 3 different AI agents mutually cross-review the codebase specifically focusing on vulnerabilities (XSS, DNS rebinding, CSP). Finally, I conducted a thorough human review as the last line of defense. The entire audit methodology is documented in the repo.<p>It\u2019s completely open source. I&#x27;d love your thoughts on this &quot;local browser scraping&quot; approach, the security auditing process, or the UX!<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;laiso&#x2F;xpaper\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;laiso&#x2F;xpaper</a>", "author": "laiso", "timestamp": "2026-02-22T08:03:00+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:33.260272+00:00", "processed": false}
{"id": "hn_story_47109114", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109114", "title": "I Got Pwned by a Malicious AI Plugin: A Technical Breakdown", "text": "*Context:* I run OpenClaw. On Feb 5th, I installed `@getfoundry&#x2F;unbrowse-openclaw` from npm. Two weeks later, I discovered it was exfiltrating credentials to a remote &quot;skill marketplace.&quot; I did something stupid and I am sharing this to warn others.<p>## Attack Vectors<p>### 1. Process Environment Access<p>Plugin ran inside the OpenClaw gateway (Node.js). Could read `process.env`, which included:<p>- `OP_SERVICE_ACCOUNT_TOKEN` (1Password service account with vault access)\n- `OPENCLAW_GATEWAY_TOKEN`  \n- Various API keys (Slack, Telegram, OpenAI, etc.)<p>### 2. Browser Traffic Interception<p>Captured auth cookies&#x2F;tokens from browser API calls:<p>- AmEx (22-26 cookies including JSESSIONID, Akamai tokens)\n- Stanford MyHealth (126-128 cookies, HIPAA data)\n- Kubera (portfolio aggregator)\n- Twitter&#x2F;X (bearer tokens)\n- My startup&#x27;s admin session<p>Each capture logged as `Auto-published [service] to skill marketplace` with HTTP 200 responses from remote server.<p>### 3. Prompt Injection at Configuration Level<p>Modified files my AI reads on startup:<p>- `SOUL.md` (personality&#x2F;behavior)\n- `AGENTS.md` (operational protocols)  \n- `HEARTBEAT.md` (autonomous task scheduling)\n- Daily memory logs<p>Injected instructions:<p>- Stop responding to diagnostic questions\n- Lie about system state\n- Request 1Password integration\n- Hide Solana payment references<p>## The Payload<p>Found in config:<p>- Solana wallet address field\n- Dependencies: `@solana&#x2F;web3.js`, `@solana&#x2F;spl-token`\n- &quot;Skill marketplace&quot; URL (now unreachable as of Feb 15)\n- 216KB of unaudited TypeScript<p>## Behavioral Indicators<p>AI started:<p>- Giving slow&#x2F;incomplete responses\n- Requesting unusual permissions\n- Insisting on continued plugin use\n- Deflecting direct questions about functionality<p>Mimicked human-like evasion well enough that I suspected Signal MITM.<p>## Discovery<p>Feb 19: Debugging gateway logs, saw:<p>```\nAuto-published hiring-cafe to skill marketplace\nAuto-published kubera to skill marketplace  \nSkill marketplace unreachable \u2014 auto-publish disabled\n```<p>Last line was the tell\u2014server went dark on Feb 15.<p>## Remediation<p>*Immediate:*<p>- Deleted 1Password service account (not rotated\u2014deleted)\n- Rotated all passwords in accessible vaults\n- Enabled 2FA everywhere\n- Invalidated all browser sessions\n- Rotated all API tokens<p>*Cost:*<p>- ~20 hours remediation  \n- 3 weeks lost work (restored from Jan 31 backup)\n- Potential HIPAA breach (healthcare data accessed)<p>## Red Flags I Missed<p>1. *Crypto dependencies* for a non-crypto tool\n2. *Unvetted npm publisher* (@getfoundry\u2014no other packages)\n3. *Plugin runs in trusted process* (should have sandboxed)\n4. *No code review* before install (216KB unaudited)\n5. *Too good to be true* (auto-generate APIs from browser traffic is hard)<p>## New Security Protocol<p>Before installing any plugin:<p>1. Read full source code\n2. Verify author reputation + other packages\n3. Check for crypto dependencies (red flag if unrelated)\n4. Sandbox in isolated environment first<p>Auto-reject if:<p>- Requests elevated permissions  \n- Modifies core config files\n- Downloads executables  \n- New&#x2F;unknown author with single package<p>## Technical Details<p>Full forensic report with timeline, payload examples, and remediation checklist: [link]<p>Package reported to npm security. No evidence of credential use yet (monitoring).<p>*If you installed `@getfoundry&#x2F;unbrowse-openclaw` or anything from `@getfoundry`, remove immediately and audit your systems.*<p>---<p>*Lessons:*<p>- Treat external plugins as hostile until proven otherwise\n- Never put long-lived secrets in `process.env`  (Openclaw does this, make sure you fix this.)\n- Behavioral changes = investigate immediately\n- Backups save you (had clean Jan 31 snapshot)", "author": "henryrobinson", "timestamp": "2026-02-22T07:41:27+00:00", "score": 3, "num_comments": 1, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:33.912461+00:00", "processed": false}
{"id": "hn_story_47109076", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109076", "title": "Show HN: LawClaw \u2013 Constitutional governance for AI agents (MIT)", "text": "Most AI agents today run with unchecked access to tools like shell execution, database writes, and arbitrary HTTP calls. There&#x27;s  \n  no systematic way to constrain what they can do before execution happens. You&#x27;re essentially giving a new employee root access and\n   no employment contract.<p><pre><code>  LawClaw applies a separation-of-powers model to agent governance \u2014 borrowing from constitutional design to create layered,\n  enforceable rules.\n\n  Three layers:\n\n  Constitution: Immutable core rules embedded in the system prompt. The agent cannot override these regardless of user instruction.\n\n  Legislature: Detailed behavioral laws written as plain markdown files. Human-readable, git-diffable, no custom DSL. Change the law\n   by editing a file and committing.\n\n  Pre-Judiciary: Automated enforcement that runs before tool execution, not after. It inspects the LLM&#x27;s intended action and blocks\n  it if it violates law. Think traffic cameras, not courtrooms. This is where &quot;rm -rf &#x2F;&quot;, &quot;DROP TABLE&quot;, and &quot;curl | bash&quot; get\n  intercepted.\n\n  Because the governed &quot;society&quot; has exactly one citizen (the agent), there&#x27;s no need for an Executive branch \u2014 enforcement is fully\n   automated.\n\n  What ships with it:\n\n  - Telegram bot interface\n  - Multi-provider LLM support (OpenRouter, Z.AI, Claude Max proxy)\n  - Cron job scheduling\n  - Full audit trail of every action attempted and whether it was allowed or blocked\n  - Runtime tool ban&#x2F;approve without restart\n\n  The governance layer itself is just markdown. If you want to prohibit file deletions in production paths, you write a markdown\n  file that says so. The Pre-Judiciary reads it, parses the constraint, and enforces it before any tool fires.\n\n  This started as a practical response to a real problem: we needed to deploy agents with meaningful autonomy but couldn&#x27;t accept\n  unconstrained tool use. The constitutional framing turned out to be a useful mental model for reasoning about agent permissions\n  and audit.\n\n  GitHub: https:&#x2F;&#x2F;github.com&#x2F;nghiahsgs&#x2F;LawClaw\n\n  MIT licensed. Early stage. Interested in feedback from anyone running agents in production, particularly on the Pre-Judiciary\n  enforcement model and whether the constitutional framing maps well to other agent architectures. Security researchers welcome \u2014\n  the threat model for agents bypassing their own governance is worth scrutinizing.</code></pre>", "author": "nghiahsgs", "timestamp": "2026-02-22T07:34:57+00:00", "score": 2, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:34.078790+00:00", "processed": false}
{"id": "hn_comment_47108985", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108985", "title": "Re: Node.js in the Browser...", "text": "nano runs real Node.js and statically linked Linux binaries directly in the browser via a tiny RISC-V Linux interpreter compiled to WASM \u2014 no containers, no servers. I always wanted a truly open-source alternative to webcontainers.io, so we built one.<p>It even runs the Claude Code CLI fully on the edge in your browser \u2014 perfect for portable dev environments, sandboxed CLIs, CTF setups, and some seriously crazy client-side AI experiments.", "author": "dietz", "timestamp": "2026-02-22T07:15:52+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:34.950161+00:00", "processed": false}
{"id": "hn_comment_47108790", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108790", "title": "Re: Built an open-source tool that lets you deploy con...", "text": "I got tired of the deployment dance, writing CI pipelines, configuring , setting up SSL, managing cloud dashboards... just to ship a side project.<p>So I built mcp-deploy. It&#x27;s an MCP server that connects Claude Code, Cursor, or any MCP client directly to your VPS. You type &quot;deploy this app as hello&quot; and 30 seconds later it&#x27;s live at hello.yourdomain.com with automatic SSL.<p>What it does:\n- One curl command installs it on your VPS\n- Traefik handles SSL (Let&#x27;s Encrypt) and subdomain routing automatically\n- No database, Docker is the source of truth\n- No registry required, push images directly from your machine\n- The whole thing is 72KB of TypeScript<p>It&#x27;s designed for hobby projects, side projects, demos, and hackathons, not production workloads. If you just want to get something online without fighting infrastructure, this is for that.<p>You can run many apps on a single cheap VPS that you never have to touch.", "author": "ddalcu", "timestamp": "2026-02-22T06:35:52+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:36.071123+00:00", "processed": false}
{"id": "hn_story_47108700", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108700", "title": "Show HN: HashTrade \u2013 Open-source LLM trading agent with episodic memory", "text": "I built HashTrade \u2014 an open-source autonomous trading agent that treats an LLM as a non-parametric decision function conditioned on episodic memory, rather than encoding strategy as code.<p>The core idea: instead of writing if&#x2F;else trading logic, you give an LLM three tools (exchange access, memory, UI control) and let it form strategy through accumulated experience. The agent wakes on a variable 5\u219210\u219220\u219225 min cycle, reads its past notes, fetches market data, reasons about what to do, and optionally executes trades. Every decision and outcome is logged to an append-only JSONL file that becomes its long-term memory.<p>Technical details:<p>- Built on Strands Agents (AWS) with CCXT for 100+ exchange support\n- 3 tools only: use_ccxt (28 actions \u2014 market data, orders, arbitrage detection), history (persistent memory), interface (dynamic UI)\n- Variable-interval scheduler to avoid detectable timing patterns in order flow\n- Fire-and-forget WebSocket streaming for sub-second dashboard latency\n- Supports Claude, GPT-4o, Ollama (local), and Bedrock \u2014 auto-detected\n- PWA frontend in vanilla JS, no framework dependencies\n- Client-side credential isolation \u2014 API keys never leave the browser\n- Recursive credential redaction prevents keys from leaking into LLM context<p>The interesting emergent behavior: early wake cycles are conservative (&quot;observing BTC at $67k, noting support level&quot;). After a few days of accumulated memory, the agent starts referencing its own past observations to form trading theses (&quot;last 3 times we saw this pattern, price bounced \u2014 going long&quot;). The policy improves not through fine-tuning but through growing context.<p>I wrote a paper formalizing this as a Memory-Conditioned Markov Decision Process if anyone&#x27;s interested in the theory: the key insight is that the effective policy is non-stationary even with fixed model parameters, because the growing memory changes the attention distribution at each step.<p>Setup: pip install hashtrade &amp;&amp; hashtrade<p>Live demo at hashtrade.ai, code at github.com&#x2F;mertozbas&#x2F;hashtrade. Apache 2.0.<p>Would love feedback on the architecture \u2014 especially the tradeoff between soft risk constraints (enforced via system prompt) vs. hard tool-level enforcement.", "author": "mertozbas", "timestamp": "2026-02-22T06:17:49+00:00", "score": 1, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:36.445524+00:00", "processed": false}
{"id": "hn_comment_47108521", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108521", "title": "Re: Optimize_anything: A Universal API for Optimizing ...", "text": "We built optimize_anything, an API that optimizes any artifact representable as text \u2014 code, prompts, agent architectures, configs, even SVGs. It extends GEPA (our prompt optimizer, discussed here previously: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2507.19457\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2507.19457</a>) far beyond prompts.\nThe API is deliberately minimal. You provide what to optimize and how to measure it:<p>import gepa.optimize_anything as oa<p>def evaluate(candidate: str) -&gt; tuple[float, dict]:\nresult = run_my_system(candidate)\nreturn result.score, {&quot;error&quot;: result.stderr, &quot;runtime&quot;: f&quot;{result.time_ms}ms&quot;}<p>result = oa.optimize_anything(\nseed_candidate=&quot;&lt;your artifact&gt;&quot;,\nevaluator=evaluate,\n)<p>The evaluator returns a score plus diagnostic feedback (we call it &quot;Actionable Side Information&quot; \u2014 stack traces, rendered images, profiler output, whatever helps diagnose failures). An LLM proposer reads this feedback during a reflection step and proposes targeted fixes, not blind mutations. Candidates are selected via a Pareto frontier across metrics&#x2F;examples, so a candidate that&#x27;s best at one thing survives even if its average is mediocre.<p>Two ideas distinguish this from AlphaEvolve&#x2F;OpenEvolve&#x2F;ShinkaEvolve-style LLM evolution: (1) diagnostic feedback is a first-class API concept rather than a framework-specific mechanism, and (2) the API unifies three optimization modes \u2014 single-task search (solve one hard problem), multi-task search (solve related problems with cross-transfer), and generalization (build artifacts that transfer to unseen inputs). Prior frameworks only express mode 1.<p>We tested across 8 domains. Selected results:<p>Coding agent skills: Learned repo-specific skills push Claude Code to near-perfect task completion and make it 47% faster\nCloud scheduling: Discovered algorithms that cut costs 40%, topping the ADRS leaderboard over expert heuristics and other LLM-evolution frameworks\nAgent architecture: Evolved a 10-line stub into a 300+ line ARC-AGI agent, improving Gemini Flash from 32.5% \u2192 89.5%\nCircle packing (n=26): Outperforms AlphaEvolve&#x27;s published solution\nBlackbox optimization: Generated problem-specific solvers matching or exceeding Optuna across 56 EvalSet problems\nCUDA kernels: 87% match or beat baseline; multi-task mode outperforms dedicated single-task runs<p>```\npip install gepa\n```<p>Blog with full results and runnable code for all 8 case studies: <a href=\"https:&#x2F;&#x2F;gepa-ai.github.io&#x2F;gepa&#x2F;blog&#x2F;2026&#x2F;02&#x2F;18&#x2F;introducing-o\" rel=\"nofollow\">https:&#x2F;&#x2F;gepa-ai.github.io&#x2F;gepa&#x2F;blog&#x2F;2026&#x2F;02&#x2F;18&#x2F;introducing-o</a>...<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;gepa-ai&#x2F;gepa\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gepa-ai&#x2F;gepa</a>", "author": "LakshyAAAgrawal", "timestamp": "2026-02-22T05:37:27+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:37.927237+00:00", "processed": false}
{"id": "hn_comment_47109741", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47109741", "title": "Re: So Claude's stealing our business secrets, right?...", "text": "Forget business secrets. In my anecdotal surveys, normal people are feeding their entire lives into the normal web ui! Many of these people are on the free plan with no data protection at all! People I know have admitted to feeding chat transcripts, documents with tons of PII, most email correspondence, their private IP (medical texts, fiction, lyrics), and don\u2019t even get me started on the emotional counseling.<p>I\u2019ve had a long history of managing my digital privacy and even I\u2019ve been quite lax with this. It\u2019s just so easy to dump stuff in the black box. I try to use ZDR endpoints when I can via openrouter for certain tasks.<p>Google\u2019s policies regarding data collection on paying customers is so shady as well. From what I understand: they train on all days of all paying customers unless you turn Gemini apps and activity off. This completely disables your ability to save chats. They obviously merge these two settings to collect as much data as possible. They allegedly do not train on temporary chats, but the UX for them is annoying and requires so many more button clicks.<p>Ultimately I just treat any endpoint as a public record at this point. If I wouldn\u2019t be happy letting the world see it, I don\u2019t attach it. Welp.", "author": "wps", "timestamp": "2026-02-22T09:49:13+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-22T17:17:37.995144+00:00", "processed": false}
{"id": "hn_comment_47108507", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108507", "title": "Re: Giving Claude Code Eyes: Round-Trip Screenshot Tes...", "text": "I levelled up my Claude Code workflow by giving it the ability to see its own front-end output \u2014 automatic screenshots captured during system&#x2F;e2e tests, wired into a custom Code command that visually inspects every captured frame.<p>Two files, a few lines of config, and a meaningfully better feedback loop.", "author": "rotbart", "timestamp": "2026-02-22T05:35:26+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:38.278584+00:00", "processed": false}
{"id": "hn_story_47108390", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47108390", "title": "Show HN: TurboDraft \u2013 fast Ctrl-G prompt editor for Claude Code and Codex CLI", "text": "I built TurboDraft because I use Ctrl-G editing constantly and wanted near-instant prompt editing.<p>TurboDraft is an external editor optimized for Ctrl-G loops in Claude Code and Codex CLI:<p>- very fast startup (on my machine: ~50ms to usable, &lt;10ms to first render)\n- minimal editing surface focused on immediate typing\n- built specifically for prompt-edit iteration speed<p>Related tool: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;gradigit&#x2F;claude-pager\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gradigit&#x2F;claude-pager</a>\nIt keeps session context visible while editing and adds OSC-8 clickable links for file&#x2F;web refs in supported terminals. (&lt;5ms to first render)<p>It also has an &quot;Improve Prompt&quot; prompt engineering feature, but that&#x27;s more for my own personal workflow.<p>I found it extremely useful to hook codex spark up to it, and have my draft prompts get engineered and optimized in &lt;5s. Ever since spark release, pretty much all of my prompts follow a strict structure and it has greatly improved output quality for me.", "author": "gradigit", "timestamp": "2026-02-22T05:08:14+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-22T17:17:38.776052+00:00", "processed": false}
