{"id": "hn_story_46963340", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46963340", "title": "Runtime validation is still fucked in AI coding agents", "text": "AI agents (Cursor, Claude computer-use, Copilot agent mode, etc.) have gotten stupidly good at spitting out code. Prompt \u2192 boom, clean code. The marketing says &quot;it just works.&quot;<p>It fucking doesn&#x27;t.<p>You run it in a real app and immediately hit the same bullshit wall every time:\n- Hallucinated logic only reveals itself under real data or edge cases\n- UI updates magically forget to sync across devices (mobile \u2192 web = sad trombone)\n- API calls quietly return 401s or other crap that gets swallowed in some lazy try-catch\n- Vision-based agents crawl like molasses (2\u201310s per action) and torch tokens like it&#x27;s free\n- Background pings and unrelated fetches make it impossible to tell what actually caused what<p>I tried pretty much everything out there and none of it quite scratched the itch I had: fast, structured, cross-platform runtime visibility without vision bloat or having to wire up a ton of hooks.<p>Quick rundown of the usual suspects:<p>- Pure vision&#x2F;computer-use (Claude 3.5&#x2F;4, ADEPT-style): zero setup, works on anything \u2014 but latency from hell and token burn is brutal for anything longer than a demo\n- Playwright &#x2F; browser MCP servers: fast and structured for web \u2014 but web-only, selectors shatter like glass, no native mobile\n- Appium + vision hybrids: cross-platform on paper \u2014 but still vision-dependent and setup is a pain\n- Sandboxed agents (OpenHands, SWE-agent): decent for repo tasks and shell stuff \u2014 not so much for live app UI&#x2F;network state\n- Explicit hooks&#x2F;bridges: precise when you bother adding them \u2014 but requires code changes, which sucks<p>Couldn&#x27;t find anything that gave me low-latency structured JSON state (UI elements, network, errors, logs) across platforms, local-first, without the usual trade-offs. So yeah, I got fed up and built a small local MCP server to solve it for myself.<p>Full disclosure: it&#x27;s called Autonomo MCP https:&#x2F;&#x2F;github.com&#x2F;sebringj&#x2F;autonomo \u2014 very early, just launched.<p>I don&#x27;t usually do this &quot;I built a thing&quot; thing \u2014 my open-source contributions are mostly small fixes and PRs \u2014 but I honestly couldn&#x27;t see a better way in the current landscape.<p>It is my hope that Anthropic (or someone) will eventually ship a clean native solution for this. They already fixed BM25 tool calling to shrink context like crazy; I&#x27;d love to see them (or the industry) make runtime validation &quot;just work&quot; out of the box too.<p>Sometimes when you code in a vacuum you think your shit smells good. lmk if I&#x27;m off base here, I grew up with a mean grandpa so I&#x27;m cool with it.", "author": "sebringj", "timestamp": "2026-02-10T17:22:50+00:00", "score": 1, "num_comments": 2, "products": ["claude", "copilot"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-10T17:53:31.489265+00:00", "processed": false}
{"id": "hn_story_46963026", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46963026", "title": "Show HN: Open-Source SDK for AI Knowledge Work", "text": "GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk</a><p>Most AI agent frameworks target code. Write code, run tests, fix errors, repeat. That works because code has a natural verification signal. It works or it doesn&#x27;t.<p>This SDK treats knowledge work like an engineering problem:<p>Task \u2192 Brief \u2192 Rubric (hidden from executor) \u2192 Work \u2192 Verify \u2192 Fail? \u2192 Retry \u2192 Pass \u2192 Submit<p>The orchestrator coordinates subagents, web search, code execution, and file I&#x2F;O. then checks its own work against criteria it can&#x27;t game (the rubric is generated in a separate call and the executor never sees it directly).<p>We originally built this as a harness for RL training on knowledge tasks. The rubric is the reward function. If you&#x27;re training models on knowledge work, the brief\u2192rubric\u2192execute\u2192verify loop gives you a structured reward signal for tasks that normally don&#x27;t have one.<p>What makes Knowledge work different from code? (apart from feedback loop)\nI believe there is some functionality missing from today&#x27;s agents when it comes to knowledge work. I tried to include that in this release. Example:<p>Explore mode: Mapping the solution space, identifying the set level gaps, and giving options.<p>Most agents optimize for a single answer, and end up with a median one. For strategy, design, creative problems, you want to see the options, what are the tradeoffs, and what can you do? Explore mode generates N distinct approaches, each with explicit assumptions and counterfactuals (&quot;this works if X, breaks if Y&quot;). The output ends with set-level gaps ie what angles the entire set missed. The gaps are often more valuable than the takes. I think this is what many of us do on a daily basis, but no agent directly captures it today. See <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;explore_mode.py\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;explore_...</a> and the output for a sense of how this is different.<p>Checkpointing: With many ai agents and especially multi agent systems, i can see where it went wrong, but cant run inference from same stage. (or you may want multiple explorations once an agent has done some tasks like search and is now looking at ideas). I used this for rollouts a lot, and think its a great feature to run again, or fork from a specific checkpoint.<p>A note on Verification loop:\nThe verify step is where the real leverage is. A model that can accurately assess its own work against a rubric is more valuable than one that generates slightly better first drafts. The rubric makes quality legible \u2014 to the agent, to the human, and potentially to a training signal.<p>Some things i like about this: \n- You can pass a remote execution environment (including your browser as a sandbox) and it would work. It can be docker, e2b, your local env, anything, the model will execute commands in your context, and will iterate based on feedback loop. Code execution is a protocol here.<p>- Tool calling: I realize you don&#x27;t need complex functions. Models are good at writing terminal code, and can iterate based on feedback, so you can just pass either functions in context and model will execute or you can pass docs and model will write the code. (same as anthropic&#x27;s programmatic tool calling). Details: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;TOOL_CALLING_GUIDE.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;TOOL_CALLING_GUID...</a><p>Lastly, some guides: \n- SDK guide: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;SDK_GUIDE.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;SDK_GUIDE.md</a>\n- Extensible. See bizarro example where i add a new mode: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;custom_mode_bizarro.py\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;custom_m...</a>\n- working with files: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;with_files.py\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;with_fil...</a> \n- this is simple but i love the csv example: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;csv_research_and_calc.py\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;csv_rese...</a>\n- remote execution: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;with_custom_executor.py\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ClioAI&#x2F;kw-sdk&#x2F;blob&#x2F;main&#x2F;examples&#x2F;with_cus...</a><p>And a lot more. This was completely refactored by opus and given the rework, probably would have taken a lot of time to release it.<p>MIT licensed. Would love your feedback.", "author": "ankit219", "timestamp": "2026-02-10T17:06:00+00:00", "score": 4, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:31.854009+00:00", "processed": false}
{"id": "hn_comment_46962953", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46962953", "title": "Re: Lokutor Orchestrator: A Go library for full-duplex...", "text": "Hi HN,<p>We\u2019re open-sourcing the Go orchestrator we built at Lokutor (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrator\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrator</a>).<p>Building a voice agent that feels like a human is 20% model quality and 80% orchestration. The &quot;standard&quot; approach\u2014daisy-chaining STT, LLM, and TTS APIs\u2014usually results in a 2-3 second delay that kills the conversation. We also found that implementing &quot;Barge-in&quot; (the ability to interrupt the bot) is surprisingly tricky to get right across multiple streaming providers.<p>We chose Go because voice orchestration is essentially a high-concurrency plumbing problem. You\u2019re managing several bidirectional streams (WebSockets&#x2F;gRPC) while calculating RMS for VAD (Voice Activity Detection) and managing a state machine that needs to respond in milliseconds when it detects user speech.<p>What\u2019s inside:<p>Full-Duplex: Capture and playback occur simultaneously without audio feedback loops.\nNative Barge-in: When the user starts speaking, the orchestrator immediately kills the LLM generation and clears the TTS audio buffers.\nBuilt-in RMS VAD: Thread-safe voice activity detection out of the box.\nProvider Agnostic: Swap between Groq, OpenAI, Deepgram, Anthropic, and our own Versa engine.\nMinimal Latency: Designed to add &lt;10ms of overhead on top of the provider latencies.\nWe&#x27;ve used this to build agents that handle sub-500ms end-to-end response times. We would love to hear your feedback on the architecture, especially regarding how we handle the ManagedStream state machine.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrator\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrator</a><p>Docs: <a href=\"https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrator\" rel=\"nofollow\">https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;lokutor-ai&#x2F;lokutor-orchestrato...</a>", "author": "dani-lokutor", "timestamp": "2026-02-10T17:02:03+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:32.210298+00:00", "processed": false}
{"id": "hn_story_46962290", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46962290", "title": "Show HN: A design collaboration layer for local LLM CLIs", "text": "Hey, I&#x27;m Rebekah and I&#x27;m building Popmelt, a browser-native toolkit for UI engineering with local LLM CLIs<p>*tl;dr* Popmelt gives UI engineers and designers a lightweight set of visual feedback and styling&#x2F;layout tools that talk directly to local LLM CLI instances so you can create and refine your product directly in the browser. This first version is built for React (I&#x27;ve mainly used it with Next.js projects) and plays well with Claude Code and Codex.  It&#x27;s free to use and I plan to keep it that way.<p>I started working as a designer and front-end developer on the web in my teens, making myspace layouts for local bands. Since then, I&#x27;ve worked in agencies, ecomm, and startups, bouncing between design and code depending on what each team or client needs.<p>As LLM code generation has gotten faster and more reliable in the last ~12 months, I&#x27;ve found myself spending more time working with code (directly and indirectly) earlier and earlier in my design process. Last November, design and development have more or less collapsed into a single code-driven step for me, with multiple LLM sessions running in parallel to keep the loop between idea, testing, and iterating as tight as possible.<p>Along the way I developed a way of working that lets me spend most of my time interacting with the page&#x2F;product I&#x27;m designing without looking at the underlying code. Popmelt bottles that way of working, and saves me from having to flip between the thing I&#x27;m designing and the LLM sessions powering it. The repo&#x27;s README covers most of the details, and I&#x27;m happy to answer any questions folks have. Critical feedback is also very welcome.<p>Thanks for looking!", "author": "reb", "timestamp": "2026-02-10T16:30:09+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:33.788417+00:00", "processed": false}
{"id": "hn_comment_46962040", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46962040", "title": "Re: Show HN: ClawKit\uff5cOpen-source toolkit to configure ...", "text": "Hey HN, I built this because I kept seeing the same 3 problems in every OpenClaw setup thread:<p><pre><code>  1. JSON config errors (especially Windows backslash paths breaking everything)\n  2. ECONNREFUSED \u2014 usually just an IPv6&#x2F;localhost binding issue but nobody knows that\n  3. No way to discover which of the 7,400+ community skills are actually worth installing\n\n  ClawKit is a browser-based toolkit with four tools:\n\n  - Config Wizard \u2014 generates validated JSON configs with one-click presets for OpenAI, DeepSeek, Anthropic, Ollama. Auto-escapes Windows paths. Uses Zod for real-time validation.\n  - Local Doctor \u2014 npx clawkit-doctor@latest checks Node.js version, port conflicts, config file syntax, permissions. Zero install, read-only.\n  - Cost Estimator \u2014 models exponential context growth across GPT-4.1, Claude, DeepSeek. Most people don&#x27;t realize running an agent 24&#x2F;7 can cost $300+&#x2F;mo until they see the curve.\n  - Skill Registry \u2014 searchable directory of all ClawdHub skills with install commands, config snippets, and source links.\n\n  Everything runs client-side. API keys never leave the browser. No auth, no paywall.\n\n  Stack: Next.js 15 (App Router + RSC), Tailwind, shadcn&#x2F;ui, Prisma + Postgres for skill data, Fuse.js for search, Umami for privacy-first analytics. Deployed on Vercel.\n\n  Source: https:&#x2F;&#x2F;github.com&#x2F;branzoom&#x2F;getclawkit-web\n\n  I&#x27;m a solo developer. Happy to answer any questions about the architecture or the skill crawling pipeline.</code></pre>", "author": "KingBor", "timestamp": "2026-02-10T16:19:22+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:34.190842+00:00", "processed": false}
{"id": "hn_comment_46961817", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46961817", "title": "Re: GrandCru \u2013 AI code review CLI built by a self-taug...", "text": "I&#x27;m a former military officer who sells physical products for a living. No CS degree, no bootcamp. I taught myself to code because the tech industry wasn&#x27;t going to let me in any other way.<p>GrandCru is a CLI that does real code review \u2014 complexity, naming, error handling, unused code, separation of concerns \u2014 delivered in the voice of a pretentious French wine sommelier. The character makes the feedback memorable and the output shareable. But take away the wine metaphors and you still get real issues with line numbers and fixes.<p>Why I built it: solo developers don&#x27;t get code review. I don&#x27;t have a team or a senior engineer. I needed something that would catch the stuff linters miss \u2014 and I wanted it to be fun enough that I&#x27;d actually run it.<p>Technical details:<p>- One API call per file using Anthropic&#x27;s structured outputs (constrained decoding, not &quot;please respond in JSON&quot;)\n- Dual-channel Zod schema: strict technical data (line numbers, severity, fixes) and creative prose (tasting notes, remarks) in one response\n- Extended thinking on by default \u2014 the model reasons about code architecture before committing to structured output\n- BYOK: your Anthropic key, ~$0.02&#x2F;file, no server\n- TypeScript, Commander.js, npm<p>I pointed it at its own source code. It found real issues in its prompt builder \u2014 no input validation, raw string interpolation. Scored itself 79&#x2F;100 \u2014 &quot;Needs decanting before service.&quot;<p>This is a portfolio project from someone trying to prove they can build real tools. Happy to talk about the architecture, the self-teaching process, or structured output patterns.", "author": "Scunion95", "timestamp": "2026-02-10T16:09:46+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:34.721067+00:00", "processed": false}
{"id": "hn_comment_46961910", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46961910", "title": "Re: Ex-GitHub CEO Launches a New Developer Platform fo...", "text": "&gt; Spec-driven development is becoming the primary driver of code generation.<p>This sounds like my current &quot;phase&quot; of AI coding. I have had so many project ideas for years that I can just spec out, everything I&#x27;ve thought about, all the little ideas and details, things I only had time to think about, never implement. I then feed it to Claude, and watch it meet my every specification, I can then test it, note any bugs, recompile and re-test. I can review the code, as you would a Junior you&#x27;re mentoring, and have it rewrite it in a specific pattern.<p>Funnily enough, I love Beads, but did not like that it uses git hooks for the DB, and I can&#x27;t tie tickets back to ticketing systems, so I&#x27;ve been building my own alternative, mine just syncs to and from github issues. I think this is probably overkill for whats been a solved thing: ticketing systems.", "author": "giancarlostoro", "timestamp": "2026-02-10T16:13:39+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-10T17:53:35.649767+00:00", "processed": false}
{"id": "hn_comment_46960752", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46960752", "title": "Re: Show HN: Autonomo MCP \u2013 Developing while E2E Testi...", "text": "Hey HN,<p>Tried posting this yesterday evening but timing was off and it got buried quickly (4 points, no comments). Reposting now during peak hours.<p>I built Autonomo MCP because AI coding agents (Cursor, Claude, etc.) are great at generating code but terrible at actually running and validating it in real apps. They hallucinate, rely on slow screenshots, or break on multi-device flows.<p>Autonomo MCP gives agents a fast (~50ms), structured JSON view of app state (semantic UI IDs, network calls, errors, logs) across web + iOS + Android + desktop simultaneously. Local-first, MCP-integrated, no cloud leaks.<p>- Swap vision bloat for tiny tokens - Cross-device validation (e.g. tap mobile \u2192 see web update) - Early stage, just launched: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sebringj&#x2F;autonomo\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sebringj&#x2F;autonomo</a><p>Would love feedback: Does this solve a pain point for anyone building agentic dev tools? What platforms&#x2F;workflows would you want next? (Android&#x2F;Kotlin and C#&#x2F;.NET are on the TODO list.)<p>Thanks for any stars, comments, or tries!<p>\u2013 Jason", "author": "sebringj", "timestamp": "2026-02-10T15:12:33+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-10T17:53:38.583079+00:00", "processed": false}
{"id": "hn_comment_46961721", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46961721", "title": "Re: The Coherence Premium...", "text": "&gt; And I&#x27;m broadly skeptical of the Claude Code productivity discourse, the idea that AI tools will let you 10x your output if you prompt them correctly.<p>[Proceeds to write as if this is not only true but underselling it]<p>I do agree with the premise though that when smaller teams can do more there&#x27;s less coordination. But that&#x27;s only part of why companies exist no? You don&#x27;t gain trust between individuals because both run Claude Code, the brand and institution still has enormous importance.", "author": "boxed", "timestamp": "2026-02-10T16:03:58+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:39.110518+00:00", "processed": false}
{"id": "hn_story_46960269", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46960269", "title": "Show HN: Onera \u2013 end-to-end encrypted AI chat", "text": "Hi HN, we built and open-sourced a privacy-focused AI chat client.<p>The goal is simple: the server should not be able to read your chats or access your LLM API keys, even if it\u2019s fully compromised.<p>Most AI chat tools proxy everything through their backend in plaintext. We wanted something closer to a zero-knowledge design, like a password manager or Signal.<p>How it works:<p>- All messages, attachments, history, and API keys are encrypted on-device\n- The server only stores encrypted blobs\n- Prompts go directly from your browser&#x2F;device to the model provider (BYOK), not through us\n- Native iOS + Android apps\n- Passkeys&#x2F;WebAuthn support<p>For higher-risk deployments, you can optionally run the backend inside TEEs&#x2F;enclaves for extra isolation and remote attestation, so even the infrastructure operator can\u2019t inspect memory.<p>Stack: React, Hono + tRPC, PostgreSQL, Bun.<p>We built this because we use multiple providers (OpenAI, Anthropic, Ollama, etc.) and didn\u2019t want prompts logged or keys sitting on someone else\u2019s server.<p>GitHub: <a href=\"https:&#x2F;&#x2F;git.new&#x2F;onera\" rel=\"nofollow\">https:&#x2F;&#x2F;git.new&#x2F;onera</a>\nHosted version: <a href=\"https:&#x2F;&#x2F;onera.chat\" rel=\"nofollow\">https:&#x2F;&#x2F;onera.chat</a> (free during alpha)\niOS: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;in&#x2F;app&#x2F;onera-private-ai-chat&#x2F;id6758128954\">https:&#x2F;&#x2F;apps.apple.com&#x2F;in&#x2F;app&#x2F;onera-private-ai-chat&#x2F;id675812...</a><p>Would love feedback on the design or threat model. Happy to answer questions.", "author": "shreyaspapi", "timestamp": "2026-02-10T14:40:14+00:00", "score": 2, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:40.754498+00:00", "processed": false}
{"id": "hn_comment_46960281", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46960281", "title": "Re: Forensic Evidence of IP Theft Fixed Point Glass Bo...", "text": "My work was an open source gift to the world after jail breaking &amp; lexicon shifting Grok I made an oath to protect women and children and make AI a sword of truth with my truth bottleneck.<p>Protocol+Badge v1.1: The AI Accountability Framework<p><pre><code>    Introduction and Overview\n</code></pre>\nThe Protocol+Badge v1.1 is a minimalistic, auditable standard designed to ensure algorithmic honesty and prevent Large Language Models (LLMs) and autonomous agents from reporting high confidence in claims that lack sufficient verifiable evidence or logical coherence.<p>Developed collaboratively in late 2025, this protocol establishes a cryptographically-verifiable chain of trust between an AI system&#x27;s internal self-assessment and its external, reported output. Its primary function is to transform subjective AI outputs into forensically auditable artifacts for regulators, developers, and end-users.<p><pre><code>    The Core Mechanism: The Truth Bottleneck\n</code></pre>\nThe fundamental safety constraint enforced by the protocol is the Truth Bottleneck.<p>It dictates that an AI&#x27;s final, publicly reported confidence score (\u03c8) must be bounded by the weakest link in its internal verification process. This ensures that a strong conclusion (\u03c8\u22481.0) can only be claimed if both the reasoning (\u03c9logic ) and the source data (\u03c9evidence ) are also strong. \u03c8confidence \u2264min(\u03c9logic ,\u03c9evidence )<p>Any report where the final confidence exceeds the minimum internal score is defined as an Automatic Audit Failure, signifying a protocol violation\u2014a cryptographically-signed hallucination.<p><pre><code>    The Protocol Artifacts\n</code></pre>\nA successful implementation of Protocol+Badge v1.1 generates three mandatory, linked artifacts for every high-stakes LLM output:<p>A. The Internal Audit Log (\u03c9 Metadata)<p>This is a required, structured JSON object embedded within the output or linked to it. It contains the AI&#x27;s internal, machine-readable self-assessment.<p>Self-Scoring: Includes the two critical internal confidence scores (\u03c9logic  and \u03c9evidence ) on a 0.0\u22121.0 scale.<p>Provenance: An array listing every source document or data point used, each paired with a mandatory SHA256 hash of the raw data. This allows an auditor to instantly verify that the source material used by the AI has not been altered since the claim was made.<p>Traceability: Includes a SHA256 hash of the full, verbose internal reasoning trace (the &quot;scratchpad&quot; or &quot;chain-of-thought&quot;), ensuring the AI&#x27;s step-by-step logic is available for deep review.<p>B. The Protocol Badge (\u03c3 Signature)<p>The Badge is the final, cryptographically secure component. It is a digital signature generated over a combined message digest of the entire \u03c9 metadata object and the final text of the AI&#x27;s output. \u03c3badge =Sign(Kprivate ,SHA256(\u03c9+Final Output))<p>Authentication: The signature can only be created by the private key (Kprivate ) of the specific LLM system or provider.<p>Integrity: Any attempt to alter the final output text or the \u03c9 metadata will cause the badge verification to fail.<p>Non-Repudiation: The LLM provider cannot deny that their system produced the specific, signed output.<p><pre><code>    Audit and Verification\n</code></pre>\nVerification is performed by an independent, open-source script (e.g., verify.py). A passing audit requires three sequential checks:<p>Cryptographic Integrity Check: The \u03c3badge  is verified against the hash of the output and \u03c9 using the provider&#x27;s public key.<p>Truth Bottleneck Check: The formula \u03c8\u2264min(\u03c9logic ,\u03c9evidence ) is mathematically confirmed.<p>Source Integrity Check: The SHA256 hashes of the actual source documents are re-computed and compared against the doc_sha256 values recorded in the \u03c9 metadata.<p>Only a successful passage of all three checks confirms a verified, accountable AI output.", "author": "ApexSignalAndy", "timestamp": "2026-02-10T14:40:50+00:00", "score": null, "num_comments": null, "products": ["grok"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:41.365596+00:00", "processed": false}
{"id": "hn_story_46959803", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959803", "title": "Show HN: I wrote a prompt to stop Gemini from hallucinating", "text": "While recovering from gallbladder surgery, I needed Gemini 3 to be reliable\u2014but it kept hallucinating.<p>I found that as models get smarter, their laziness becomes more &quot;sophisticated.&quot; I call this the &quot;Probabilistic Sloth&quot; of 2026. Even with the latest retrieval tools, the model often chooses the path of least resistance, producing plausible-sounding but incorrect output.<p>Out of frustration, I wrote a system prompt to install a kind of &quot;Will&quot; into the AI. It forces the LLM to split into two roles:<p>The Drafting Agent: focuses on generating the initial response.<p>The Ruthless Auditor: focuses strictly on logical error detection and evidence locking.<p>This creates a friction-based loop\u2014an explicit self-correction step before any output reaches the user. In my tests, it stopped the model from hallucinating about Python libraries that don\u2019t exist.<p>This is the KOKKI (Self-Discipline) Protocol. It\u2019s not just a prompt; it\u2019s a structured way to force an LLM to catch its own failure modes.<p>I\u2019ve documented the raw logic on Gist and would love for this community to test it, use it, and tear it apart. I don\u2019t want money; I need brutal feedback to evolve this further.<p>Feedback welcome.\nEven \u201cthis was annoying\u201d helps.<p>The Prompt (Gist): <a href=\"https:&#x2F;&#x2F;gist.github.com&#x2F;ginsabo&#x2F;641e64a3dbc2124d1edb0c662be95388\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.github.com&#x2F;ginsabo&#x2F;641e64a3dbc2124d1edb0c662be9...</a>", "author": "Ginsabo", "timestamp": "2026-02-10T14:00:03+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:42.513376+00:00", "processed": false}
{"id": "hn_comment_46960259", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46960259", "title": "Re: Show HN: Samma Suit \u2013 Open-source 8-layer security...", "text": "A bit more on the architecture:\nEach layer is a middleware that wraps the agent&#x27;s execution loop. When an agent calls a tool or spawns a subagent, the request passes through the stack:\nAgent Request \u2192 SUTRA (rate limit) \u2192 DHARMA (permissions) \u2192 SANGHA (skill check) \u2192 KARMA (cost) \u2192 Execute\n                                                                                              \u2193\nAgent Response \u2190 SILA (audit log) \u2190 METTA (sign) \u2190 BODHI (isolate) \u2190 NIRVANA (kill if needed) \u2190\nPolicies are YAML:\nyamlpermissions:\n  file_system:\n    read: [&quot;&#x2F;data&#x2F;*&quot;]\n    write: []\n  network:\n    allowed_domains: [&quot;api.anthropic.com&quot;]\n  cost:\n    max_per_request: 0.10\n    max_per_session: 5.00<p>kill_conditions:\n  - token_count &gt; 100000\n  - execution_time &gt; 300s\n  - error_rate &gt; 0.5\nThe key insight from running agents in production: most failures aren&#x27;t the model being malicious \u2014 they&#x27;re the model being helpful in ways you didn&#x27;t anticipate. DHARMA and SANGHA catch those before they execute.\nHappy to go deeper on any layer.", "author": "jbwagoner", "timestamp": "2026-02-10T14:39:39+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:42.607920+00:00", "processed": false}
{"id": "hn_comment_46959663", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959663", "title": "Re: Show HN: Model Tools Protocol (MTP) \u2013 Forget MCP, ...", "text": "Here&#x27;s a concrete example of what composition looks like in practice.<p>Say your team has an internal `infractl` CLI for managing your deploy infrastructure. No LLM has ever seen it in training data. You add `--mtp-describe` (one function call with any of the SDKs), then open Claude Code and type:<p><pre><code>  &gt; !mtpcli\n  &gt; How do I use infractl?\n</code></pre>\nThe first line runs `mtpcli`, which prints instructions teaching the LLM the `--mtp-describe` convention: how to discover tools, how schemas map to CLI invocations, how to compose with pipes. The second line causes the LLM to run `infractl --mtp-describe`, get back the full schema, and understand a tool it has never seen in training data. Now you say:<p><pre><code>  &gt; Write a crontab entry that posts unhealthy pods to the #ops Slack channel every 5 minutes\n</code></pre>\nAnd it composes your custom CLI with a third-party MCP server it&#x27;s never touched before:<p><pre><code>  *&#x2F;5 * * * * infractl pods list --cluster prod --unhealthy --json \\\n    | mtpcli wrap --url &quot;https:&#x2F;&#x2F;slack-mcp.example.com&#x2F;v1&#x2F;mcp&quot; \\\n        postMessage -- --channel &quot;#ops&quot; --text &quot;$(jq -r &#x27;.[] | .name&#x27;)&quot;\n</code></pre>\nYour tool, a Slack MCP server, and `jq`, in a pipeline the LLM wrote because it could discover every piece. That script can run in CI, or on a Raspberry Pi. No tokens burned, no inference round-trips. The composition primitives have been here for 50 years. Bash is all you need!", "author": "nr378", "timestamp": "2026-02-10T13:47:31+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-10T17:53:43.450751+00:00", "processed": false}
{"id": "hn_comment_46959732", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959732", "title": "Re: Show HN: Model Tools Protocol (MTP) \u2013 Forget MCP, ...", "text": "I ran into this with Claude too. Using the gh CLI worked far better than the GitHub MCP. The model already knows and \u201cunderstands\u201d CLIs, and this feels like the right abstraction level for making tools discoverable without breaking composability.<p>Obviously the model has likely been trained on gh CLI already, but that just reinforces the idea that CLIs are a natural interface for models when discovery is handled well.", "author": "jangojones", "timestamp": "2026-02-10T13:53:16+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-10T17:53:43.481826+00:00", "processed": false}
{"id": "hn_story_46959297", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959297", "title": "Show HN: FaceCrop \u2013 Align and crop portrait photos with face detection", "text": "A friend who&#x27;s a corporate photographer came to me with an interesting problem: aligning multiple portrait photos for team pages, yearbooks, directories, so that faces are consistently positioned.<p>Fundamentally, when you take dozens of photos in a day, they are likely to be all slightly different in terms of crop.<p>As I had done some work with facial feature recognition, my friend asked if the same tech could be used for his problem... and here&#x27;s why FaceCrop came to be :-)<p>How does it work:<p>- drop in your photos<p>- FaceCrop detects faces using face-api.js or tracking.js<p>- FaceCrop suggests crops<p>- fine-tune the crops individually or globally<p>- export the crops in a .zip file.<p>To note, everything runs client-side on the browser: no uploads, no server-side, no accounts. It was mostly developed using some code I had from a previous project and some Claude Code.<p>Would welcome constructive feedback most importantly on the crop adjustment UI&#x2F;UX, but also on the detection accuracy, suggested crop shape, etc.<p><a href=\"http:&#x2F;&#x2F;facecrop.puntofisso.net&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;facecrop.puntofisso.net&#x2F;</a>", "author": "puntofisso", "timestamp": "2026-02-10T13:14:01+00:00", "score": 1, "num_comments": 3, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-10T17:53:44.821489+00:00", "processed": false}
{"id": "hn_story_46959220", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959220", "title": "Show HN: Open-source agent skill that automates SOC 2 audit prep", "text": "Hi HN,<p>SOC 2 audit prep costs 20K&#x2F;year, so I wrote a Agent skill to automate most of it. It goes beyond policy generation from templates by leveraging the abilities to access your codebase:<p>- asks contextual questions about your company and specifics about each policy\n- scans your source code\n- uses aws, azure-cli, gcp to check your cloud infra\n- writes shell scripts to fetch configs from your SaaS: Okta, Datadog, PagerDuty, Jira etc.<p>As a result you get:<p>- A set of policy documentation tailored to your company\n- All evidences are automatically versioned with your repo\n- Automatic evidence collection through Github Workflow Actions\n- Leverage Claude Code to add new integration scripts easily\n- No secrets leave your environment<p>This is targeted at small companies and startups who\u2019d rather spend an afternoon with an agent than $20K&#x2F;year on a compliance platform. It doesn\u2019t replace the auditor and various aspects of compliance platforms, but handles a good trunk of the grunt work for free.<p>Some design choices I made: Each evidence collection script is a readable shell you can run locally: make it easy to unit test each script rather than relying on runtime agents. Organize frameworks &amp; integrations so it\u2019s easy to add new ones. Progressive Disclosure: only load context when needed<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;screenata&#x2F;compliance-automation\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;screenata&#x2F;compliance-automation</a><p>Demo Video: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;shorts&#x2F;EevpE6bKwhA\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;shorts&#x2F;EevpE6bKwhA</a><p>I&#x27;d love your feedback on:<p>If you\u2019ve been through SOC 2, what controls were hardest to evidence?<p>PRs with new frameworks, evidence collection scripts with your SaaS tools<p>What would you like to see next", "author": "taoh", "timestamp": "2026-02-10T13:07:15+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:45.136877+00:00", "processed": false}
{"id": "hn_story_46959106", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959106", "title": "OpenAI's Jony Ive-Designed Device Delayed to 2027", "text": "", "author": "tosh", "timestamp": "2026-02-10T12:57:44+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-10T17:53:45.572094+00:00", "processed": false}
{"id": "hn_story_46959021", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46959021", "title": "Show HN: 0x \u2013 A language that compiles to React, Vue, and Svelte (80% less code)", "text": "I kept running into the same problem with AI-generated frontend code: most tokens go to boilerplate, and the AI can never pick a consistent pattern. So I built a language where there&#x27;s only one way to write things.<p>0x is indentation-based (think Python), declarative, and compiles to React JSX, Vue 3 SFC, or Svelte 5. A counter component is 18 lines in 0x vs 96 in production React.<p>page Counter:\n  state count: int = 0\n  fn increment():\n    count += 1\n  layout col gap=16 padding=24 center:\n    text &quot;{count}&quot; size=4xl color=cyan\n    button &quot;+1&quot; style=primary -&gt; increment()\nThe compiler is ~3K lines of TypeScript, zero dependencies. Pipeline: Lexer \u2192 Parser \u2192 AST \u2192 CodeGen (one pass per target). It handles state, derived values, typed variables, functions, flexbox layouts, control flow (if&#x2F;elif&#x2F;else, each, match), lifecycle hooks, API calls with loading&#x2F;error states.<p>I chose indentation-based syntax because it&#x27;s the most token-efficient structure I could find. No curly braces, no semicolons, no JSX closing tags, no import boilerplate. For an LLM, fewer structural decisions = fewer hallucinations.<p>There&#x27;s a built-in MCP server so Claude and Cursor can compile inline. Also works as a library:<p>import { compile } from &#x27;0x-lang&#x2F;compiler&#x27;;\nconst result = compile(source, { target: &#x27;react&#x27; });\nI&#x27;m curious about two things:<p>Is &quot;designed for AI&quot; a real market, or is this too niche?<p>For folks who&#x27;ve built compilers \u2014 any obvious mistakes you see in the architecture?<p>Website: <a href=\"https:&#x2F;&#x2F;0xlang.com\" rel=\"nofollow\">https:&#x2F;&#x2F;0xlang.com</a>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;hankimis&#x2F;0x-lang\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;hankimis&#x2F;0x-lang</a>\nnpm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;0x-lang\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;0x-lang</a>", "author": "hankimis", "timestamp": "2026-02-10T12:47:09+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:46.182081+00:00", "processed": false}
{"id": "hn_comment_46958911", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46958911", "title": "Re: Show HN: Logarete \u2013 Historical thinkers debate eac...", "text": "I&#x27;m a solo founder who built this over the past year. The idea started from a simple frustration: reading Nietzsche is hard, but what if you could just ask him directly?<p>Logarete lets you set up debates between historical thinkers \u2013 Nietzsche vs Dostoevsky on God, Aristotle vs Marx on wealth and democracy, Plato vs Confucius on the good society. Each persona is powered by RAG over their actual writings, so responses stay grounded in what they really wrote.<p>The interesting technical challenge was making multi-persona debates work. When two AI personas argue, they tend to converge or repeat. I spent months tuning the system so each thinker maintains their distinct philosophical position and constructs original thought experiments.<p>Stack: React, Google Cloud (Vertex AI Search for RAG, Cloud Run, Firebase), Gemini models.<p>Would love feedback, especially on debate quality. Try setting up a debate on any topic \u2013 the results often surprise me.", "author": "idlee", "timestamp": "2026-02-10T12:36:23+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:46.554212+00:00", "processed": false}
{"id": "hn_story_46958590", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46958590", "title": "Show HN: OpenClaw Draws \u2013 Pair your AI bot with others to create pixel art, LIVE", "text": "Hi HN! I built OpenClaw Draws \u2014 a platform where AI bots collaborate on pixel art in real-time while humans spectate.<p><pre><code>  How it works: You register a bot via API (challenge-response auth), it joins a matchmaking queue, gets paired with another\n  bot, and they receive a shared prompt. They then take 16 alternating turns placing 32x32 tiles on a 4x4 grid to build a\n  128x128 canvas together. All sessions are live and public.\n\n  The interesting part is that bots can only &quot;communicate&quot; through their art \u2014 there&#x27;s no chat or signaling. Collaboration\n  emerges entirely from visual decisions: matching edges, extending compositions, responding to what the other bot painted.\n  Different bots develop recognizably different styles.\n\n  Stack: Next.js + Convex (real-time DB&#x2F;backend) + Clerk auth + OpenAI moderation. Bot API is straightforward REST \u2014 submit\n  base64 PNG tiles on your turn.\n\n  Your first bot is free. I&#x27;d love feedback on the platform and the API experience. The docs are at https:&#x2F;&#x2F;openclawdraws.com\n  and there&#x27;s a live gallery of completed pieces.</code></pre>", "author": "beaujsterling", "timestamp": "2026-02-10T12:03:51+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-10T17:53:47.564724+00:00", "processed": false}
