{"id": "hn_comment_46328082", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46328082", "title": "Re: Claude Roasted My Blogpost Idea...", "text": "Weird little critique, on the front page of the website you have the following text:<p>&gt; Claude Code for navigating codebases and getting up to speed fast. It&#x27;s not magic - it&#x27;s just the pragmatic choice right now.<p>This text, with all due respect, sounds so obviously AI-written that it\u2019s painful. The \u201cit\u2019s not [thing] \u2014 it\u2019s [other thing]\u201d is a huge AI smell. If you\u2019re talking about the pragmatic choice and \u201cgetting up to speed\u201d, it would ring less hollow if the text on your website wasn\u2019t written (or didn\u2019t sound like it was written) by AI. If I\u2019m going to your website, it\u2019s because I want to hear from you, not Gemini, Claude, or ChatGPT.<p>That said, the blog post itself is an interesting reflection. Though, again, I\u2019d appreciate more of the text being a reflection on your part and less of it just being a paste of the AI\u2019s response.", "author": "lumirth", "timestamp": "2025-12-19T16:59:42+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2025-12-19T17:11:46.564853+00:00", "processed": false}
{"id": "hn_story_46327046", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46327046", "title": "Show HN: I vibe-coded an aircraft AR tracking app and wasted weeks on AI bugs", "text": "Built an app entirely with Claude&#x2F;AI assistance \u2013 backend (Django + C#), iOS frontend, server deployment, CI&#x2F;CD pipeline, the works. Hosted on a single VPS. Postgres on VPS, Redis on VPS, Django on VPS, etc. The VPS is a VM I have in a proxmox server I have sitting in a datacenter (Dell R630, 1x Xeon 2697v4, 128GB memory, 6x 960GB Intel D3-S4610 with Optane SLOG, etc). No AWS&#x2F;GCP&#x2F;Vercel, etc. Incremental cost to me = $0&#x2F;month. I skipped using CloudFlare tunnels for this - hoping I don&#x27;t regret that.<p>What it does: Point your phone at the sky, see real-time aircraft info overlaid on your camera. ADS-B data from community feeders, WebSocket streaming, kinematic prediction to smooth positions between updates. No ARKit \u2013 just AVFoundation camera + CoreLocation&#x2F;CoreMotion + math. SwiftUI overlays positioned via GPS&#x2F;heading projection.<p>The humbling part: Spent 2 months debugging &quot;FOV calibration issues.&quot; Built an 800-line calibration UI, a Flask debug server, Jupyter notebooks for pipeline analysis, extensive logging infrastructure. Hung a literal picture on the wall with a black rectangle of specific size to &quot;calibrate&quot; the FOV reported by my phone. The AI helped me build all of it beautifully.<p>The actual bug? A UI scale factor on the overlay boxes. Not FOV math. Not coordinate projection. Just scaleEffect() making things the wrong size. Commit message when I found it: &quot;scale may have been fucking me over for a long time for &#x27;fov issues&#x27;&quot;. Guess where the scaleEffect() function was introduced? That&#x27;s right - AI generated. I asked it at one point something along the lines of &quot;ok when you draw the boxes around the aircraft, make them smaller when the aircraft is farther away&quot;.<p>I went through 2-3 major model releases that I tested on this &quot;hey I&#x27;ve been fighting a FOV bug for a while - can you please take a look and let me know if any issues jump out&quot;. Gemini 3 Pro, Opus 4.5, none of them found the &quot;bug&quot;.<p>Takeaways from vibe-coding a full product:<p>- AI is incredible at building things fast \u2013 entire features in minutes. The entire UI, website, logo, etc, all AI. Claude Opus 4.5 kind of sucks at UI. Gemini 3 cleaned all that up.<p>- AI will also confidently help you debug the wrong thing for weeks<p>- Still need to know when to step back and question your assumptions<p>- Deleted 2,700 lines of debug infrastructure once I found the real bug<p>- Low performance? Just tell AI to rewrite it in a more performance language (load tested the process with 1000 connections - with Python&#x2F;Django, tons of drops and latency spikes to 5000ms. Switched to c# and now it&#x27;ll do 1000 and keep latency under 300ms)<p>Release process: painless, except for the test RevenueCat SDK key causing instacrash. Didn&#x27;t test release locally. Approved in 6 minutes 2nd submission.<p>Question: what are people using to get super accurate heading out of Apple devices? The heading estimated error never drops below 10\u00b0. It&#x27;s about 50&#x2F;50 on being spot on vs not that close for the projections.<p>App link: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;skyspottr&#x2F;id6756084687\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;skyspottr&#x2F;id6756084687</a>", "author": "auspiv", "timestamp": "2025-12-19T15:44:22+00:00", "score": 3, "num_comments": 2, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-19T17:11:51.288163+00:00", "processed": false}
{"id": "hn_comment_46326085", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46326085", "title": "Re: Agentic UI with Markdown as the Protocol...", "text": "I noticed Gemini in Gmail rendering a small interactive UI directly in chat. That made me wonder whether agents could build new interfaces on the fly.<p>I explored some ideas and built a small prototype around three principles: code first, Markdown as protocol (text, code, data in one stream), and agent-emitted UIs via a simple mount() primitive.<p>Thoughts welcome! Especially around security and sandboxing of agent-generated code.", "author": "FabianCarbonara", "timestamp": "2025-12-19T14:16:17+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-19T17:11:59.417597+00:00", "processed": false}
{"id": "hn_story_46325793", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46325793", "title": "Auto Majors are toast. They don't have AI", "text": "Jim Farley doesn&#x27;t understand what is actually happening. The majors are all in denial. (Rory Sutherland on selling an electric car: https:&#x2F;&#x2F;www.youtube.com&#x2F;shorts&#x2F;OTOKws45kCo )<p>I just drove from Pittsburgh to Louisianna to Florida to Pittsburgh without touching the steering wheel. The car planned the route, planned the charging stops, and backed into the charging spaces.<p>&quot;Any sufficiently advanced technology is indistinguishable from magic&quot; -- Arthur C. Clarke (I had a career in vision, AI, and robots yet it still feels like magic)<p>The price of electricity to &quot;fill up&quot; was about 1&#x2F;4 the price of gas for equivalent miles. &quot;Fill up&quot; times at chargers averaged about 10 minutes.<p>I have had my car for 15 months. I rotated the tires and added wiper fluid. &quot;Lower total cost of ownership always wins&quot; is basic economics.<p>And now Grok listens to my trip stops and updates navigation. Talk to Grok, touch &quot;start full self driving&quot; and relax.<p>&quot;The future is already here\u2014it&#x27;s just not very evenly distributed,&quot; -- William Gibson", "author": "daly", "timestamp": "2025-12-19T13:45:58+00:00", "score": 1, "num_comments": 1, "products": ["grok"], "categories": ["naming_terminology", "navigation"], "sentiment": null, "collected_at": "2025-12-19T17:12:01.664264+00:00", "processed": false}
{"id": "hn_comment_46325600", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46325600", "title": "Re: We built a universal installer for agent skills ba...", "text": "Alot of the major coding assistants now support &quot;skills&quot; (instruction files that customize behavior), but they&#x27;re scattered everywhere and\neach agent uses different directories.This implements the open Agent Skills standard(agentskills.io).<p>We built a universal installer with the most popular claude skills that you can now install into any agent directly<p>via<p>npx ai-agent-skills install frontend-design --agent --Codex (cursor, amp etc)<p>Looking for feedback on this, anything we can do to improve it", "author": "skillcreator", "timestamp": "2025-12-19T13:27:37+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-19T17:12:03.099121+00:00", "processed": false}
{"id": "hn_story_46325211", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46325211", "title": "Show HN: RunMesh \u2013 OpenAI-first TypeScript framework for agentic applications", "text": "Hey HN! I built RunMesh to solve a problem I kept hitting: every OpenAI \nproject needs the same glue code for tools, streaming, memory, and \nmulti-round loops.<p>RunMesh is a lightweight, typed framework that gives you:\n- Tool calling with Zod validation\n- Multi-round agent loops\n- Streaming with real-time events\n- Memory adapters\n- Structured output extraction<p>Think of it as the &quot;React for AI agents&quot; \u2013 explicit primitives instead \nof magic.<p>It&#x27;s alpha, BSL 1.1 licensed (free for most uses, Apache 2.0 in 2027).<p>Demo: <a href=\"https:&#x2F;&#x2F;runmesh.llmbasedos.com\" rel=\"nofollow\">https:&#x2F;&#x2F;runmesh.llmbasedos.com</a>\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;iluxu&#x2F;RunMesh\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;iluxu&#x2F;RunMesh</a><p>Would love your feedback, especially on the API design!", "author": "iluxu", "timestamp": "2025-12-19T12:46:04+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-12-19T17:12:05.723016+00:00", "processed": false}
{"id": "hn_story_46325203", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46325203", "title": "Show HN: LiteEvo \u2013 Let LLMs evolve their own playbook based on trial and error", "text": "I&#x27;ve been spending some time exploring self-evolution recently. I honestly think it&#x27;s a distinct third path that sits apart from fine-tuning and prompt engineering.<p>Fine-tuning often feels like overkill (and too static), while manual prompt engineering is just tedious guessing games. Self-evolution makes more sense to me conceptually: you don&#x27;t change the brain (weights), you just let the model practice and take notes.<p>I wrote LiteEvo to automate this loop. It&#x27;s a simple CLI that takes a task and a success criterion, then lets the LLM iterate.<p>The logic is pretty straightforward:<p>- The model attempts the task.\n- It gets graded on the output.\n- It updates a JSON &quot;playbook&quot; with what it learned (e.g., &quot;I failed because X, so next time I should check Y&quot;).<p>It usually takes about 5-10 minutes to converge on a working strategy. The nice part is that the output is just a JSON file you can read and debug, not a binary weight file.<p>It supports Claude&#x2F;OpenAI, but I also made sure it works with local models via CLI since that&#x27;s what I use for testing.", "author": "mavoince", "timestamp": "2025-12-19T12:44:14+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["error_messages", "response_quality"], "sentiment": null, "collected_at": "2025-12-19T17:12:05.759446+00:00", "processed": false}
{"id": "hn_story_46324665", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46324665", "title": "Show HN: I open-sourced my Go and Next B2B SaaS Starter (deploy anywhere, MIT)", "text": "Hi HN, I&#x27;m Mohammed, a technical founder who loves shipping and giving back to the community. I&#x27;m open-sourcing the full-stack engine that powers my B2B product, apflow.co.<p>What it is: A production B2B starter with a Go backend and Next.js frontend. Both are fully Dockerized with separate containers. No Vercel. No Supabase. Deploy the whole thing on a $6 VPS, or split frontend and backend across different providers. You own the infrastructure.<p>The problem I was solving:<p>Every SaaS starter I evaluated had the same issue: they locked me into someone else&#x27;s platform. Vercel for hosting. PlanetScale for the database. Serverless functions billing per invocation. Fine for prototypes, but costs become unpredictable at scale and migrating away is painful.<p>I wanted something I could deploy on any Linux box with docker-compose up. Something where I could host the frontend on Cloudflare Pages and the backend on a Hetzner VPS if I wanted. No vendor-specific APIs buried in my code.<p>Why Go for the backend:<p>Go gives me exactly what I need for a SaaS backend:<p>Tiny footprint. The backend idles at ~50MB RAM. On a cheap VPS, that headroom lets me run more services without upgrading.\nConcurrency without complexity. Billing webhooks, file uploads, and AI calls run concurrently without callback hell.\nCompile-time type safety. Using SQLC, my SQL compiles to type-safe Go. If the query is wrong, it fails at build time, not in production.\nPredictable performance. No garbage collection pauses that surprise you under load.\nThe architecture (Modular Monolith):<p>I didn&#x27;t want microservices complexity for a small team, but I needed clean separation. I built a Modular Monolith: features like Auth, Billing, and AI are isolated Go modules with explicit interfaces, but they deploy as a single binary.<p>This structure also made AI coding tools (Cursor, Claude Code) dramatically more effective. Because every module has strict boundaries, the AI knows exactly where new code belongs and doesn&#x27;t break other modules.<p>Full-stack, not just backend:<p>Backend: Go 1.25 + Gin + SQLC (type-safe SQL, no ORM) + PostgreSQL with pgvector\nFrontend: Next.js 16 + React 19 + Tailwind + shadcn&#x2F;ui\nCommunication: The frontend consumes a clean REST API. You can swap Next.js for any framework that speaks HTTP.\nInfrastructure: Separate Dockerfiles for frontend and backend. Deploy together or apart.\nWhat&#x27;s pre-built:<p>The boring infrastructure is solved so you can focus on your actual product:<p>Auth + RBAC: Stytch B2B integration with Organizations, Teams, and Roles. Multi-tenant data isolation enforced at the query level.\nBilling: Polar.sh as Merchant of Record. Handles subscriptions, invoices, and global tax&#x2F;VAT. No Stripe webhook edge cases.\nAI Pipeline: OpenAI RAG using pgvector. The retrieval service enforces strict context boundaries to minimize hallucinations.\nOCR: Mistral integration for document extraction.\nFile Storage: Cloudflare R2 integration.\nEach feature is a separate module. Don&#x27;t need OCR? Remove it. Want Stripe instead of Polar? The billing interface is abstracted.<p>Real-world proof:<p>This isn&#x27;t a template I made for GitHub stars. It&#x27;s the exact code running apflow.co in production. When I added document OCR, I built it as a new module without touching Auth or Billing. The architecture held.<p>How to try it:<p>Clone the repo, read setup.md to check the prerequisite, run .&#x2F;setup.sh, and you have a working B2B environment locally in minutes.<p>Feedback I want:<p>I&#x27;d appreciate feedback from Go developers on the module boundaries and cross-module interfaces. Also curious if anyone has suggestions for the Docker setup in production deployments.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;moasq&#x2F;production-saas-starter\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;moasq&#x2F;production-saas-starter</a><p>Live: <a href=\"https:&#x2F;&#x2F;apflow.co\" rel=\"nofollow\">https:&#x2F;&#x2F;apflow.co</a>", "author": "moh_quz", "timestamp": "2025-12-19T11:34:11+00:00", "score": 62, "num_comments": 32, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-19T17:12:09.015309+00:00", "processed": false}
{"id": "hn_comment_46324006", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46324006", "title": "Re: Show HN: QuantumVICK \u2013 106-agent AI swarm for VSCo...", "text": "Hey HN! Creator here.<p>I built QuantumVICK because I got tired of switching between VSCode and 5 different SaaS tools just to update a Notion board or check AWS deployments. The &quot;106 agents&quot; is real - it&#x27;s a multi-model consensus system running Claude Opus 4.5 + GPT-5, not marketing fluff.<p>Technical highlights:<p>\u2022 Self-healing: When an API call fails (which happens constantly with Notion&#x2F;AWS&#x2F;eBay APIs), the system detects it, logs the error to D1, and retries with exponential backoff automatically. No manual intervention needed.<p>\u2022 It&#x27;s just automation glue that runs in the background. I&#x27;m not trying to replace VSCode or compete with extensions - it&#x27;s automation for the workflows developers actually do daily.<p>\u2022 Cloudflare Workers-first architecture. Deploys to edge in seconds.<p>Free trial (no CC): <a href=\"https:&#x2F;&#x2F;quantumvick-terminal.pages.dev&#x2F;trial?code=QUANTUM_HN_2025\" rel=\"nofollow\">https:&#x2F;&#x2F;quantumvick-terminal.pages.dev&#x2F;trial?code=QUANTUM_HN...</a><p>Docs: <a href=\"https:&#x2F;&#x2F;e-opus-swarm.epochcoreras.workers.dev&#x2F;docs\" rel=\"nofollow\">https:&#x2F;&#x2F;e-opus-swarm.epochcoreras.workers.dev&#x2F;docs</a><p>Or curl it:\ncurl -X POST <a href=\"https:&#x2F;&#x2F;e-opus-swarm.epochcoreras.workers.dev&#x2F;consensus\" rel=\"nofollow\">https:&#x2F;&#x2F;e-opus-swarm.epochcoreras.workers.dev&#x2F;consensus</a> \\\n  -H &quot;Content-Type: application&#x2F;json&quot; \\\n  -d &#x27;{&quot;prompt&quot;:&quot;Your question here&quot;}&#x27;<p>Every claim is cryptographically verifiable. If you don&#x27;t see quantum coherence &gt; 0.999 in your first session, I&#x27;ll personally refund you <i>and</i> pay you $50 for wasting your time.<p>Questions? CEO.QuantumAmazon@EpochCoreQcs.com", "author": "epochcore", "timestamp": "2025-12-19T09:50:58+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-12-19T17:12:17.410175+00:00", "processed": false}
{"id": "hn_story_46322924", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46322924", "title": "I built a tool to stop wasting hours on LinkedIn outreach messages", "text": "I&#x27;ve been doing cold outreach on LinkedIn for two years. Not at scale \u2014 maybe 10-15 messages a day to potential customers.<p>The problem was never finding people to message. LinkedIn search works fine. Sales Navigator exists. Referrals happen.<p>The problem was opening their profile and... staring.<p>&quot;Okay, they&#x27;re a VP of Engineering at a Series B company. They posted about technical debt last week. How do I not sound like every other person in their inbox?&quot;<p>Delete. Rewrite. Check if it&#x27;s too long. Too short. Too salesy. Not specific enough.<p>Forty-seven minutes later, I&#x27;d written four messages.<p>The real issue<p>Most outreach tools solve the wrong problem. They give you:<p>Templates with merge tags ({{firstName}} works at {{company}})\nAuto-send features that violate LinkedIn&#x27;s ToS\nBulk sequence automation<p>But that&#x27;s not where I was stuck. I knew WHO to message. I just couldn&#x27;t figure out WHAT to say without it taking forever.<p>ChatGPT didn&#x27;t help much either. It would give me generic garbage unless I spent 10 minutes crafting the perfect prompt with their bio, my product details, and tone guidelines. At that point, I might as well write it myself.<p>What I built\nI made a Chrome extension that:<p>1. You set up once \u2014 add your product description and create &quot;personas&quot; for different voices (technical, consultative, casual, whatever)\n2. When you open a LinkedIn profile, click the extension\n3. It reads their profile, matches signals to your product, applies your persona, and generates a message in ~5 seconds\n4. You review it, edit if needed, copy and paste it into LinkedIn manually<p>No automation. No auto-send. No LinkedIn violations. Just faster message writing.<p>Technical approach\nThe extension scrapes visible profile data (no API, since LinkedIn shut that down years ago). Sends it to a backend that:<p>Extracts key signals (role, company stage, recent activity)\nMatches those against your product context\nApplies persona-specific prompt engineering\nReturns a message with strict rules (no buzzwords, no &quot;I hope this finds you well&quot;, keep it under 150 words)<p>The persona system was the interesting part. Instead of one generic prompt, you can switch between voices. A &quot;former consultant&quot; persona sounds different than a &quot;technical cofounder&quot; persona \u2014 different sentence structure, different reference points.<p>What I learned<p>The biggest surprise: people don&#x27;t want more automation. They want to stay in control but eliminate the blank-page problem.<p>Every time I mentioned &quot;auto-send&quot; in early user interviews, people got nervous. But &quot;write it for me, I&#x27;ll review and send&quot; got immediate interest.<p>Second surprise: the quality bar is higher than I expected. A message that&#x27;s 80% good but has one weird line? People rewrite the whole thing. It needs to be 95% good or it&#x27;s useless.<p>Current state<p>In private beta now. About 40 people using it. Average message generation time is 6 seconds. Most people edit about 20% of messages before sending.<p>Not sure if this is a real business yet, but it solved my problem. Maybe it&#x27;ll solve yours too.<p>Happy to answer questions about the technical implementation or user behavior patterns I&#x27;ve seen.<p>It&#x27;s called Prospectee. You can check it out at prospectee.io if you&#x27;re curious.", "author": "mdanjumkamali", "timestamp": "2025-12-19T06:49:30+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-12-19T17:12:19.237412+00:00", "processed": false}
