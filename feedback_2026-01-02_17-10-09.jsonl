{"id": "hn_comment_46466594", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46466594", "title": "Re: We need to talk about Claude's 'soul' document...", "text": "Nice piece.<p>Computers used to be like dogs. You could teach them some really cool tricks. We enjoyed the accomplishment, and appreciated the tricks. But, dogs are dogs. Essentially, even as much as one might love them, they&#x27;re just property.<p>Now, computers have a soul; they&#x27;re persons? Maybe not by definition, but that belief would seem to foreclose the property argument. One can destroy property, but one ought to shy away from destroying persons. Well, anyway, I think one should.<p>If someone pulled the plug on Claude, what does that mean, ethically?", "author": "kayo_20211030", "timestamp": "2026-01-02T16:44:33+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["naming_terminology"], "sentiment": null, "collected_at": "2026-01-02T17:10:12.978586+00:00", "processed": false}
{"id": "hn_comment_46466868", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46466868", "title": "Re: Ask HN: Who is hiring? (January 2026)...", "text": "Goody | Remote | $200\u2013250K + equity and benefits | Full-time<p>Goody is hiring a full-stack Staff Software Engineer who likes to ship at a startup pace and has an eye for exceptional UI&#x2F;UX.<p>I&#x27;m Mark, the technical co-founder and CTO at Goody. Despite being something everyone does, gifting is one of the areas of commerce yet to be disrupted. Our goal is to make people&#x27;s days by making gifting easy, while building a sustainable business on that market opportunity.<p>We&#x27;re looking for engineers who like to build at a startup pace, have a critical eye for detail and user experience, and thrive when given autonomy and ownership.<p>Our product is used by Google, Stripe, Anthropic, Meta, NBCUniversal, Notion, and others, and we also offer a developer API for commerce.<p>Check out our jobs minisite at <a href=\"https:&#x2F;&#x2F;jobs.ongoody.com&#x2F;swe\" rel=\"nofollow\">https:&#x2F;&#x2F;jobs.ongoody.com&#x2F;swe</a> and feel free to email me at mark@ongoody.com.", "author": "markbao", "timestamp": "2026-01-02T17:06:18+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-02T17:10:14.046195+00:00", "processed": false}
{"id": "hn_comment_46466882", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46466882", "title": "Re: Vibe Coding Killed Cursor...", "text": "&gt; The context is king<p>Agree<p>&gt; and AI Studio is the only serious product for human-in-the-loop SWE<p>Disagree. I use Claude Code and Codex daily, and I couldn\u2019t be happier. Had started with Cursor, switched to CLI based agents and never looked back. I use WezTerm, tmux, neovim, Zoxide, and create several tabs and panes and run claude code not only for vibe coding, scripting, analysing files, letting it write concepts, texts, documentation. Totally different kind of computing experience. As if I have several assistants 24&#x2F;7 at my fingertips.", "author": "submeta", "timestamp": "2026-01-02T17:07:47+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-02T17:10:18.121216+00:00", "processed": false}
{"id": "hn_story_46464606", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46464606", "title": "Show HN: Vibora \u2013 Run Claude Code remotely, close your laptop, keep shipping", "text": "I built Vibora because I wanted more than a UI to orchestrate multiple Claude Code sessions \u2014 I wanted to kick off work, close my laptop, and check progress from my phone while I&#x27;m out. You don&#x27;t need to run it remotely. Vibora is still incredibly useful running on your laptop. But once you get used to telling Claude to work on a feature, notify you when it&#x27;s finished, and getting that first notification 20 minutes later \u2014 you won&#x27;t want to go back.<p>Vibora is a self-hosted web app that orchestrates Claude Code across isolated git worktrees. You&#x27;ve seen this before. Each task is its own kanban card with its own AI agent. Part of what makes Vibora unique is each task is an actual terminal running unmodified Claude Code. No wrapper APIs, no chat abstraction built on the Agent SDK \u2014 just raw Claude Code in xterm.js.<p>What makes Vibora different from similar tools:<p>- *Client-server architecture*: Run the backend on a VPS or home server. Connect from anywhere. Your agents don&#x27;t die when you close your laptop.\n- *Deep Claude Code integration*: Bundled plugin with skills, MCP server, and slash commands. Claude can manage tasks, query status, and send notifications \u2014 all from within the terminal. The MCP server even lets Claude execute commands on your remote machine through SSH port forwarding. No other tool has this level of native integration.\n- *Production deployment built-in*: Deploy Docker Compose apps with Traefik routing and Cloudflare DNS integration. Go from task to production without leaving the UI.\n- *Intentionally minimal*: No swarm intelligence, no 100+ MCP tools, no auto-generated roadmaps. Just parallel Claude Code sessions you control.\n- *Desktop app*: Native macOS and Linux apps that bundle everything \u2014 just install and run.\n- *z.ai integration*: Use Claude Code at a fraction of the cost if you&#x27;re willing to make the tradeoff.<p>The philosophy: today&#x27;s bottleneck isn&#x27;t AI capability \u2014 it&#x27;s your time and attention. Vibora doesn&#x27;t try to replace your workflow or make decisions for you. It just gives you better leverage.<p>Built with Bun, React, SQLite. Runs on a $5 VPS. Ships as a CLI (`npx vibora@latest up`) and desktop app.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;knowsuchagency&#x2F;vibora\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;knowsuchagency&#x2F;vibora</a><p>Documentation: <a href=\"https:&#x2F;&#x2F;vibora.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;vibora.dev</a><p>Demo screenshots in the README.", "author": "knowsuchagency", "timestamp": "2026-01-02T13:37:36+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-02T17:10:25.298272+00:00", "processed": false}
{"id": "hn_story_46462910", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46462910", "title": "I'm building a 30k\u2011line V12 codebase solo with a \"team\" of 4 AIs", "text": "I\u2019m a solo developer working on a \u201ccomplex systems measurement\u201d project that has grown to over 30k lines of code and is now at V12. Every line so far has been written by one person (me), with the research notes and design docs in a separate repo: https:&#x2F;&#x2F;github.com&#x2F;Garylauchina&#x2F;Prometheus-Research.<p>I\u2019ve been using Cursor heavily along the way. The models are genuinely good and the local code they generate is often excellent, but on a large, evolving codebase I kept running into the same problem: context limits caused subtle architectural drift. The AI would write clean functions that were globally wrong, quietly breaking earlier design decisions and long\u2011range invariants.<p>What finally helped was to stop treating \u201cAI\u201d as a single assistant and instead treat different models as different team members with clear roles and constraints.<p>My current setup looks like this:<p>Perplexity + ChatGPT \u2192 \u201cproduct &#x2F; research brains\u201d\nI use them for requirements, trade\u2011offs, and high\u2011level architecture sketches. They live outside the IDE and exist to clarify what I\u2019m building and why before any code is touched.<p>Cursor, window 1 (GPT\u20115.2) \u2192 \u201carchitect\u201d\nThis instance is not allowed to write production code. It is responsible for architecture and module boundaries, writing design notes and developer guides, defining interfaces and contracts, and reviewing diffs. I treat it like a senior engineer whose main output is prose: mini\u2011RFCs, comments, and checklists.<p>Cursor, window 2 (Sonnet 4.5) \u2192 \u201cprogrammer\u201d\nThis one only implements tasks described by the architect: specific files, functions, and refactors, following explicit written instructions and style rules. It doesn\u2019t get to redesign the system; it just writes the code.<p>The key rule is: architect always goes first. Every non\u2011trivial change starts as text (design notes, constraints, examples), then the \u201cprogrammer\u201d instance turns that into code.<p>This simple separation fixed a lot of the weirdness I was seeing with a single, all\u2011purpose assistant. There is much less logical drift, because the global structure is repeatedly restated in natural language. The programmer only ever sees local tasks framed inside that structure, so it\u2019s harder for it to invent a new accidental architecture. The codebase, despite being tens of thousands of lines, feels more coherent than earlier, smaller iterations.<p>It also changed how I think about Cursor. Many of my earlier \u201cCursor is dumb\u201d moments turned out to be workflow problems: I was asking one agent, under tight context limits, to remember architecture, requirements, and low\u2011level implementation all at once. Once I split those responsibilities across different models and forced everything through written instructions, the same tools started to look a lot more capable.<p>This isn\u2019t a Cursor ad, and it\u2019s not an anti\u2011Cursor rant either. It\u2019s just one way to make these tools work on a large solo project by treating them like a small team instead of a single magical pair\u2011programmer.<p>One downside of this setup: at my current pace, Cursor is happily charging me something like $100 a day. If anyone from Cursor is reading this \u2013 is there a \u201csolo dev building absurdly large systems\u201d discount tier I\u2019m missing?", "author": "garylauchina", "timestamp": "2026-01-02T09:08:39+00:00", "score": 7, "num_comments": 5, "products": ["chatgpt", "perplexity"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-02T17:10:37.214781+00:00", "processed": false}
{"id": "hn_comment_46463811", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46463811", "title": "Re: Setting up a new PC used to be fun, now it is ad-r...", "text": "A nice tip: make sure to install the LTSC version of Windows 10, which is the most perfect setup you&#x27;ll ever have (well, other than installing Linux)<p>No Cortana, no Copilot, no Windows Apps. Just pure unadulterated Windows, with extended support until 2032 (if you install the IOT version)", "author": "cyber_kinetist", "timestamp": "2026-01-02T11:40:04+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-02T17:10:37.622101+00:00", "processed": false}
{"id": "hn_comment_46462535", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46462535", "title": "Re: How do you realistically render RAL colors on alum...", "text": "Hi HN Community! This is my first time sharing here, so be gentle :O :D<p>My wife and I are building a house, and as many enw house owners, we are shocked by the amount of choices we have to make. Not a bad thing per se, but in general, it is quite disheartening when you see it.<p>One of the choices we have to make are window and door material and color. We are on the fence between going all white uPVC or going for RAL colored aluminium. And here lies the problem \u2013 we don&#x27;t have a way to see how the RAL colors appear on aluminium.<p>Most, if not all, new builds around use use anthracite (RAL 7016), which we dislike, and we are limited to trying to find examples online with Pinterest and Instagram. Unfortunately, we are quite sure that many images we encounter are mislabeled and showing a different RAL color under a different code.<p>This has led to me trying to build something to help us visualise the colors. Well, a software engineer tries to solve everything with software eventually. I built something, and it is live here <a href=\"https:&#x2F;&#x2F;protabula.com&#x2F;en\" rel=\"nofollow\">https:&#x2F;&#x2F;protabula.com&#x2F;en</a> but I am not happy with the way the colors are rendered.<p>This is my rendering &quot;pipeline&quot;, summarised by Claude. I use a base render image and a black and white mask image to isolate the areas that need coloring:<p><pre><code>  Applies RAL colors to pre-rendered house scenes using ratio-based tinting in linear RGB:\n\n  1. Load base scene + pixel mask\n  2. Convert target color to linear RGB (gamma decode)\n  3. Compute adaptation ratio: targetChannel &#x2F; neutralBaseChannel\n  4. For each pixel: tintedChannel = baseChannel \u00d7 ratio\n  5. Blend by mask strength to preserve highlights\n  6. Convert back to sRGB (gamma encode)\n\n  Uses adaptive neutral base selection (lighter neutral for light colors, darker for dark).\n</code></pre>\nDo you have experience with this? Does anyone know how to render the colors better? Any suggestions on how to do mapping? Is there some library of materials online that I am not aware of that includes RAL colors? Should I switch to 3d rendering?<p>Thanks in advance, sorry for the lengthy post, and I hope you have a great New year!", "author": "apavlinovic", "timestamp": "2026-01-02T08:06:24+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["onboarding", "navigation"], "sentiment": null, "collected_at": "2026-01-02T17:10:40.244086+00:00", "processed": false}
{"id": "hn_story_46462517", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46462517", "title": "Building a company where AI runs operations, not just assists", "text": "<p><pre><code>  I&#x27;m running an experiment.\n\n  A few weeks ago I built 60% of a legal management platform (lex-pro.co) using only Claude Code. Colombian market, real users. I couldn&#x27;t believe how far I got.\n\n  So I&#x27;m stretching it further.\n\n  The goal: a &quot;morning ritual&quot; where I check in once a day to make decisions. AI handles everything else - product development, deployments, customer support, operations.\n\n  Not AI-assisted. AI leading.\n\n  The first problem: AI is blind. Claude can debug code, but only if it can see it. Can help customers, but only if it has context. Right now I&#x27;m the bottleneck, copy-pasting everything.\n\n  So step one: build the infrastructure that gives AI eyes.\n\n  That&#x27;s Brainz Lab (github.com&#x2F;brainz-lab) - self-hosted observability tools with native MCP support. Logs, errors, APM, feature flags, secrets. Claude can query everything directly.\n\n  Tech stack: Rails 8, PostgreSQL + TimescaleDB, Hotwire. Runs via docker-compose.\n\n  This isn&#x27;t Lovable or Bolt (type a sentence, get an app). This is trying to answer: can one person + AI actually run a company? Not a demo. A real business.\n\n  Building in public. Happy to discuss the approach, tech decisions, or why this might be crazy.</code></pre>", "author": "brainz_cto", "timestamp": "2026-01-02T08:03:06+00:00", "score": 4, "num_comments": 1, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-02T17:10:40.803030+00:00", "processed": false}
{"id": "hn_comment_46462116", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46462116", "title": "Re: Show HN: A small game localization tool for indie ...", "text": "Hi HN,\nI&#x27;m a new indie game developer, and I needed a localization tool for my own game.\nMost existing solutions I tried were either too expensive at scale, or hard to control\n(especially when it comes to preserving code tags and custom formatting).<p>So I built a small localization tool around the Gemini API.<p>I&#x27;m not a professional Python developer \u2014 I designed the logic myself\n(regex-based tag protection, glossary handling, cost tracking),\nand used Gemini to help generate the actual code.\nSo in a way, this is a tool wrapping Gemini, built with Gemini.<p>For my use case, the biggest wins are:\n- Reliable tag &#x2F; placeholder protection\n- Simple glossary support\n- Predictable and very low cost<p>In terms of cost, translating ~10k lines comes out to around $0.60 using Gemini Flash Lite,\nwhich works well enough for my workflow.\nI&#x27;ve translated 2000+ lines so far for my tactics game and my friend&#x27;s game.<p>(Windows .exe included for non-Python users)<p>Hope this is useful to other indie devs dealing with localization.\nHappy to answer questions or hear feedback.", "author": "GardenAtDesk", "timestamp": "2026-01-02T06:50:21+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-02T17:10:42.712939+00:00", "processed": false}
{"id": "hn_comment_46461951", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46461951", "title": "Re: I'm a developer for a major food delivery app...", "text": "Trying to find any hints of this elsewhere online as I\u2019m inherently skeptical of posts such as this. This is what I have found, take it for what it is. Sorry for any formatting or spelling. It\u2019s 1:15am and I\u2019m scrolling HN rather than sleeping.<p>I don\u2019t know why but I always just assumed priority delivery meant \u201cfaster\u201d. It doesn\u2019t.<p>&gt; If you select the Priority Delivery option, a Priority Fee will be added on top of the delivery fee for your order to be dropped off first in case of a batched delivery.<p>So, I\u2019m guessing, if you are in a batched delivery of priority orders you are paying for normal service. [0][1]<p>Looking at the DoorDash blog, they are constantly running experiments so none of this really shocks me.<p>&gt; At the time of writing, we run about one thousand experiments per year, including 30 concurrently running switchback experiments, which make up to 200,000 QPS of bucket evaluations. [2]<p>Regarding the desperation score: algorithmic wage discrimination appears very well studied and verified. [3][4]<p>The delivery fees to pay for lobbying efforts is very well covered apparently.<p>&gt; In an earnings call last month, DoorDash executives told investors that the number of commission caps more than doubled from August, when there were 32, to December, when there were 73. Still more have been added since then. Localities that imposed caps are small cities like Pacific Grove, California, and larger cities like Oakland; some are entire states, like Oregon and Washington. Prabir Adarkar, the company&#x27;s chief financial officer, said the company made $36 million less in revenue during the last three months of 2020 because of the new limits.<p>&gt; DoorDash executives have argued that they have no financial choice but to fight back by adding fees in jurisdictions where there are caps.<p>&gt; In Oakland, according to the city&#x27;s online lobbyist database, DoorDash now has a dedicated representative registered with the city for the first time. Other lobbyists for DoorDash are handling efforts for multiple cities. On March 15, Chad Horrell, a lobbyist for DoorDash, left nearly identical public comment voicemails for the city councils in Akron, Ohio, and Huntington Beach, California. [5]<p>&gt; Uber, Lyft, DoorDash, and other gig companies who authored and advertised Proposition 22 spent a record $200 million on the ballot initiative to persuade Californians to vote it into law. In the weeks leading up to the 2020 general election, Uber and Lyft bombarded its riders and drivers with endless messaging through its apps and by saturating the television and digital ad space. [6]<p>The section on companies subsidizing pay looks to have been proven in court multiple times and led to millions in settlements.<p>&gt; On Feb. 24, New York Attorney General Letitia James said in a press release that between May 2017 and September 2019, an Office of the Attorney General (OAG) investigation found that the delivery platform \u201cused customer tips to offset the base pay it had already guaranteed to workers, instead of giving workers the full tips they rightfully earned.\u201d<p>&gt; Attorney General Karl A. Racine today announced a $2.54 million settlement with Instacart, an online delivery company, resolving a lawsuit alleging that the company misled DC consumers, used tips left for workers to boost the company\u2019s bottom line, and failed to pay required sales taxes. [8]<p>[0] <a href=\"https:&#x2F;&#x2F;help.uber.com&#x2F;ubereats&#x2F;restaurants&#x2F;article&#x2F;how-the-different-delivery-options-work?nodeId=b11a4cf0-efb6-4334-96b4-b6ad34481253\" rel=\"nofollow\">https:&#x2F;&#x2F;help.uber.com&#x2F;ubereats&#x2F;restaurants&#x2F;article&#x2F;how-the-d...</a><p>[1] <a href=\"https:&#x2F;&#x2F;www.uberpeople.net&#x2F;threads&#x2F;angry-uber-eats-customers-pay-for-priority-delivery-then-both-get-dispatched-to-me-in-a-batch-order.458542&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.uberpeople.net&#x2F;threads&#x2F;angry-uber-eats-customers...</a><p>[2] <a href=\"https:&#x2F;&#x2F;careersatdoordash.com&#x2F;blog&#x2F;the-4-principles-doordash-used-to-increase-its-logistics-experiment-capacity-by-1000&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;careersatdoordash.com&#x2F;blog&#x2F;the-4-principles-doordash...</a><p>[3] <a href=\"https:&#x2F;&#x2F;www.columbialawreview.org&#x2F;content&#x2F;on-algorithmic-wage-discrimination&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.columbialawreview.org&#x2F;content&#x2F;on-algorithmic-wag...</a><p>[4] <a href=\"https:&#x2F;&#x2F;www.hrw.org&#x2F;report&#x2F;2025&#x2F;05&#x2F;12&#x2F;the-gig-trap&#x2F;algorithmic-wage-and-labor-exploitation-in-platform-work-in-the-us\" rel=\"nofollow\">https:&#x2F;&#x2F;www.hrw.org&#x2F;report&#x2F;2025&#x2F;05&#x2F;12&#x2F;the-gig-trap&#x2F;algorithm...</a><p>[5] <a href=\"https:&#x2F;&#x2F;www.nbcnews.com&#x2F;news&#x2F;amp&#x2F;ncna1262088\" rel=\"nofollow\">https:&#x2F;&#x2F;www.nbcnews.com&#x2F;news&#x2F;amp&#x2F;ncna1262088</a><p>[7] <a href=\"https:&#x2F;&#x2F;www.today.com&#x2F;food&#x2F;news&#x2F;doordash-settlement-payout-rcna193728\" rel=\"nofollow\">https:&#x2F;&#x2F;www.today.com&#x2F;food&#x2F;news&#x2F;doordash-settlement-payout-r...</a><p>[8] <a href=\"https:&#x2F;&#x2F;oag.dc.gov&#x2F;release&#x2F;ag-racine-announces-instacart-must-pay-254-million\" rel=\"nofollow\">https:&#x2F;&#x2F;oag.dc.gov&#x2F;release&#x2F;ag-racine-announces-instacart-mus...</a>", "author": "LostMyLogin", "timestamp": "2026-01-02T06:14:37+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["error_messages", "onboarding", "navigation"], "sentiment": null, "collected_at": "2026-01-02T17:10:46.224754+00:00", "processed": false}
{"id": "hn_comment_46461322", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46461322", "title": "Re: Proteus: The AI-native editor for multimodal creat...", "text": "I&#x27;m building Proteus, an open-source multimodal editor (think Figma meets Notion, but AI-native) where *AI writes most of the code* while I focus on architecture, technical decisions, and quality control.<p>*Why this matters:*<p>In 2025, tools like Cursor and Claude can write good enough code in 80% of scenarios. The question isn&#x27;t &quot;Can AI code?&quot; but &quot;What becomes valuable when AI can code?&quot; I believe it&#x27;s *system design, technical decision-making, and end-to-end ownership*\u2014not just knowing APIs.<p>*What makes this different:*<p>- *AI-native from day one*: Every architectural decision prioritizes AI-friendliness. This isn&#x27;t AI bolted on later\u2014it&#x27;s designed for AI collaboration from the first line.\n- *Fully transparent*: All code, architecture decisions, and lessons learned are public. I&#x27;m documenting the entire journey in weekly technical articles.\n- *Real editor, not a toy*: Phase 1 is complete with a working demo. You can create shapes, text, images, transform them, copy&#x2F;paste, undo&#x2F;redo\u2014all the core editor capabilities.\n- *Learning resource*: If you want to understand how editors work (scene graphs, rendering, interaction systems) or how to structure code for AI collaboration, this is a live case study.<p>*Current status:*<p>Phase 1: Core editing (scene graph, rendering, interaction, tools)  \n Phase 2: Multimodal elements (video, audio, web embeds)  \n Phase 3: AI Agent integration (natural language \u2192 editor actions)  \n Phase 4: Real-time collaboration<p>*Try it:* [Live Demo](<a href=\"https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;proteus.gezilinll.com&#x2F;</a>)  \n*Code:* [GitHub](<a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus</a>)  \n*Articles:* [Tech Blog](<a href=\"https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gezilinll&#x2F;Proteus&#x2F;tree&#x2F;main&#x2F;articles</a>) (4 articles so far, covering architecture, rendering, interaction design)<p>*The experiment:* What happens when you stop reviewing AI&#x27;s code and instead focus entirely on architecture, problem diagnosis, and guiding AI through testing and context-building? That&#x27;s what I&#x27;m exploring here.<p>Would love feedback from the HN community\u2014especially from those building complex frontend apps or thinking about AI-native development workflows.", "author": "gezilinll", "timestamp": "2026-01-02T04:12:22+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-02T17:10:47.825761+00:00", "processed": false}
