{"id": "hn_story_46708613", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46708613", "title": "Show HN: Rowboat \u2013 Open-Source Claude Cowork with an Obsidian Vault", "text": "Claude Cowork just launched, bringing agentic AI to everyday work. Rowboat is an open-source alternative that builds knowledge that persists over time.<p>A quick demo is here: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;T2Bmiy05FrI\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;T2Bmiy05FrI</a><p>It connects to Gmail and meeting notes (Granola, Fireflies) and organizes them into an Obsidian-compatible vault. Plain Markdown files with backlinks, organized around things like people, projects, organizations, and topics. As new emails and meetings come in, the right notes update automatically.<p>Rowboat is also the primary interface for this vault. You can read, navigate, edit, and add notes directly. It includes a full markdown editor and graph visualization so you can see how context builds up across conversations.<p>Why not just search transcripts when you need something? Search only answers the questions you think to ask. A system that accumulates context over time can track decisions, commitments, and relationships across conversations, surfacing patterns you didn\u2019t know to look for.<p>Once this context exists, it becomes knowledge that Rowboat can work with. Because it runs on your machine, it can work directly with local files and run shell commands or scripts, including tools like ffmpeg when needed.<p>The link in the title opens an interactive example graph showing how context accumulates across emails and meetings. We used a founder example because it naturally includes projects, people, and long-running conversations, but the structure applies to any role.<p>Examples of what you can do with Rowboat: draft emails from accumulated context, prep for meetings by assembling past decisions and enriching them with external research (for example via Exa MCP), organize files and project artifacts on your machine as work evolves, or turn notes into voice briefings via MCP servers like ElevenLabs.<p>We\u2019re opinionated about noise. We prioritize recurring contacts, active projects, and ongoing work, and ignore one-off emails and notifications. The goal is long-lived knowledge that compounds over time.<p>All data is stored locally as plain Markdown. You can use local models via Ollama or LM Studio, or a hosted model. Apache-2.0 licensed.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;rowboatlabs&#x2F;rowboat\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;rowboatlabs&#x2F;rowboat</a><p>Curious how this fits into your current workflow for everyday work.", "author": "segmenta", "timestamp": "2026-01-21T17:22:12+00:00", "score": 5, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:21.011272+00:00", "processed": false}
{"id": "hn_story_46708299", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46708299", "title": "Genie AI Is Hiring a Founding Engineer/ CTO(AI Social Media Copywriting Systems)", "text": "Genie AI is an early-stage product that generates social media content using AI. We focus on multi-frame posts like carousels and threads, creating content that maintains structure, pacing, and brand voice rather than generic outputs.<p>This role is about designing the core AI system that powers copy generation. It is not an infra-only role, not a prompt-only role, and not about single-line captions. The work involves translating persuasion and human judgment into scalable AI systems.<p>The position starts as fractional&#x2F;consulting with a clear path to a full-time leadership or CTO role for the right person.<p>## Responsibilities\n- Design and build AI systems for multi-frame social media copy  \n- Implement pipelines, routing, constraints, and evaluation layers  \n- Work directly with LLM APIs (OpenAI, Anthropic, etc.)  \n- Diagnose and fix why AI outputs fail at a system level  \n- Define quality standards for shippable outputs  \n- Collaborate with product and strategy as the system evolves<p>## Who we\u2019re looking for\n- Experience building AI systems for multi-frame social media content  \n- Ability to preserve hooks, pacing, and narrative flow across sequential posts  \n- Can improve output quality through system design, not just prompts  \n- Able to build production-level systems  \n- Understand persuasion, copywriting, and human judgment in addition to LLM mechanics  \n- Take ownership of outcomes and quality<p>## Not a fit if\n- AI experience is limited to single captions, blogs, or generic content  \n- You focus only on backend infrastructure or DevOps  \n- You mainly identify as a prompt engineer  \n- You need very detailed specs before starting work  \n- You are only interested in short-term freelance projects<p>## Technical requirements\n- Production software experience  \n- Hands-on with LLM APIs  \n- Experience building internal tools, products, or SaaS  \n- Can design modular systems with evaluation logic and feedback loops<p>## How to apply\nSubmit a short Loom video including:  \n- Your background  \n- An AI system you\u2019ve built for multi-frame or sequential social content  \n- Your experience with LLMs  \n- Your answer to: <i>Why does most AI-generated copy feel generic, and how would you design a system to fix it?</i><p>Applications without a Loom video or a relevant system example will not be considered.", "author": "paulhilse", "timestamp": "2026-01-21T16:59:32+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:22.519264+00:00", "processed": false}
{"id": "hn_story_46707712", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46707712", "title": "Show HN: Unified Python SDK for Multimodal AI (OpenAI, ElevenLabs, Flux, Ollama)", "text": "", "author": "Kamilbenkirane", "timestamp": "2026-01-21T16:15:18+00:00", "score": 5, "num_comments": 2, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-21T17:45:26.732831+00:00", "processed": false}
{"id": "hn_comment_46707626", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46707626", "title": "Re: Open-source toolkit for enterprise-ready AI develo...", "text": "We listened to customers as they refined their AI strategies in response to the rapid evolution of LLMs, Agentic AI and integration technologies such as the Model Context Protocol (MCP), and as we did so a few things stood out to us.<p>First and foremost, many of the newly available tools and technologies are not suited to the needs of the enterprise, particularly in highly regulated industries or major government agencies. Many of the new AI application builders and code generators \u2013 and the database platforms supporting them \u2013 do not adequately address enterprise requirements for high availability, data sovereignty, global deployment, security and compliance and the need in some cases to run on-premises or in self-managed cloud accounts. As one CIO from a large financial services firm put it to us recently: \u201cWe\u2019ve got a couple of dozen AI generated applications end users really want to put into production, but first we\u2019ve got to figure out how to deploy them on our own internal compliant infrastructure.\u201d<p>Secondly, as compelling as it is to automate workflows with Agentic AI, or to generate new applications with tools like Claude Code, Replit, Cursor or Lovable, the biggest need is to work with existing databases and applications. While some of the newer Postgres-based cloud services work well with Agentic AI and AI app builders for brand new applications they cannot accommodate existing databases and applications without a costly migration \u2013 and perhaps to an environment that doesn\u2019t meet the organization\u2019s strict security and compliance requirements. Enterprise customers need AI tooling \u2013 including an MCP Server \u2013 that can operate against their existing databases.<p>Additionally we saw there was no dedicated Postgres vendor offering a fully featured and fully supported MCP Server that works with all your existing Postgres databases. Most of the available Postgres MCP Servers are tied to the vendor&#x27;s own products, and in particular their cloud database offering.<p>And thirdly, developing new AI applications such as a chatbot running on top of an existing knowledge base, is overly complex with developers having to stitch together too many tools, APIs, Postgres extensions and data pipelines. We saw an opportunity to make it easier to develop AI applications without having to undertake a major exercise in tool sourcing and integration.<p>We are addressing each of these with the pgEdge Agentic AI Toolkit for Postgres.", "author": "pgedge_postgres", "timestamp": "2026-01-21T16:08:53+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:27.953486+00:00", "processed": false}
{"id": "hn_story_46706848", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46706848", "title": "Show HN: I built an AI book recommender in 2 days", "text": "Hi HN! I built this in ~2 days over the New Year&#x27;s break, and it was the most fun I&#x27;ve had coding in a while...<p>*Why I built it:*\nI was tired of generic listicles and recoms from Google Search, ChatGPT&#x2F;Gemini, and Goodreads. I wanted something where I could say &quot;a cozy mystery for a rainy weekend&quot; or &quot;something like Kafka but less depressing&quot; and get actual niche results.<p>*How it works:*\n- Describe what you&#x27;re looking for in plain text (or voice) [<a href=\"https:&#x2F;&#x2F;mynextbook.ai&#x2F;onboarding-books\" rel=\"nofollow\">https:&#x2F;&#x2F;mynextbook.ai&#x2F;onboarding-books</a>]\n- A RAG system, built using Gemini 2.5 Flash Lite + Exa search, finds personalized recommendations\n- Metadata is fetched from multiple sources\n- ~5-10 seconds from input to recs (5-10X faster with cache)<p>*Stack:*\n- Next.js 14 &#x2F; TypeScript on Vercel\n- Neon (Postgres) + Prisma\n- Gemini + Exa Search API\n- Built with Cursor + Claude Code, &amp; AntiGravity (happy to discuss which was better for what)<p>*Try it without signing up:* no sign-up required to explore<p>*Bonus:* It also recommends movies and TV shows based on your book taste! I&#x27;ve found some binge-worthy stuff through it that I would&#x27;ve never found otherwise.<p>Still a tiny side project, but I love seeing people actually find useful recoms with it. Would love feedback on rec quality, UX, or features you&#x27;d want!", "author": "PouyaRZ", "timestamp": "2026-01-21T15:17:04+00:00", "score": 3, "num_comments": 2, "products": ["claude", "chatgpt", "gemini"], "categories": ["onboarding", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:33.935876+00:00", "processed": false}
{"id": "hn_comment_46707969", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46707969", "title": "Re: Show HN: yolo-cage \u2013 AI coding agents that can't e...", "text": "The whole issue is why i stopped using in-editor LLMs and wont use Agents for &quot;real&quot; work. I cant be sure of what context it wants to grab. With the good ol&#x27; copy paste into webui I can be 100%sure what the $TECHCORP sees and can integrate whatever it spits out by hand, acting as the first version of &quot;code review&quot;. (Much like you would read over stackoverflow code back in the day).<p>If you want to build some greenfield auxiliary tools fine, agents make sense but I find that even gemini&#x27;s webui has gotten good enough to create multiple files instead of putting everything in one file.<p>This way I also dont get locked in to any provider", "author": "p410n3", "timestamp": "2026-01-21T16:34:07+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-21T17:45:34.376204+00:00", "processed": false}
{"id": "hn_story_46706614", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46706614", "title": "Show HN: An open source \"Cursor for Google Sheets\" with conversation memory", "text": "Hey HN ,<p>I\u2019ve just pivoted *AISheeter* from a simple formula generator into a full AI Agent. Last year, it was just auto-complete; recently, with the help of Claude Opus, I rewrote it to handle multi-step workflows. Think of it as *Cursor, but for spreadsheets.*<p>The problem that I often faces: Most existing tools (including Gemini in Sheets) treat every query as an isolated, one-off task. If you want to run complex operations on data, you have to manually prompt every single step. It\u2019s tedious and stateless.<p>This app, the solution : it is an agent that persists context per spreadsheet with multiple sheets. It allows for chained workflow. I.e. (e.g., &quot;Analyze raw data \u2192 Extract signals \u2192 Score priority&quot;) where the AI remembers the output of step 1 when performing step 2.<p>*The Stack:*<p>- *Frontend&#x2F;Backend:* Next.js 16, Vercel AI SDK<p>- *Database:* Supabase (for context persistence)<p>- *Integration:* Google Apps Script<p>- *Models:* BYOK (OpenAI, Anthropic, Gemini, Groq)<p>*The  Challenge:* The hardest part was managing the conversation memory without blowing up token costs. We implemented a system that maps conversation threads to specific Spreadsheet IDs, allowing the agent to &quot;recall&quot; previous context without needing to re-ingest the entire sheet history for every request.<p>*The Good Finding:* I do a lot of context engineering in the backend to handle tokens carefully. I actually found that smaller models like *gpt-5-mini* and *Claude Haiku* can actually handle this level of complexity surprisingly well if the context is structured correctly.<p>Link to repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Ai-Quill&#x2F;ai-sheeter\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Ai-Quill&#x2F;ai-sheeter</a><p>Download extension : <a href=\"https:&#x2F;&#x2F;aisheeter.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;aisheeter.com&#x2F;</a><p>I\u2019d love feedback on the architecture\u2014specifically how we\u2019re handling the context window management.<p>Thanks", "author": "tuantruong", "timestamp": "2026-01-21T15:00:27+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:35.684998+00:00", "processed": false}
{"id": "hn_comment_46706179", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46706179", "title": "Re: Show HN: PasteGuard \u2013 Use OpenAI and Claude withou...", "text": "Everyone says don&#x27;t send personal data to cloud LLMs. But when you&#x27;re working with customer emails, support tickets, or code with credentials \u2014 it&#x27;s hard to avoid.<p>So I built a proxy that handles it for you \u2014 it&#x27;s open source and free.<p>How it works:<p><pre><code>  You send:        &quot;Email john@acme.com about meeting Sarah Miller&quot;\n  LLM receives:    &quot;Email [[EMAIL_1]] about meeting [[PERSON_1]]&quot;\n  LLM responds:    &quot;Dear [[PERSON_1]], I wanted to follow up...&quot;\n  You get back:    &quot;Dear Sarah Miller, I wanted to follow up...&quot;\n</code></pre>\nPasteGuard finds personal data and secrets in your prompt, swaps them with placeholders, and restores the real values in the response. The LLM never sees the actual data.<p>What it catches:\n- PII: Names, emails, phones, credit cards, IBANs, IPs (24 languages)\n- Secrets: API keys (OpenAI, Anthropic, AWS, GitHub), JWTs, SSH keys<p>Works with both OpenAI and Anthropic APIs. Point your app to localhost:3000&#x2F;openai&#x2F;v1 or localhost:3000&#x2F;anthropic&#x2F;v1. Compatible with LangChain, Cursor, Claude Code, Open WebUI.<p>One command to run:<p><pre><code>  docker run -p 3000:3000 ghcr.io&#x2F;sgasser&#x2F;pasteguard:en\n</code></pre>\nHappy to answer questions.", "author": "sgasser", "timestamp": "2026-01-21T14:27:45+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:38.816883+00:00", "processed": false}
{"id": "hn_comment_46706322", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46706322", "title": "Re: Ask HN: What are good resources to get familiar wi...", "text": "using them. there really is no other way.<p>It&#x27;s like asking &quot;how do I use my text editor&quot;.<p>Almost everything you read online will be out of date, and the person working on it won&#x27;t work the same way you do.<p>Some people love it, some people hate it.<p>And unless you&#x27;ve got your own experience, it&#x27;s hard applying other people&#x27;s experience to your experience.<p>Especially for something like Claude Code where you&#x27;re just prompting and getting results back.<p>I mean, half the time I use VS Code, half the time I use a terminal window.<p>You&#x27;re going to get a lot of conflicting advice because everyone&#x27;s environment is different and they work on different sorts of code bases.<p>But I&#x27;ll give you mine.<p>I&#x27;m a Claude Max Pro 200 subscriber.<p>I sit with the Opus chat-bot have a discussion and come up with a spec. We turn this into a zip full of documents and upload it to a GitHub Repo.<p>e.g. <a href=\"https:&#x2F;&#x2F;github.com&#x2F;lawless-m&#x2F;BattleForMoscow\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;lawless-m&#x2F;BattleForMoscow</a><p>I&#x27;ll then get Claude Code for the Web to go to that repo unzip the zip and read the documents. It will make a first pass at the entire codebase.<p>I&#x27;ll merge that into main and create another Claude Code for the Web Opus session with any ideas I&#x27;ve had in the meantime - which will usually be a few.<p>Then I clone it to a local machine and get Claude Code Opus to try and get it to work. And I&#x27;ll prompt it from there until it works. If it&#x27;s a Linux program, that&#x27;ll be in a terminal window. If it&#x27;s Windows, I&#x27;ll use VS Code because it&#x27;s a better terminal in VS Code than it is in a terminal window on Windows.<p>That&#x27;s a general workflow. Sometimes I won&#x27;t use GitHub at all. Sometimes a PXE boot an entire Linux machine and give it that with admin privs.<p>And sometimes I just tell it to use sudo as my own account. On my router for instance, if we want to do things with the firewall.", "author": "delaminator", "timestamp": "2026-01-21T14:39:47+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:38.905074+00:00", "processed": false}
{"id": "hn_comment_46705618", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46705618", "title": "Re: Show HN: Threadyx \u2013 BYOK multi-agent AI coding pla...", "text": "Hey HN! I&#x27;m the creator of Threadyx.<p>I built this because I was frustrated paying for Claude API access, then paying again for tools like Cursor that use my API credits. It felt like paying twice for the same thing.<p>Threadyx takes a different approach:\n- BYOK (Bring Your Own Key) - use your Claude API keys directly, no markup\n- Works with your Claude Developer Console skills natively\n- Multi-agent architecture (planning \u2192 coding \u2192 review) that runs asynchronously\n- API-first design - trigger development tasks programmatically without being in an IDE\n- All changes in cloned environments, you decide what merges<p>The core idea: instead of real-time IDE assistance, we focus on async workflows. Kick off a refactor, go grab coffee, come back to reviewed code.<p>Happy to answer any questions about the architecture, the BYOK model, or how the multi-agent orchestration works!<p>Setup guide: <a href=\"https:&#x2F;&#x2F;docs.google.com&#x2F;document&#x2F;d&#x2F;1gCV9ox1sTx-RF3TUCgh5ON2Lr6MfekQK&#x2F;edit?tab=t.0\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.google.com&#x2F;document&#x2F;d&#x2F;1gCV9ox1sTx-RF3TUCgh5ON2L...</a>\nDemo videos: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCiklY21pbodcv4i9J1llBpA\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCiklY21pbodcv4i9J1llBpA</a>", "author": "threadyx", "timestamp": "2026-01-21T13:44:03+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:43.581642+00:00", "processed": false}
{"id": "hn_story_46705382", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46705382", "title": "Show HN: X-Pilot \u2013 Code-Driven AI Video Generator for Online Courses", "text": "Hi HN,<p>I&#x27;m Heshan, founder of X-Pilot. We&#x27;re building an AI Video Generator for online courses and educational content. Unlike most text-to-video generator that render videos directly from models (which often produce random stock footage unrelated to the actual content), we take a code-first approach: generate editable code layers, let users verify&#x2F;refine them, then render to video.<p>The Problem We&#x27;re Solving<p>Most AI video generators treat &quot;education&quot; and &quot;marketing&quot; the same\u2014they optimize for &quot;looks good&quot; rather than &quot;logically accurate.&quot; When you feed a technical tutorial or course script into a generic video AI, you get:\n- Random B-roll that doesn&#x27;t match the concept being explained\n- Incorrect visualizations (e.g., showing a &quot;for loop&quot; diagram when explaining recursion)\n- No way to systematically fix errors without regenerating everything<p>For educators, corporate trainers, and knowledge creators, accuracy matters more than aesthetics. A single incorrect diagram can break a learner&#x27;s mental model.<p>Our Approach: Code as the Intermediate Layer<p>Instead of text \u2192 video blackbox, we do:\nText&#x2F;PDF&#x2F;Doc \u2192 Structured Code (Remotion + Visual Box Engine) \u2192 Editable Preview \u2192 Final Render<p>Tech Stack\n- Agent orchestration: LangGraph (with Gemini 2.5 Flash for planning, reasoning, and content structuring)\n- Video Code generation model: Gemini3.0 for Remotion Code &amp; Veo 3  (for generative footage where needed)\n- Code-based rendering: Remotion (React-based video framework)\n- Knowledge visualization engine: Our own &quot;Visual Box Engine&quot;\u2014a library of parameterized educational animation components (flowcharts, comparisons, step-by-step sequences, system diagrams, etc.)\n- Voice synthesis: Fish Audio (for natural narration)\n- Rendering: Google Cloud (distributed video rendering using chrome headless)\n- Code execution sandbox: E2B (for safe, isolated code execution during generation and preview\uff0c but we will update to our own sandbox\uff0c because e2b offen time out\uff0cand low performance for bundle and render)<p>Why Remotion + Custom Components\uff1f\nWe chose Remotion because:\n1. Editability: Every visual element is React code. Users (or our AI agents) can modify text, swap components, adjust timing\u2014without touching raw video files.\n2. Reproducibility: Same input \u2192 same output. No model randomness in final render.\n3. Composability: We built a &quot;Visual Box&quot; library\u2014reusable animation patterns for education (e.g., &quot;cause-and-effect flow,&quot; &quot;comparison table,&quot; &quot;hierarchical breakdown&quot;). These aren&#x27;t generic motion graphics; they&#x27;re designed around pedagogical principles.<p>The trade-off: We sacrifice some &quot;cinematic quality&quot; for logical accuracy and user control. Right now, output can feel closer to &quot;animated slides&quot; than &quot;documentary footage&quot;\u2014which is actually our biggest unsolved challenge (more on that below).<p>What We&#x27;re Struggling With (and Planning to Fix)<p>1. Code Error Rate\nGenerating Remotion code via LLMs is powerful but error-prone. \n2. Limited Asset Handling\nRight now, if a user wants to insert a custom image&#x2F;GIF&#x2F;video mid-generation, they need to upload \u2192 we process \u2192 regenerate. This breaks flow.\n3. The &quot;PPT Feel&quot; Problem\nThis is the hardest one. Because we prioritize structure and editability, our videos can feel like &quot;animated PowerPoint&quot; rather than &quot;produced content.&quot;<p>We&#x27;re experimenting with:\n- Hybrid rendering: Use generative video (Veo) for transitions&#x2F;B-roll, but keep Visual Boxes for core explanations\n- Cinematic presets: Camera movements, depth effects, color grading\u2014applied as composable layers\n- Motion design constraints: Teaching our agent to follow motion design principles (easing curves, visual hierarchy, pacing)<p>Honest question for HN: Has anyone solved this trade-off between &quot;programmatically editable&quot; and &quot;cinematic quality&quot;? I&#x27;d love to hear how others have approached it (especially in contexts where correctness &gt; vibes).", "author": "bianheshan", "timestamp": "2026-01-21T13:24:33+00:00", "score": 1, "num_comments": 1, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:45.565587+00:00", "processed": false}
{"id": "hn_story_46705302", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46705302", "title": "Show HN: Lensr \u2013 Visual search for Amazon without the login wall", "text": "I built this because I was tired of &quot;utility&quot; apps that demand my email address or location data just to scan an item.<p><pre><code>  Lensr is a single-purpose iOS tool:\n\n  1.Open app.\n\n  2.Snap a photo of an object (furniture, tech, shoes).\n\n  3.Get the Amazon match instantly.\n\n  The Tech:\n\n  Built with Expo (React Native).\n\n  Image analysis via OpenAI&#x27;s Vision API through a Cloudflare Worker proxy - no images are stored.\n\n  No user accounts, no tracking pixels, no data collection.\n\n  Monetization: Totally free and ad-free. I use Amazon affiliate links for the results. If you buy the match, I get a small commission. This keeps the UX clean without selling data.</code></pre>", "author": "adriant_dev", "timestamp": "2026-01-21T13:16:35+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:46.090292+00:00", "processed": false}
{"id": "hn_story_46705058", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46705058", "title": "Code review your plans and your implementation", "text": "It\u2019s 2026 and the human language now more or less compiles. We&#x27;ve slowly moved away from writing code and towards writing detailed plans. The plans have gotten to the point where they\u2019re built into our tools(Cursor Plan mode, CC also has one). Why shouldn&#x27;t we review these plans like its a code review?<p>Eventually we won\u2019t be looking at Python the same way we don&#x27;t look at Assembly. I never check the binary output of a GCC compiler because I trust it. The workflow I\u2019m seeing and using is completely different. I want to see teams code reviewing the Plan, not just the implementation.<p>AI is not deterministic yet so we&#x27;re not quite at the GCC compiler level yet. However, a good plan review is worth 10x more than an implementation review. Code is a commodity, the plan is the not solved part. You can spend hours letting your agent implement and throw it all away, or get buy in from your team and (almost) one shot most tasks. Of course this was always true even before AI, aligning on what to build always mattered more than the how but tools like Claude Code and Cursor make it the only part that really matters.<p>The team should align on a structured text file. Call it a plan.md or whatever depending on what you\u2019re implementing it with. It describes the feature, the logic, and most importantly the measurement of success.<p>Here\u2019s the actual workflow:<p>1. Pick up a task and create a plan.md file using Claude code &#x2F; Cursor. Iterate on this for as long as you need to. Make sure you have good success criteria the agent can build towards<p>2. Open a Draft PR with that text file. Drop it in Slack. The team aligns on the approach in Slack or GitHub comments. I usually prefer Slack for iterating on a plan and GitHub comments for code comments<p>3. Once the team thumbs-ups the plan, point the agent at it. Since the success criteria are written out, the agent can self-verify.<p>4. Once you\u2019re happy with the implementation , now you update the PR with the generated code, get your teammates to review the code as they would any code review except they have much more context since they\u2019ve already reviewed your plan.", "author": "mayassin", "timestamp": "2026-01-21T12:54:51+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:48.484724+00:00", "processed": false}
{"id": "hn_comment_46704902", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46704902", "title": "Re: I'm 20 and built trinith after losing mass money t...", "text": "You know that feeling when you&#x27;re up at 2 AM, staring at a chart, convinced you&#x27;ve found a bull flag \u2014 then you wake up liquidated? Yeah. That was me. Multiple times. The problem wasn&#x27;t that I didn&#x27;t know technical analysis. I&#x27;d spent hundreds of hours learning patterns, watching videos, reading books. The problem was confirmation bias. When you&#x27;re already in a position, your brain sees what it wants to see. So I built Trinith. Upload any chart screenshot, get AI-powered pattern detection in seconds. It tells you what it sees and how confident it is \u2014 no emotions, no bias, just pattern recognition.<p>Why I&#x27;m sharing this on HN:\nI&#x27;m not a CS grad. I taught myself to code specifically to build this. Most of what I know came from docs, Stack Overflow, and honestly \u2014 Claude and GPT helping me debug at 3 AM. I figure if there&#x27;s anywhere that appreciates &quot;I had a problem, so I built something&quot; energy, it&#x27;s here.<p>Why Gemini instead of GPT-4 Vision or Claude?<p>I tested all three. For chart analysis specifically, Gemini gave me the most consistent structured outputs. GPT-4V was good but more expensive. Claude was sometimes too cautious, would refuse to give confidence scores because &quot;markets are unpredictable&quot; (fair, but not helpful for my use case).<p>The hard parts weren&#x27;t AI \u2014 they were auth flows, credit systems, and making it not look like an MVP (I&#x27;m a backend guy, CSS hurts).<p>The Honest Truth Is this going to make you rich? No.<p>Is the AI always right? Definitely not.<p>What it does is give you a second opinion that isn&#x27;t emotionally attached to your position. When I&#x27;m long on something, I see bullish patterns everywhere. The AI doesn&#x27;t care what I&#x27;m holding. I&#x27;ve been using it myself for a few weeks. It&#x27;s caught a few patterns I would&#x27;ve missed, and more importantly, it&#x27;s talked me out of a few bad trades.<p>Link : <a href=\"https:&#x2F;&#x2F;trinith-ai.vercel.app\" rel=\"nofollow\">https:&#x2F;&#x2F;trinith-ai.vercel.app</a><p>Would genuinely love feedback  especially from:<p>- People who trade and can tell me if the analysis output is useful \n- People who&#x27;ve built with vision APIs and have optimization tips \n- People who think this is dumb and can tell me whyHappy to answer any technical questions.", "author": "rvnx_exe", "timestamp": "2026-01-21T12:43:17+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:50.136392+00:00", "processed": false}
{"id": "hn_comment_46704778", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46704778", "title": "Re: Boss wants me to post too often...", "text": "Boss wants me to post a reel, a post, and a story every single day. I\u2019m a one person marketing team aka: graphic designer, content creator, photographer&#x2F;videographer, website designer, admin, project manager, etc. You know the deal.<p>It\u2019s a small business that mostly specializes in juice and protein shakes. My posts are doing poorly and I\u2019m sure it\u2019s because I\u2019m posting just to hit my quota - I still try obviously but even with research and planning and ChatGPT it\u2019s difficult. Just creating QUALITY content is difficult in this structure.<p>I also do other random design&#x2F;admin tasks outside of this - sometimes it takes a lot of time from my day - but not always, it\u2019s random.<p>On another note: My boss said she could only give me a raise if I did more things for her - and I guess this was her way of doing that because I\u2019ve been posting 3 times a day since September and she just gave me a $1 raise this month. I did one post or reel a day before this and usually a story a day.<p>So I fear she won\u2019t want to change this flow because to her I\u2019m \u201cearning\u201d my pay by doing more even though I think it\u2019s hurting our numbers.<p>Any suggestions?<p>Edit: Thanks for the feedback y\u2019all, a lot of you had some really solid advice.<p>I\u2019m realizing that although I\u2019m capable and have been pushing out this much content consistently, it\u2019s my motivation + compensation (lack of benefits, not great pay, and only 5 PTO days a year) that makes me struggle to want to keep going with the job. I\u2019m going to just keep learning what I can and finding something else that fits me better down the line.", "author": "our79511", "timestamp": "2026-01-21T12:32:47+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-21T17:45:51.162680+00:00", "processed": false}
{"id": "hn_comment_46703941", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46703941", "title": "Re: Show HN: Architect: A terminal for running multipl...", "text": "I built this because I kept losing track of which agents needed attention. Running 4+ Claude Code sessions across terminal tabs, I&#x27;d find one sitting idle for 20 minutes waiting for approval while I was focused elsewhere. Desktop notifications didn&#x27;t help \u2014 they&#x27;d vanish before I noticed.<p>Architect solves this with visual feedback. When an agent finishes, its cell changes hue. When it needs approval, it glows. The grid layout means I can see all sessions at once and know immediately where to focus. I also built in git worktree support, so switching between tasks is fast.<p>It&#x27;s built on ghostty-vt (the terminal emulation library from Ghostty) and uses hooks from Claude Code, Gemini CLI, and Codex to detect agent state. Written in Zig \u2014 partly to learn the language, partly because ghostty-vt is also Zig.<p>macOS only right now. Linux is planned.<p>Blog post with more details: <a href=\"https:&#x2F;&#x2F;forketyfork.github.io&#x2F;blog&#x2F;2026&#x2F;01&#x2F;21&#x2F;running-4-ai-coding-agents-at-once-the-terminal-i-built-to-keep-up&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;forketyfork.github.io&#x2F;blog&#x2F;2026&#x2F;01&#x2F;21&#x2F;running-4-ai-c...</a>", "author": "forketyfork", "timestamp": "2026-01-21T11:07:57+00:00", "score": null, "num_comments": null, "products": ["claude", "gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-01-21T17:45:57.741564+00:00", "processed": false}
