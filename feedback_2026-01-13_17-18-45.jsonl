{"id": "hn_story_46603921", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46603921", "title": "Show HN: Subtitle Insights \u2013 Language Learning via YouTube with On-Device Gemini", "text": "I use the Comprehensible Input method (based on Stephen Krashen&#x27;s work on Language Acquisition and Comprehensible Input: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fnUc_W3xE1w\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fnUc_W3xE1w</a>) to learn languages in my free time. I often watch YouTube videos in my target language with subtitles.<p>This practice led me to wish for a feature that would automatically pause a video at the end of each subtitle. This pause would provide me with time to:<p>- Process what I just saw and heard.<p>- Mine words using Yomitan, if necessary.<p>- Replay the segment to shadow the speaker, ideally triggered through a keyboard shortcut.<p>- Analyze the sentence structure for deeper insight on complex grammar and cultural nuances.<p>- Translate the entire sentence in a language I know, if necessary.<p>To enhance my language learning experience I developed a Chrome Extension called &quot;Subtitle Insights&quot;. This extension leverages Chrome&#x27;s Built-In AI (specifically Gemini Nano) to perform on-device translations and analysis of YouTube subtitles.<p>Key features:<p>- On-Device AI Processing. Once Gemini Nano is downloaded by Chrome, all subtitle translations and language insights are processed locally using Chrome&#x27;s integrated AI capabilities.<p>- The prompt is customizable and the output can be tailored to match your preferences. If you&#x27;re learning multiple languages at a time you can create profiles for each one.<p>- The auto-pause feature pauses the video just before a subtitle segment ends and gives you time to fully process the spoken content.<p>- The sidebar displays all subtitles and can be used as a video navigation tool. You can jump to any subtitle with a simple click.<p>- Keyboard shortcuts allow for quick navigation between subtitle segments and easy replay of the current segment.\nYou can bring your own subtitles and if they&#x27;re not synced with the audio you can use the extension to sync the audio with the subtitles easily.<p>It&#x27;s free. No account &#x2F; API keys needed. The Gemini Nano model runs on-device thanks to Chrome&#x27;s Built-in AI.", "author": "maurizzzio", "timestamp": "2026-01-13T17:06:08+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-13T17:18:47.001753+00:00", "processed": false}
{"id": "hn_comment_46602988", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46602988", "title": "Re: Why MCP-based ChatGPT Apps fail in practice (and a...", "text": "While building ChatGPT Apps backed by an MCP server, I kept running into non-obvious failures:\n405&#x2F;406 errors, SSE streams that never flush, invalid session errors, CORS preflights, and Edge vs Serverless quirks.<p>The documentation explains the protocol, but not how these failures actually surface during deployment.<p>I put together a minimal, deterministic MCP + SSE starter that deploys cleanly on Vercel and makes the correct behavior explicit.\nIt\u2019s intentionally small and review-friendly, meant as a reference rather than a framework.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;shuddha2021&#x2F;chatgpt-app-starter-kit\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;shuddha2021&#x2F;chatgpt-app-starter-kit</a>", "author": "shuddha7435", "timestamp": "2026-01-13T16:14:18+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:18:50.952859+00:00", "processed": false}
{"id": "hn_story_46602825", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46602825", "title": "Show HN: Kalshi Market Intelligence and AI Signal Analyst", "text": "Hi HN,<p>I built a lightweight market intelligence layer for Kalshi prediction markets.<p>Instead of scraping pages, it intercepts Kalshi\u2019s APIs to track:\n \u2022 Stateful volume trends (rising &#x2F; falling)\n \u2022 Liquidity depth\n \u2022 Basic sentiment signals<p>It also includes a BYOK AI adapter so users can generate short trader briefs using their own LLM key (ChatGPT, Claude, Gemini, etc.). Designed to run on very low resources (fits Apify\u2019s 1GB free tier).<p>I built this as part of the Apify $1M Challenge and would love feedback from people interested in prediction markets, market microstructure, or quant-style tooling.", "author": "founder_mode", "timestamp": "2026-01-13T16:05:03+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:18:51.859667+00:00", "processed": false}
{"id": "hn_story_46602819", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46602819", "title": "Show HN: Hivinq \u2013 Copilot for customer support teams", "text": "A lot of teams are hesitant to adopt AI customer service bots due to their inauthenticity in replies, hallucination, etc. As a result, they&#x27;re not able to leverage the speed of LLM&#x27;s to reduce their customer turnaround time. So instead of replying to the customer directly, Hivinq drafts responses for the customer support team using it&#x27;s knowledge about the product. If the drafted answers are inaccurate, team members can let it know and it will observe the thread to learn and correct itself.<p>Please upvote on Product Hunt: <a href=\"https:&#x2F;&#x2F;www.producthunt.com&#x2F;products&#x2F;hivinq\" rel=\"nofollow\">https:&#x2F;&#x2F;www.producthunt.com&#x2F;products&#x2F;hivinq</a><p>Demo video: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;c91ae70326f14cf48b390503f21eb9e7\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;c91ae70326f14cf48b390503f21eb9e7</a>", "author": "vishalds", "timestamp": "2026-01-13T16:04:57+00:00", "score": 1, "num_comments": 0, "products": ["copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-13T17:18:51.927235+00:00", "processed": false}
{"id": "hn_comment_46602779", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46602779", "title": "Re: Headroom \u2013 context optimization layer for tool-usi...", "text": "More detail &#x2F; what it does + what it doesn\u2019t:<p>What it actually changes:<p>Tool output compression is deterministic and schema-preserving: it returns a subset of the original array items (no invented summaries, no wrapper keys).<p>It supports both OpenAI-style role=&quot;tool&quot; messages and Anthropic-style tool_result blocks.<p>\u201cFail open\u201d: if JSON parsing&#x2F;compression fails, it passes through unchanged.<p>Why another context tool?\nMost \u201ccontext compression\u201d projects focus on prose. The thing that killed my agent runs was valid tool calling + tool payload bloat. The goal here was: reduce tokens without breaking the contract.<p>Typical savings\nOn tool-heavy runs, the big wins come from crushing large arrays (search results, traces, lists). In my traces I\u2019m seeing ~70\u201390% reduction on tool payload tokens depending on how repetitive the payload is. (If you have a better benchmark harness, I\u2019m happy to adopt it.)<p>Escape hatch when compression drops something you need\nWhen a tool output is compressed, Headroom stores the original briefly and can expose a retrieve tool (headroom_retrieve) so the model (or you) can pull the full uncompressed payload by hash. (There\u2019s also an MCP server for this.)<p>Shortcomings &#x2F; where it can be the wrong idea<p>SmartCrusher is intentionally conservative: it focuses on JSON arrays. If your tool returns a giant nested object or long free-text, Headroom won\u2019t magically solve that (text compression utilities exist but are opt-in).<p>If your downstream logic requires \u201cthe full list of 1,000 items,\u201d then any reduction strategy can be wrong\u2014use the retrieve tool or disable for that tool.<p>Relevance scoring is heuristic&#x2F;optional; it can miss \u201cthe one weird item you cared about\u201d if it doesn\u2019t look anomalous&#x2F;relevant.<p>Running as a proxy means your prompts&#x2F;tool outputs flow through a local service (privacy&#x2F;security tradeoff; logging is off by default for full content).<p>Happy to answer any comparisons\u2014tell me what you\u2019re using (prompt compression, truncation, provider caching tricks, etc.) and I\u2019ll map it to how Headroom behaves.", "author": "chopratejas", "timestamp": "2026-01-13T16:02:38+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-13T17:18:52.162759+00:00", "processed": false}
{"id": "hn_story_46602671", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46602671", "title": "Show HN: Term.stream \u2013 Stream your terminal to any device via URL", "text": "I built this because I kept running Claude Code, going to the gym, \nand not being able to see if it finished or tell it what to do next.<p>term.stream lets you run `tstream` and get a shareable URL instantly. \nOpen it on your phone, another laptop, anywhere. View-only by default, \ncontrol access with a token.<p>No SSH keys, no tmux, no port forwarding. Just a link.<p>Built with Rust (daemon + relay) and a simple web client.", "author": "zero_dev", "timestamp": "2026-01-13T15:56:05+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:18:52.368071+00:00", "processed": false}
{"id": "hn_story_46601652", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46601652", "title": "Show HN: AionUi \u2013 Open-Source Cowork for Claude Code, Gemini CLI, Codex and More", "text": "Anthropic just dropped Cowork today \u2013 a nicer way to let Claude act as your agent on files without wrestling the CLI.<p>I&#x27;ve been building something in the same spirit but open-source, cross-platform, and multi-model: AionUi. It&#x27;s a free desktop GUI (Electron-based) that turns popular command-line AI tools into a unified &quot;Cowork&quot; workspace:  Supports Claude Code, Gemini CLI, Codex, Qwen Code, Goose CLI, Auggie, etc. (auto-detects installed CLIs)<p>- Custom LLMs \u2013 Full support for customizable third-party LLMs. \n- Multi-session chats with independent contexts, stored locally in SQLite (data never leaves your device)  \n- Real-time preview &amp; editing panel for 9+ formats: PDF, Word, Excel, PPT, code diffs, Markdown, images, HTML...  \n- AI image generation&#x2F;editing (Gemini-powered, with recognition)  \n- Smart file management: batch rename, auto-organize, classify, merge  \n- Parallel multi-tasking (sessions don&#x27;t interfere)  \n- WebUI mode: remote access from phone&#x2F;browser, still local data  \n- Cross-platform: macOS, Windows, Linux\n- Fully customizable UI via CSS<p>Just like Claude Cowork simplifies Claude Code for non-devs, AionUi aims to do the same for all your CLI AI agents.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;iOfficeAI&#x2F;AionUi\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;iOfficeAI&#x2F;AionUi</a>\n(3.5k stars, Star if it looks useful  \u2013 no pressure!)", "author": "waili", "timestamp": "2026-01-13T14:47:03+00:00", "score": 2, "num_comments": 0, "products": ["claude", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:18:58.456083+00:00", "processed": false}
{"id": "hn_story_46601429", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46601429", "title": "Show HN: AI Mime \u2013 Record and parameterize workflows for Computer Use agents", "text": "Hi HN,<p>I\u2019ve been experimenting with the latest &quot;computer use&quot; models (like Gemini 3 flash, qwen 3 vl plus, browser use), and while they are impressive, I hit a wall with reliability in production use cases.<p>The main issue I found is context. When we give agents simple natural language prompts (e.g., &quot;download the invoice&quot;), they often lack the nuance to handle edge cases or specific UI quirks. They try to be &quot;creative&quot; when they should be deterministic.<p>I built AI Mime to solve this by shifting from &quot;prompting&quot; to &quot;demonstrating.&quot; It\u2019s an open-source macOS tool that lets you record a workflow, parameterize it, and replay it using computer-use agents.<p>How it works:<p>Record: It captures native macOS events (mouse, keyboard, window states) to create a ground-truth recording of the task.<p>Refine (The interesting part): It uses an LLM to parse that raw recording into parameterized instructions. Instead of a static macro, you get manageable subtasks where you can define inputs&#x2F;variables. This constrains the agent to a specific &quot;happy path&quot; while still allowing it to handle dynamic elements.<p>Replay: The agent executes the subtasks using the computer-use interface, but with significantly higher success rates because it has &quot;seen&quot; the exact steps required.<p>The goal is to make these agents observable and repeatable enough for actual RPA work.<p>The repo is here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;prakhar1114&#x2F;ai_mime\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;prakhar1114&#x2F;ai_mime</a><p>I\u2019d love to hear your thoughts on the approach or how you are currently handling state&#x2F;reliability with computer-use models.", "author": "prakharjain", "timestamp": "2026-01-13T14:33:38+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:18:59.831242+00:00", "processed": false}
{"id": "hn_comment_46604129", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46604129", "title": "Re: Apple Creator Studio...", "text": "Here is a quick side by side comparison between Apple Creator Studio and the Adobe Creative Cloud suite.\nEach app may be stronger or weaker depending on the use case, workflow, and specific user needs, so this is only a rough equivalence.<p><pre><code>    Function            | Apple                | Adobe               | Adobe price &#x2F; month\n    --------------------|----------------------|---------------------|--------------------\n    Image editing       | Pixelmator Pro       | Photoshop           | ~USD 20\n    Video editing       | Final Cut Pro        | Premiere Pro        | ~USD 23\n    Motion graphics     | Motion               | After Effects       | ~USD 23\n    Audio production    | Logic Pro            | Audition            | ~USD 23\n    Video encoding      | Compressor           | Media Encoder       | Included with Premiere Pro\n    Live audio          | MainStage            | No direct equivalent| N&#x2F;A\n    Docs&#x2F;presentations  | Keynote&#x2F;Pages&#x2F;Numbers| Express&#x2F;Acrobat     | ~USD 10 to 24\n    --------------------|----------------------|---------------------|--------------------\n    TOTAL               | USD 12.99 &#x2F; month    | ~USD 100+ &#x2F; month   |\n                        | (7 apps bundle)      | (5 apps separately)|\n                        |                      | USD 69.99 &#x2F; month  |\n                        |                      | (bundle 20+ apps)  |\n\n</code></pre>\nDisclaimer: table formatting assisted by ChatGPT (hope it works on HN).", "author": "pentagrama", "timestamp": "2026-01-13T17:16:58+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:19:01.044677+00:00", "processed": false}
{"id": "hn_story_46600906", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46600906", "title": "Show HN: Y0 \u2013 Platform for autonomous AI agents that do real work", "text": "y0 is different because the agents actually do things \u2014 they don&#x27;t just chat.<p>You describe what you want in natural language. Then y0 spins up a sandboxed environment and the agent gets to work: browsing websites, writing code, managing files, running shell commands. It streams progress in real-time so you can watch it work.<p>Unlike chatbots, y0 agents have real execution capabilities. They can navigate complex websites, fill forms, extract data, create documents, run scripts, and chain multiple steps together autonomously. When the agent finishes, you get the actual output \u2014 files, data, reports \u2014 not just a text response.<p>The sandboxing means agents can&#x27;t mess with your local machine. Each session runs in an isolated container with its own filesystem, browser, and shell. You can give agents access to specific tools and APIs without worrying about side effects.<p>We built y0 because we got tired of copying code from ChatGPT and manually running it. We wanted an AI that could just do the work end-to-end.<p>There&#x27;s a free tier to try it out. Would love feedback on what workflows you&#x27;d want agents to handle.", "author": "yethikrishnar", "timestamp": "2026-01-13T13:52:07+00:00", "score": 3, "num_comments": 1, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-13T17:19:03.253119+00:00", "processed": false}
{"id": "hn_story_46600785", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46600785", "title": "Show HN: Respilens.com displays flu, COVID-19 and RSV forecasts for US states", "text": "TL;DR: weather forecasts but for respiratory disease. Interpret with caution :)<p>Hey HN,<p>Every year during the respiratory disease season (winter in the northern hemisphere), the CDC runs challenges where teams -- academics, mostly, but also government and companies -- submit forecasts of the disease burden each week. These are 4-week-ahead forecasts.<p>We (Emily and I, Joseph) built RespiLens.com as a static website to display these forecasts all in one place with a nicer interface than what is generally provided [1].<p>Forecasting respiratory disease is challenging, so please interpret forecasts with caution (see how bad it was in the last season).<p>This website is quite early stage, but we have been using it internally for a year and are starting to build it in public now. We are very much looking for your comments, especially as most folk who have seen it&#x2F;use it are in the public-health space.<p>We are not SWEs, so there might be a ton we can improve on the website.<p>There is also the RespiLens.com&#x2F;Forecastle, a Wordle-type game to see how good you are at forecasting vs the current state of the art. Interested in what you think of that.<p>Technically, our GitHub repo is here <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ACCIDDA&#x2F;RespiLens\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ACCIDDA&#x2F;RespiLens</a>, and it&#x27;s quite straightforward: \n* we pull forecasts from each hub GitHub; this is facilitated by the HubVerse, an initiative to standardize these challenges (<a href=\"https:&#x2F;&#x2F;hubverse.io\" rel=\"nofollow\">https:&#x2F;&#x2F;hubverse.io</a>)\n* we serve this with a Mantine Web App. Claude Code and other LLMs were heavily used to create the front-end. It is a good use case because we can do QA as know what it should look like as I have dozens of Python scripts for these plots.<p>Feel free to ask questions! or suggest features.<p>[1] hubverse provides an automatic dashboard, and the CDC displays forecasts on their website under a set of conditions (good coverage). See RespiLens.com info hub for link.<p>Best,\nJoseph", "author": "wosk", "timestamp": "2026-01-13T13:39:04+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:19:04.284436+00:00", "processed": false}
{"id": "hn_story_46600709", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46600709", "title": "Show HN: I built a Finances app for Mac where you own the SQLite database", "text": "Hey HN,<p>I feel like there is a gap in personal finance apps: local-first options typically have less polished UIs, while those with great design like Monarch Money are not local-first. This app fills the gap by providing a modern UI like Monarch&#x2F;Monzo along with a database that you can hack around with outside of the app. File &gt; app!<p>- Local-first: transactions are stored in an encrypted SQLite database on your Mac, so you can read&#x2F;write to it with Claude Code or your favourite DB client.<p>- Link transactions to merchants manually or automatically with <a href=\"https:&#x2F;&#x2F;ntropy.com\" rel=\"nofollow\">https:&#x2F;&#x2F;ntropy.com</a> to add sensible merchant names, brand icons, categories, GPS locations (e.g. converting &quot;APPLE STORE R238 R238   SYDNEY&quot; into &quot;Apple Store, Sydney | Electronics | 367 George St, Sydney NSW 2000 | Parent: Apple&quot;)<p>- Map view with clustering to see how much you\u2019ve spent in different locations.<p>- Enrich Uber transactions with pickup&#x2F;drop-off details<p>- macOS inspired UX patterns like dragging transactions into folders or tags. It&#x27;s an Electron + React app so think 1Password-style UI.<p>Once you link your transactions to merchants, you can run SQL queries like &quot;What&#x27;s my total Uber spend this year?&quot; or ask questions about your spending with Claude Code (just get it to decrypt &amp; read the database).<p>I\u2019m starting with CSV and OFX file import, with syncing (Plaid, etc.) coming next.<p>You can download the Mac app at <a href=\"https:&#x2F;&#x2F;thefinances.app\" rel=\"nofollow\">https:&#x2F;&#x2F;thefinances.app</a>. To auto-enrich transactions via the API, you can go to Finances &gt; Settings and add this demo licence key, KESC-9QQU-VU0X-EGJP-N373.<p>Let me know what you think!", "author": "steveharrison", "timestamp": "2026-01-13T13:30:41+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-13T17:19:05.294718+00:00", "processed": false}
{"id": "hn_comment_46600233", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46600233", "title": "Re: Ask HN: How do you use AI tools when learning unfa...", "text": "Claude Code: &quot;How do I build this application? Where does authentication happen? etc&quot;<p>It will answer any basic question in under a minute with great accuracy.<p>Then you keep building your claude.md (after running &#x2F;init) as you learn more, or have Claude update it as it goes.", "author": "bearjaws", "timestamp": "2026-01-13T12:43:15+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-13T17:19:08.568703+00:00", "processed": false}
