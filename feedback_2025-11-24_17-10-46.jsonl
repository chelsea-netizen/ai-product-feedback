{"id": "hn_story_46036175", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46036175", "title": "Show HN: ProDisco \u2013 Progressive Disclosure Kubernetes MCP Server", "text": "ProDisco gives AI agents Kubernetes access that closely follows Anthropic\u2019s Progressive Disclosure pattern [1]: the MCP server exposes search tools which in turn surface TypeScript modules, agents discover them to write code, and only the final console output returns to the agent.<p>ProDisco goes a step further: instead of exposing custom TypeScript modules, it provides a structured parameter search tool that returns the most suitable methods from the official Kubernetes client library, including the type definitions for their input and return values. This lets agents dynamically interact with the upstream Kubernetes library while avoiding any ongoing maintenance burden in this repository to mirror or wrap those APIs.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;harche&#x2F;ProDisco\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;harche&#x2F;ProDisco</a><p>[1] <a href=\"https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;code-execution-with-mcp\" rel=\"nofollow\">https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;code-execution-with-mc...</a>", "author": "pharshal", "timestamp": "2025-11-24T16:56:21+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-24T17:10:48.091857+00:00", "processed": false}
{"id": "hn_story_46035340", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46035340", "title": "Show HN: Contrarian Signals \u2013 market sentiment indicators", "text": "A dashboard of market sentiment indicators deliberately biased towards the opposite of whatever the crowd is doing right now.<p>This was also partly motivated by wanting to play with terminal aesthetics and dense user interfaces.<p>Indicators: CNN Fear&amp;Greed, Put&#x2F;Call ratio, AAII Sentiment Survey, BofA Sell-side indicator, among others \u2014 feedback appreciated on potential signals to track!<p>Disclaimer: this was ~70% vibe coded using Cursor &#x2F; Claude Code.<p>Link: <a href=\"https:&#x2F;&#x2F;contrariansignals.com\" rel=\"nofollow\">https:&#x2F;&#x2F;contrariansignals.com</a> (free to access, subscription required to get daily alerts)", "author": "victordg", "timestamp": "2025-11-24T15:45:10+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-24T17:10:54.315967+00:00", "processed": false}
{"id": "hn_story_46034987", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46034987", "title": "Show HN: Pg-aiguide \u2013 Write better PostgreSQL code with AI", "text": "Hi HN,<p>I built a suite of tools to help ai generate better PostgreSQL code. The most interesting part is an opinionated set of skills to help it design better Postgres schemas. Also includes search over the manual.<p>Deployeable as both an MCP server and as a Claude Code Plugin.<p>I want to also include ecosystem docs and skills. Timescale (where I work) is already included. Looking for help with PostGIS and pgvector.<p>Full open source.", "author": "cevian", "timestamp": "2025-11-24T15:14:34+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-24T17:10:56.588269+00:00", "processed": false}
{"id": "hn_comment_46034997", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46034997", "title": "Re: BYO \u2013 A multi-agent runtime optimized for parallel...", "text": "You&#x27;re burying the lede: SOTA &#x27;Reasoning Models&#x27; (o1&#x2F;GPT-4) are actually unusable for agent swarms because inference latency kills the recursion loop.<p>The real alpha here is Parallel Consensus. Running 5 Llama-3 instances via vLLM to critique each other at &lt;200ms TTFT (Time To First Token) beats a single, slow GPT-4 wrapper every time.<p>Error correction belongs in the orchestration layer, not the model weights. Is the &#x27;One Giant Model&#x27; era finally over for agents?", "author": "Shahaf_Wieder", "timestamp": "2025-11-24T15:15:58+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-24T17:10:57.731386+00:00", "processed": false}
{"id": "hn_story_46031537", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46031537", "title": "I am building a collaborative coding agent", "text": "Hello folks,<p>I know there are way too many coding agents out there but I believe I am taking a different approach. I am building nocodo for entire teams, particularly for non-technical teams. It is self-hosted and I want to share how I am building it. Happy to hear thoughts and criticisms. At a high level:<p><pre><code>  - Runs on a Linux box on your cloud\n  - nocodo has a &quot;manager&quot; which is the agent and it runs on Ubuntu Linux\n  - Linux makes it easy to setup a full development environment on the cloud so team members do not have to\n  - LLMs are OK with multiple languages and frameworks for software development and nocodo does not add any restrictions of its own - no system prompt even at this point\n  - nocodo (the manager) is also a headless coding agent, regular HTTP API\n  - nocodo does&#x2F;will (depending on the feature) support managing a Linux box, managing multiple projects, users and teams, permissions, multiple models, coding plans (like GLM 4.6 from zAI)\n  - mix and match models for analytical or coding needs, will be mostly done for you\n  - Commands, like &quot;build&#x2F;run [backend, frontend]&quot;, &quot;create test DB&quot;, etc.\n  - Git, GitHub integration, branch&#x2F;worktree management all through the manager&#x27;s HTTP API\n  - Desktop and mobile (coming) apps for team members to connect to &quot;manager&quot; (let&#x27;s call them admin apps)\n  - Admin apps use SSH and port forwarding to connect to the coding agent\n  - Admin apps does&#x2F;will allow project and prompt management, prompting, collaboration (@ mention team mates into prompts)\n  - Admin apps does&#x2F;will have buttons for the &quot;commands&quot; described earlier, e.g., run the full-stack generated apps, open frontend in browser\n</code></pre>\nI want to add a prompt library, a real-time project context that models can use as a tool to help anyone to improve the technical details of prompts. Or to assist models figure out technical details on their own. Project management, Git management, infra management will also be available as tools to the models. Think `apt install []`. When someone needs full isolation, spinning up another cloud instance should also be possible.<p>I still have to figure out a bunch of things. I am now showing demos with early prototype. I plan to share a proper &quot;Show HN&quot; in a couple weeks time. I am really focused on non-technical teams and nocodo will have a much heavy server side to get users there. I believe project management will also change as we embrace code generation with LLMs. When features take a couple hours of wrestling with agents instead of days with developers, what will project management look like.<p>nocodo is itself mostly Rust and that is because I do not want to spend time wrestling with the compiler, but the model can and does it cheap. And the compiler does not allow many types of errors that other languages might. I may nudge nocodo&#x27;s users, who are backend tech stack agnostic, to also use Go&#x2F;Rust.<p>nocodo is itself generated by Claude Code and opencode (using Grok Code Fast 1 and GLM 4.6). I have Claude Pro and a Coding Plan from zAI. Overall about $ 35 &#x2F; month for about 3 months now.<p>Personal: I am Sumit. I have been a trying founder and engineer all my adult life. I have been in at least 12 startups across the world. I own nocodo.com since 2013 when I wanted to build a &quot;no code&quot; product. Tried multiple times with ideas around template based code generation. Finally, with LLMs, I can see this may work out at scale. I believe businesses want custom software and they will build (vs buy), if custom software keeps pace with their needs. I live in a little Himalayan village and I have been building LLM enabled products for some time now. nocodo is the one getting real user demand. I have 2 early adopters (founders). I am setting up for 2 small sized businesses now. There is a lot of manual hand-holding I do for them, including jumping into Claude to fix issues nocodo cannot. Please feel free to share your thoughts.<p>https:&#x2F;&#x2F;github.com&#x2F;brainless&#x2F;nocodo<p>Cheers!\nSumit", "author": "brainless", "timestamp": "2025-11-24T08:06:18+00:00", "score": 2, "num_comments": 0, "products": ["claude", "grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-24T17:11:18.500528+00:00", "processed": false}
{"id": "hn_story_46031208", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46031208", "title": "Syd \u2013 An offline-first, AI-augmented workstation for blue teams", "text": "Hi HN, I\u2019m Paul. I\u2019m building Syd, an offline-first forensic workstation that orchestrates tools like YARA and Nmap through a GUI, using a local LLM to analyze the results without leaking data. It runs completely offline on localhost\u2014no data is ever sent to the cloud, making it safe for sensitive investigations.<p>Here&#x27;s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8dQV3JbLrRE\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8dQV3JbLrRE</a>.<p>I built this because while tools like YARA are powerful, managing rule sets and decoding hex strings is slow. AI is great at explaining malware signatures, but I couldn&#x27;t use ChatGPT for my work because pasting potential malware or sensitive logs into a web form is a massive security risk. I needed the intelligence of an LLM but with the privacy of an air-gapped machine.<p>Under the hood, it\u2019s built on Python 3. I use subprocess to manage the heavy lifting of the scanning engines so the UI (built with CustomTkinter) doesn&#x27;t freeze. The &quot;secret sauce&quot; isn&#x27;t the AI itself, but the parser I wrote that converts the unstructured text output from YARA into a structured JSON format that the local LLM can actually understand and reason about.<p>I\u2019ve been using it to triage files for my own learning. In one case, Syd flagged a file matching a &quot;SilentBanker&quot; rule and the AI pointed out specific API calls for keylogging, saving me about 20 minutes of manual hex-editing. In the demo video linked, you can see this workflow: scanning a directory, hitting on a custom YARA rule, and having the local AI immediately analyze the strings.<p>Through this process, I learned that &quot;AI wrappers&quot; are easy, but AI orchestration is hard\u2014getting the tools to output clean data for the LLM is the real challenge. I&#x27;d love to hear if there are other static analysis tools (like PEStudio or Capa) you consider essential for a workstation like this, or how you currently handle the privacy risk of using AI for log analysis.", "author": "paul2495", "timestamp": "2025-11-24T07:11:38+00:00", "score": 20, "num_comments": 5, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-24T17:11:19.333990+00:00", "processed": false}
{"id": "hn_comment_46031464", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46031464", "title": "Re: Syd \u2013 An offline-first, AI-augmented workstation f...", "text": "Author here. Happy to answer questions!<p>A bit more context on how Syd works: it uses Dolphin Llama 3 (dolphin-2.9-llama3-8b) running locally via llama-cpp-python. You&#x27;ll need about 12-14GB RAM when the model is loaded, plus ~8GB disk space for the base system (models, FAISS index, CVE database). The full exploit database is an optional 208GB add-on.<p>What makes this different from just wrapping an LLM, the core challenge wasn&#x27;t the AI\u2014it was making security tools output data that an LLM can actually understand tools like YARA, Volatility, and Nmap output unstructured text with inconsistent formats. I built parsers that convert this into structured JSON, which the LLM can then reason about intelligently. Without that layer, you get\nhallucinations and garbage analysis.<p>Current tool integrations:\n  - Red Team: Nmap (with CVE correlation), Metasploit, Sliver C2, exploit database lookup\n  - Blue Team: Volatility 3 (memory forensics), YARA (malware detection), Chainsaw (Windows event log analysis),\n  PCAP analysis, Zeek, Suricata\n  - Cross-tool intelligence: YARA detection \u2192 CVE lookup \u2192 patching steps; Nmap scan \u2192 Metasploit modules ready-to-run commands<p>The privacy angle exists because I couldn&#x27;t paste potential malware samples, memory dumps, or customer network scans into ChatGPT without violating every security policy. Everything runs on localhost:11434\u2014no data ever leaves your\nmachine. For blue teamers handling sensitive investigations or red teamers on client networks, this is non-negotiable.<p>Real-world example from the demo syd scans a directory with YARA, hits on a custom ransomware rule, automatically looks up which CVE was exploited(EternalBlue&#x2F;MS17-010), explains the matched API calls, and generates an incident response workflow\u2014all in about 15 seconds. That beats manual analysis by a significant margin.<p>What I&#x27;d love feedback on:<p>1. Tool suggestions: What other security tools would you want orchestrated this way? I&#x27;m looking at adding Capa(malware capability detection) and potentially Ghidra integration.\n  2. For SOC&#x2F;IR folks: How are you currently balancing AI utility with operational security? Are you just avoiding\n  LLMs entirely, or have you found other solutions?\n  3. Beta testers: If you&#x27;re actively doing red&#x2F;blue team work and want to try this on real investigations, I&#x27;m\n  looking for people to test and provide feedback. Especially interested in hearing what breaks or what features are\n   missing.<p><pre><code>  The goal isn&#x27;t to replace your expertise\u2014it&#x27;s to automate the tedious parts (hex decoding, correlating CVEs,explaining regex patterns) so you can focus on the actual analysis. Think of it as having a junior analyst who never gets tired of looking up obscure Windows API calls.\n\n  Check out sydsec.co.uk for more info, or watch the full demo at the YouTube link in the original post.</code></pre>", "author": "paul2495", "timestamp": "2025-11-24T07:54:44+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-24T17:11:19.367792+00:00", "processed": false}
