{"id": "hn_story_47197243", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47197243", "title": "Anthropic vs. DoD: \"Any lawful use\" is a fight about control", "text": "I served 12 years infantry, then built targeting tools at JSOC vs ISIS. Now I lead a team building AI tools automating the compliance process. I\u2019ve got opinions on Anthropic + DoD<p>When people argue about \u201cAI in weapons\u201d like it\u2019s a sci-fi trigger bot\u2026 I can\u2019t take it seriously.<p>A \u201ckill chain\u201d isn\u2019t a vibe. It\u2019s a process<p>Find, Fix, Track, Target, Engage, Assess (F2T2EA) and most of it is information work: sorting signal from noise, building confidence, tightening timelines, and getting decisions to the right humans fast enough to matter.<p>That\u2019s why this Anthropic vs. DoD fight is getting attention. It\u2019s not just \u201cethics.\u201d<p>-&gt; It\u2019s about control.<p>Here\u2019s what\u2019s actually on the table:<p>Anthropic says they\u2019ll support the military \u2014 but they want two carve-outs: no mass domestic surveillance and no fully autonomous weapons (their definition: systems that \u201ctake humans out of the loop entirely\u201d and automate selecting&#x2F;engaging targets).<p>Anthropic also says DoD demanded \u201cany lawful use\u201d and threatened offboarding &#x2F; \u201csupply chain risk\u201d pressure if they didn\u2019t comply.<p>A DoD memo posted on media.defense.gov explicitly calls for models \u201cfree from usage policy constraints\u201d and directs adding standard \u201cany lawful use\u201d language into AI contracts.<p>The dispute escalated fast \u2014 including federal offboarding&#x2F;blacklist actions and a \u201csupply chain risk\u201d designation as reported by major outlets. \nNow my take, as someone who\u2019s lived inside the targeting reality:<p>AI can absolutely help the kill chain without ever being the one \u201cpulling the trigger.\u201d<p>Speeding up Find&#x2F;Fix&#x2F;Track&#x2F;Target changes outcomes \u2014 and it\u2019s not hypothetical.<p>But if we\u2019re going to talk about \u201cany lawful use,\u201d then stop outsourcing national policy to contract fights.<p>DoD already has policy that autonomous weapon systems should allow appropriate human judgment over the use of force. \nSo the real question isn\u2019t whether humans matter.<p>It\u2019s this:<p>Do we want safety and governance implemented at the model layer (vendor guardrails), the contract layer (\u201cany lawful use\u201d), or the law&#x2F;policy layer (Congress + DoD doctrine + auditing)?<p>Because \u201cTerms of Service vs. warfighting\u201d is a stupid place to settle a question this big.<p>If you\u2019ve worked in intel, targeting, acquisition, or governance:<p>Where should the boundary live? model, contract, or law, and who owns accountability when it breaks?", "author": "colek42", "timestamp": "2026-02-28T16:30:32+00:00", "score": 1, "num_comments": 1, "products": ["claude"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-28T17:11:14.506279+00:00", "processed": false}
{"id": "hn_comment_47197149", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47197149", "title": "Re: Unfreeze for ChatGPT \u2013 Fix freezing on long conver...", "text": "ChatGPT renders every message in the DOM at once. At 2,000 messages that&#x27;s ~500K nodes. The tab freezes or crashes.<p>The AI handles long conversations fine. It&#x27;s purely a frontend problem \u2014 React re-rendering an ever-growing tree.<p>The fix is simple: intercept the fetch response for &#x2F;backend-api&#x2F;conversation&#x2F;{id}, truncate the mapping to the last N messages for rendering, keep full context for the model. 30KB, no dependencies, no external requests.<p>I built this because my most useful conversations were becoming unusable. Chrome Web Store submission is pending review, so distributing via Gumroad for now.<p>Happy to answer questions about the implementation.", "author": "inem", "timestamp": "2026-02-28T16:23:37+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:14.762348+00:00", "processed": false}
{"id": "hn_story_47196746", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47196746", "title": "Garbage In, Garbage Out: The Degradation of Human Requirements in the LLM Era", "text": "The LLM Paradox: We\u2019re Forgetting How to Speak to Humans<p>The longer we use LLM services, the more I see a specific kind of &quot;psychosis&quot; spreading in the workplace. LLMs are so good at hallucinating a coherent answer from a vague prompt that people have started to believe their vague prompts were actually coherent.<p>LLMs Are Not Humans\nIt sounds obvious, but we are losing our grip on this fact. People are beginning to treat their colleagues like a black-box LLM. They\u2019ve forgotten that human communication requires precision, shared context, and accountability. In the pre-LLM era, &quot;make it pop&quot; was a phrase reserved for clueless clients. Now, it\u2019s becoming the standard operating procedure inside engineering teams.<p>The &quot;Do It Well, You Figure It Out&quot; Fallacy\nI see managers\u2014even those with engineering backgrounds\u2014who are terrified of being held accountable for their own bad ideas. They hide behind vagueness. They use tools like Claude Code as a shield to bypass technical debt discussions.<p>When an engineer spends days fixing a half-baked requirement and managing technical constraints, the feedback isn&#x27;t &quot;Thank you for the due diligence.&quot; Instead, it\u2019s: &quot;See? It was possible after all. Why did you push back so hard? LLMs could&#x27;ve done it in seconds.&quot; This is gaslighting. They want the output of a senior engineer while providing the input of a garbage prompt.<p>The Death of Articulation\nLLMs accept &quot;garbage in&quot; and provide &quot;plausible out.&quot; This has become a drug. People are losing the ability to articulate their own thoughts. They throw a mess of words at you and expect a miracle. If this continues, we aren&#x27;t just looking at bad software; we\u2019re looking at a breakdown of professional sanity.<p>I\u2019ve felt the symptoms myself. Lately, I\u2019ve caught myself thinking, &quot;Explaining this to my team is a waste of &#x27;communication cost.&#x27; I\u2019d rather just pay for more API tokens and do it myself.&quot;<p>But we must remember: A high-functioning team is not a collection of prompt engineers. True teamwork is exponentially more efficient than a lone developer with an LLM. We cannot afford to lose the art of talking to each other.", "author": "waylake", "timestamp": "2026-02-28T15:51:27+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:16.228047+00:00", "processed": false}
{"id": "hn_story_47196596", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47196596", "title": "Show HN: IssueScout \u2013 Find open source issues worth contributing to", "text": "I built IssueScout to solve a problem I had as a beginner looking to contribute to open source: GitHub has hundreds of thousands of &quot;good first issue&quot; labeled issues, but there&#x27;s no way to know if the repo behind one is actively maintained or if the issue is actually beginner-friendly.<p>IssueScout adds two things on top of GitHub&#x27;s search:<p>1. A Community Health Score (0-100) per repository \u2014 computed from 7 factors: CONTRIBUTING.md, license, code of conduct, recent activity, star count, issue response time, and PR merge rate. A score of 80+ means someone will actually review your PR.<p>2. AI Difficulty Estimation \u2014 a rule-based keyword analyzer runs first. If confidence is below 80%, it falls back to GPT-4o-mini. A purple sparkle shows when AI was used.<p>Architecture choices that might be interesting to HN:\n- Each user&#x27;s GitHub OAuth token powers their own API requests (5K&#x2F;hr per user) instead of a single server PAT. Scales linearly with users.\n- Two-level caching: issue difficulty cached 24h, repo health cached permanently with stale-while-revalidate at 48h. The IndexedRepo collection grows over time into a shared database of scored repos.\n- Two-phase progressive loading: raw GitHub results return instantly, enrichment fills in asynchronously. No spinners.\n- Rule-based AI first, LLM fallback only when needed. Keeps costs near zero for most queries.\nStack: Next.js 16, TypeScript, MongoDB Atlas, GitHub GraphQL API, OpenAI GPT-4o-mini, Vercel.<p>Live at <a href=\"https:&#x2F;&#x2F;issuescout.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;issuescout.dev</a> \u2014 sign in with GitHub to try it.<p>MIT licensed. Full architecture docs: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;turazashvili&#x2F;issuescout.dev&#x2F;blob&#x2F;main&#x2F;docs&#x2F;ARCHITECTURE.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;turazashvili&#x2F;issuescout.dev&#x2F;blob&#x2F;main&#x2F;doc...</a>", "author": "axrisi", "timestamp": "2026-02-28T15:40:07+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:16.736636+00:00", "processed": false}
{"id": "hn_comment_47197073", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47197073", "title": "Re: Cognitive Debt: When Velocity Exceeds Comprehensio...", "text": "Very much feel this.<p>I wrote a SaaS project over the weekend. I was amazed at how fast Claude implemented features. 1 sentence turned into a TDD that looked right to me and features worked<p>but now 3 weeks later I only have the outlines of how it works and regaining the context on the system sounds painful<p>In projects I hand wrote I could probably still locate major files and recall system architectures after years being away", "author": "sghiassy", "timestamp": "2026-02-28T16:17:42+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone", "navigation"], "sentiment": null, "collected_at": "2026-02-28T17:11:17.087133+00:00", "processed": false}
{"id": "hn_story_47196085", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47196085", "title": "Show HN: Nano Banana 2 \u2013 4K AI image generator with accurate text rendering", "text": "Hey HN,<p><pre><code>  I built Nano Banana 2, an AI image generation platform powered by Google&#x27;s Gemini 3.1 Flash Image   \n  model.                                                                                               \n                                                                                                       \n  The main problems I wanted to solve:                                                                 \n  - Text rendering in AI images has always been broken. This model gets it right ~90% of the time.     \n  - Most generators cap at 1-2K. This does true 4K output.                                             \n  - No character consistency across images. This tracks up to 5 characters + 14 objects.               \n                                                                                                       \n  Tech stack: Next.js 16, React 19, TypeScript, Drizzle ORM, PostgreSQL, Cloudflare R2.                \n                                                                                                       \n  4 models available depending on your needs \u2014 from $0.039&#x2F;image (budget) to $0.134&#x2F;image (pro).       \n  Credits never expire. Free credits on signup.                                                        \n                                                                                                       \n  Live at https:&#x2F;&#x2F;ainanobanana2.pro                                                                    \n                                                                                                       \n  Happy to answer any questions about the tech, the Gemini API integration, or the business model</code></pre>", "author": "hoxihan", "timestamp": "2026-02-28T14:59:54+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:19.342135+00:00", "processed": false}
{"id": "hn_story_47195713", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47195713", "title": "Show HN: OpenPencil - Open-source vector design tool controlled by AI Agents", "text": "Hey! I&#x27;m the creator of OpenPencil, and I&#x27;m super excited to share it with you today.\nWe are entering the era of AI Agents, but our design tools are still stuck in the GUI era. We are constantly downloading &quot;final_v9.fig&quot; and manually clicking to tweak UI elements. I wanted to change that.<p>OpenPencil isn&#x27;t just another design tool with a magic AI button. It is structurally built for AI.<p>Here is why it&#x27;s different:<p>Agentic Design (MCP Server): You can connect Claude, Cursor, or any MCP-compatible agent directly to your design. Tell your AI IDE to &quot;update the login screen to match the new dark mode theme,&quot; and it modifies the design file without you ever touching a mouse.<p>Design-as-Code: The .op format is pure JSON. Finally, you can Git commit, diff, and PR your design files just like your codebase.<p>100% Open Source (MIT): No subscriptions, no vendor lock-in. Build on top of it, fork it, make it yours.<p>I built this because I believe the future of design is Human creativity + Agent execution.<p>I&#x27;d love your feedback! Drop your questions below, and let me know what features you want to see next!", "author": "finiking", "timestamp": "2026-02-28T14:21:23+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-28T17:11:20.806996+00:00", "processed": false}
{"id": "hn_story_47195225", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47195225", "title": "Show HN: Paster \u2013 A keyboard-first clipboard manager for Vim users", "text": "Hi HN,<p>I\u2019ve tried just about every clipboard manager for macOS, but I&#x27;ve always ran into the same two issues: either they were heavy Electron apps that felt sluggish, or they required me to take my hands off\nthe keyboard to find what I needed. \nRaycast is what I used most of the time, but it&#x27;s slow in loading screenshots and is search first, meaning I needed to leave the loved home row to scroll down through items.<p>I built Paster because I wanted something that felt like an extension of my terminal and had instant load of the content being copied. It&#x27;s written in Rust to keep the latency as low as possible and uses a local SQLite database for history.\nIt&#x27;s completely private and does not have any telemetry, your data is your own. It does reach to it&#x27;s domain to validate the license.<p>Some specific choices I made:\n- Navigation: I mapped it to j&#x2F;k and &#x2F; for search. If you use Vim or a terminal, it should feel like second nature.\n- Privacy: I\u2019m not a fan of cloud-syncing my clipboard. Everything stays local on your machine.\n- Quick look: I&#x27;ve added a nice little bonus feature to view each clipboard item in a larger quick look window. Pretty handy for screenshots and offers syntax highlighting for text.<p>It\u2019s currently a paid app with a 7-day trial. I\u2019m really curious what the community thinks about the &quot;Vim-for-everything&quot; approach.\nFor transparency sake, it&#x27;s built with help from AI (Gemini) mostly for UI stuff which requires lots of boiler plate.<p>It&#x27;s Macos only for now, I do intend to work on a Linux version but no promises.", "author": "luanderock", "timestamp": "2026-02-28T13:37:44+00:00", "score": 2, "num_comments": 0, "products": ["gemini"], "categories": ["navigation"], "sentiment": null, "collected_at": "2026-02-28T17:11:23.322074+00:00", "processed": false}
{"id": "hn_story_47195190", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47195190", "title": "Show HN: AdaptGauge \u2013 I found that adding few-shot examples can make LLMs worse", "text": "I tested 8 LLMs across 4 tasks at different few-shot counts (0, 1, 2, 4, 8) and found three patterns where adding examples actively degrades performance:<p>1. Peak regression: Gemini 3 Flash scored 64% at 4-shot, then crashed back to 33% at 8-shot\n2. Ranking reversal: The zero-shot leader dropped to third once examples were added\n3. Selection method matters: Switching from hand-picked to TF-IDF examples collapsed a model from 50%+ to 35%<p>This aligns with recent research (Tang et al. 2025 &quot;over-prompting&quot;, NDSS 2025 vulnerability detection drops, Chroma Research &quot;context rot&quot;).<p>I built AdaptGauge to detect these patterns automatically. It tracks learning curves across shot counts and flags collapse with pattern classification (immediate, gradual, peak regression).<p>Open source, MIT licensed. Pre-computed demo results included so you can see the patterns without API keys.<p>Article with full results: <a href=\"https:&#x2F;&#x2F;shuntaro-okuma.medium.com&#x2F;when-more-examples-make-your-llm-worse-discovering-few-shot-collapse-d3c97ff9eb01\" rel=\"nofollow\">https:&#x2F;&#x2F;shuntaro-okuma.medium.com&#x2F;when-more-examples-make-yo...</a><p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ShuntaroOkuma&#x2F;adapt-gauge-core\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ShuntaroOkuma&#x2F;adapt-gauge-core</a>", "author": "shuntaro-okuma", "timestamp": "2026-02-28T13:34:47+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["onboarding", "response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:23.715284+00:00", "processed": false}
{"id": "hn_comment_47195710", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47195710", "title": "Re: Timeline: Anthropic, OpenAI, and U.S. Government...", "text": "Kind of odd it doesn&#x27;t lead with the Anthropic statement predicting they were about be designated a risk because they&#x27;d refused to move past their red lines.", "author": "mpalmer", "timestamp": "2026-02-28T14:21:11+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-28T17:11:25.025984+00:00", "processed": false}
{"id": "hn_comment_47196621", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47196621", "title": "Re: Full Interview: Anthropic CEO Dario Amodei on Pent...", "text": "The interviewer was super biased, no?<p>The framing of &quot;so you think you know better than the pentagon&quot; which she said verbatim sounds like a pentagon talking point.<p>That said, Dario could have responded better. Instead of flailing around he could&#x27;ve said &quot;on the question of reliability of Anthropic&#x27;s products in killing autonomously, Anthropic knows better, yes.", "author": "ekjhgkejhgk", "timestamp": "2026-02-28T15:41:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-28T17:11:25.380105+00:00", "processed": false}
{"id": "hn_comment_47197313", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47197313", "title": "Re: What AI coding costs you...", "text": "I recently accepted-ish a position at a very ai-forward company. Manual programming was somewhat discouraged entirely.<p>I&#x27;ve used AI tools in the past for maths I didn&#x27;t understand or errors I couldn&#x27;t make sense of, and wrote the bulk myself, but now we have as mentioned, opus&#x2F;sonnet 4.5- which work <i>great</i>.<p>As part of this, I had to integrate two new apis- nornally, when I write an API wrapper I end up learning a lot about how the API feels, what leads to what and how it smells, etc. This time? I just asked Claude to read it&#x27;s docs, then gave suggestions about how I wanted it to be laid out. As a result? I have no idea how these apis feel, their models, etc. If I want to interact with them, I ask Claude how I do a thing with the library it made.<p>Mind you, the library is good. I looked over everything, it&#x27;s fairly thin and it&#x27;s exactly how I would write it, as I suggested it do. But I have no deep understanding, much less an understanding of how it got integrated in.<p>Like, normally when I integrate something in I learn a bit about the codebase I&#x27;m integrating it into. Do that enough times, and I understand the codebase at depth, how things plug in. This time? Nada.<p>It&#x27;s.... Deeply uncomfortable, to know so little but still be able to do so much. It doesn&#x27;t matter if I get it to explain it, that&#x27;s just information that washes off when I move onto the next thing. The reflexive memory isn&#x27;t built.<p>All of which is to say, I agree with the article.", "author": "Vexs", "timestamp": "2026-02-28T16:35:42+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:25.604404+00:00", "processed": false}
{"id": "hn_story_47194625", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47194625", "title": "Show HN: Expose \u2013 OSS localhost tunneling CLI with a self\u2011hosted server", "text": "Expose is a small open\u2011source tunneling CLI written in Go that lets you expose localhost with a simple command, similar to ngrok&#x2F;localtunnel.<p>So far it has focused on the client side. Over the last few weekends I\u2019ve been working on a self\u2011hosted tunnel server so you can run the whole stack yourself.<p>The new server (still early) lets you:<p>Run expose server --domain yourdomain.com on a VPS&#x2F;home server<p>Connect clients with expose tunnel --server yourdomain.com:8080<p>Proxy public HTTP traffic \u2192 server \u2192 client \u2192 localhost<p>Keep a simple in\u2011memory tunnel registry to drive the flow end\u2011to\u2011end<p>What\u2019s missing for now:<p>No auth or TLS yet<p>No persistence or clustering<p>Minimal protocol, focused on being easy to read and change<p>Links:<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kernelshard&#x2F;expose\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kernelshard&#x2F;expose</a><p>Self\u2011hosted server PR: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;kernelshard&#x2F;expose&#x2F;pull&#x2F;26\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;kernelshard&#x2F;expose&#x2F;pull&#x2F;26</a><p>I\u2019d love feedback from people who\u2019ve built tunneling&#x2F;reverse\u2011proxy tools (design, failure modes, protocol), and from self\u2011hosters who might want to run their own lightweight tunnel server.", "author": "samiulsk", "timestamp": "2026-02-28T12:40:47+00:00", "score": 1, "num_comments": 0, "products": ["grok"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-28T17:11:27.355809+00:00", "processed": false}
{"id": "hn_story_47194215", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47194215", "title": "Show HN: Prompt-run \u2013 run .prompt files against any LLM from the terminal", "text": "I built this because prompts kept ending up in the worst possible places \u2014 Python strings, Notion docs, `.txt` files, Slack threads. There was no clean way to version them, diff them, or test the same prompt across different models without writing a throwaway script.<p>prompt-run treats `.prompt` files as first-class runnable artifacts. A `.prompt` file is a YAML header (model, provider, temperature, variable declarations) followed by a plain text body with `{{variable}}` substitution. You run it from the terminal:<p>```\nprompt run summarize.prompt --var text=&quot;$(cat article.txt)&quot;\n```<p>You can override model and provider at runtime without editing the file:<p>```\nprompt run summarize.prompt --model gpt-4o --provider openai\n```<p>The `prompt diff` command runs the same prompt for two different inputs (or two prompt versions against the same input) and shows outputs side by side. That&#x27;s the feature I find most useful when iterating.<p>Supports Anthropic, OpenAI, and Ollama out of the box. MIT license. No telemetry, no accounts, no backend \u2014 just a local CLI tool that talks directly to whichever provider you configure.<p>The file lives in your repo, gets versioned by git, and can be reviewed in PRs like any other code.<p>Would be curious to hear whether others have hit this same friction and how you&#x27;ve handled it.<p>PyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;prompt-run&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;prompt-run&#x2F;</a>", "author": "maneeshthakur", "timestamp": "2026-02-28T12:03:45+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:29.043418+00:00", "processed": false}
{"id": "hn_story_47194011", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47194011", "title": "Show HN: H-CLI \u2013 Manage network infrastructure with natural language", "text": "Network engineer here. I&#x27;ve been building my own parallel SSH tooling (h-ssh) for years, multi-vendor (Junos, Arista, IOS, NXOS), parallel telnet, parallel REST API calls. It&#x27;s been my daily driver in production.<p>A few months ago I gave it an AI brain. h-cli lets you manage infrastructure by sending plain English messages in Telegram. Claude Code by default, also works with self-hosted models through the Claude Code framework via API calls to vLLM&#x2F;Ollama.<p>What it can do:<p>- &quot;Discover the CLOS fabric and document everything in NetBox with cable detail&quot; \u2014 12 routers, full cabling, 4 minutes (GIF on the repo)\n- Parallel REST calls across APIs in a single job \u2014 correlated results in seconds ; copied from h-ssh\n- EVE-NG lab automation \u2014 natural language to full lab deployment, bootstrap, and verification\n- Grafana dashboard rendering straight into Telegram\n- Teachable skills \u2014 demonstrate a workflow, it learns it\n- Chunk-based conversation memory (24h) + Qdrant vector memory for your own datasets (I used EVPN docs, worked perfectly for creating templates and troubleshooting)\n- Redis-based horizontal scaling,  designed with future plans to run multiple instances against a shared vLLM backend<p>Safety: a separate stateless LLM (Haiku, also adjustable for local LLMs) gates every command with zero conversation context \u2014 can&#x27;t be social-engineered. Pattern denylist, two isolated Docker networks, non-root, cap_drop ALL, HMAC-signed results. 44 hardening items total.<p>Self-hosted, Docker Compose, 9 containers, MIT licensed.<p>The interesting part might be how it was built: one operator coordinating 8 parallel AI agent teams, zero human developers. The development methodology doc covers the full process, architecture, coordination via git + Redis, conflict resolution between agents. Of course i reviewed the code changes, hence the commit discipline.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;h-network&#x2F;h-cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;h-network&#x2F;h-cli</a>", "author": "h-network", "timestamp": "2026-02-28T11:43:46+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:29.876322+00:00", "processed": false}
{"id": "hn_story_47193789", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47193789", "title": "Show HN: Jarvish \u2013 The J.A.R.V.I.S. AI inside your shell investigates errors", "text": "Hi HN, I&#x27;m the creator of Jarvish.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;tominaga-h&#x2F;jarvis-shell\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tominaga-h&#x2F;jarvis-shell</a><p>I spend most of my day in the terminal, and I got incredibly frustrated with the standard error-resolution loop: command fails -&gt; copy the stderr -&gt; open a browser -&gt; paste into ChatGPT&#x2F;Google -&gt; copy the fix -&gt; paste back into the terminal. It completely breaks the flow state.<p>I wanted a seamless experience where the shell already knows the context of what just happened.<p>So I built Jarvish. It\u2019s a fully functional interactive shell written in Rust, but with an AI agent seamlessly integrated into the REPL loop. You don&#x27;t need any special prefixes\u2014if you type `ls -la`, it runs it. If you type `Jarvis, why did that build fail?`, it routes to the AI.<p>Here is how it works under the hood:<p>- The &quot;Black Box&quot; (I&#x2F;O Capture): It uses `os_pipe` and multithreading to tee the `stdout`&#x2F;`stderr` of child processes in real-time. This captures the output to memory for the AI while simultaneously rendering it to the terminal without breaking interactive TUI tools.<p>- Context Memory: The captured I&#x2F;O is compressed with `zstd`, hashed (like Git blobs), and the metadata is stored in a local SQLite database (`rusqlite`). When you ask the AI a question, it automatically retrieves this recent I&#x2F;O history as context.<p>- Agentic Capabilities: Using `async-openai` with function calling, the AI can autonomously read files, execute shell commands, and investigate issues before giving you an answer.<p>- REPL: Built on top of `reedline` for a Fish-like experience (syntax highlighting, autosuggestions).<p>I\u2019ve been using it as my daily driver (currently v1.1.0). I would absolutely love to hear your thoughts on the architecture, the Rust implementation, or any feature requests!", "author": "tominaga-h", "timestamp": "2026-02-28T11:19:27+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:30.779332+00:00", "processed": false}
{"id": "hn_comment_47194323", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47194323", "title": "Re: OpenAI \u2013 How to delete your account...", "text": "I was just about to change from OpenAI to Anthropic, however when signing up I get this message:<p>&gt; Unfortunately, Claude is not available to new users right now. We&#x27;re working hard to expand our availability soon.<p>That&#x27;s unfortunate timing.", "author": "aniviacat", "timestamp": "2026-02-28T12:12:52+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt"], "categories": ["onboarding"], "sentiment": null, "collected_at": "2026-02-28T17:11:31.978001+00:00", "processed": false}
{"id": "hn_comment_47193948", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47193948", "title": "Re: OpenAI \u2013 How to delete your account...", "text": "LOL I keep getting, \u201c\nOops, an error occurred!\nToo many failed attempts.\nTry again\u201d\u2026 my login codes are mysteriously not working when trying to delete my OpenAI&#x2F;ChatGPT account.", "author": "abbadadda", "timestamp": "2026-02-28T11:37:11+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["error_messages"], "sentiment": null, "collected_at": "2026-02-28T17:11:32.009766+00:00", "processed": false}
{"id": "hn_story_47193064", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47193064", "title": "Stop Burning Your Context Window \u2013 How We Cut MCP Output by 98% in Claude Code", "text": "", "author": "mksglu", "timestamp": "2026-02-28T10:01:20+00:00", "score": 34, "num_comments": 7, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:34.034620+00:00", "processed": false}
{"id": "hn_comment_47193074", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47193074", "title": "Re: Stop Burning Your Context Window \u2013 How We Cut MCP ...", "text": "Author here. I shared the GitHub repo a few days ago (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=47148025\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=47148025</a>) and got great feedback. This is the writeup explaining the architecture.<p>The core idea: every MCP tool call dumps raw data into your 200K context window. Context Mode spawns isolated subprocesses \u2014 only stdout enters context. No LLM calls, purely algorithmic: SQLite FTS5 with BM25 ranking and Porter stemming.<p>Since the last post we&#x27;ve seen 228 stars and some real-world usage data. The biggest surprise was how much subagent routing matters \u2014 auto-upgrading Bash subagents to general-purpose so they can use batch_execute instead of flooding context with raw output.<p>Source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;mksglu&#x2F;claude-context-mode\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;mksglu&#x2F;claude-context-mode</a>\nHappy to answer any architecture questions.", "author": "mksglu", "timestamp": "2026-02-28T10:02:07+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:34.100665+00:00", "processed": false}
{"id": "hn_story_47192693", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47192693", "title": "Israel Is Attacking Iran", "text": "If you&#x27;re not willing to die building what you&#x27;re building, move on\nThe war will escalate. It may spill over, include a lot of parties.<p>I&#x27;m in Jordan right now, not in direct danger but i do see the missiles from my window as i am typing this WHAT A VIEW.  I hear sirens.\nAnd I&#x27;m in the middle of building a zero knowledge architecture for an AI operating system for founders. Agentic work. Rebuilt Word, Excel, Forms, Calendar to be ai native blah blah blah...\nDo you see how ridiculous this sounds when F22s are over my head?\ni have to reflect because is this how i want to die? what will i say to god? I was one step away from PMF, god please put me back?<p>I am a highschool dropout, my co founder works oil rigs to fund both of us and works between shifts as the business guy, we have it hard.<p>I don&#x27;t know. But I can&#x27;t stop. So I just keep building.<p>I just wanted to give my voice to the first world, to the Valley specifically.<p>The world is much bigger than whether Anthropic declines a deal with the DoD. Bigger than whether you raise your seed round. Bigger than whether you fail or get into YC.<p>If you&#x27;re not willing to die building what you&#x27;re building, move on. Take a better hobby. Go into finance or law.<p>Because some of us are building from places where that question isn&#x27;t hypothetical.", "author": "alsufinow", "timestamp": "2026-02-28T09:16:16+00:00", "score": 28, "num_comments": 19, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-02-28T17:11:35.127783+00:00", "processed": false}
{"id": "hn_story_47192207", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47192207", "title": "Show HN: Agent Hand \u2013 Tmux session manager for AI coding agents (Rust)", "text": "I was juggling 5+ Claude Code instances simultaneously. Four terminal windows, each with 3-4 tmux panes. &quot;Which Claude is working on which task?&quot; Wasting 10+ minutes just finding the right session.<p>Built Agent Hand, a Rust rewrite of agent-deck with:<p>- Ctrl+N jumps to the most urgent session (waiting \u2192 ready \u2192 running)\n- Visual status from PTY output patterns (regex, no polling)\n- Sub-millisecond fuzzy search (Ctrl+G)\n- Dedicated tmux server (isolated from your default)<p>The WAITING state (!) is detected from prompt patterns like &quot;Do you want to proceed?&quot; The READY state () uses a TTL\u2014if it was running recently and now idle, it&#x27;s probably done.<p>MIT licensed. Would appreciate feedback on the PTY monitoring approach and any edge cases I&#x27;m missing.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;weykon&#x2F;agent-hand\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;weykon&#x2F;agent-hand</a>\n<a href=\"https:&#x2F;&#x2F;weykon.github.io&#x2F;agent-hand&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;weykon.github.io&#x2F;agent-hand&#x2F;</a>", "author": "weykon", "timestamp": "2026-02-28T08:22:44+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:37.270787+00:00", "processed": false}
{"id": "hn_story_47191530", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47191530", "title": "Show HN: Bridge your Claude/OpenAI subs into a team API with per-key cost caps", "text": "Hey HN, I built this because I wanted to give my team access to Claude and GPT models for internal testing, but the official APIs have no per-key spending controls. You can&#x27;t cap a key at $5&#x2F;day or 100 requests&#x2F;month \u2014 it&#x27;s all or nothing. With non-technical team members in the mix (designers, PMs, QA), one forgotten loop or oversized prompt away from an ugly bill wasn&#x27;t a risk I wanted to manage manually. Idea was to allow the members to test with these restricted API keys before using official keys.<p>So I built a bridge: it wraps the Claude Code CLI and Codex CLI behind an Express API, backed by existing Max&#x2F;Pro subscriptions instead of per-token billing. Each team member gets their own API key with hard limits \u2014 requests&#x2F;day, tokens&#x2F;month, cost caps. Hit the limit and the key stops working. No surprises. An admin dashboard shows who&#x27;s using what in real time.<p>Key features:\n- Two providers: &#x2F;generate (Claude) and &#x2F;generate-codex (Codex)\n- Per-user API keys with SHA-256 hashing (shown once, never stored raw)\n- Per-key hard limits with real-time tracking and enforcement\n- Admin dashboard for key management, usage monitoring, and request logs\n- Deploy on a $5 VPS behind Cloudflare Tunnel<p>What it&#x27;s NOT: A production API replacement. It&#x27;s for internal tooling and prototyping. CLI invocations add ~3-8s latency vs direct API calls.<p>Important: Wrapping CLI subscriptions behind a shared API may violate the Terms of Service of the underlying providers. Anthropic&#x27;s Consumer ToS (updated Feb 2026) prohibits using subscription OAuth tokens in third-party tools, and OpenAI&#x27;s ToS prohibits account sharing. Review the applicable terms before using this. See the Disclaimer section in the README for details.<p>Security was a focus: execFile (no shell injection), timing-safe auth, CSP&#x2F;HSTS, input validation, rate limiting. Details in SECURITY.md.<p>Stack: Node.js, TypeScript, Express. No database \u2014 JSON files on disk.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Shreyas-Dayal&#x2F;ai-cli-bridge\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Shreyas-Dayal&#x2F;ai-cli-bridge</a><p>Would love feedback on the approach and any security concerns I might have missed.", "author": "shreyas8", "timestamp": "2026-02-28T07:11:15+00:00", "score": 1, "num_comments": 2, "products": ["claude", "chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-28T17:11:38.995888+00:00", "processed": false}
{"id": "hn_story_47190997", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47190997", "title": "How do I cancel my ChatGPT subscription?", "text": "", "author": "tobr", "timestamp": "2026-02-28T05:55:01+00:00", "score": 959, "num_comments": 230, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-02-28T17:11:41.793240+00:00", "processed": false}
{"id": "hn_comment_47192700", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47192700", "title": "Re: How do I cancel my ChatGPT subscription?...", "text": "The real story isn&#x27;t about cancelling one subscription. It&#x27;s that we&#x27;re watching vendor lock-in dissolve in real time.<p>18 months ago switching from ChatGPT meant meaningfully worse outputs. Today I routinely bounce between Claude, Gemini, local Qwen and Deepseek models depending on the task - coding in one, writing in another, privacy-sensitive stuff locally. The switching cost is approaching zero because the interface is converging on &quot;text box + API&quot;.<p>This is genuinely unusual in tech. Usually the longer you use a platform, the harder it is to leave (social graphs, file formats, ecosystem). With LLMs the opposite is happening - the longer the market matures, the easier switching gets, because open weights keep getting better and every provider&#x27;s API looks basically the same.<p>OpenAI&#x27;s moat was never the model. It was habit and brand recognition. Events like this erode brand faster than any technical competitor could.", "author": "Paddyz", "timestamp": "2026-02-28T09:16:55+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:41.890970+00:00", "processed": false}
{"id": "hn_comment_47190735", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47190735", "title": "Re: Show HN: Vigil \u2013 Zero-dependency safety guardrails...", "text": "Author here, happy to answer any questions.<p>Some context on why we built this: you might have seen the post earlier this week about someone building a file recovery tool after Claude Code rm -rf&#x27;d their Obsidian vault through a symlink. We had similar near-misses running our own agent swarm, agents curling cloud metadata endpoints, attempting path traversal, executing destructive commands during &quot;cleanup&quot; steps. We kept adding one-off guards and eventually realized this should be a proper library.<p>The main design choice was making it deterministic rather than using an LLM to review tool calls. An LLM guarding another LLM felt like asking the fox to guard the henhouse. Pattern matching is boring, but it&#x27;s fast, predictable, and works offline.<p>Happy to hear about false positives, missing threat categories, or use cases where the rule set is too aggressive. That&#x27;s the main thing we want to calibrate for v0.2.", "author": "HexitLabs", "timestamp": "2026-02-28T05:11:52+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:43.628668+00:00", "processed": false}
{"id": "hn_story_47190656", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47190656", "title": "Show HN: Magicreader \u2013 shorten and simplify web articles in-place", "text": "Hey HN! This is Michael from magicreader. We\u2019ve just released a Chrome extension that enables you to read web articles in the style and length you prefer.<p>The idea is similar to Violentmonkey&#x2F;Tampermonkey and Tweeks, but focused on reading. For example, let\u2019s say you want to read a research paper online, but you\u2019re not an expert in the domain. You can use magicreader to rewrite the paper for a general audience and swap this simplified version directly into the page. While you\u2019re reading, you can seamlessly flip back and forth between the simplified version and the original.<p>How this is different from using Claude&#x2F;ChatGPT: with magicreader, there\u2019s no need to copy-paste the text into a chat window, and there is no sidebar. Instead, the HTML of the article simply changes in-place, maintaining the core reading experience.<p>We currently support the following use cases:\n- Shorten: shorten web articles in-place to read 4x faster\n- Simplify (&quot;ELI5&quot;): adapt specialist writing (e.g., research papers) for a general audience\n- De-spin (&quot;Honest&quot;): annotate marketing&#x2F;PR materials to quickly spot unsupported claims\n- Clean: rewrite unclear or old-fashioned writing in a clean, modern style<p>Notes:\n- We don\u2019t bypass paywalls. We only operate on text you can already view in your browser.\n- When you rewrite a webpage, we send the full HTML to our backend; the rewritten text is then locally stored in your Chrome extension storage. The extension only sends data to the backend when you actively invoke magicreader. We don\u2019t track your browsing activity across pages.\n- We use AI to rewrite content, and AI can make mistakes. That\u2019s why we made it easy to flip back and forth between the rewritten version and the original\u2014without losing your place in the text.<p>Rewriting full web articles using large language models is expensive, so we\u2019re offering a limited free tier plus two paid plans. We\u2019re planning to expand the free tier by using smaller and on-device LLMs.<p>Demo video: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;pckMSxCFUDo\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;pckMSxCFUDo</a><p>Chrome extension: <a href=\"https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;magicreader&#x2F;phncpkelnahoiikbooekkgkjnefgfhil\" rel=\"nofollow\">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;magicreader&#x2F;phncpke...</a><p>We&#x27;d love feedback, particularly on 1) which reading mode is most useful, 2) where it breaks on real sites, and 3) any suggestions you have for new features.<p>You can reply directly here or email me at michael@magicreader.com.", "author": "mzelling", "timestamp": "2026-02-28T04:58:55+00:00", "score": 2, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["content_clarity"], "sentiment": null, "collected_at": "2026-02-28T17:11:43.857057+00:00", "processed": false}
{"id": "hn_comment_47189930", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47189930", "title": "Re: Show HN: Agents-lint \u2013 detect stale paths and cont...", "text": "Author here. To pre-empt the obvious question: yes, you could write a shell script to check if paths exist. The value here is three things a shell script doesn&#x27;t do:<p>1. Framework-specific pattern detection \u2014 knowing that @NgModule is stale in Angular 14+, or that ReactDOM.render() was removed in React 19, requires versioned knowledge about what&#x27;s current vs. deprecated. That&#x27;s not a grep.<p>2. The weekly CI schedule \u2014 context rot happens even when AGENTS.md hasn&#x27;t changed. Your codebase evolves around a static file. A one-time check misses this entirely.<p>3. Cross-file consistency \u2014 if you have both AGENTS.md and CLAUDE.md, they can silently contradict each other. One says `npm run test`, the other says `npm run test:unit`. Agents pick one arbitrarily.<p>A few things I found on real repos while building this: steipete&#x2F;agent-scripts has absolute paths like ~&#x2F;Projects&#x2F;bird&#x2F;bird in their AGENTS.md \u2014 works on one MacBook, fails silently everywhere else. The official agentsmd&#x2F;agents.md spec repo says &quot;execute the test suite (if present)&quot; in their own AGENTS.md \u2014 they&#x27;re not sure if they have tests. The sample AGENTS.md that everyone copy-pastes includes Turborepo monorepo commands that break in single-package projects.<p>None of this is criticism \u2014 it&#x27;s just how files rot. Happy to answer questions about the design.", "author": "devGiacomo", "timestamp": "2026-02-28T03:32:49+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:45.739277+00:00", "processed": false}
{"id": "hn_story_47189906", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=47189906", "title": "Show HN: Recall \u2013 Persistent Memory for Claude Code via MCP Hooks", "text": "Hi HN,<p>A while back I posted about recall MCP - <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45516584\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45516584</a>\nSince then I updated a series of times and received quite a good amount of positive response. I decided to take it a step further and make it an actual product. It has been a super interesting journey.<p>I built Recall because I was spending 10+ minutes every Claude Code session re-explaining my project. Architecture, conventions, past decisions \u2014 all gone after a session restart or context compaction.<p>Recall is an MCP server that gives Claude Code persistent memory.\nIt works by running four lifecycle hooks:<p>- session-start: fetches relevant memories and injects them as context\n- observe: captures key events (git commits, file changes, decisions) silently after Write&#x2F;Edit&#x2F;Task operations\n- pre-compact: saves critical state before Claude&#x27;s context window gets summarised (this is the most valuable hook \u2014 compaction kills nuance)\n- session-end: records a session summary<p>Install as a native Claude Code plugin:<p><pre><code>  &#x2F;plugin install recall@claude-plugins-official\n  &#x2F;recall:setup   \u2190 connects your API key\n</code></pre>\nThe plugin bundles the MCP server config, all 4 hooks, and auto-updates itself in the background. Alternatively, hooks-only install is still available for those who prefer it:<p><pre><code>  curl -fsSL https:&#x2F;&#x2F;recallmcp.com&#x2F;install-hooks | bash\n</code></pre>\nHooks are pure bash + curl. No daemon, no npm packages, no background processes. Every hook exits 0 on errors so it never blocks Claude.<p>Memory is stored in Redis with semantic search via embeddings (Voyage AI, Cohere, OpenAI, or others). Each tenant gets isolated storage with AES-256-GCM encryption.<p>Some features that might be interesting to this audience:<p>1. Native Claude Code plugin \u2014 ships as a proper plugin installable with `&#x2F;plugin install recall@claude-plugins-official`. Bundles MCP server config + all 4 hooks. Auto-updates in the background.<p>2. Webhook ingestion \u2014 route GitHub&#x2F;Stripe&#x2F;any webhook into a Claude session. Your AI becomes event-aware.<p>3. Self-hosted \u2014 `curl -fsSL <a href=\"https:&#x2F;&#x2F;install.recallmcp.com\" rel=\"nofollow\">https:&#x2F;&#x2F;install.recallmcp.com</a> | bash` gives you a Docker Compose stack with Redis + Recall. $12&#x2F;mo license, air-gapped compatible.<p>4. Team sharing \u2014 one Claude learns, all team Claudes know. Workspace-scoped with selective sharing.<p>Open source (MIT): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;joseairosa&#x2F;recall\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;joseairosa&#x2F;recall</a>\nHosted: <a href=\"https:&#x2F;&#x2F;recallmcp.com\" rel=\"nofollow\">https:&#x2F;&#x2F;recallmcp.com</a> (free tier: 500 memories)<p>Technical details: TypeScript, Express 5, Redis&#x2F;Valkey adapters,\nDrizzle ORM for billing&#x2F;teams on PostgreSQL, StreamableHTTP MCP transport. 16 consolidated MCP tools exposed.<p>Happy to discuss the architecture, MCP protocol integration, or the memory&#x2F;embedding strategy.", "author": "elfenleid", "timestamp": "2026-02-28T03:30:23+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-02-28T17:11:45.771295+00:00", "processed": false}
