{"id": "hn_comment_46080064", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46080064", "title": "Re: Meta hiding $27B in debt using advanced geometry...", "text": "I asked ChatGPT to make this more readable since it&#x27;s a mix of satire and actual information:<p>==============<p>Meta wants to build a huge AI data center campus in Louisiana. It costs about $28\u201329 billion. Instead of just borrowing the money itself and putting the debt on its own balance sheet, Meta uses a maze of LLCs and contracts to:<p>- Get $27.3 billion of debt raised by a special company called Beignet Investor LLC (80% owner of the project).<p>- Keep that debt off Meta\u2019s official balance sheet, even though:<p>\u25ab Meta designs the campus,<p>\u25ab pays for overruns,<p>\u25ab pays the rent,<p>\u25ab guarantees the value at the end,<p>\u25ab and will basically be the only user.<p>In real life, this is basically Meta borrowing to build its own data center. On paper, it\u2019s \u201csomeone else\u2019s\u201d debt.<p>Why is this off-balance-sheet?<p>The accounting rules say you only have to put an entity on your balance sheet if you \u201ccontrol\u201d it and take on most of the risk&#x2F;benefit.<p>Meta\u2019s position is:\n\u201cWe don\u2019t control this JV company, even though we do all the important things and take on all the risk.\u201d<p>The rating agency in the piece is mocking this. They list all the ways Meta obviously controls and supports the project, then say: under current accounting rules, if Meta insists it doesn\u2019t control it, we all politely pretend that\u2019s true. So the $27B debt doesn\u2019t show up on Meta\u2019s balance sheet, even though economically it\u2019s Meta\u2019s problem.", "author": "exacube", "timestamp": "2025-11-28T16:28:03+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-28T17:09:15.028514+00:00", "processed": false}
{"id": "hn_comment_46078490", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46078490", "title": "Re: Show HN: Calcurious \u2013 Step-by-step math with dynam...", "text": "Hey HN,<p>I\u2019ve been building Calcurious \u2014 a math tool that solves problems step-by-step and generates dynamic visuals (graphs, geometry, symbolic breakdowns) for each step. Each part of the reasoning can be expanded with a \u201cstep chat\u201d for deeper explanations. The LLM handles reasoning, but the diagrams + visualization manim engine are fully custom.<p>I\u2019m looking for feedback from people who care about correctness and clarity. It\u2019s truly inspiring to see the space evolving so quickly! I understand that recent advancements to the Gemini 3 model are a breakthrough in how we will all learn math even better, with its PhD-level reasoning and state-of-the-art scores on challenging math benchmarks like MathArena Apex and AIME 2025.<p>The focus on enhanced reasoning, multimodal understanding (for interpreting diagrams and video), and agentic capabilities for multi-step planning is a profound validation of the direction Calcurious is heading with its custom visualization and step-chat features. We&#x27;re all pushing toward a future where complex subjects like math are genuinely accessible to everyone. I&#x27;d love to hear your thoughts on how Calcurious can best serve learners and educators. I\u2019m especially interested in the features you think will be essential as these advanced models become more widespread.<p>I\u2019d appreciate thoughts on: where the reasoning is unclearvisuals that help vs visuals that distractproblem classes where it failsperformance issues, or rough UX edges Features We\u2019d Love to See in Math Tools What would your ideal AI-powered math learning assistant do? Given the immense potential of these new models, here are a few ideas for features we&#x27;d love to explore.<p>Which of these\u2014or others you suggest\u2014would be most impactful for you?<p>Error Analysis &amp; Correction: A mode that analyzes a user&#x27;s incorrect step, not just to show the right answer, but to diagnose the specific conceptual misunderstanding (e.g., &quot;You confused the product rule with the chain rule here&quot;) and provide targeted remedial practice on just that concept.<p>Proof Generation&#x2F;Debugging: For higher-level courses (like Abstract Algebra or Real Analysis), a feature that can help a student construct or debug a mathematical proof with the same step-by-step, explainable detail that Calcurious provides for calculations.<p>Interactive Simulation Generation: Beyond static graphs, what if the tool could generate a live, interactive simulation or mini-game based on the problem (e.g., a projectile motion problem generates a small game where you adjust launch angles)?<p>&quot;What If&quot; Scenarios: The ability to instantly tweak variables in the problem and see how the final solution, the steps, and the visualizations dynamically change. (e.g., &quot;What if the spring constant was 2k instead of k?&quot;)<p>Link again for convenience: <a href=\"https:&#x2F;&#x2F;beta.calcurious.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;beta.calcurious.ai&#x2F;</a><p>Thanks for checking it out \u2014 all critiques are welcome.", "author": "Tito-arch", "timestamp": "2025-11-28T13:35:27+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["content_clarity", "response_quality"], "sentiment": null, "collected_at": "2025-11-28T17:09:24.075326+00:00", "processed": false}
{"id": "hn_comment_46077750", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46077750", "title": "Re: Have you guys tried Stitch with Google?...", "text": "Have you guys tried Stitch with Google? It\u2019s amazing. I\u2019m really curious to know how it works in the backend. Does anyone have any idea? I noticed that the designs are quite good even though it uses Gemini. When I tried the same thing by cloning blot.new locally and testing it, there was a huge difference. I know it\u2019s a coding model, but still how is Google Stitch able to achieve this? Are they generating text or images behind the scenes? How are they so accurate and good?", "author": "pradeepodela", "timestamp": "2025-11-28T11:38:00+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-28T17:09:28.724367+00:00", "processed": false}
{"id": "hn_story_46077631", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46077631", "title": "Show HN: Claude Opus and Front End-Design Skill = Insane Results", "text": "", "author": "jackculpan", "timestamp": "2025-11-28T11:18:33+00:00", "score": 3, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-28T17:09:29.334234+00:00", "processed": false}
{"id": "hn_story_46077197", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46077197", "title": "Show HN: I vibe-coded a complete React rewrite of my audio waveform editor", "text": "I vibe-coded a complete React rewrite of my multi-track audio editor with Claude.<p><pre><code>  Waveform Playlist v5 started as a &quot;let&#x27;s see how far AI can take this&quot; experiment. The original was vanilla JS (~8 years\n  old). The new version is React + Tone.js with proper TypeScript, tree-shaking, and a modular package structure.\n\n  What we built: canvas waveforms, drag-and-drop clip editing, 20+ Tone.js effects, AudioWorklet recording, WAV export,\n  annotations, theming.\n\n  Demos: https:&#x2F;&#x2F;naomiaro.github.io&#x2F;waveform-playlist&#x2F;examples&#x2F;stem-tracks\n\n  GitHub: https:&#x2F;&#x2F;github.com&#x2F;naomiaro&#x2F;waveform-playlist\n\n  Still in alpha, but functional. I&#x27;d estimate 80%+ of the code was AI-generated.</code></pre>", "author": "st0ryteller", "timestamp": "2025-11-28T09:50:13+00:00", "score": 4, "num_comments": 0, "products": ["claude"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-11-28T17:09:32.292036+00:00", "processed": false}
{"id": "hn_comment_46077026", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46077026", "title": "Re: What's the most surprisingly useful thing you've d...", "text": "The jump in writing quality between GPT-4 and GPT-5.1 is hugely noticeable if you&#x27;re specific with prompting (requires a bit of trial and error).<p>I&#x27;ve been using it to generate children&#x27;s stories and reading comprehension questions for a UK curriculum app. The difference:<p>\u2022 GPT-4: Generic questions, often not engaging enough for 7-year-olds \u2022 GPT-5.1: Adapts tone, vocabulary, and complexity when you give it curriculum constraints<p>I realised the model isn&#x27;t &quot;smart enough&quot; just to throw in a prompt like &quot;write a story about...&quot; - I needed structured prompts with specific examples of the target style.<p>It&#x27;s still not perfect, but it&#x27;s a massive improvement and can be called genuinely useful vs. just a novelty.", "author": "Barooahn", "timestamp": "2025-11-28T09:20:36+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2025-11-28T17:09:34.701641+00:00", "processed": false}
{"id": "hn_comment_46076305", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46076305", "title": "Re: Show HN: Open-source RAG server with retrieval vis...", "text": "I&#x27;ve been building local agents and found debugging the RAG retrieval step frustrating. I often couldn&#x27;t tell why the LLM was pulling specific context chunks, and console logging vector arrays didn&#x27;t help.<p>I built this tool to act as a standalone &#x27;memory server&#x27; sitting on top of PostgreSQL with the pgvector extension. I wanted to avoid managing separate specialized vector DBs for smaller projects.<p>The main feature is the visualizer dashboard. It shows the retrieval process in real-time, displaying raw chunks, similarity scores, and how &#x27;recency decay&#x27; influences the final ranking.<p>The backend is Node.js&#x2F;TypeScript using Prisma. It runs via Docker Compose.<p>Current limitation: The default config relies on OpenAI for embedding generation. I am working on adding local support via Ollama bindings as the next priority so the entire stack can run offline.<p>The code is MIT licensed.", "author": "northerndev", "timestamp": "2025-11-28T07:15:36+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-28T17:09:37.809530+00:00", "processed": false}
{"id": "hn_story_46075664", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46075664", "title": "Are We Becoming Distilled Versions of AI?", "text": "I\u2019ve been thinking about a possibility that seems right to me but I don\u2019t see discussed directly. As people use AI for more decisions, our cognition may start to shift through normal learning processes. The brain absorbs repeated patterns. If AI becomes part of everyday decision-making, some of its reasoning habits may get reflected in ours. This would be a kind of \u201ccognitive distillation,\u201d similar to how small AI models learn from large ones.<p>Most AI use today are medium decisions: planning a trip, organizing a project, or writing an algorithm. These have low emotional pressure and low friction, so it\u2019s easy to ask an AI for help. But small and large decisions are not currently widely influenced.<p>Small decisions are things like where to put an item, which door to use at a gas station (AI that can see the broken door sign you miss), or the order of misc tasks. We make thousands of these each day without thinking. AI doesn\u2019t influence these yet because the interface friction is too high. It\u2019s not convenient to open a device for choices that happen in seconds.<p>Large decisions are major life choices: lying to get out of a family event, complex interpersonal situations (even psych pros struggle to influence these), or who inherits a sentimental item desired by multiple family members. People ask AI about these already, but the barrier isn\u2019t the interface. It\u2019s that these choices have deep personal weight and are heavily influenced by emotion.<p>Right now AI lives in the middle, but both edges are shifting.<p>On the small-decision side, friction is dropping fast. Glasses, earbuds, smart environments, and real-time overlays will bring AI into the same sensory space we use. Instead of being something you consult, AI will simply be present and able to offer a suggestion at the moment a decision happens. That doesn\u2019t require control. Even small cues can shape many tiny choices per day. These small decisions matter because they are frequent and form habits.<p>On the large-decision side, AI systems are becoming better at recognizing behavioral patterns and presenting structured analysis. And as people interact with them more often, they may feel a kind of narrative familiarity with the system, similar to how characters in books become mentally \u201cpredictable.\u201d Over time this could give AI regular influence over complex situations without needing emotional depth.<p>Once AI informs both rapid small decisions and major long-term ones, it stops being a tool used only for specific tasks and becomes part of the whole decision-making pipeline.<p>This returns to the idea of distillation. In machine learning, a small model can learn from a large one by observing its outputs. The small model ends up with a compressed version of the large model\u2019s behavior.<p>Humans learn similarly. Repeated exposure leads to internal shortcuts. When you interact with AI regularly, you start to pick up its patterns. Eventually you start structuring your own thoughts in similar ways without intending to. Similar to how we learn writing styles, heuristics, or professional habits simply by being exposed to them often.<p>If AI becomes heavily involved in daily decisions, especially rapid ones, it becomes a dense pattern source. Over time this could shift how people naturally break down problems or frame choices. It doesn\u2019t require AI to be humanlike, only consistent.<p>If large numbers of people rely on the same families of AI systems over long periods, their thinking may converge in certain ways and eventually dramatic changes may occur given enough time fully interfaced. This may be most drastic with early exposure. As this distillation starts you may find yourself wondering if a given thought is entirely your own.  And what does it even mean for a thought to be mine when my own neural pathways are a ChatGPT distillation?<p>I\u2019m posting this because I\u2019m curious whether you find this framing reasonable and if there\u2019s existing research along these lines.", "author": "3chinproblem", "timestamp": "2025-11-28T05:01:04+00:00", "score": 3, "num_comments": 3, "products": ["chatgpt"], "categories": ["naming_terminology", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-28T17:09:43.375412+00:00", "processed": false}
{"id": "hn_comment_46078059", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46078059", "title": "Re: Shor's algorithm: the one quantum algo that ends R...", "text": "That article is likely LLM generated. It has the typical signs and a Grok-like pseudo casual tone.", "author": "cubefox", "timestamp": "2025-11-28T12:29:05+00:00", "score": null, "num_comments": null, "products": ["grok"], "categories": ["tone"], "sentiment": null, "collected_at": "2025-11-28T17:09:47.299241+00:00", "processed": false}
{"id": "hn_comment_46075326", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46075326", "title": "Re: Ask HN: What's your AI coding setup?...", "text": "&gt; What&#x27;s your AI coding setup?<p>Eclipse with the Github Copilot plugin. Nice and simple, but it works.<p>I&#x27;ve  been dabbling a bit with things like Codex and OpenCode, but I haven&#x27;t really adopted any of them as a major part of my routine workflow so far. But time will tell.<p>And then sometimes I just ask coding related questions to Gemini or ChatGPT and copy &amp; paste from the response, into my codebase, as indicated by the situation at hand.", "author": "mindcrime", "timestamp": "2025-11-28T03:46:25+00:00", "score": null, "num_comments": null, "products": ["chatgpt", "gemini", "copilot"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-28T17:09:50.741686+00:00", "processed": false}
