{"id": "hn_comment_46070922", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46070922", "title": "Re: Show HN: Readit \u2013 Portable, dynamic context for AI...", "text": "Hi HN, I&#x27;m Claudio. I built Readit (<a href=\"https:&#x2F;&#x2F;readit.md\" rel=\"nofollow\">https:&#x2F;&#x2F;readit.md</a>) because I was tired of keeping my system prompts and documentation in sync across different LLM chats.<p>Every time I started a new session for a project, I found myself manually copy-pasting the same stack definitions, coding guidelines, and API references. I wanted a way to pass a &quot;state&quot; to the agent via a single URL, without relying on custom GPTs or copy-paste fatigue.<p>HOW IT WORKS<p>Readit serves dynamic Markdown. You point the LLM to a URL, and it fetches a rendered context. Unlike a static Gist or Pastebin, Readit treats Markdown as a dynamic template:<p>- Templating: It uses Liquid to handle variables, loops, and logic.<p>- Transclusion: You can embed other markdown files (local or remote) directly into the main response.<p>- Searchable: The URL accepts query params (?q=...), allowing the server to filter content before rendering the markdown for the LLM.<p>THE TECH<p>The stack is Node.js, TypeScript and Fastify, paired with a React frontend. We rely on Postgres for data storage and to manage the recursive file structures. I am also currently working on integrating pgvector to enable semantic search capabilities. And a lot of coffee.<p>It&#x27;s free to use. I&#x27;d love to hear your feedback on the architecture or if you find this &quot;context-as-a-URL&quot; approach useful for your workflows.<p>TRY THE META-DEMO (NO SIGNUP)<p>The documentation is hosted on a readit (of course). You can verify it by pasting the docs URL into ChatGPT, Claude, or Gemini and asking technical questions about the tool itself.<p>1) Copy the docs URL: <a href=\"https:&#x2F;&#x2F;readit.md&#x2F;gi0wQgl6GoFx37MY&#x2F;readit-docs\" rel=\"nofollow\">https:&#x2F;&#x2F;readit.md&#x2F;gi0wQgl6GoFx37MY&#x2F;readit-docs</a><p>2) Paste into your LLM<p>3) Ask: &quot;Write a Python script to push a commit log using the API described in these docs.&quot; or &quot;Explain how the templating engine handles search results.&quot;", "author": "zeerg", "timestamp": "2025-11-27T16:43:27+00:00", "score": null, "num_comments": null, "products": ["claude", "chatgpt", "gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:21.348320+00:00", "processed": false}
{"id": "hn_story_46070773", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46070773", "title": "Show HN: GemGuard \u2013 a security auditing tool for Linux and Windows", "text": "I\u2019ve been working on a small security auditing tool called GemGuard and wanted to share it with the community.<p>GemGuard collects system information \u2014 running processes, network connections, and recently installed packages \u2014 and then uses Google\u2019s Gemini models to generate a human-readable assessment of anything that might look suspicious or worth checking.<p>The tool is cross-platform and works on: Linux (Fedora, Ubuntu&#x2F;Debian, Kali, Alpine) and Windows 10&#x2F;11<p>It offers both a CLI and a Textual-based TUI, supports multiple Gemini models, and includes a quiet mode for automation or integration with other tools.<p>Features include:\n- Process auditing\n- Package review (auto-detects package manager)\n- Network&#x2F;port inspection\n- Optional raw AI output (quiet mode)\n- Works in Bash&#x2F;Zsh&#x2F;CMD&#x2F;PowerShell<p>I\u2019m not a security expert, so the project is experimental, and contributions or feedback are very welcome.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;AlvaroHoux&#x2F;gem-guard\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;AlvaroHoux&#x2F;gem-guard</a>", "author": "Alvaro_Houx", "timestamp": "2025-11-27T16:28:48+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:21.732565+00:00", "processed": false}
{"id": "hn_story_46070749", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46070749", "title": "Tested OpenAI's prompt caching across models. Found undocumented behavior", "text": "Been building an AI agent from scratch to understand token economics. Spent a week on prompt caching. Found something interesting that isn&#x27;t in OpenAI&#x27;s docs.\nSetup: Network device monitoring chatbot, 10 tools, ~1,400 token prefix. Tested gpt-4o-mini, gpt-5-mini, gpt-5. Logged cached_tokens from every response.<p>Finding 1: Caching works as documented\nOnce prefix exceeds 1024 tokens, OpenAI caches it automatically. I saw 80-90% cache hit rates after the first call. Cost reduction of 47-49% on input tokens. Cache discount is 50% for 4o-mini, 90% for gpt-5 family.<p>Finding 2: Tool schema tokenization is heavily compressed\nAdded 4 tools to my existing 6. Expected +400-500 tokens based on JSON size. Actual increase: 56 tokens. OpenAI is clearly doing aggressive compression on function schemas.<p>Finding 3: Cache is shared across model generations (undocumented)\nThis is the interesting part.\nTest: Call gpt-4o-mini first (cold start). Wait 5 seconds. Call gpt-5-mini with identical prefix.\nResult: gpt-5-mini got a cache hit on its first call.\nTested all permutations. Every time, model 2 and 3 hit cache from model 1&#x27;s warmup. The prefix-processing cache is shared across 4o-mini, 5-mini, and 5.\nI couldn&#x27;t find this documented anywhere.<p>Why it matters:\nIf you have many cold starts (separate user sessions, different contexts), you can warm cache with the cheapest model.\nExample - 1,000 cold starts&#x2F;day, 10K token prefix, primary model gpt-5:\nWithout cross-model warming:\nEach session pays 10K tokens at $1.25&#x2F;1M = $0.0125\nDaily: $12.50, Annual: $4,562\nWith nano warming first:\n10K tokens at $0.05&#x2F;1M = $0.0005 per warmup\nDaily: $0.50, Annual: $182\nSavings: $4,380&#x2F;year\nAt gpt-5-pro pricing ($15&#x2F;1M), difference is $54K+&#x2F;year on warmup costs alone.<p>Technical note: This is prefix-processing cache sharing, not KV-cache sharing. Models share tokenization and prefix hashing, not attention states. But billing-wise, cached tokens are cached tokens.<p>Reproduction: Create 1024+ token prefix. Call model A, log cached_tokens. Call model B with same prefix. Check if B&#x27;s first call shows cached tokens. Field is in response.usage.prompt_tokens_details.cached_tokens.\nHappy to share test scripts.", "author": "harsharanga", "timestamp": "2025-11-27T16:26:29+00:00", "score": 2, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:21.762765+00:00", "processed": false}
{"id": "hn_comment_46070633", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46070633", "title": "Re: I built a startupkit with built in AI agents actin...", "text": "I\u2019ve been building something for technical founders who want to ship faster without redoing the same setup work for every new idea.<p>It\u2019s called StartupKit \u2014 a MicroSaaS boilerplate that includes the usual fundamentals (auth, payments, emails, dashboard, SEO, blog, etc.), but the main focus is actually the AI agents that come built in.<p>These aren\u2019t generic chatbots. They\u2019re role-based agents designed to act like a tiny product team you can talk to while you\u2019re building:<p>Analyst \u2013 clarifies your idea and requirements<p>Architect \u2013 helps design the system structure<p>Product Manager \u2013 builds a roadmap<p>UX Designer \u2013 reviews and improves flows<p>Developer \u2013 assists with implementation<p>Technical Writer \u2013 generates documentation<p>Test Architect \u2013 creates QA checklists<p>Everything lives inside your IDE as a simple .yaml config and works with whatever model you prefer (GPT-5, Claude, Cursor, etc.).<p>The idea is simple:\nGo live in ~24 hours instead of spending weeks setting up and planning.<p>If you want to check it out:\nWebsite \u2192 <a href=\"https:&#x2F;&#x2F;startupkit.today&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;startupkit.today&#x2F;</a><p>Demo \u2192 <a href=\"https:&#x2F;&#x2F;demo.startupkit.today&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;demo.startupkit.today&#x2F;</a>", "author": "VladCovaci", "timestamp": "2025-11-27T16:16:16+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-27T17:09:22.130401+00:00", "processed": false}
{"id": "hn_story_46069556", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46069556", "title": "Show HN: Runprompt \u2013 run .prompt files from the command line", "text": "I built a single-file Python script that lets you run LLM prompts from the command line with templating, structured outputs, and the ability to chain prompts together.<p>When I discovered Google&#x27;s Dotprompt format (frontmatter + Handlebars templates), I realized it was perfect for something I&#x27;d been wanting: treating prompts as first-class programs you can pipe together Unix-style. Google uses Dotprompt in Firebase Genkit and I wanted something simpler - just run a .prompt file directly on the command line.<p>Here&#x27;s what it looks like:<p>---\nmodel: anthropic&#x2F;claude-sonnet-4-20250514\noutput:\n  format: json\n  schema:\n    sentiment: string, positive&#x2F;negative&#x2F;neutral\n    confidence: number, 0-1 score\n---\nAnalyze the sentiment of: {{STDIN}}<p>Running it:<p>cat reviews.txt | .&#x2F;runprompt sentiment.prompt | jq &#x27;.sentiment&#x27;<p>The things I think are interesting:<p>* Structured output schemas: Define JSON schemas in the frontmatter using a simple `field: type, description` syntax. The LLM reliably returns valid JSON you can pipe to other tools.<p>* Prompt chaining: Pipe JSON output from one prompt as template variables into the next. This makes it easy to build multi-step agentic workflows as simple shell pipelines.<p>* Zero dependencies: It&#x27;s a single Python file that uses only stdlib. Just curl it down and run it.<p>* Provider agnostic: Works with Anthropic, OpenAI, Google AI, and OpenRouter (which gives you access to dozens of models through one API key).<p>You can use it to automate things like extracting structured data from unstructured text, generating reports from logs, and building small agentic workflows without spinning up a whole framework.<p>Would love your feedback, and PRs are most welcome!", "author": "chr15m", "timestamp": "2025-11-27T14:26:35+00:00", "score": 43, "num_comments": 15, "products": ["claude", "chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:26.432561+00:00", "processed": false}
{"id": "hn_story_46069064", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46069064", "title": "Tell HN: OpenAI Security Incident with PII", "text": "Today I got the following email from OpenAI:<p>Subject: Third-party security incident<p>From: OpenAI &lt;noreply@email.openai.com&gt;<p>Transparency is important to us, so we want to inform you about a recent security incident at Mixpanel, a data analytics provider that OpenAI used for web analytics on the frontend interface for our API product (platform.openai.com). The incident occurred within Mixpanel\u2019s systems and involved limited analytics data related to your API account.<p>This was not a breach of OpenAI\u2019s systems. No chat, API requests, API usage data, passwords, credentials, API keys, payment details, or government IDs were compromised or exposed.<p>What happened<p>On November 9, 2025, Mixpanel became aware of an attacker that gained unauthorized access to part of their systems and exported a dataset containing limited customer identifiable information and analytics information. Mixpanel notified OpenAI that they were investigating, and on November 25, 2025, they shared the affected dataset with us.<p>What this means for you<p>User profile information associated with use of platform.openai.com may have been included in data exported from Mixpanel. The information that may have been affected was limited to:<p>* Name that was provided to us on the API account<p>* Email address associated with the API account<p>* Approximate coarse location based on API user browser (city, state, country)<p>* Operating system and browser used to access the API account<p>* Referring websites<p>* Organization or User IDs associated with the API account<p>Our response<p>As part of our security investigation, we removed Mixpanel from our production services, reviewed the affected datasets, and are working closely with Mixpanel and other partners to fully understand the incident and its scope. We are in the process of notifying impacted organizations, admins, and users directly. While we have found no evidence of any effect on systems or data outside Mixpanel\u2019s environment, we continue to monitor closely for any signs of misuse.<p>Trust, security, and privacy are foundational to our products, our organization, and our mission. We are committed to transparency, and are notifying all impacted customers and users. We also hold our partners and vendors accountable for the highest bar for security and privacy of their services. After reviewing this incident, OpenAI has terminated its use of Mixpanel.<p>Beyond Mixpanel, we are conducting additional and expanded security reviews across our vendor ecosystem and are elevating security requirements for all partners and vendors.<p>What you should keep in mind<p>The information that may have been affected here could be used as part of phishing or social engineering attacks against you or your organization.<p>Since names, email addresses, and OpenAI API metadata (e.g., user IDs)  were included, we encourage you to remain vigilant for credible-looking phishing attempts or spam. As a reminder:<p>* Treat unexpected emails or messages with caution, especially if they include links or attachments.<p>* Double-check that any message claiming to be from OpenAI is sent from an official OpenAI domain.<p>* OpenAI does not request passwords, API keys, or verification codes through email, text, or chat.<p>* Further protect your account by enabling multi-factor authentication.<p>The security and privacy of our products are paramount, and we remain resolute in protecting your information and communicating transparently when issues arise. Thank you for your continued trust in us.<p>For more information about this incident and what it means for impacted users, please see our blog post here. [ https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;mixpanel-incident&#x2F; ]<p>Please contact your account team or mixpanelincident@openai.com if you have any questions or need our support.<p>OpenAI", "author": "vintagedave", "timestamp": "2025-11-27T13:31:36+00:00", "score": 4, "num_comments": 2, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:27.662560+00:00", "processed": false}
{"id": "hn_story_46068874", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46068874", "title": "AI-First Web:Practical guidelines for making your site readable by AI assistants", "text": "Most people still design websites only for browsers \u2014 not for the world we actually live in now, where a huge portion of users ask AI assistants first (ChatGPT, Claude, Gemini) instead of navigating the web manually.<p>I\u2019ve started a small open guide called AI-First Web:\n https:&#x2F;&#x2F;ai-first-guides.github.io&#x2F;first.ai&#x2F;<p>The idea is simple:<p>AI assistants need structure, clarity and semantics, not heavy JS<p>Clean HTML, good metadata, proper JSON-LD<p>Content designed to be understandable, interpretable and citable by LLMs<p>Think of it like \u201cSEO, but for AI assistants\u201d<p>It\u2019s a living document and I\u2019d love feedback or contributions from devs who build modern web apps, static sites, docs, or content platforms.<p>If you have thoughts on AI-readable markup, JSON-LD best practices, or examples of sites that are already \u201cAI-first\u201d, jump in.", "author": "kure256", "timestamp": "2025-11-27T13:04:05+00:00", "score": 3, "num_comments": 1, "products": ["claude", "chatgpt", "gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-27T17:09:28.262353+00:00", "processed": false}
{"id": "hn_story_46068181", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46068181", "title": "Show HN: SpecX \u2013 Workflow Automation for AI Agents", "text": "Hi HN,<p>I&#x27;m excited to share <i>SpecX</i>, a task orchestration engine for teams using coding agents like Cursor and Claude.<p>## Motivation<p>While building projects with AI coding agents, I noticed a few patterns:<p>* As projects grew in size, writing effective prompts became progressively harder\n* Agents performed best when requirements were short and well-defined\n* Many everyday tasks \u2014 testing, deployment, documentation, reporting \u2014 were structured and repeatable, even across projects.<p>&gt; The manual translation from goal to prompt felt redundant, lossy, and inefficient.<p>I decided to remove prompts from the equation entirely. Instead:\n* For automation, focus on the workflow and break it into steps.\n* For feature work, focus on requirements and break them into tasks.<p>## The Core Solution: Reliable Workflow Automation<p>At the center of SpecX is the <i>Task Orchestration Engine</i>.<p>You define <i>Pipelines</i> \u2014 reusable sequences of actions the agent must perform. Common use cases include:<p>* Automated compliance or audit checks\n* Reporting (code coverage, engineering velocity, documentation)\n* Refactor \u2192 test \u2192 verify loops<p>Built on top of the orchestration engine is the <i>Requirement Tree</i>, a structured, AI-assisted way to turn rough, unstructured ideas into well-defined tasks.<p>You write requirements the way you think; the engine builds them using one of the pipelines.<p>## Status<p><i>SpecX is in preview</i>. I&#x27;d love feedback from the HN community \u2014 especially on the Pipeline model and the idea of separating goal definition from prompt generation.<p>* Login required (to protect your project context)\n* Requires a coding agent (Cursor or any MCP-enabled agent).<p>Try SpecX: <a href=\"https:&#x2F;&#x2F;redoxsoft.com\" rel=\"nofollow\">https:&#x2F;&#x2F;redoxsoft.com</a>\nDemo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=1JNYIhoHmbQ\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=1JNYIhoHmbQ</a><p>Happy to answer questions about the architecture, design choices, or roadmap.", "author": "dhaundy", "timestamp": "2025-11-27T11:18:05+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:29.964242+00:00", "processed": false}
{"id": "hn_comment_46068091", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46068091", "title": "Re: Ask AI \u2013 GPT-5 \u2013 LUMA \u2013 O1...", "text": "ASK AI is your personal AI companion, crafted by a solo developer with a clear mission: to build the assistant others were missing. Every feature is designed with care to give you control, creativity, and premium intelligence\u2014without the clutter. One Price | Multiple Models | One AI Tool  Premium Intelligence \u27e1 Auto model routing: ASK AI automatically selects the right model for your task\u2014whether it\u2019s speed, deep reasoning, or technical depth. \u27e1 GPT\u20115\u2011nano &amp; Gemini Flash | FREE TIER| with blazing fast results when speed matters most. Smart, responsive chat for everyday use. \u27e1 GPT-5, Grok, Luma &amp; Gemini 2.5 Pro - PREMIUM TIER \u2013 $12.99&#x2F;month | Real\u2011time, high\u2011quality answers with advanced reasoning. \u27e1 Gemini Flash: Blazing fast results when speed matters most. \u27e1 O1 Reasoning, Luma &amp; Gemini 3 - ULTRA TIER \u2013 $189.99&#x2F;month | Deliberate, deep reasoning for complex analysis and mission\u2011critical tasks. \u27e1 Expert Codex Engine: Premium\u2011grade logic for coding, debugging, and technical depth. \u27e1 Deep Thinking Mode: Slower, more thoughtful responses for nuanced queries.  Real\u2011Time Data \u27e1 Real time data using Grok \u27e1 Current events, weather, finance, and more \u27e1 Always fresh, always relevant  Adaptive Chat Experience \u27e1 Custom instructions: Tell ASK AI how you\u2019d like it to respond\u2014it adapts to your style. \u27e1 Chat memory: Keep context across sessions for smoother conversations. Persona models: Switch between Friendly, Professional, Creative, and more. \u27e1 Anonymous mode: Chat without storing data. \u27e1 Data storage: Save important responses and insights.  Visual Creativity &amp; Customization \u27e1 ASK AI isn\u2019t just smart\u2014it\u2019s beautiful. \u27e1 Image generation with DALL\u00b7E 3 \u27e1 20+ wallpapers including animated and JavaScript\u2011generated designs \u27e1 Live 4K wallpapers that evolve with your mood \u27e1 Transparent chat bubbles so wallpapers shine through while you chat \u27e1 Themes: Frosted Glass, Terminal, Matrix, Space, and more \u27e1 Font styles, sizes, and colors for accessibility and personalization \u27e1 System sounds for tactile feedback  Accessibility \u27e1 Voice output for hands\u2011free use \u27e1 Adjustable fonts and colors for readability \u27e1 Transparent UI that blends with live wallpapers  Designed for Everyone \u27e1 Whether you\u2019re a student, professional, creator, or explorer, ASK AI helps you: \u27e1 Generate images and creative concepts \u27e1 Convert, summarize, and query documents  Clean, Fast, Affordable \u27e1 Elegant UI with premium polish \u27e1 Optimized for mobile responsiveness \u27e1 No ads, no clutter\u2014just pure AI power Affordable pricing: $12.99&#x2F;month for GPT5, Grok, Luma &amp; Gemini on Premium Tier $189.99&#x2F;month for O1 Reasoning, Luma &amp; Gemini 3", "author": "sarymismail", "timestamp": "2025-11-27T11:04:06+00:00", "score": null, "num_comments": null, "products": ["gemini", "grok"], "categories": ["tone", "response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:30.233356+00:00", "processed": false}
{"id": "hn_story_46067294", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46067294", "title": "Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult", "text": "", "author": "jonesn11", "timestamp": "2025-11-27T09:04:06+00:00", "score": 6, "num_comments": 1, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2025-11-27T17:09:31.541682+00:00", "processed": false}
{"id": "hn_comment_46066165", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46066165", "title": "Re: OpenAI API user data exposed in Mixpanel security ...", "text": "Got this email from the OpenAI team -<p>Transparency is important to us, so we want to inform you about a recent security incident at Mixpanel, a data analytics provider that OpenAI used for web analytics on the frontend interface for our API product (platform.openai.com). The incident occurred within Mixpanel\u2019s systems and involved limited analytics data related to your API account.<p>This was not a breach of OpenAI\u2019s systems. No chat, API requests, API usage data, passwords, credentials, API keys, payment details, or government IDs were compromised or exposed.<p>What happened\nOn November 9, 2025, Mixpanel became aware of an attacker that gained unauthorized access to part of their systems and exported a dataset containing limited customer identifiable information and analytics information. Mixpanel notified OpenAI that they were investigating, and on November 25, 2025, they shared the affected dataset with us.<p>What this means for you\nUser profile information associated with use of platform.openai.com may have been included in data exported from Mixpanel. The information that may have been affected was limited to:\nName that was provided to us on the API account \nEmail address associated with the API account\nApproximate coarse location based on API user browser (city, state, country)\nOperating system and browser used to access the API account\nReferring websites\nOrganization or User IDs associated with the API account\nOur response  \nAs part of our security investigation, we removed Mixpanel from our production services, reviewed the affected datasets, and are working closely with Mixpanel and other partners to fully understand the incident and its scope. We are in the process of notifying impacted organizations, admins, and users directly. While we have found no evidence of any effect on systems or data outside Mixpanel\u2019s environment, we continue to monitor closely for any signs of misuse.<p>Trust, security, and privacy are foundational to our products, our organization, and our mission. We are committed to transparency, and are notifying all impacted customers and users. We also hold our partners and vendors accountable for the highest bar for security and privacy of their services. After reviewing this incident, OpenAI has terminated its use of Mixpanel.<p>Beyond Mixpanel, we are conducting additional and expanded security reviews across our vendor ecosystem and are elevating security requirements for all partners and vendors.<p>What you should keep in mind  \nThe information that may have been affected here could be used as part of phishing or social engineering attacks against you or your organization.<p>Since names, email addresses, and OpenAI API metadata (e.g., user IDs)  were included, we encourage you to remain vigilant for credible-looking phishing attempts or spam. As a reminder:\nTreat unexpected emails or messages with caution, especially if they include links or attachments.\nDouble-check that any message claiming to be from OpenAI is sent from an official OpenAI domain.\nOpenAI does not request passwords, API keys, or verification codes through email, text, or chat.\nFurther protect your account by enabling multi-factor authentication.\nThe security and privacy of our products are paramount, and we remain resolute in protecting your information and communicating transparently when issues arise. Thank you for your continued trust in us.<p>For more information about this incident and what it means for impacted users, please see our blog post here.<p>Please contact your account team or mixpanelincident@openai.com if you have any questions or need our support.<p>OpenAI", "author": "deeptishukla22", "timestamp": "2025-11-27T05:57:47+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:34.356076+00:00", "processed": false}
{"id": "hn_comment_46067615", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46067615", "title": "Re: Vibe coding: What is it good for? Absolutely nothi...", "text": "I kinda want authors to define &quot;vibe coding&quot; in their specific context when they write articles like this.<p>Is it &quot;try to one-shot something via a Web UI&quot; or &quot;Figure out proper spec with Claude in Plan mode, let it implement according to the plan&quot;? Both give completely different results.<p>And it doesn&#x27;t matter a bit if LLM produced code isn&#x27;t deterministic. We have 100% deterministic tools to check the code. Have had for decades. Agentic LLMs might produce bad code, but they can also run deterministic checks on the output and fix them immediately before even bothering the user.", "author": "theshrike79", "timestamp": "2025-11-27T09:54:31+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:37.215139+00:00", "processed": false}
{"id": "hn_story_46064652", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46064652", "title": "Show HN: Calcumake \u2013 A 3D print pricing calculator (Rails and Kamal)", "text": "Hi HN,<p>I just got into 3D printing about 3 months ago after picking up a K2 Plus. I live in a somewhat rural area of Japan and don&#x27;t know a single person with a 3D printer, so friends and family immediately started asking me to print things for them.<p>I struggled to give them accurate prices. At first, I was guessing (&quot;100 yen for this, 200 yen for that&quot;), but I realized I was ignoring setup time, CAD work, failed prints, and electricity. I checked out the top results like OmniCalculator and Prusa\u2019s tool but found them frustrating\u2014specifically the inability to save calculations or handle complex projects with multiple plates and different filaments.<p>So, I decided to build my own. I have Rails experience, and using Kamal I was able to keep cloud pricing to a minimum. I used Claude Code to assist, finishing the MVP in about 2 months of free time (real talk: I know some people ship SaaS apps in a week, but that sounds hellish to me).<p>I&#x27;m trying to optimize the code and push updates every day. The next big update involves an AI tool where you can paste text or invoices to automatically bulk import filaments. I&#x27;m also working on:<p>A native 3MF import tool.<p>Per-unit pricing (for people running web stores).<p>Better failed print calculations.<p>I&#x27;ve even considered adding a directory to search for makers by city or neighborhood (since I can&#x27;t find anyone near me!), but I&#x27;m undecided on that.<p>Right now, I&#x27;m just trying to get the word out. Hopefully, someone besides me finds this useful.<p>Feedback is welcome!", "author": "moabjp", "timestamp": "2025-11-27T02:01:04+00:00", "score": 1, "num_comments": 2, "products": ["claude"], "categories": ["error_messages", "tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2025-11-27T17:09:37.762183+00:00", "processed": false}
{"id": "hn_story_46064322", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46064322", "title": "Show HN: Splintr \u2013 Rust BPE tokenizer, 12x faster than tiktoken for batches", "text": "Hi HN,<p>I built Splintr, a BPE tokenizer in Rust (with Python bindings), because I found existing Python-based tokenizers were bottlenecking my data processing pipelines.<p>While OpenAI&#x27;s tiktoken is the gold standard for correctness, I found I could get significantly better throughput on modern multi-core CPUs by rethinking how parallelism is applied.<p>Splintr achieves ~111 MB&#x2F;s batch throughput (vs ~9 MB&#x2F;s for tiktoken).<p>The Design Choice: &quot;Sequential by Default&quot; One of the most interesting findings during development was that naive parallelism actually hurts performance for typical LLM inputs. Thread pool overhead is significant for texts under 1MB.<p>I implemented a hybrid strategy:<p>Single Text (encode): Purely sequential. It\u2019s 3-4x faster than tiktoken simply by using pcre2 with JIT instead of standard regex handling.<p>Batch Processing (encode_batch): Parallelizes across texts using Rayon, rather than within a text. This saturates all cores without the overhead of splitting small strings.<p>Other Features:<p>Safety: Strict UTF-8 compliance, including a streaming decoder that correctly buffers incomplete multi-byte characters.<p>Compatibility: Drop-in support for cl100k_base (GPT-4), o200k_base (GPT-4o), and llama3 vocabularies.<p>The repo is written in Rust with PyO3 bindings. I\u2019d love feedback on the implementation or other potential optimization tricks for BPE.<p>Thanks!", "author": "fs90", "timestamp": "2025-11-27T01:11:15+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["navigation"], "sentiment": null, "collected_at": "2025-11-27T17:09:38.829908+00:00", "processed": false}
