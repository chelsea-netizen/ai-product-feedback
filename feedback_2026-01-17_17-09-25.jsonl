{"id": "hn_story_46659147", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46659147", "title": "Ask HN: How do you evaluate a LLM these days?", "text": "Hello HN. Recent events and me being Danish (EU) strongly encourage me to reconsider US services like Anthropic&#x27;s Claude. I mention this to say that the problem of evaluating LLMs suddenly got very necessary for me.\nWhile I don&#x27;t doubt Claude is nearly ideal for my corner of software development, I would like to have a better sense of how much I am giving up.<p>With that in mind, how do you go about best evaluating LLM&#x27;s these days, short of going with &quot;gut feel&quot;? My best idea so far is to design&#x2F;write various small &quot;design a program&#x2F;library&quot; tasks with clear functional requirements and letting each model try implementing the tasks, probably using Open Code and Open Router as the common components throughout the evaluation.<p>But this field moves fast and I may well have missed many better or easier approaches. What would you do?", "author": "pseudony", "timestamp": "2026-01-17T16:10:04+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:29.219237+00:00", "processed": false}
{"id": "hn_comment_46659163", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46659163", "title": "Re: Does AI mean the demand on labor goes up?...", "text": "There is no way AI is making you 10x more productive at the current moment. And if AI is supposed to work well, then that doesn&#x27;t mean you&#x27;ll need to put in 10x more hours (because the AI will seamlessly and magically make that effortless). So you&#x27;ll still be working the same hours even in that scenario.<p>Overall, I would say, if you want to pursue serious writing, please do it without have LLM generate everything. This blog is just a pattern of vomit-inducing AI-writing cliches and cites nothing of value.<p>In fact, I went through all your other AI-generated posts and created a meta prompt that you can just paste into ChatGPT and have one of these articles come out, saving you the time to be 10x more or whatever.<p>---<p>Write a short essay (800\u20131,200 words) in a reflective, intellectually restless tone that blends personal observation with a contrarian insight about technology, work, progress, or human behavior.<p>Constraints and style:<p>* Open with a concrete hook: a quote, anecdote, tweet, or cultural reference that feels slightly overfamiliar.\n* Use clear, confident prose. No emojis. No motivational clich\u00e9s. No listicles.\n* The essay should feel like thinking out loud, not teaching.\n* Avoid moralizing. Let implications emerge implicitly.\n* Assume an intelligent, online reader who is tired of hype but curious.<p>Core structure:<p>1. Start with a relatable observation or irritation about modern life, tech discourse, or self-improvement culture.\n2. Introduce a <i>somewhat unexpected but real</i> tech or economics idea (e.g., Jevons paradox, Goodhart\u2019s law, Conway\u2019s law, scaling laws, second-order effects of AI tooling, coordination problems, invisible infrastructure, option value, etc.).\n3. Use that idea to reframe a dominant narrative people take for granted.\n4. Explore at least one uncomfortable implication for individuals or society.\n5. End without a neat conclusion. Close with an open tension, question, or quiet reversal.<p>Content rules:<p>* Cite or reference one specific person, company, paper, or concept from tech or economics, but don\u2019t over-explain it.\n* No product reviews or tutorials.\n* No explicit calls to action.\n* No \u201cthe future will\u2026\u201d certainty language.<p>Voice:<p>* Calm, slightly skeptical, observant.\n* Curious rather than cynical.\n* Written like a public notebook entry, not a polished op-ed.<p>The goal is not to persuade, but to sharpen how the reader sees something they already thought they understood.", "author": "altmanaltman", "timestamp": "2026-01-17T16:12:12+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-01-17T17:09:29.578043+00:00", "processed": false}
{"id": "hn_story_46659042", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46659042", "title": "Show HN: LaReview, Plan-first AI code review, runs locally, bring your own agent", "text": "Hi HN, I built LaReview because AI review bots spam PRs with 50+ nitpicky comments that authors just batch-dismiss.<p>I also didn&#x27;t want to pay $15-30&#x2F;month for another AI subscription when I already have an amazing coding agent (Claude Code, OpenCode, Gemini, etc.) that&#x27;s way better than what these review bots use.<p>LaReview works differently: you paste a PR link, it groups the changes by logical area (auth changes, API endpoints, migrations, UI updates) ordered by risk, then uses your coding agent to draft review comments that you edit before posting. Nothing posts automatically.<p>Example: a 40-file PR touching auth, API, and frontend becomes 3 reviewable chunks. You start with auth (highest risk), draft 2-3 focused comments, then move to the next chunk. No 40-comment dump.<p>How it works:\n1. Paste a GitHub&#x2F;GitLab PR link or unified diff\n2. AI analyzes the changes and proposes a review plan grouped by area and risk\n3. You open each task and see only the relevant code hunks\n4. AI drafts potential feedback for that specific task\n5. You edit, approve, or delete each suggestion before posting to GitHub&#x2F;GitLab (or export as Markdown)<p>Install:<p>macOS: <i>brew install --cask puemos&#x2F;tap&#x2F;lareview</i><p>Linux: <i>brew install puemos&#x2F;tap&#x2F;lareview</i><p>Windows: not yet (let me know if you need it)<p>LaReview runs locally and fetches PR data directly from GitHub&#x2F;GitLab - no LaReview server involved.<p>Why it&#x27;s different from Copilot&#x2F;CodeRabbit&#x2F;PR-Agent:\n1. They mostly comment file-by-file, LaReview groups changes by logical area first\n2. They auto-post or make you filter spam, LaReview drafts suggestions you review\n3. They often need cloud integrations, LaReview is local-first<p>License: MIT + Apache-2.0", "author": "deofoo", "timestamp": "2026-01-17T16:00:37+00:00", "score": 1, "num_comments": 0, "products": ["claude", "gemini", "copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:29.642335+00:00", "processed": false}
{"id": "hn_story_46659039", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46659039", "title": "Show HN: Long-horizon LLM coherence benchmark (500 cycles)", "text": "We ran a 500-cycle benchmark to test long-horizon coherence, reasoning stability, and identity persistence in large language models.<p>The experiment used the Sigma Runtime, a model-agnostic control layer that adds long-term memory, structural coherence tracking, and adaptive equilibrium regulation to standard LLMs. It enables stable reasoning and personality continuity across hundreds of interactions without context resets.<p>Protocol overview\n- 500 reasoning cycles divided into 10 blocks of 50 questions.\n- Every 50th response (\u201cRib Point\u201d) compresses and validates reasoning from the previous 49 cycles.\n- Each block builds on prior synthesis, forming a cumulative reasoning chain up to cycle 500.\n- The final cycle (C500) performs full closure, verifying long-range consistency.<p>Two independent tests\n- OpenAI GPT-5.2 \u2014 phase-stable regime: early micro-fractures during lattice formation self-corrected by C50; zero structural drift afterward.\n- Google Gemini-3-Flash \u2014 forced-equilibrium regime: proportional feedback absorbed API truncations and prevented over-stabilization.<p>Results\n- Both runs maintained full coherence and stable identity across 500 cycles.\n- Rib Points confirmed successful recursive compression: reasoning remained referentially consistent.\n- Structural drift and semantic degradation \u2248 0 across both architectures.<p>Architecture components\n- SRIP-09: Long-Term Memory + Structural Coherence Layer\n- SRIP-09c: Nucleus Integration Protocol (semantic anchoring)<p>Full report (DOI): <a href=\"https:&#x2F;&#x2F;doi.org&#x2F;10.5281&#x2F;zenodo.18271591\" rel=\"nofollow\">https:&#x2F;&#x2F;doi.org&#x2F;10.5281&#x2F;zenodo.18271591</a> \nAppendix &amp; data: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sigmastratum&#x2F;documentation&#x2F;blob&#x2F;a57bae59ba9aee86a27e06bb8a9f3c4c05d797d7&#x2F;sigma-runtime&#x2F;SR-050&#x2F;README.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sigmastratum&#x2F;documentation&#x2F;blob&#x2F;a57bae59b...</a>", "author": "teugent", "timestamp": "2026-01-17T16:00:20+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt", "gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:29.675219+00:00", "processed": false}
{"id": "hn_story_46659011", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46659011", "title": "Show HN: OpenAI to show ads in ChatGPT for logged-in U.S. adults", "text": "It appears OpenAI is testing or planning to introduce ads inside ChatGPT for logged-in users in the U.S.\nFrom what I can tell, ads would appear in limited placements and not affect free access immediately, but this raises questions about product direction, user experience, privacy, and long-term incentives.<p>Curious how others here feel about ads inside AI tools:<p>1.Would this change how you use ChatGPT?<p>2.Are ads inevitable for consumer AI products?<p>3.What would be an acceptable implementation?", "author": "SRMohitkr", "timestamp": "2026-01-17T15:57:21+00:00", "score": 1, "num_comments": 0, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:29.835798+00:00", "processed": false}
{"id": "hn_story_46658815", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46658815", "title": "Show HN: Kate Code \u2013 KDE Kate Editor Plugin for Accessing Claude Code", "text": "A plugin for the Kate text editor that integrates Claude Code (an AI coding assistant) directly into the editor&#x27;s interface. It provides an interactive chat panel where you can converse with Claude to get help with coding tasks\u2014all without leaving your KDE development environment.", "author": "empressplay", "timestamp": "2026-01-17T15:31:42+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:30.922910+00:00", "processed": false}
{"id": "hn_story_46658491", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46658491", "title": "Looking for technical cofounder \u2013 guided, safety-critical maintenance software", "text": "I\u2019m looking for a technical cofounder to build a guided, safety-enforced troubleshooting and repair system for industrial maintenance.<p>I\u2019m a maintenance&#x2F;mechanical guy working with a lot of old, undocumented, heavily modified machines. The real problems I deal with daily: tribal knowledge, repeating the same diagnoses every few months, junior techs thrown at complex equipment, and safety steps getting skipped under pressure.<p>The product is not a CMMS and not an \u201cAI copilot\u201d. It\u2019s a work-execution system for the moment a machine is down: it guides troubleshooting step-by-step, enforces lockout&#x2F;tagout and live-work warnings in the workflow, hard-blocks unsafe or unauthorized steps unless a supervisor approves, and captures what was tried and what actually fixed the problem so the shop doesn\u2019t start from zero next time.<p>I already have a clear, realistic MVP spec and access to real machines and shops to test in. The initial version is a straightforward web app (assets, cases, step flows, safety gates, supervisor unlock, search).<p>I\u2019m looking for a strong full-stack or product-minded engineer who\u2019s interested in workflow systems, safety-critical software, or industrial problems. This is a serious long-term project, not a quick demo or a content startup.<p>If this sounds interesting, email me at: wagner.steven.j@gmail.com", "author": "SteveWShopBrain", "timestamp": "2026-01-17T14:49:32+00:00", "score": 4, "num_comments": 1, "products": ["copilot"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-01-17T17:09:31.993777+00:00", "processed": false}
{"id": "hn_comment_46658710", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46658710", "title": "Re: The Risks of AI in Schools Outweigh the Benefits, ...", "text": "I have two kids (sophmore in HS and a middle schooler) and in both their individual studies and when I&#x27;m helping them with homework we use AI pretty extensively now.<p>The one off stuff is mostly taking a picture of a math problem and asking it to walk step by step through the process. In particular this has been helpful to me as the processes and techniques have changed.<p>It&#x27;s been useful in foreign languages as well to rapidly check work, and make corrections.<p>On the generative side it&#x27;s fantastic for things like: give me 3 more math problems similar to this one or for generating worksheets and study guides.<p>As far as technological adoption goes, it&#x27;s 100% that every kid knows what ChatGPT is (even maybe more than just &quot;AI&quot; in general). There&#x27;s some very mixed feelings from the kids with it: my middle schooler was pretty creeped out by the ChatGPT voice interface for example.", "author": "michaelbuckbee", "timestamp": "2026-01-17T15:18:52+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:37.729399+00:00", "processed": false}
{"id": "hn_story_46657624", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46657624", "title": "Tested 31 AI detection/humanization tools \u2013 $5/mo GPTs beat $300/mo", "text": "I ran a systematic comparison of AI content detection and humanization tools after a client terminated a contract over an AI detection flag (87% AI-generated on content I&#x27;d manually edited).<p>*Methodology:*\n- 31 tools tested over 90 days\n- 200+ content samples (technical docs, marketing copy, blog posts, academic-style)\n- Measured detection accuracy against known AI&#x2F;human content\n- Measured humanization &quot;bypass rate&quot; against Originality.ai (industry standard)\n- Controlled for content type and length<p>*Key finding:* ChatGPT Custom GPTs ($5&#x2F;mo via team plans) performed within 2-7% of standalone SaaS tools charging $50-300&#x2F;mo.<p>*Detection tools tested:*\n- Originality.ai: 91.3% accuracy, $149&#x2F;mo unlimited\n- GPTZero: 87.4% accuracy, $16&#x2F;mo\n- Copyleaks: 88.2% accuracy, $9-499&#x2F;mo\n- Winston AI: 84.1% accuracy, $19&#x2F;mo<p>*Humanization bypass rates (against Originality.ai):*<p><i>SaaS:</i>\n- Undetectable.ai: 91.2%, $49-209&#x2F;mo<p><i>Custom GPTs ($5&#x2F;mo):</i>\n- StealthGPT AI: 89.3% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c88e5737388191aea00acc2e248afd\n- TurnitinPRO: 88.1% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67a36b4314548191a132428520afbf2d\n- BypassGPT: 87.6% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-677e3f6ff8648191a96356838c564012\n- ZeroGPT: 86.4% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c88362d8e081918b73f42d780e53cb\n- GPT Zero: 86.2% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-6786439fa24c81919660e0152ad5f4f3\n- scribbr AI: 85.7% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c89bebe2e48191962eaefb1e46530a\n- Humanize AI: 85.4% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-674192227ff481918ff66a8dfe5378d9\n- HumanizerPRO: 84.9% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67bfc9f5ab848191b7a80e386e7963af\n- Humanize AI Text: 84.7% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-678cc08f1b048191a9428748d02916b1<p>*Cost comparison:*<p>Old stack: $223&#x2F;mo\n- Originality.ai unlimited: $149\n- Undetectable.ai: $49\n- Quillbot: $10\n- Grammarly: $15<p>New stack: $20&#x2F;mo\n- ChatGPT Plus (team): $5\n- Originality.ai pay-per-scan: ~$15<p>*Technical observations:*<p>1. Custom GPTs use the same base models as SaaS competitors. The differentiation is prompt engineering and workflow design, not proprietary detection&#x2F;bypass algorithms.<p>2. Most humanizers fail on long-form content (&gt;1500 words). Output becomes repetitive, tone drifts. BypassGPT and StealthGPT maintained consistency at 4000+ words.<p>3. Detection tools have different strengths: Originality.ai best overall accuracy, Copyleaks best for non-English content, GPTZero has more false positives on technical writing.<p>4. The &quot;bypass rate&quot; gap between $5 and $50+ tools (2-7%) matters less than workflow efficiency. Integrated detection+humanization in one interface saves ~30 min&#x2F;article.<p>5. All tools struggle with heavily templated content (listicles, how-to formats). Detection accuracy drops 15-20% on these patterns regardless of actual AI involvement.<p>*Limitations:*<p>- Single tester, potential bias\n- Originality.ai as primary benchmark (other detectors may vary)\n- Custom GPT performance depends on OpenAI model updates\n- 90-day window; detection&#x2F;bypass landscape evolves quickly<p>*Questions I&#x27;m still exploring:*<p>- How do detection tools handle fine-tuned models vs base GPT-4&#x2F;Claude?\n- Is there a content length threshold where detection becomes unreliable?\n- How much does writing style (technical vs conversational) affect detection accuracy?", "author": "khadinakbar", "timestamp": "2026-01-17T12:43:06+00:00", "score": 1, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:38.539067+00:00", "processed": false}
{"id": "hn_story_46657610", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46657610", "title": "Tested 31 AI detection/humanization tools for 90 days \u2013 $5/mo GPTs beat $300/mo", "text": "I ran a systematic comparison of AI content detection and humanization tools after a client terminated a contract over an AI detection flag (87% AI-generated on content I&#x27;d manually edited).<p>*Methodology:*\n- 31 tools tested over 90 days\n- 200+ content samples (technical docs, marketing copy, blog posts, academic-style)\n- Measured detection accuracy against known AI&#x2F;human content\n- Measured humanization &quot;bypass rate&quot; against Originality.ai (industry standard)\n- Controlled for content type and length<p>*Key finding:* ChatGPT Custom GPTs ($5&#x2F;mo via team plans) performed within 2-7% of standalone SaaS tools charging $50-300&#x2F;mo.<p>*Detection tools tested:*\n- Originality.ai: 91.3% accuracy, $149&#x2F;mo unlimited\n- GPTZero: 87.4% accuracy, $16&#x2F;mo\n- Copyleaks: 88.2% accuracy, $9-499&#x2F;mo\n- Winston AI: 84.1% accuracy, $19&#x2F;mo<p>*Humanization bypass rates (against Originality.ai):*<p><i>SaaS:</i>\n- Undetectable.ai: 91.2%, $49-209&#x2F;mo<p><i>Custom GPTs ($5&#x2F;mo):</i>\n- StealthGPT AI: 89.3% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c88e5737388191aea00acc2e248afd\n- TurnitinPRO: 88.1% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67a36b4314548191a132428520afbf2d\n- BypassGPT: 87.6% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-677e3f6ff8648191a96356838c564012\n- ZeroGPT: 86.4% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c88362d8e081918b73f42d780e53cb\n- GPT Zero: 86.2% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-6786439fa24c81919660e0152ad5f4f3\n- scribbr AI: 85.7% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67c89bebe2e48191962eaefb1e46530a\n- Humanize AI: 85.4% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-674192227ff481918ff66a8dfe5378d9\n- HumanizerPRO: 84.9% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-67bfc9f5ab848191b7a80e386e7963af\n- Humanize AI Text: 84.7% \u2014 https:&#x2F;&#x2F;chatgpt.com&#x2F;g&#x2F;g-678cc08f1b048191a9428748d02916b1<p>*Cost comparison:*<p>Old stack: $223&#x2F;mo\n- Originality.ai unlimited: $149\n- Undetectable.ai: $49\n- Quillbot: $10\n- Grammarly: $15<p>New stack: $20&#x2F;mo\n- ChatGPT Plus (team): $5\n- Originality.ai pay-per-scan: ~$15<p>*Technical observations:*<p>1. Custom GPTs use the same base models as SaaS competitors. The differentiation is prompt engineering and workflow design, not proprietary detection&#x2F;bypass algorithms.<p>2. Most humanizers fail on long-form content (&gt;1500 words). Output becomes repetitive, tone drifts. BypassGPT and StealthGPT maintained consistency at 4000+ words.<p>3. Detection tools have different strengths: Originality.ai best overall accuracy, Copyleaks best for non-English content, GPTZero has more false positives on technical writing.<p>4. The &quot;bypass rate&quot; gap between $5 and $50+ tools (2-7%) matters less than workflow efficiency. Integrated detection+humanization in one interface saves ~30 min&#x2F;article.<p>5. All tools struggle with heavily templated content (listicles, how-to formats). Detection accuracy drops 15-20% on these patterns regardless of actual AI involvement.<p>*Limitations:*<p>- Single tester, potential bias\n- Originality.ai as primary benchmark (other detectors may vary)\n- Custom GPT performance depends on OpenAI model updates\n- 90-day window; detection&#x2F;bypass landscape evolves quickly<p>*Questions I&#x27;m still exploring:*<p>- How do detection tools handle fine-tuned models vs base GPT-4&#x2F;Claude?\n- Is there a content length threshold where detection becomes unreliable?\n- How much does writing style (technical vs conversational) affect detection accuracy?<p>Happy to share raw data or answer questions about methodology.", "author": "khadinakbar", "timestamp": "2026-01-17T12:41:48+00:00", "score": 1, "num_comments": 1, "products": ["claude", "chatgpt"], "categories": ["tone", "navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:38.731916+00:00", "processed": false}
{"id": "hn_comment_46658227", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46658227", "title": "Re: Architecture for Disposable Systems...", "text": "I like the perspective and phrasing. Build the foundation carefully and vibe code colors on the wall, decoration in the room, and design of wallpaper&#x2F;carpets<p>Want a dashboard from an API with openapi docs or from SQL database with known schema, or want a quick interactive GUI that highlights something in `perf stat` data, unleash claude.", "author": "dilawar", "timestamp": "2026-01-17T14:14:41+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:41.271727+00:00", "processed": false}
{"id": "hn_comment_46656868", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46656868", "title": "Re: In the coming weeks, we plan to start testing ads ...", "text": "Makes sense for the free tier, sucks to include ads in a paid tier though. Not sure who the target audience for the Go subscription is anyway, they might be better off removing it purely from a product point of view.<p>&gt; What matters most:<p>&gt; - Responses in ChatGPT will not be influenced by ads.<p>&gt; - Ads are always separate and clearly labeled.<p>&gt; - Your conversations are private from advertisers.<p>The part that&#x27;s left out is that you&#x27;ll obviously be profiled as an user and get targeted ads based on your chat history.", "author": "trio8453", "timestamp": "2026-01-17T10:20:31+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:45.481069+00:00", "processed": false}
{"id": "hn_story_46656593", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46656593", "title": "Show HN: Partner \u2013 An AI co-founder that remembers you", "text": "Hi HN,<p>I\u2019m a solo founder (currently running PlayCode.io). For the last few years, I\u2019ve been battling a specific kind of burnout: the loneliness of having no one to think with.<p>I have friends and a wife, but they aren&#x27;t in the trenches with me. I tried using ChatGPT and Claude as &quot;sounding boards,&quot; but I hit a wall: Amnesia.<p>Every time I opened a new chat, I had to re-explain my context, my values, and my history. It felt like explaining my life story to a new stranger every day. It was exhausting. I didn&#x27;t need a code generator; I needed a partner who knew me.<p>So I built Partner.<p>What it is: Partner is an AI cognitive companion designed for &quot;active debuggers&quot; - founders and creators who are trying to debug their own psychology and decision-making processes.<p>How it\u2019s different: Most AI memory is just a vector database of facts. Partner is built around a &quot;Living Constitution&quot;.<p>It doesn&#x27;t just remember &quot;Ruslan likes coffee.&quot;<p>It remembers principles we&#x27;ve agreed on (e.g., &quot;I have a tendency to over-engineer,&quot; &quot;My goal is freedom, not just revenue&quot;).<p>It proactively uses this context to check me. If I say &quot;I&#x27;m going to build X,&quot; it might say, &quot;Wait, last week we agreed that X is a distraction from your main goal. What changed?&quot;<p>The Tech:<p>Memory Architecture: Instead of raw RAG, it uses a structured memory system (Insights, Patterns, Decisions) that acts as a long-term operating system for my brain.<p>Psychotherapeutic Inquiry: It\u2019s prompted not to give advice (unless asked), but to ask the &quot;one question&quot; that peels back a layer. It helps me find the root cause, rather than just patching symptoms.<p>Deep Context: It holds the &quot;full picture&quot; of my life, business, health, relationships, because they are all interconnected. A fight at home affects my deployment; a failed deployment affects my sleep. Partner sees the whole system.<p>Why I built it: I built this to save myself. I needed a co-founder who doesn&#x27;t sleep, doesn&#x27;t judge, and remembers every lesson I&#x27;ve learned so I don&#x27;t have to learn them twice. It has helped me navigate burnout, fix my sleep schedule, and make harder business decisions.<p>It\u2019s currently in beta. It\u2019s not cheap (because high-context AI isn&#x27;t cheap), but if you\u2019re a lonely founder trying to keep your head straight, it might be for you.<p>I\u2019d love to hear your feedback.<p><a href=\"https:&#x2F;&#x2F;getpartner.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;getpartner.ai</a>", "author": "ianberdin", "timestamp": "2026-01-17T09:22:45+00:00", "score": 1, "num_comments": 0, "products": ["claude", "chatgpt"], "categories": ["error_messages", "navigation"], "sentiment": null, "collected_at": "2026-01-17T17:09:45.513122+00:00", "processed": false}
{"id": "hn_comment_46658687", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46658687", "title": "Re: Office app has changed to copilot and now I can't ...", "text": "Did you remember to say please and thank you to copilot....&#x2F;s<p>For a single user error, pbkac.", "author": "fortranfiend", "timestamp": "2026-01-17T15:16:10+00:00", "score": null, "num_comments": null, "products": ["copilot"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:46.573669+00:00", "processed": false}
{"id": "hn_story_46655529", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46655529", "title": "Show HN: Use Claude CLI to analyze its own protocol", "text": "Claude CLI is not just a widely used vibe coding tool, but also the engine powering pretty much every client side tools Anthropic made available, sdk, Claude Cowork, you name it.<p>Claude CLI exposes a JSON&#x2F;RPC interface over stdio&#x2F;stdout. But the protocol is largely undocumented. Fortunately, the python sdk is open source.<p>By asking Claude to write code to exercise the SDK and capture the messages, we can establish a much better understanding of the protocol.<p>So here comes this repo <a href=\"https:&#x2F;&#x2F;github.com&#x2F;mzhaom&#x2F;claude-cli-protocol\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;mzhaom&#x2F;claude-cli-protocol</a><p>With that, I hope efforts like building the SDK in a new language, creating another UI for Claude CLI becomes much easier.<p>Feedback and PRs are welcome!", "author": "keytalker", "timestamp": "2026-01-17T05:21:19+00:00", "score": 2, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:52.827207+00:00", "processed": false}
{"id": "hn_comment_46655429", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46655429", "title": "Re: Show HN: CodeSyncer \u2013 Store AI coding context in c...", "text": "Hey HN,<p>I built this after getting frustrated with Claude Code forgetting everything between sessions.<p>*The problem:* Every new session, AI has no memory. You end up re-explaining architecture, past decisions, why you chose X over Y. Gets old fast.<p>*What CodeSyncer does:* Records AI decisions as comment tags directly in your code.<p>```typescript\n&#x2F;&#x2F; @codesyncer-decision [2026-01-15] Chose sync over async (UX feedback)\n&#x2F;&#x2F; @codesyncer-inference Min $1 (Stripe policy)\nasync function processPayment(amount: number) { ... }\n```<p>Next session, AI reads the code and instantly knows the context. No re-explaining.<p>*Setup:*\n```bash\nnpx codesyncer init\nnpx codesyncer watch\n```<p>*Why not just use CLAUDE.md?*\nCLAUDE.md is great for rules (&quot;use TypeScript strict mode&quot;). But it doesn&#x27;t capture <i>why</i> specific code was written a certain way. CodeSyncer stores that context where it belongs\u2014in the code itself.<p>*Similar project:* Steve Yegge&#x27;s Gas Town (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;steveyegge&#x2F;gastown\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;steveyegge&#x2F;gastown</a>) solves this for teams with 20-30 agents. CodeSyncer is the solo developer version\u2014simpler, 5-min setup.<p>Would love feedback, especially:\n- Does this solve a real problem for you?\n- What&#x27;s missing?\n- Any concerns with the approach?", "author": "bitjaru0402", "timestamp": "2026-01-17T05:07:24+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:54.012707+00:00", "processed": false}
{"id": "hn_story_46655389", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46655389", "title": "Open Claude Cowork Compatible with Any LLM API on Win/Linux/macOS", "text": "", "author": "agi-hub", "timestamp": "2026-01-17T05:00:22+00:00", "score": 1, "num_comments": 0, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:54.416699+00:00", "processed": false}
{"id": "hn_comment_46655222", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46655222", "title": "Re: My Week with OpenCode...", "text": "&gt; you can already see this with AWS, NVIDIA and Microsoft beginning to suffer the early stages of LLM blight in their outputs. Things break, they&#x27;re inefficient and they don&#x27;t work as expected.\nI don&#x27;t think it&#x27;s possible to identify those things as caused by LLMs. Microsoft has been producing inefficient code for many years.<p>Also, why didn&#x27;t they try out Claude Code? It&#x27;s the leader in the space and the pro plan isn&#x27;t too expensive to try out for 1 month. Other than that I agree with most of what was been written. Especially about the tendency to write a lot of code that isn&#x27;t highly efficient and the tendency to go off the rails.", "author": "kristianp", "timestamp": "2026-01-17T04:25:51+00:00", "score": null, "num_comments": null, "products": ["claude"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:54.927799+00:00", "processed": false}
{"id": "hn_comment_46656087", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46656087", "title": "Re: A Calif. teen trusted ChatGPT's drug advice. He di...", "text": "&gt; Asked about \u201cthe pros\u201d of ChatGPT by Jimmy Fallon on a December episode of \u201cThe Tonight Show,\u201d Altman talked effusively about the tool\u2019s use for health care. \u201cThe number of people that reach out to us and are like, \u2018I had this crazy health condition. I couldn\u2019t figure out what was going on. I just put my symptoms into ChatGPT, and it told me what test to ask the doctor for, and I got it and now I\u2019m cured.\u2019\u201d<p>I&#x27;ve always believed, don&#x27;t blame the tool for the user, but can&#x27;t help but feel the sellers are a little complicit here. That statement was no accident. It was carefully conceived to be part of discourse and set the narrative on how people are using AI.<p>It&#x27;s understandable that they want to tout their tool&#x27;s intelligence over imitation, so expecting them to go out of their way to warn people about flaws may be asking too much. But the least thing to do is simply refrain from dangerous topics and let people decide for themselves. To actively influence perception and set the tone on these topics when you know the what ramifications will be, is deeply disappointing.", "author": "potamic", "timestamp": "2026-01-17T07:38:23+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["tone"], "sentiment": null, "collected_at": "2026-01-17T17:09:55.444391+00:00", "processed": false}
{"id": "hn_comment_46655486", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46655486", "title": "Re: A Calif. teen trusted ChatGPT's drug advice. He di...", "text": "This brings to mind some of the \u201cdarker\u201d subreddits that circle around drug abuse. I\u2019m sure there are some terrible stories about young people going down tragic paths due to information they found on those subreddits, or even worse, encouragement. There\u2019s even the commonly-discussed account that (allegedly) documented their first experiences with heroin, and then the hole of despair they fell into shortly afterwards due to addiction.<p>But the question here is one of liability. Is Reddit liable for the content available on its website, if that content encourages young impressionable people to abuse drugs irresponsibly? Is ChatGPT liable for the content available through its web interface? Is anyone liable for anything anymore in a post-AI world?", "author": "datsci_est_2015", "timestamp": "2026-01-17T05:15:01+00:00", "score": null, "num_comments": null, "products": ["chatgpt"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:09:55.703677+00:00", "processed": false}
{"id": "hn_story_46654697", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46654697", "title": "Show HN: Explain Yourself \u2013 An AI party game app built with SwiftUI", "text": "Hi HN,<p>I just released &quot;Explain Yourself,&quot; a local multiplayer party game (Jackbox style) where players have to give excuses for absurd AI-generated scenarios. An AI Judge then ranks the answers, roasts the players, and determines a winner.<p>I built this because I wanted an AI-first party app game that was fun and made people use their brains. This is my first app, but I have spent months on it and it is pretty thoroughly thought out.<p>The Stack:<p>Frontend: \nSwiftUI (using NavigationStack and EnvironmentObjects for state).<p>Backend: \nFirebase (Firestore for real-time syncing, Cloud Functions for the game logic).\nAI: Gemini API (via Cloud Functions) for both generating scenarios and the &quot;Judge&quot; persona.\nThe Technical Challenges:<p>Prompt Engineering: \nTuning the &quot;Judge&quot; to be fun and a bit savage was a fun part. I also expected Gemini (which  I ended up choosing for simplicity over other AIs) to not respond to many of the players answers if completely inappropriate, but it always does... so far.<p>The judge analyzes the answers and decided which was the most logical with a bit of creativity. The game scores 90% of one and 10% on the other to determine the ranking.<p>Monetization:\nIt\u2019s free to play with a daily limit&#x2F;starter rounds. I hate ads, so I limited them strictly to &quot;watch to earn&quot; if you run out of credits, plus a standard IAP model for specific question packs. I wonder if starting out I should simply give out everything for free though, leaving only a couple of things like the custom categories as the locked IAP part. Would love some insight on that if you got any.<p>I\u2019d love feedback on the latency of the app in general, the quality of the AI responses, and the IAP model most of all. Means the world. Thank you in advance.<p>Link: <a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;app&#x2F;id6748743734\">https:&#x2F;&#x2F;apps.apple.com&#x2F;app&#x2F;id6748743734</a>", "author": "sntedo", "timestamp": "2026-01-17T02:24:03+00:00", "score": 1, "num_comments": 2, "products": ["gemini"], "categories": ["navigation", "response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:09:59.570771+00:00", "processed": false}
{"id": "hn_comment_46654327", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46654327", "title": "Re: Built the missing GUI for Gemini File Search manag...", "text": "Gemini File Search Manager\nThe missing web-based GUI for managing Google&#x27;s Gemini File Search (RAG) API. Upload documents, configure chunking, add metadata, and test retrieval via an integrated chat playground.<p>Features\nStore Management - Create, list, and delete File Search stores<p>Document Uploads - Drag-and-drop with custom chunking and metadata<p>Async Processing - Real-time status polling for document ingestion<p>RAG Playground - Chat interface with model selection and citation display<p>Metadata Filtering - Filter searches by custom document metadata", "author": "pvr90", "timestamp": "2026-01-17T01:12:04+00:00", "score": null, "num_comments": null, "products": ["gemini"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:10:00.727232+00:00", "processed": false}
{"id": "hn_story_46654288", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46654288", "title": "Ask HN: Has Claude Code changed its usage limits for you?", "text": "I hadn&#x27;t used Claude Code for a couple of weeks, but today when I used it (on Pro Plan) it did a few tasks full of errors and then claimed to hit a rate limit. Normally it will work for at least a feature&#x27;s amount of work in one day, but in this case it mostly caused problems (with very basic tasks) and then ran out of juice before it could fix them. I know they are suffering from demand-supply problems but I don&#x27;t recall comms from them saying you&#x27;re going to get less for your money now?", "author": "laurex", "timestamp": "2026-01-17T01:03:03+00:00", "score": 2, "num_comments": 2, "products": ["claude"], "categories": ["general_ux"], "sentiment": null, "collected_at": "2026-01-17T17:10:00.903093+00:00", "processed": false}
{"id": "hn_story_46654284", "source": "hackernews", "source_url": "https://news.ycombinator.com/item?id=46654284", "title": "Show HN: React hook for Gemini Live API \u2013 real-time voice and screen sharing", "text": "I built a React hook that makes it easy to add real-time AI conversations with screen sharing to any app.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;loffloff&#x2F;gemini-live-react\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;loffloff&#x2F;gemini-live-react</a><p>What it does:                                                                                                                                                    \n- Stream mic audio to Gemini, get voice responses back                                                                                                           \n- Share your screen so AI can see what you&#x27;re doing                                                                                                              \n- Real-time transcripts for both sides                                                                                                                           \n- Tool calling support<p>Just added: useCapturedSurfaceControl hook for Chrome 124+ that lets you programmatically scroll&#x2F;zoom a captured tab without injecting scripts.<p>Built this for deflectionrate.com (AI support that resolves issues before they become tickets), extracted the core into this package.<p>npm install gemini-live-react<p>Happy to answer questions.<p>Want me to tweak anything?", "author": "loffloff", "timestamp": "2026-01-17T01:02:26+00:00", "score": 1, "num_comments": 0, "products": ["gemini"], "categories": ["response_quality"], "sentiment": null, "collected_at": "2026-01-17T17:10:01.298807+00:00", "processed": false}
